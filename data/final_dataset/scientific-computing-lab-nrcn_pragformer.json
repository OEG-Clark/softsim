{"home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.__init__": [[12, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pragma_node", ",", "node", ")", ":", "\n", "        ", "self", ".", "pragma", "=", "pragma_node", "\n", "self", ".", "for_node", "=", "node", "\n", "self", ".", "inner_nodes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.set_inner_nodes": [[17, 19], ["None"], "methods", ["None"], ["", "def", "set_inner_nodes", "(", "self", ",", "inner", ")", ":", "\n", "        ", "self", ".", "inner_nodes", "=", "inner", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.has_openmp": [[20, 25], ["None"], "methods", ["None"], ["", "def", "has_openmp", "(", "self", ")", ":", "\n", "        ", "coord", "=", "\"%s\"", "%", "self", ".", "pragma", ".", "coord", "\n", "if", "coord", "==", "\"None\"", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.get_string_data": [[26, 33], ["pycparser.c_generator.CGenerator", "pycparser.c_generator.CGenerator.visit", "pycparser.c_generator.CGenerator.visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "def", "get_string_data", "(", "self", ")", ":", "\n", "        ", "generator", "=", "c_generator", ".", "CGenerator", "(", ")", "\n", "code_data", "=", "generator", ".", "visit", "(", "self", ".", "for_node", ")", "\n", "for", "n", "in", "self", ".", "inner_nodes", ":", "\n", "            ", "code_data", "=", "code_data", "+", "\"\\n\"", "+", "generator", ".", "visit", "(", "n", ")", "\n", "\n", "", "return", "self", ".", "pragma", ".", "string", ",", "code_data", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.get_coord": [[34, 39], ["None"], "methods", ["None"], ["", "def", "get_coord", "(", "self", ")", ":", "\n", "        ", "coord", "=", "\"%s\"", "%", "self", ".", "pragma", ".", "coord", "\n", "if", "coord", "==", "\"None\"", ":", "\n", "            ", "coord", "=", "\"%s\"", "%", "self", ".", "for_node", ".", "coord", "\n", "", "return", "coord", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.__init__": [[47, 51], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "Pragma_str", ",", "for_str", ")", ":", "\n", "        ", "self", ".", "pragma", "=", "Pragma_str", "\n", "self", ".", "for_node", "=", "for_str", "\n", "self", ".", "inner_nodes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.set_inner_nodes": [[52, 57], ["print", "exit"], "methods", ["None"], ["", "def", "set_inner_nodes", "(", "self", ",", "inner", ")", ":", "\n", "# self.inner_nodes = inner", "\n", "        ", "print", "(", "\"TRYING TO SET INNER NODES TO REGULAR PRAGMA - BAD!!\"", ")", "\n", "exit", "(", "1", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.get_string_data": [[58, 61], ["None"], "methods", ["None"], ["", "def", "get_string_data", "(", "self", ")", ":", "\n", "\n", "        ", "return", "self", ".", "pragma", ",", "self", ".", "for_node", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.main.get_project_name": [[21, 28], ["os.listdir", "str", "os.path.basename"], "function", ["None"], ["def", "get_project_name", "(", "folder_path", ":", "os", ".", "path", ",", "file_name", ":", "os", ".", "path", ",", "index", ")", ":", "\n", "    ", "indir", "=", "os", ".", "listdir", "(", "folder_path", ")", "\n", "# if len(indir) > 1:", "\n", "#     print (\"Two projects in one username\", indir, file_name)", "\n", "# exit(1)", "\n", "full_project_name", "=", "os", ".", "path", ".", "basename", "(", "folder_path", ")", "+", "\"_\"", "+", "indir", "[", "0", "]", "+", "\"_\"", "+", "file_name", "+", "\"_\"", "+", "str", "(", "index", ")", "\n", "return", "full_project_name", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.main.create_files": [[30, 56], ["os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "open", "open.close", "os.remove", "os.remove", "os.remove", "os.remove", "open", "open.readlines", "open.close", "int", "print"], "function", ["None"], ["", "def", "create_files", "(", "override", ")", ":", "\n", "    ", "num_pragma", "=", "0", "\n", "if", "override", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "PRAGMA_FILES", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "PRAGMA_FILES", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "f", "=", "open", "(", "gp", ".", "PRAGMA_FILES", ",", "\"r\"", ")", "\n", "num_pragma", "=", "f", ".", "readlines", "(", ")", "\n", "if", "not", "num_pragma", ":", "\n", "                    ", "num_pragma", "=", "0", "\n", "", "else", ":", "\n", "                    ", "num_pragma", "=", "int", "(", "num_pragma", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Hmm\"", ")", "\n", "", "", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "GOOD_FILE", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "GOOD_FILE", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "BAD_FILE", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "BAD_FILE", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "LOG_FILE", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "LOG_FILE", ")", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "gp", ".", "LOG_FILE", ")", ":", "\n", "        ", "f", "=", "open", "(", "gp", ".", "LOG_FILE", ",", "\"w\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "return", "num_pragma", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.main.main": [[58, 143], ["extract_for.FileParser", "database.Database", "main.create_files", "os.listdir", "enumerate", "os.path.join", "files_handler.check_folder_exists_in_log", "print", "files_handler.get_files_from_repo", "print", "print", "print", "os.path.basename", "files_handler.check_openmp_pragma", "main.get_project_name", "database.Database.check_if_repo_exists", "files_handler.prep_file", "extract_for.FileParser.parse", "print", "enumerate", "open", "open.writelines", "open.close", "file.__contains__", "print", "print", "print", "main.get_project_name", "database.Database.check_if_repo_exists", "pragmafor.get_coord", "open", "open.writelines", "open.close", "database.Database.insert", "len", "print", "print", "str", "pragmafor.has_openmp", "pragmafor.get_coord.split"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.main.create_files", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.check_folder_exists_in_log", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.get_files_from_repo", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.check_openmp_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.main.get_project_name", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.check_if_repo_exists", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.prep_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.parse", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.main.get_project_name", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.check_if_repo_exists", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.get_coord", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.insert", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.has_openmp"], ["", "def", "main", "(", "repos_path", ",", "override", ")", ":", "\n", "    ", "parser", "=", "extract_for", ".", "FileParser", "(", ")", "\n", "db", "=", "database", ".", "Database", "(", "gp", ".", "DB_PATH", ",", "gp", ".", "JSON_PATH", ",", "override", "=", "override", ")", "\n", "num_pragma", "=", "create_files", "(", "override", ")", "# The log, the parsed files, the failed files", "\n", "repos", "=", "os", ".", "listdir", "(", "repos_path", ")", "\n", "\n", "\n", "for", "i", ",", "folder", "in", "enumerate", "(", "repos", ")", ":", "\n", "        ", "folder", "=", "os", ".", "path", ".", "join", "(", "repos_path", ",", "folder", ")", "\n", "if", "i", "%", "50", "==", "0", ":", "\n", "            ", "print", "(", "\"################################## FINISHED ANOTHER 50 REPOS #####################################\"", ")", "\n", "print", "(", "\"PROGRESS:\"", ",", "i", "*", "100", "/", "len", "(", "repos", ")", ",", "\"%\"", ")", "\n", "# LOGGER", "\n", "", "if", "check_folder_exists_in_log", "(", "gp", ".", "LOG_FILE", ",", "folder", ")", ":", "# Exists, skip this folder", "\n", "            ", "print", "(", "folder", ",", "\": exists. skipping\"", ")", "\n", "continue", "\n", "", "print", "(", "\"Working on:\"", ",", "folder", ")", "\n", "files_of_project", ",", "header_files", "=", "get_files_from_repo", "(", "folder", ")", "\n", "inserted_file", "=", "True", "\n", "# Notes for this loop:", "\n", "# 1) Unfortently the code first builds the AST and extracts all the directives and only then it checks if it exists in the DB", "\n", "for", "file", "in", "files_of_project", ":", "\n", "            ", "file_name", "=", "os", ".", "path", ".", "basename", "(", "file", ")", "\n", "\n", "################### LOGIC OF \"DO WE WANT TO PARSE THIS FILE?\" ##################", "\n", "found", "=", "False", "\n", "for", "f", "in", "gp", ".", "EXCLUDE_FOLDERS", ":", "\n", "                ", "if", "file", ".", "__contains__", "(", "f", ")", ":", "\n", "                    ", "found", "=", "True", "\n", "break", "\n", "", "", "if", "file", "in", "gp", ".", "EXCLUDE_FILES", "or", "found", ":", "\n", "                ", "continue", "\n", "", "number_pragmas_parser", "=", "check_openmp_pragma", "(", "file", ")", "\n", "if", "number_pragmas_parser", "<=", "0", ":", "\n", "                ", "print", "(", "\"REEM CHECKER: No pragma found in file: \"", ",", "file", ")", "\n", "continue", "\n", "", "project_name", "=", "get_project_name", "(", "folder", ",", "file_name", ",", "0", ")", "\n", "if", "db", ".", "check_if_repo_exists", "(", "project_name", ")", ":", "\n", "                ", "print", "(", "\"File:\"", ",", "file_name", ",", "\"exists in the project.\"", ")", "\n", "continue", "\n", "################### LOGIC OF \"DO WE WANT TO PARSE THIS FILE?\" ##################", "\n", "\n", "######### C PYTHON PARSER ################", "\n", "", "prep_file", "(", "file", ")", "\n", "list_of_pragmafor", ",", "num_pragmas_cparser", "=", "parser", ".", "parse", "(", "file", ",", "header_files", ")", "# List of PragmaForTuple[0:n]", "\n", "if", "not", "list_of_pragmafor", ":", "\n", "                ", "print", "(", "\"C_AST: No pragma found in file\"", ")", "\n", "\n", "continue", "\n", "######### C PYTHON PARSER ################", "\n", "\n", "", "if", "number_pragmas_parser", "!=", "num_pragmas_cparser", "and", "(", "num_pragmas_cparser", "+", "parser", ".", "pragma_removed", ")", "*", "3", "<", "number_pragmas_parser", ":", "\n", "                ", "if", "file", "not", "in", "NESTED_FILES", ":", "\n", "                    ", "print", "(", "file", ",", "\": incosistency with number of pragmas parsed\"", ",", "num_pragmas_cparser", ",", "\"vs:\"", ",", "number_pragmas_parser", ")", "\n", "# exit(1)", "\n", "inserted_file", "=", "False", "\n", "continue", "\n", "", "", "print", "(", "\"Adding: \"", ",", "num_pragmas_cparser", ",", "\" directives\"", ",", "\"out of:\"", ",", "number_pragmas_parser", ")", "\n", "num_pragma", "=", "num_pragma", "+", "num_pragmas_cparser", "\n", "\n", "# print (\"Found: \", len(list_of_pragmafor), \" OpenMP directives\")", "\n", "for", "i", ",", "pragmafor", "in", "enumerate", "(", "list_of_pragmafor", ")", ":", "\n", "                ", "if", "i", ">", "100", ":", "\n", "                    ", "if", "not", "pragmafor", ".", "has_openmp", "(", ")", ":", "\n", "                        ", "continue", "\n", "", "", "project_name", "=", "get_project_name", "(", "folder", ",", "file_name", ",", "i", ")", "\n", "if", "db", ".", "check_if_repo_exists", "(", "project_name", ")", ":", "\n", "                    ", "continue", "\n", "# It was found that it parses the .h file and their .c as well, so we need to verify that the loop is from", "\n", "# the same file.. this can be found in coord!", "\n", "", "coord", "=", "pragmafor", ".", "get_coord", "(", ")", "\n", "\n", "rel_coord", "=", "\"\"", ".", "join", "(", "coord", ".", "split", "(", "\":\"", ")", "[", "0", "]", ")", "\n", "if", "file", "!=", "rel_coord", ":", "# Not a pragma and not in file", "\n", "                    ", "print", "(", "\"NOT REAL FILE\"", ")", "\n", "continue", "\n", "", "f", "=", "open", "(", "gp", ".", "PRAGMA_FILES", ",", "\"w\"", ")", "\n", "f", ".", "writelines", "(", "str", "(", "num_pragma", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "db", ".", "insert", "(", "pragmafor", ",", "project_name", ")", "\n", "# We finished working on a folder so we added it to the complete list..", "\n", "", "", "if", "inserted_file", ":", "\n", "            ", "f", "=", "open", "(", "gp", ".", "LOG_FILE", ",", "\"a+\"", ")", "\n", "f", ".", "writelines", "(", "folder", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ReplaceIdsVisitor.__init__": [[23, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "var_prefix", ",", "array_prefix", ",", "struct_prefix", ",", "func_prefix", ")", ":", "\n", "        ", "self", ".", "var_prefix", "=", "var_prefix", "\n", "self", ".", "array_prefix", "=", "array_prefix", "\n", "self", ".", "struct_prefix", "=", "struct_prefix", "\n", "self", ".", "func_prefix", "=", "func_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ReplaceIdsVisitor.visit_ID": [[29, 48], ["enumerate", "enumerate", "enumerate", "enumerate", "print", "exit", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "visit_ID", "(", "self", ",", "node", ")", ":", "\n", "        ", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "array", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "array_prefix", "+", "str", "(", "i", ")", "\n", "return", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "struct", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "struct_prefix", "+", "str", "(", "i", ")", "\n", "return", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "func", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "func_prefix", "+", "str", "(", "i", ")", "\n", "return", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "var", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "var_prefix", "+", "str", "(", "i", ")", "\n", "return", "\n", "", "", "print", "(", "\"Error id\"", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ReplaceIdsVisitor.visit_Decl": [[49, 66], ["enumerate", "enumerate", "enumerate", "enumerate", "visitors.ReplaceIdsVisitor.generic_visit", "visitors.ReplaceIdsVisitor.generic_visit", "visitors.ReplaceIdsVisitor.generic_visit", "visitors.ReplaceIdsVisitor.generic_visit", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "def", "visit_Decl", "(", "self", ",", "node", ")", ":", "\n", "        ", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "array", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "array_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "struct", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "struct_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "func", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "func_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "var", ")", ":", "\n", "            ", "if", "node", ".", "name", "==", "val", ":", "\n", "                ", "node", ".", "name", "=", "self", ".", "var_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "# print(\"Error decl\")", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ReplaceIdsVisitor.visit_TypeDecl": [[69, 89], ["enumerate", "enumerate", "enumerate", "enumerate", "visitors.ReplaceIdsVisitor.generic_visit", "visitors.ReplaceIdsVisitor.generic_visit", "visitors.ReplaceIdsVisitor.generic_visit", "visitors.ReplaceIdsVisitor.generic_visit", "visitors.ReplaceIdsVisitor.generic_visit", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "", "", "def", "visit_TypeDecl", "(", "self", ",", "node", ")", ":", "\n", "# print (node)", "\n", "        ", "if", "not", "node", ".", "declname", ":", "\n", "            ", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "array", ")", ":", "\n", "            ", "if", "node", ".", "declname", "==", "val", ":", "\n", "                ", "node", ".", "declname", "=", "self", ".", "array_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "struct", ")", ":", "\n", "            ", "if", "node", ".", "declname", "==", "val", ":", "\n", "                ", "node", ".", "declname", "=", "self", ".", "struct_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "func", ")", ":", "\n", "            ", "if", "node", ".", "declname", "==", "val", ":", "\n", "                ", "node", ".", "declname", "=", "self", ".", "func_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "var", ")", ":", "\n", "            ", "if", "node", ".", "declname", "==", "val", ":", "\n", "                ", "node", ".", "declname", "=", "self", ".", "var_prefix", "+", "str", "(", "i", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "# print(\"Error type decl\")", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ReplaceIdsVisitor.reset": [[113, 124], ["list", "list", "list", "list", "collections.OrderedDict.fromkeys", "collections.OrderedDict.fromkeys", "collections.OrderedDict.fromkeys", "collections.OrderedDict.fromkeys"], "methods", ["None"], ["", "", "", "def", "reset", "(", "self", ",", "var", ",", "array", ",", "struct", ",", "func", ")", ":", "\n", "# remove duplicates..", "\n", "        ", "self", ".", "var", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "var", ")", ")", "\n", "self", ".", "array", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "array", ")", ")", "\n", "self", ".", "struct", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "struct", ")", ")", "\n", "self", ".", "func", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "func", ")", ")", "\n", "\n", "# now remove from self.var all the names from array struct and func", "\n", "self", ".", "var", "=", "[", "v", "for", "v", "in", "self", ".", "var", "if", "v", "not", "in", "self", ".", "array", "]", "\n", "self", ".", "var", "=", "[", "v", "for", "v", "in", "self", ".", "var", "if", "v", "not", "in", "self", ".", "struct", "]", "\n", "self", ".", "var", "=", "[", "v", "for", "v", "in", "self", ".", "var", "if", "v", "not", "in", "self", ".", "func", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.CounterIdVisitor.__init__": [[128, 130], ["visitors.CounterIdVisitor.reset"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.CounterIdVisitor.visit_ID": [[131, 136], ["visitors.CounterIdVisitor.ids.append"], "methods", ["None"], ["", "def", "visit_ID", "(", "self", ",", "node", ")", ":", "\n", "# print(\"ID:\", node.name)", "\n", "# if node.name != \"i\" and node.name != \"j\":", "\n", "        ", "if", "node", ".", "name", ":", "\n", "            ", "self", ".", "ids", ".", "append", "(", "node", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.CounterIdVisitor.visit_FuncCall": [[137, 145], ["isinstance", "visitors.CounterIdVisitor.func.append", "visitors.CounterIdVisitor.generic_visit", "visitors.CounterIdVisitor.generic_visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "", "def", "visit_FuncCall", "(", "self", ",", "node", ")", ":", "\n", "# print(\"FuncCall:\", node)", "\n", "        ", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "UnaryOp", ")", ":", "\n", "            ", "if", "node", ".", "name", ".", "op", "==", "'*'", ":", "\n", "                ", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "func", ".", "append", "(", "node", ".", "name", ".", "name", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.CounterIdVisitor.visit_ArrayRef": [[146, 186], ["isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "visitors.CounterIdVisitor.generic_visit", "isinstance", "isinstance", "isinstance", "isinstance", "visitors.CounterIdVisitor.generic_visit", "isinstance", "visitors.CounterIdVisitor.array.append", "visitors.CounterIdVisitor.generic_visit", "isinstance", "isinstance", "isinstance", "print", "exit", "visitors.CounterIdVisitor.generic_visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "", "def", "visit_ArrayRef", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "BinaryOp", ")", ":", "\n", "            ", "self", ".", "generic_visit", "(", "node", ")", "\n", "return", "\n", "# CASTING", "\n", "", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "Cast", ")", ":", "\n", "            ", "if", "isinstance", "(", "node", ".", "name", ".", "expr", ",", "c_ast", ".", "ID", ")", "or", "isinstance", "(", "node", ".", "name", ".", "expr", ",", "c_ast", ".", "ArrayRef", ")", ":", "\n", "                ", "name", "=", "node", ".", "name", ".", "expr", ".", "name", "\n", "", "if", "isinstance", "(", "node", ".", "name", ".", "expr", ",", "c_ast", ".", "StructRef", ")", ":", "\n", "                ", "name", "=", "node", ".", "name", ".", "expr", ".", "field", "\n", "", "if", "isinstance", "(", "node", ".", "name", ".", "expr", ",", "c_ast", ".", "UnaryOp", ")", ":", "\n", "                ", "if", "isinstance", "(", "node", ".", "name", ".", "expr", ".", "expr", ",", "c_ast", ".", "ArrayRef", ")", ":", "\n", "                    ", "self", ".", "generic_visit", "(", "node", ")", "\n", "return", "\n", "", "name", "=", "node", ".", "name", ".", "expr", ".", "expr", ".", "name", "\n", "# ARRAY OF STRUCT", "\n", "", "", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "StructRef", ")", ":", "\n", "            ", "name", "=", "node", ".", "name", ".", "field", "\n", "# NORMAL", "\n", "", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "ID", ")", ":", "\n", "            ", "name", "=", "node", ".", "name", ".", "name", "\n", "# UNARY OP WHICH IS BASICALLY CAST TO STRUCT..", "\n", "", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "UnaryOp", ")", ":", "\n", "            ", "if", "isinstance", "(", "node", ".", "name", ".", "expr", ",", "c_ast", ".", "StructRef", ")", ":", "\n", "                ", "name", "=", "node", ".", "name", ".", "expr", ".", "field", "\n", "", "if", "isinstance", "(", "node", ".", "name", ".", "expr", ",", "c_ast", ".", "ID", ")", ":", "\n", "                ", "name", "=", "node", ".", "name", ".", "expr", ".", "name", "\n", "", "", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "ArrayRef", ")", ":", "\n", "# if it is an array of arrays (2d array etc, we will just continue to the next expr..)", "\n", "            ", "self", ".", "generic_visit", "(", "node", ")", "\n", "return", "\n", "# print (node.name)", "\n", "", "try", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "c_ast", ".", "ID", ")", ":", "\n", "                ", "name", "=", "name", ".", "name", "\n", "", "self", ".", "array", ".", "append", "(", "name", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "node", ".", "name", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.CounterIdVisitor.visit_ArrayDecl": [[187, 203], ["isinstance", "isinstance", "isinstance", "visitors.CounterIdVisitor.generic_visit", "visitors.CounterIdVisitor.array.append", "visitors.CounterIdVisitor.generic_visit", "print", "exit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "", "def", "visit_ArrayDecl", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "isinstance", "(", "node", ".", "type", ",", "c_ast", ".", "PtrDecl", ")", ":", "\n", "            ", "name", "=", "node", ".", "type", ".", "type", ".", "declname", "\n", "", "if", "isinstance", "(", "node", ".", "type", ",", "c_ast", ".", "TypeDecl", ")", ":", "\n", "            ", "name", "=", "node", ".", "type", ".", "declname", "\n", "", "if", "isinstance", "(", "node", ".", "type", ",", "c_ast", ".", "ArrayDecl", ")", ":", "\n", "# if it is an array of arrays (2d array etc, we will just continue to the next expr..)", "\n", "            ", "self", ".", "generic_visit", "(", "node", ")", "\n", "return", "\n", "# print (node.name)", "\n", "", "try", ":", "\n", "            ", "self", ".", "array", ".", "append", "(", "name", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "node", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.CounterIdVisitor.visit_StructRef": [[204, 209], ["isinstance", "visitors.CounterIdVisitor.generic_visit", "visitors.CounterIdVisitor.struct.append"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "", "def", "visit_StructRef", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "isinstance", "(", "node", ".", "name", ",", "c_ast", ".", "ID", ")", ":", "\n", "            ", "name", "=", "node", ".", "name", ".", "name", "\n", "self", ".", "struct", ".", "append", "(", "name", ")", "\n", "", "self", ".", "generic_visit", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.CounterIdVisitor.reset": [[210, 215], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "ids", "=", "[", "]", "\n", "self", ".", "func", "=", "[", "]", "\n", "self", ".", "array", "=", "[", "]", "\n", "self", ".", "struct", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.LengthVisitor.__init__": [[218, 221], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "max_len", "=", "0", "\n", "self", ".", "curr_len", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.LengthVisitor.generic_visit": [[222, 229], ["visitors.LengthVisitor.visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "def", "generic_visit", "(", "self", ",", "node", ")", ":", "\n", "        ", "\"\"\" Called if no explicit visitor function exists for a\n            node. Implements preorder visiting of the node.\n        \"\"\"", "\n", "self", ".", "curr_len", "=", "self", ".", "curr_len", "+", "1", "\n", "for", "c", "in", "node", ":", "\n", "            ", "self", ".", "visit", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForVisitor.__init__": [[232, 236], ["pycparser.c_generator.CGenerator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "out_for_loop_found", "=", "True", "\n", "self", ".", "generator", "=", "c_generator", ".", "CGenerator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForVisitor.visit_For": [[237, 239], ["visitors.ForVisitor.nodes.append"], "methods", ["None"], ["", "def", "visit_For", "(", "self", ",", "node", ")", ":", "\n", "        ", "self", ".", "nodes", ".", "append", "(", "node", ")", "\n", "#  (\"FOUND A FOR\")", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForVisitor.generic_visit": [[245, 252], ["visitors.ForVisitor.visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "def", "generic_visit", "(", "self", ",", "node", ")", ":", "\n", "        ", "\"\"\" Called if no explicit visitor function exists for a\n            node. Implements preorder visiting of the node.\n        \"\"\"", "\n", "self", ".", "found", "=", "False", "\n", "for", "c", "in", "node", ":", "\n", "            ", "self", ".", "visit", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.__init__": [[259, 261], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "found", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset": [[262, 264], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "found", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.visit_Pragma": [[265, 270], ["visitors.ForLoopChecker.generic_visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "def", "visit_Pragma", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "\"omp\"", "in", "node", ".", "string", "and", "(", "\"atomic\"", "in", "node", ".", "string", "or", "\"barri\"", "in", "node", ".", "string", "or", "\"critical\"", "in", "node", ".", "string", ")", ":", "\n", "            ", "self", ".", "found", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "generic_visit", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.__init__": [[274, 278], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "pragmas", "=", "[", "]", "\n", "self", ".", "found", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.visit_For": [[279, 285], ["visitors.PragmaForVisitor.nodes.append", "visitors.PragmaForVisitor.generic_visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "def", "visit_For", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "self", ".", "found", ":", "\n", "            ", "self", ".", "nodes", ".", "append", "(", "node", ")", "\n", "self", ".", "found", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "generic_visit", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.visit_Pragma": [[286, 290], ["visitors.PragmaForVisitor.pragmas.append"], "methods", ["None"], ["", "", "def", "visit_Pragma", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "\"parallel\"", "in", "node", ".", "string", "and", "\"for\"", "in", "node", ".", "string", "and", "\"omp\"", "in", "node", ".", "string", ":", "\n", "            ", "self", ".", "pragmas", ".", "append", "(", "node", ")", "\n", "self", ".", "found", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit": [[291, 298], ["visitors.PragmaForVisitor.visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "", "def", "generic_visit", "(", "self", ",", "node", ")", ":", "\n", "        ", "\"\"\" Called if no explicit visitor function exists for a\n            node. Implements preorder visiting of the node.\n        \"\"\"", "\n", "self", ".", "found", "=", "False", "\n", "for", "c", "in", "node", ":", "\n", "            ", "self", ".", "visit", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.FuncDefVisitor.__init__": [[302, 305], ["pycparser.c_generator.CGenerator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "func_def", "=", "[", "]", "\n", "self", ".", "generator", "=", "c_generator", ".", "CGenerator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.FuncDefVisitor.visit_FuncDef": [[306, 309], ["isinstance", "visitors.FuncDefVisitor.func_def.append"], "methods", ["None"], ["", "def", "visit_FuncDef", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "isinstance", "(", "node", ",", "c_ast", ".", "FuncDef", ")", ":", "\n", "            ", "self", ".", "func_def", ".", "append", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.__init__": [[313, 317], ["pycparser.c_generator.CGenerator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "func_calls", "=", "[", "]", "\n", "self", ".", "c_gen", "=", "c_generator", ".", "CGenerator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit_FuncCall": [[322, 325], ["visitors.Visitor.func_calls.append", "visitors.Visitor.generic_visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.PragmaForVisitor.generic_visit"], ["", "def", "visit_FuncCall", "(", "self", ",", "node", ")", ":", "\n", "        ", "self", ".", "func_calls", ".", "append", "(", "node", ")", "\n", "self", ".", "generic_visit", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit": [[326, 340], ["visitors.Visitor._method_cache.get", "getattr.", "getattr"], "methods", ["None"], ["", "def", "visit", "(", "self", ",", "node", ")", ":", "\n", "        ", "\"\"\" Visit a node.\n        \"\"\"", "\n", "\n", "if", "self", ".", "_method_cache", "is", "None", ":", "\n", "            ", "self", ".", "_method_cache", "=", "{", "}", "\n", "\n", "", "visitor", "=", "self", ".", "_method_cache", ".", "get", "(", "node", ".", "__class__", ".", "__name__", ",", "None", ")", "\n", "if", "visitor", "is", "None", ":", "\n", "            ", "method", "=", "'visit_'", "+", "node", ".", "__class__", ".", "__name__", "\n", "visitor", "=", "getattr", "(", "self", ",", "method", ",", "self", ".", "generic_visit", ")", "\n", "self", ".", "_method_cache", "[", "node", ".", "__class__", ".", "__name__", "]", "=", "visitor", "\n", "# print (type(node))", "\n", "", "return", "visitor", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.get_length_ast": [[12, 19], ["max", "len", "lengther.append", "node.children", "visitors.get_length_ast"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.get_length_ast"], ["def", "get_length_ast", "(", "node", ")", ":", "\n", "    ", "if", "not", "len", "(", "node", ".", "children", "(", ")", ")", ":", "\n", "        ", "return", "1", "\n", "", "lengther", "=", "[", "]", "\n", "for", "c", "in", "node", ":", "\n", "        ", "lengther", ".", "append", "(", "get_length_ast", "(", "c", ")", "+", "1", ")", "\n", "", "return", "max", "(", "lengther", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.__init__": [[14, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "pragma_removed", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.parse": [[17, 142], ["print", "c_generator.CGenerator", "FuncDefVisitor", "FuncDefVisitor.visit", "PragmaForVisitor", "PragmaForVisitor.visit", "ForLoopChecker", "range", "range", "enumerate", "len", "cpp_args.append", "parse_file", "open", "open.writelines", "open.close", "len", "ForLoopChecker.reset", "ForLoopChecker.visit", "PragmaForVisitor", "ForVisitor", "ForVisitor.visit", "extract_for.FileParser.extract_nodes_inside_for_loop", "pragma_for_tuple[].set_inner_nodes", "enumerate", "print", "print", "open", "open.writelines", "open.close", "remove_for.append", "remove_pragma.append", "print", "for_nodes_without_openmp.append", "len", "print", "open", "open.writelines", "open.close", "len", "len", "len", "len", "len", "ForPragmaExtractor.global_parameters.PragmaForTuple", "extract_for.FileParser.extract_nodes_inside_for_loop", "pragma_for_tuple[].set_inner_nodes", "PragmaForVisitor.visit", "len", "len", "ForPragmaExtractor.global_parameters.PragmaForTuple", "len", "len", "c_ast.Pragma"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.extract_nodes_inside_for_loop", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.set_inner_nodes", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.extract_nodes_inside_for_loop", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.set_inner_nodes", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "def", "parse", "(", "self", ",", "file", ":", "os", ".", "path", ",", "headers", ":", "list", ")", ":", "\n", "        ", "self", ".", "pragma_removed", "=", "0", "\n", "print", "(", "\"parsing file:\"", ",", "file", ")", "\n", "# cpp_args = ['-E', r'-Iutils/fake_libc_include']", "\n", "cpp_args", "=", "[", "'-nostdinc'", ",", "'-E'", ",", "r'-I'", "+", "FAKE_HEADER_PATH", "]", "\n", "\n", "for", "header_file", "in", "headers", ":", "\n", "            ", "cpp_args", ".", "append", "(", "r'-I'", "+", "header_file", ")", "\n", "", "try", ":", "\n", "            ", "ast", "=", "parse_file", "(", "file", ",", "use_cpp", "=", "True", ",", "cpp_path", "=", "'mpicc'", ",", "cpp_args", "=", "cpp_args", ")", "\n", "f", "=", "open", "(", "GOOD_FILE", ",", "\"a+\"", ")", "\n", "f", ".", "writelines", "(", "file", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"FAILED TO PARSE!!!!!!\"", ")", "\n", "print", "(", "e", ")", "\n", "# print(\"Command:\", cpp_args)", "\n", "\n", "f", "=", "open", "(", "BAD_FILE", ",", "\"a+\"", ")", "\n", "f", ".", "writelines", "(", "\"@extract_for.py:\"", "+", "file", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "None", ",", "None", "\n", "\n", "\n", "# General description of the algorithm:", "\n", "# 1. Get all for loops that contain a pragma with \"for\" and \"parallel\" in them.", "\n", "# 2. Remove from that list all for loops with a pragma of a barriar or atomic - this is usually a bad openmp case..", "\n", "# 3. Get all the for-loops without openmp directives (this is done by searching all for loops that do not contain a pragma with \"for\" or \"parallel\" in them", "\n", "# 4. Find all the function calls inside the two for-loop list (with openmp and without openmp)", "\n", "# 5. return a list of PragmaFor tuples that contain the for node and the pragma node (if without openmp then it is none)", "\n", "", "generator", "=", "c_generator", ".", "CGenerator", "(", ")", "\n", "# for n in relevant_nodes:", "\n", "# print(generator.visit(ast))", "\n", "# We get all function defenitions for later use", "\n", "fdv", "=", "FuncDefVisitor", "(", ")", "\n", "fdv", ".", "visit", "(", "ast", ")", "\n", "func_list", "=", "fdv", ".", "func_def", "\n", "\n", "# We first prep the for and pragma tuples then we get the for loops without openmp", "\n", "\n", "################################# FOR LOOPS WITH OPENMP: #################################", "\n", "\n", "# Exctract all loops with a pragma above them", "\n", "pfv", "=", "PragmaForVisitor", "(", ")", "# Should hold all the for loops nodes  that contain a pragma above them", "\n", "pfv", ".", "visit", "(", "ast", ")", "# Get the most outer for loops", "\n", "for_loops_with_openmp", "=", "pfv", ".", "nodes", "\n", "openmp_directives", "=", "pfv", ".", "pragmas", "\n", "# We now found all nodes that contain a pragma and afterwards a for loop", "\n", "# But what happends when it is a for loop with an atomic or barriar inside of it?", "\n", "# This is usually a bad directive, so we want to remove them from the for_loops_with_openmp list", "\n", "verify_loops", "=", "ForLoopChecker", "(", ")", "\n", "remove_for", "=", "[", "]", "\n", "remove_pragma", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "for_loops_with_openmp", ")", ")", ":", "\n", "            ", "verify_loops", ".", "reset", "(", ")", "\n", "verify_loops", ".", "visit", "(", "for_loops_with_openmp", "[", "i", "]", ")", "\n", "if", "verify_loops", ".", "found", ":", "# we found barriar or atomic inside the loop", "\n", "                ", "remove_for", ".", "append", "(", "for_loops_with_openmp", "[", "i", "]", ")", "\n", "remove_pragma", ".", "append", "(", "openmp_directives", "[", "i", "]", ")", "\n", "self", ".", "pragma_removed", "=", "self", ".", "pragma_removed", "+", "1", "\n", "print", "(", "\"Removed\"", ")", "\n", "", "", "for_loops_with_openmp", "=", "[", "ele", "for", "ele", "in", "for_loops_with_openmp", "if", "ele", "not", "in", "remove_for", "]", "\n", "openmp_directives", "=", "[", "ele", "for", "ele", "in", "openmp_directives", "if", "ele", "not", "in", "remove_pragma", "]", "\n", "####################################################### END OF FOR LOOPS WITH OPENMP #############33", "\n", "\n", "for_nodes_without_openmp", "=", "[", "]", "\n", "\n", "if", "WITH_NO_PRAGMA", ":", "\n", "            ", "pfv", "=", "PragmaForVisitor", "(", ")", "\n", "############################ FOR LOOPS WITHOUT OPENMP ############################", "\n", "# Now we extract all the outer for loops", "\n", "for_v", "=", "ForVisitor", "(", ")", "\n", "for_v", ".", "visit", "(", "ast", ")", "\n", "all_for_nodes", "=", "for_v", ".", "nodes", "\n", "# Now we should create a list of for loops without", "\n", "for", "for_loop", "in", "all_for_nodes", ":", "\n", "# We want to create a list that contains for loops nodes without OpenMP directives.", "\n", "# Therefore, we first check if the for loop is in the list of the for loops we gathered above.", "\n", "# Of course, the first if is ONLY for the outermost for loop, so we still need to ask the inner for loops...", "\n", "# This is handled in the else case", "\n", "# if the for loop node is in the list of for loops with pragma in them...", "\n", "                ", "if", "for_loop", "in", "for_loops_with_openmp", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "pfv", ".", "found", "=", "False", "\n", "pfv", ".", "visit", "(", "for_loop", ")", "\n", "# The visit of this specific Visitor, is first a pragma, if the following node after the pragma is a for loop", "\n", "# it adds the nodes to some list. In our case, we are searching for the exact opposite case:", "\n", "# given a \"father\" node of a for loop, if it contains a pragma (for one..) do not add it to the list.", "\n", "# So basically, we can use this function to determine if the some for_loop contains a pragma in it.", "\n", "# Of course this is only true given the above if fails.", "\n", "if", "pfv", ".", "pragmas", "!=", "[", "]", ":", "\n", "                        ", "continue", "\n", "# print (\"Found for loop without openmp\", generator.visit(for_loop))", "\n", "", "", "for_nodes_without_openmp", ".", "append", "(", "for_loop", ")", "\n", "", "if", "len", "(", "all_for_nodes", ")", "!=", "len", "(", "for_nodes_without_openmp", ")", "+", "len", "(", "for_loops_with_openmp", ")", ":", "\n", "                ", "print", "(", "\"You Missed a for loop..\"", ")", "\n", "f", "=", "open", "(", "BAD_FILE", ",", "\"a+\"", ")", "\n", "f", ".", "writelines", "(", "file", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "# return None", "\n", "\n", "# We now create a list of PragmaForTuple that contains three parameters, the most outer for loop, the relevant pragma", "\n", "# and later, the nodes inside the for loop", "\n", "\n", "", "", "pragma_for_tuple", "=", "[", "PragmaForTuple", "]", "*", "(", "len", "(", "for_loops_with_openmp", ")", "+", "len", "(", "for_nodes_without_openmp", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "for_loops_with_openmp", ")", "+", "len", "(", "for_nodes_without_openmp", ")", ")", ":", "\n", "            ", "if", "i", "<", "len", "(", "for_loops_with_openmp", ")", ":", "\n", "                ", "pragma_for_tuple", "[", "i", "]", "=", "PragmaForTuple", "(", "openmp_directives", "[", "i", "]", ",", "for_loops_with_openmp", "[", "i", "]", ")", "\n", "", "elif", "WITH_NO_PRAGMA", ":", "\n", "# add to the pragma for tuple", "\n", "                ", "j", "=", "i", "-", "len", "(", "for_loops_with_openmp", ")", "\n", "pragma_for_tuple", "[", "i", "]", "=", "PragmaForTuple", "(", "c_ast", ".", "Pragma", "(", "\"\"", ")", ",", "for_nodes_without_openmp", "[", "j", "]", ")", "\n", "\n", "# Extract the pragma for loops", "\n", "", "", "for", "i", ",", "n", "in", "enumerate", "(", "for_loops_with_openmp", ")", ":", "\n", "            ", "node", "=", "self", ".", "extract_nodes_inside_for_loop", "(", "n", ",", "func_list", ")", "\n", "pragma_for_tuple", "[", "i", "]", ".", "set_inner_nodes", "(", "node", ")", "# yes intentional", "\n", "", "num_pragmas", "=", "len", "(", "for_loops_with_openmp", ")", "\n", "if", "WITH_NO_PRAGMA", ":", "\n", "            ", "for", "j", ",", "n", "in", "enumerate", "(", "for_nodes_without_openmp", ")", ":", "\n", "                ", "i", "=", "j", "+", "len", "(", "for_loops_with_openmp", ")", "\n", "node", "=", "self", ".", "extract_nodes_inside_for_loop", "(", "n", ",", "func_list", ")", "\n", "pragma_for_tuple", "[", "i", "]", ".", "set_inner_nodes", "(", "node", ")", "# yes intentional", "\n", "", "", "return", "pragma_for_tuple", ",", "num_pragmas", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.extract_nodes_inside_for_loop": [[143, 176], ["c_generator.CGenerator", "Visitor", "Visitor.visit", "relevant_nodes.append"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "def", "extract_nodes_inside_for_loop", "(", "self", ",", "for_loop", ":", "c_ast", ".", "For", ",", "function_list", ":", "list", ")", ":", "\n", "        ", "\"\"\"\n        :param for_loop: A For node, should be under Pragma omp parallel for\n        :param function_list:  the function list of the whole project\n        :return:\n        We create a node list that we will serialize afterwards. Each element in the array will be a node that is connected to\n        the For Loop.\n        For now, the relevant parts are the for loop itself and the function calls!\n        \"\"\"", "\n", "generator", "=", "c_generator", ".", "CGenerator", "(", ")", "\n", "\n", "relevant_nodes", "=", "[", "]", "\n", "v", "=", "Visitor", "(", ")", "\n", "v", ".", "visit", "(", "for_loop", ")", "\n", "func_calls", "=", "v", ".", "func_calls", "\n", "\n", "for", "func_call", "in", "func_calls", ":", "\n", "\n", "# If we have a decleration of this function, we will add it to the relevant node list", "\n", "            ", "try", ":", "\n", "                ", "relevant_nodes", ".", "append", "(", "[", "func_def", "for", "func_def", "in", "function_list", "if", "func_call", ".", "name", ".", "name", "==", "func_def", ".", "decl", ".", "name", "]", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "# print(generator.visit(func_call))", "\n", "# if isinstance(func_call.name, c_ast.FuncDef):", "\n", "#     print(\"Function:\", func_call.name.name, \"Doesn't exist in the project\")", "\n", "# else:", "\n", "#     print(\"Not a function but is in something that we thought is a Function call..\")", "\n", "#     print(generator.visit(func_call))", "\n", "\n", "# for n in relevant_nodes:", "\n", "#     print(generator.visit(n))", "\n", "", "", "return", "relevant_nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.generate_c_from_node": [[177, 181], ["c_generator.CGenerator", "c_generator.CGenerator.visit"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "def", "generate_c_from_node", "(", "self", ",", "node", ")", ":", "\n", "        ", "generator", "=", "c_generator", ".", "CGenerator", "(", ")", "\n", "c_code", "=", "generator", ".", "visit", "(", "node", ")", "\n", "return", "c_code", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.extract_for.FileParser.extract_by_regular_parse": [[182, 199], ["open", "f.readlines", "enumerate", "openmp_contents.append"], "methods", ["None"], ["", "def", "extract_by_regular_parse", "(", "self", ",", "file", ")", ":", "\n", "        ", "openmp_contents", "=", "[", "]", "\n", "number_of_pragmas", "=", "0", "\n", "\n", "with", "open", "(", "file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "found_pragma", "=", "False", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "if", "found_pragma", ":", "\n", "                    ", "openmp_contents", "[", "number_of_pragmas", "]", "[", "j", "]", "=", "line", "\n", "\n", "\n", "\n", "# What if they continue it in the nxt line?", "\n", "", "if", "\"#pragma\"", "in", "line", "and", "\"omp\"", "in", "line", "and", "\"parallel\"", "in", "line", "and", "\"for\"", "in", "line", ":", "\n", "                    ", "found_pragma", "=", "True", "\n", "openmp_contents", ".", "append", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.prep_file": [[19, 35], ["print", "open", "f.readlines", "enumerate", "open", "f.writelines", "line.strip().startswith", "line.strip"], "function", ["None"], ["def", "prep_file", "(", "file", ")", ":", "\n", "    ", "found", "=", "False", "\n", "with", "open", "(", "file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", ".", "startswith", "(", "\"//\"", ")", ":", "\n", "                ", "continue", "\n", "", "if", "\"#include\"", "in", "line", "and", "\"omp.h\"", "in", "line", ":", "\n", "                ", "lines", "[", "i", "]", "=", "\"#include \\\"omp.h\\\"\\n\"", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "", "if", "not", "found", ":", "\n", "        ", "return", "\n", "", "print", "(", "\"EDITING FILE\"", ")", "\n", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "writelines", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.get_files_from_repo": [[37, 46], ["glob.glob", "os.path.dirname", "glob.glob", "header_folders.append", "len"], "function", ["None"], ["", "", "def", "get_files_from_repo", "(", "folder_path", ")", ":", "\n", "    ", "header_files", "=", "glob", ".", "glob", "(", "folder_path", "+", "\"/**/*.h\"", ",", "recursive", "=", "True", ")", "\n", "header_folders", "=", "[", "]", "\n", "max_folders", "=", "100", "\n", "for", "header", "in", "header_files", ":", "\n", "        ", "header_dir", "=", "os", ".", "path", ".", "dirname", "(", "header", ")", "\n", "if", "header_dir", "not", "in", "header_folders", "and", "len", "(", "header_folders", ")", "<", "max_folders", ":", "\n", "            ", "header_folders", ".", "append", "(", "header_dir", ")", "\n", "", "", "return", "glob", ".", "glob", "(", "folder_path", "+", "\"/**/*.c\"", ",", "recursive", "=", "True", ")", ",", "header_folders", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.check_openmp_pragma": [[48, 67], ["open", "open.readlines", "print", "open", "open.writelines", "open.close", "line.strip().startswith", "line.strip"], "function", ["None"], ["", "def", "check_openmp_pragma", "(", "file", ":", "os", ".", "path", ")", ":", "\n", "    ", "num_pragmas", "=", "0", "\n", "try", ":", "\n", "        ", "with", "open", "(", "file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", ".", "startswith", "(", "\"//\"", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "\"#pragma\"", "in", "line", "and", "\"omp\"", "in", "line", "and", "\"parallel\"", "in", "line", "and", "\"for\"", "in", "line", ":", "\n", "                    ", "num_pragmas", "=", "num_pragmas", "+", "1", "\n", "", "if", "\"#pragma\"", "in", "line", "and", "\"omp\"", "in", "line", "and", "(", "\"critical\"", "in", "line", "or", "\"atomic\"", "in", "line", ")", ":", "\n", "                    ", "num_pragmas", "=", "num_pragmas", "-", "1", "\n", "", "", "", "return", "num_pragmas", "\n", "", "except", ":", "\n", "        ", "print", "(", "\"FAILED TO PARSE IN check_openmp_pragma\"", ")", "\n", "f", "=", "open", "(", "BAD_FILE", ",", "\"a+\"", ")", "\n", "f", ".", "writelines", "(", "\"@files_handler.py:\"", "+", "file", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.files_handler.check_folder_exists_in_log": [[69, 78], ["folder.strip.strip", "open", "f.readlines", "line.strip.strip", "os.path.samefile"], "function", ["None"], ["", "", "def", "check_folder_exists_in_log", "(", "log_path", ":", "str", ",", "folder", ":", "str", ")", ":", "\n", "    ", "folder", "=", "folder", ".", "strip", "(", ")", "\n", "with", "open", "(", "log_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "os", ".", "path", ".", "samefile", "(", "line", ",", "folder", ")", ":", "\n", "                ", "return", "True", "\n", "", "", "", "return", "False", "", "", ""]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.__init__": [[10, 32], ["os.path.isdir", "os.mkdir", "os.path.isfile", "os.path.isdir", "os.path.isfile", "print", "print", "open", "print", "json.dump", "shutil.rmtree", "os.remove"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "json_path", ",", "override", "=", "False", ")", ":", "\n", "        ", "if", "override", ":", "\n", "            ", "inp", "=", "'y'", "\n", "if", "inp", "==", "'y'", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "                    ", "shutil", ".", "rmtree", "(", "path", ")", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "json_path", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "json_path", ")", "\n", "", "print", "(", "\"Removing\"", ",", "path", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"You chose no, continue as if not inserted override...\"", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "path", ")", "\n", "", "self", ".", "db_path", "=", "path", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "json_path", ")", ":", "\n", "            ", "with", "open", "(", "json_path", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "dict1", "=", "{", "\"key\"", ":", "1", "}", "\n", "print", "(", "dict1", ")", "\n", "json", ".", "dump", "(", "dict1", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "", "self", ".", "json_path", "=", "json_path", "\n", "self", ".", "override", "=", "override", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.insert": [[33, 75], ["os.path.join", "pragmafor.get_string_data", "pragmafor.get_coord", "database.Database.check_if_repo_exists", "os.mkdir", "os.path.join", "os.path.join", "os.path.join", "pickle.dump", "database.Database._write_json", "database.Database._write_json", "database.Database._write_json", "database.Database._write_json", "database.Database._write_json", "print", "open", "open.writelines", "open.close", "print", "input", "open", "open.writelines", "open.close", "open"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.get_string_data", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTuple.get_coord", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.check_if_repo_exists", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._write_json", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._write_json", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._write_json", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._write_json", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._write_json"], ["", "def", "insert", "(", "self", ",", "pragmafor", ",", "project_name", ",", "id", "=", "0", ")", ":", "\n", "#def insert(self, pragmafor: gp.PragmaForTuple, project_name: str, id=0):", "\n", "\n", "\n", "        ", "folder_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "db_path", ",", "project_name", ")", "\n", "file_data_pragma", ",", "file_data_for_loops", "=", "pragmafor", ".", "get_string_data", "(", ")", "\n", "original_file", "=", "pragmafor", ".", "get_coord", "(", ")", "\n", "if", "self", ".", "check_if_repo_exists", "(", "project_name", ")", ":", "\n", "            ", "print", "(", "\"Folder:\"", ",", "folder_path", ",", "\" exists\"", ")", "\n", "return", "\n", "\n", "# As a part of the database, we create a folder of the project", "\n", "", "os", ".", "mkdir", "(", "folder_path", ")", "\n", "\n", "# Now we copy the pragma.c and code.c that contains the relevant code segments.", "\n", "no_openmp", "=", "os", ".", "path", ".", "join", "(", "folder_path", ",", "gp", ".", "FULL_CODE_NAME", "+", "\".c\"", ")", "\n", "pickle_file", "=", "os", ".", "path", ".", "join", "(", "folder_path", ",", "gp", ".", "PICKLE_CODE_NAME", "+", "\".pkl\"", ")", "\n", "with_openmp", "=", "os", ".", "path", ".", "join", "(", "folder_path", ",", "gp", ".", "OPENMP_CODE_NAME", "+", "\".c\"", ")", "\n", "\n", "# CREATE AND WRITE THE FILES", "\n", "if", "file_data_for_loops", "!=", "\"\"", ":", "\n", "            ", "f", "=", "open", "(", "no_openmp", ",", "\"w\"", ")", "\n", "f", ".", "writelines", "(", "file_data_for_loops", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"NO FOR LOOP DATA\"", ")", "\n", "input", "(", ")", "\n", "no_openmp", "=", "\"\"", "\n", "", "if", "file_data_pragma", "!=", "\"\"", ":", "\n", "            ", "f", "=", "open", "(", "with_openmp", ",", "\"w\"", ")", "\n", "f", ".", "writelines", "(", "file_data_pragma", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "            ", "with_openmp", "=", "\"\"", "\n", "", "pickle", ".", "dump", "(", "pragmafor", ",", "open", "(", "pickle_file", ",", "\"wb\"", ")", ",", "protocol", "=", "2", ")", "\n", "# Now we add project_name to the json (should be the username along with the project name)", "\n", "# And add to the that key, the path to pragma.c and code.c", "\n", "self", ".", "_write_json", "(", "project_name", ",", "gp", ".", "FULL_CODE_NAME", ",", "no_openmp", ")", "\n", "self", ".", "_write_json", "(", "project_name", ",", "gp", ".", "OPENMP_CODE_NAME", ",", "with_openmp", ")", "\n", "self", ".", "_write_json", "(", "project_name", ",", "gp", ".", "PICKLE_CODE_NAME", ",", "pickle_file", ")", "\n", "self", ".", "_write_json", "(", "project_name", ",", "\"original\"", ",", "original_file", ")", "\n", "self", ".", "_write_json", "(", "project_name", ",", "\"id\"", ",", "id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._write_json": [[76, 91], ["open", "json.load", "file.seek", "json.dump"], "methods", ["None"], ["", "def", "_write_json", "(", "self", ",", "proj_name", ",", "key", ",", "new_data", ")", ":", "\n", "        ", "filename", "=", "self", ".", "json_path", "\n", "with", "open", "(", "filename", ",", "'r+'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "# Join new_data with file_data inside emp_details", "\n", "if", "proj_name", "in", "file_data", ":", "\n", "                ", "file_data", "[", "proj_name", "]", "[", "key", "]", "=", "new_data", "\n", "", "else", ":", "\n", "                ", "file_data", "[", "proj_name", "]", "=", "{", "}", "\n", "file_data", "[", "proj_name", "]", "[", "key", "]", "=", "new_data", "\n", "# Sets file's current position at offset.", "\n", "", "file", ".", "seek", "(", "0", ")", "\n", "# convert back to json.", "\n", "json", ".", "dump", "(", "file_data", ",", "file", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._exists_in_json": [[92, 106], ["open", "json.load"], "methods", ["None"], ["", "", "def", "_exists_in_json", "(", "self", ",", "key1", ",", "key2", "=", "\"\"", ")", ":", "\n", "        ", "filename", "=", "self", ".", "json_path", "\n", "with", "open", "(", "filename", ",", "'r+'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "try", ":", "\n", "                ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "if", "key1", "in", "file_data", ":", "\n", "                    ", "if", "not", "key2", ":", "\n", "                        ", "return", "True", "\n", "", "return", "key2", "in", "file_data", "[", "key1", "]", "\n", "", "else", ":", "\n", "                    ", "return", "False", "\n", "", "", "except", ":", "\n", "                ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.check_if_repo_exists": [[107, 111], ["database.Database._exists_in_json", "database.Database._exists_in_json", "database.Database._exists_in_json"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._exists_in_json", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._exists_in_json", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database._exists_in_json"], ["", "", "", "def", "check_if_repo_exists", "(", "self", ",", "project_name", ")", ":", "\n", "        ", "return", "self", ".", "_exists_in_json", "(", "project_name", ")", "and", "self", ".", "_exists_in_json", "(", "project_name", ",", "gp", ".", "FULL_CODE_NAME", ")", "and", "self", ".", "_exists_in_json", "(", "project_name", ",", "gp", ".", "OPENMP_CODE_NAME", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.get_plot_data": [[18, 32], ["open", "f.readlines", "enumerate", "line.split.split", "train_loss.append", "valid_loss.append", "accuracy.append", "epochs.append", "float", "float", "float"], "function", ["None"], ["def", "get_plot_data", "(", "data_path", ")", ":", "\n", "    ", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "train_loss", "=", "[", "]", "\n", "valid_loss", "=", "[", "]", "\n", "accuracy", "=", "[", "]", "\n", "epochs", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "line", "=", "line", ".", "split", "(", ")", "\n", "train_loss", ".", "append", "(", "float", "(", "line", "[", "0", "]", ")", ")", "\n", "valid_loss", ".", "append", "(", "float", "(", "line", "[", "1", "]", ")", ")", "\n", "accuracy", ".", "append", "(", "float", "(", "line", "[", "2", "]", ")", ")", "\n", "epochs", ".", "append", "(", "i", "+", "1", ")", "# + 1 because it starts with 0", "\n", "", "", "return", "epochs", ",", "accuracy", ",", "train_loss", ",", "valid_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.plot_train": [[34, 53], ["statistics.get_plot_data", "matplotlib.subplots", "ax1.set_xlabel", "ax1.set_ylabel", "ax1.plot", "ax1.twinx", "ax1.twinx.set_ylabel", "ax1.twinx.plot", "ax1.twinx.plot", "ax1.legend", "fig.tight_layout", "matplotlib.show", "l.get_label"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.get_plot_data"], ["", "def", "plot_train", "(", "data_path", ")", ":", "\n", "    ", "epochs", ",", "accuracy", ",", "train_loss", ",", "valid_loss", "=", "get_plot_data", "(", "data_path", ")", "\n", "fig", ",", "ax1", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'# Epoch'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'%'", ")", "# we already handled the x-label with ax1", "\n", "lns1", "=", "ax1", ".", "plot", "(", "epochs", ",", "accuracy", ",", "label", "=", "'Accuracy'", ",", "color", "=", "\"red\"", ")", "\n", "# ax1.tick_params(axis = 'y', labelcolor = color)", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "# instantiate a second axes that shares the same x-axis", "\n", "ax2", ".", "set_ylabel", "(", "'Loss'", ")", "\n", "lns2", "=", "ax2", ".", "plot", "(", "epochs", ",", "train_loss", ",", "label", "=", "'Train Loss'", ")", "\n", "lns3", "=", "ax2", ".", "plot", "(", "epochs", ",", "valid_loss", ",", "label", "=", "'Valid Loss'", ")", "\n", "\n", "lns", "=", "lns1", "+", "lns2", "+", "lns3", "\n", "labs", "=", "[", "l", ".", "get_label", "(", ")", "for", "l", "in", "lns", "]", "\n", "ax1", ".", "legend", "(", "lns", ",", "labs", ",", "loc", "=", "0", ")", "\n", "fig", ".", "tight_layout", "(", ")", "# otherw-ise the right y-label is slightly clipped", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.plot_all": [[55, 75], ["matplotlib.style.use", "range", "statistics.plot_loss", "statistics.plot_loss", "statistics.plot_loss", "len", "names.append", "statistics.get_plot_data", "epochs.append", "accuracy.append", "train_loss.append", "valid_loss.append"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.plot_loss", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.plot_loss", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.plot_loss", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.get_plot_data"], ["", "def", "plot_all", "(", "datas", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'/home/reemh/plot_style.txt'", ")", "\n", "LABELS", "=", "[", "\"Text\"", ",", "\"Replaced Text\"", ",", "\"AST\"", ",", "\"Replaced AST\"", "]", "\n", "epochs", "=", "[", "]", "\n", "accuracy", "=", "[", "]", "\n", "train_loss", "=", "[", "]", "\n", "valid_loss", "=", "[", "]", "\n", "names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "datas", ")", ")", ":", "\n", "        ", "names", ".", "append", "(", "LABELS", "[", "i", "]", ")", "\n", "e", ",", "a", ",", "tl", ",", "vl", "=", "get_plot_data", "(", "datas", "[", "i", "]", ")", "\n", "epochs", ".", "append", "(", "e", ")", "\n", "accuracy", ".", "append", "(", "a", ")", "\n", "train_loss", ".", "append", "(", "tl", ")", "\n", "valid_loss", ".", "append", "(", "vl", ")", "\n", "", "clr", "=", "[", "'rs-'", ",", "'gx-'", ",", "'b^-'", ",", "'mo-'", "]", "\n", "\n", "plot_loss", "(", "epochs", ",", "train_loss", ",", "names", ",", "clr", ",", "\"Train Loss\"", ")", "\n", "plot_loss", "(", "epochs", ",", "valid_loss", ",", "names", ",", "clr", ",", "\"Valid Loss\"", ")", "\n", "plot_loss", "(", "epochs", ",", "accuracy", ",", "names", ",", "clr", ",", "\"Accuracy\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.plot_loss": [[77, 87], ["range", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.axvline", "matplotlib.legend", "matplotlib.xlim", "matplotlib.show", "len", "matplotlib.plot"], "function", ["None"], ["", "def", "plot_loss", "(", "epochs", ",", "train_loss", ",", "labels", ",", "clr", ",", "type", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "epochs", ")", ")", ":", "\n", "        ", "plt", ".", "plot", "(", "epochs", "[", "i", "]", ",", "train_loss", "[", "i", "]", ",", "clr", "[", "i", "]", ",", "label", "=", "labels", "[", "i", "]", ")", "\n", "", "plt", ".", "xlabel", "(", "\"# Epochs\"", ")", "\n", "plt", ".", "ylabel", "(", "type", ")", "\n", "plt", ".", "axvline", "(", "x", "=", "9", ",", "color", "=", "'k'", ",", "linestyle", "=", "\"--\"", ",", "linewidth", "=", "1", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlim", "(", "[", "0", ",", "15", "]", ")", "\n", "# plt.xlim([0, 15])", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.create_data_tokenizer": [[89, 135], ["AutoModel.from_pretrained", "deepscc_tokenizer", "deepscc_tokenizer", "deepscc_tokenizer", "numpy.asarray", "dat.flatten.flatten", "numpy.asarray", "dat.flatten.flatten", "numpy.asarray", "dat.flatten.flatten", "len", "enumerate", "print", "enumerate", "print", "enumerate", "print", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "numpy.asarray", "numpy.asarray", "len", "len", "len", "len", "len", "len", "len", "numpy.unique", "numpy.unique", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.tokenizer.deepscc_tokenizer", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.tokenizer.deepscc_tokenizer", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.tokenizer.deepscc_tokenizer"], ["", "def", "create_data_tokenizer", "(", "data", ":", "gp", ".", "Data", ")", ":", "\n", "    ", "model_pretained_name", "=", "\"NTUYG/DeepSCC-RoBERTa\"", "# 'bert-base-uncased'", "\n", "pt_model", "=", "AutoModel", ".", "from_pretrained", "(", "model_pretained_name", ")", "\n", "train", ",", "_", "=", "deepscc_tokenizer", "(", "data", ".", "train", ",", "150", ",", "model_pretained_name", ")", "#maxlen", "\n", "val", ",", "_", "=", "deepscc_tokenizer", "(", "data", ".", "val", ",", "150", ",", "model_pretained_name", ")", "#maxlen", "\n", "test", ",", "_", "=", "deepscc_tokenizer", "(", "data", ".", "test", ",", "150", ",", "model_pretained_name", ")", "\n", "\n", "new_data", "=", "{", "}", "\n", "dat", "=", "np", ".", "asarray", "(", "train", "[", "\"input_ids\"", "]", ")", "\n", "dat", "=", "dat", ".", "flatten", "(", "order", "=", "'C'", ")", "\n", "new_data", "[", "\"train\"", "]", "=", "dat", "\n", "\n", "dat", "=", "np", ".", "asarray", "(", "val", "[", "\"input_ids\"", "]", ")", "\n", "dat", "=", "dat", ".", "flatten", "(", "order", "=", "'C'", ")", "\n", "new_data", "[", "\"valid\"", "]", "=", "dat", "\n", "dat", "=", "np", ".", "asarray", "(", "test", "[", "\"input_ids\"", "]", ")", "\n", "dat", "=", "dat", ".", "flatten", "(", "order", "=", "'C'", ")", "\n", "new_data", "[", "\"test\"", "]", "=", "dat", "\n", "\n", "total_data", "=", "[", "]", "\n", "total_data", "=", "np", ".", "asarray", "(", "train", "[", "\"input_ids\"", "]", ")", "*", "np", ".", "asarray", "(", "train", "[", "\"attention_mask\"", "]", ")", "\n", "total_len", "=", "len", "(", "total_data", ")", "\n", "total_uniqe", "=", "0", "\n", "uniq_tokens", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "total_data", ")", ":", "\n", "        ", "uniq_tokens", "=", "uniq_tokens", "+", "len", "(", "np", ".", "unique", "(", "line", ")", ")", "-", "1", "# for the 0...", "\n", "", "print", "(", "\"NUMBER OF TOKENS IN TRAIN:\"", ",", "uniq_tokens", "/", "len", "(", "total_data", ")", ")", "\n", "total_uniqe", "=", "total_uniqe", "+", "uniq_tokens", "\n", "\n", "uniq_tokens", "=", "0", "\n", "total_data", "=", "np", ".", "asarray", "(", "val", "[", "\"input_ids\"", "]", ")", "*", "np", ".", "asarray", "(", "val", "[", "\"attention_mask\"", "]", ")", "\n", "total_len", "=", "total_len", "+", "len", "(", "total_data", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "total_data", ")", ":", "\n", "        ", "uniq_tokens", "=", "uniq_tokens", "+", "len", "(", "np", ".", "unique", "(", "line", ")", ")", "\n", "", "print", "(", "\"NUMBER OF TOKENS IN VALID:\"", ",", "uniq_tokens", "/", "len", "(", "total_data", ")", ")", "\n", "total_uniqe", "=", "total_uniqe", "+", "uniq_tokens", "\n", "\n", "total_data", "=", "np", ".", "asarray", "(", "test", "[", "\"input_ids\"", "]", ")", "*", "np", ".", "asarray", "(", "test", "[", "\"attention_mask\"", "]", ")", "\n", "total_len", "=", "total_len", "+", "len", "(", "total_data", ")", "\n", "uniq_tokens", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "total_data", ")", ":", "\n", "        ", "uniq_tokens", "=", "uniq_tokens", "+", "len", "(", "np", ".", "unique", "(", "line", ")", ")", "\n", "", "print", "(", "\"NUMBER OF TOKENS IN TEST:\"", ",", "uniq_tokens", "/", "len", "(", "total_data", ")", ")", "\n", "total_uniqe", "=", "total_uniqe", "+", "uniq_tokens", "\n", "\n", "return", "new_data", ",", "total_uniqe", "/", "total_len", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.total_tokens": [[137, 150], ["print", "statistics.get_total_tokens", "range", "len", "print", "print", "data.keys", "numpy.average", "print", "print", "numpy.unique", "len", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.get_total_tokens"], ["", "def", "total_tokens", "(", "tokenized_data", ",", "avg", ")", ":", "\n", "    ", "print", "(", "\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Number Tokens @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"", ")", "\n", "num_tokens", "=", "get_total_tokens", "(", "tokenized_data", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "DATA_PICKLES", ")", ")", ":", "\n", "        ", "data", "=", "tokenized_data", "[", "i", "]", "\n", "print", "(", "\"Case of:\"", ",", "DATA_PICKLES", "[", "i", "]", ")", "\n", "print", "(", "\"Average tokens per line:\"", ",", "avg", "[", "i", "]", ")", "\n", "# Unique tokens in train valid test", "\n", "for", "key", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "print", "(", "\"Number of tokens in {0}: {1}\"", ".", "format", "(", "key", ",", "len", "(", "np", ".", "unique", "(", "data", "[", "key", "]", ")", ")", ")", ")", "\n", "\n", "", "np", ".", "average", "(", "np", ".", "unique", "(", "data", "[", "key", "]", ")", ")", "\n", "print", "(", "\"Total number of tokens:\"", ",", "num_tokens", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.get_total_tokens": [[151, 162], ["range", "len", "tokens.append", "data.keys", "len", "lst.extend", "numpy.unique"], "function", ["None"], ["", "", "def", "get_total_tokens", "(", "tokenized_data", ")", ":", "\n", "    ", "tokens", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "DATA_PICKLES", ")", ")", ":", "\n", "        ", "data", "=", "tokenized_data", "[", "i", "]", "\n", "tokens", ".", "append", "(", "0", ")", "\n", "# Unique tokens in train valid test", "\n", "lst", "=", "[", "]", "\n", "for", "key", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "lst", ".", "extend", "(", "data", "[", "key", "]", ")", "\n", "", "tokens", "[", "i", "]", "=", "len", "(", "np", ".", "unique", "(", "lst", ")", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.histogram_tokens": [[164, 201], ["print", "statistics.get_total_tokens", "range", "print", "len", "print", "print", "data.keys", "print", "data.keys", "print", "matplotlib.hist", "n.max", "n.max", "list", "print", "range", "range", "list", "print", "len", "len", "len", "len", "len", "numpy.unique", "set", "set", "len", "len", "set", "set", "len"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.get_total_tokens"], ["", "def", "histogram_tokens", "(", "tokenized_data", ")", ":", "\n", "    ", "print", "(", "\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Unique Tokens @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"", ")", "\n", "num_tokens", "=", "get_total_tokens", "(", "tokenized_data", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "DATA_PICKLES", ")", ")", ":", "\n", "        ", "data", "=", "tokenized_data", "[", "i", "]", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"Case of:\"", ",", "DATA_PICKLES", "[", "i", "]", ")", "\n", "\n", "# Total tokens:", "\n", "for", "key", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "print", "(", "\"Number of tokens in {0}: {1}\"", ".", "format", "(", "key", ",", "len", "(", "np", ".", "unique", "(", "data", "[", "key", "]", ")", ")", ")", ")", "\n", "", "print", "(", "\"Total number of tokens:\"", ",", "num_tokens", "[", "i", "]", ")", "\n", "# keys are train valid test", "\n", "max_val", "=", "0", "\n", "unique_unique", "=", "data", "[", "\"test\"", "]", "\n", "for", "key", "in", "data", ".", "keys", "(", ")", ":", "\n", "# print(\"Histogram of tokens in {0}\".format(key))", "\n", "\n", "            ", "n", ",", "bins", ",", "patches", "=", "plt", ".", "hist", "(", "x", "=", "data", "[", "key", "]", ",", "bins", "=", "'auto'", ",", "label", "=", "key", ",", "\n", "alpha", "=", "0.7", ")", "\n", "if", "max_val", "<", "n", ".", "max", "(", ")", ":", "\n", "                ", "max_val", "=", "n", ".", "max", "(", ")", "\n", "# Calculate", "\n", "", "if", "key", "!=", "\"test\"", ":", "\n", "                ", "unique_unique", "=", "list", "(", "set", "(", "data", "[", "\"test\"", "]", ")", "-", "set", "(", "data", "[", "key", "]", ")", ")", "\n", "print", "(", "\"Found \"", ",", "len", "(", "unique_unique", ")", ",", "\"token that were in test and not in\"", ",", "key", ")", "\n", "", "if", "key", "==", "\"train\"", ":", "\n", "                ", "data_tot", "=", "[", "None", "]", "*", "(", "len", "(", "data", "[", "\"valid\"", "]", ")", "+", "len", "(", "data", "[", "\"test\"", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", "[", "\"valid\"", "]", ")", ")", ":", "\n", "                    ", "data_tot", "[", "i", "]", "=", "data", "[", "\"valid\"", "]", "[", "i", "]", "\n", "", "for", "i", "in", "range", "(", "len", "(", "data", "[", "\"test\"", "]", ")", ")", ":", "\n", "                    ", "data_tot", "[", "i", "+", "len", "(", "data", "[", "\"valid\"", "]", ")", "]", "=", "data", "[", "\"test\"", "]", "[", "i", "]", "\n", "", "unique_unique", "=", "list", "(", "set", "(", "data_tot", ")", "-", "set", "(", "data", "[", "key", "]", ")", ")", "\n", "print", "(", "\"Out-of-Vocabolary: \"", ",", "len", "(", "unique_unique", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Done @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.histogram_of_num_tokens": [[203, 212], ["range", "len", "print", "data.keys", "uniq_tokens.append", "numpy.unique"], "function", ["None"], ["", "def", "histogram_of_num_tokens", "(", "tokenized_data", ")", ":", "\n", "    ", "uniq_tokens", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "DATA_PICKLES", ")", ")", ":", "\n", "        ", "data", "=", "tokenized_data", "[", "i", "]", "\n", "print", "(", "\"Case of:\"", ",", "DATA_PICKLES", "[", "i", "]", ")", "\n", "\n", "# Unique tokens in train valid test", "\n", "for", "key", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "uniq_tokens", ".", "append", "(", "np", ".", "unique", "(", "data", "[", "key", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.histograms": [[214, 233], ["print", "enumerate", "print", "enumerate", "print", "statistics.total_tokens", "statistics.histogram_tokens", "statistics.create_data_tokenizer", "avg.append", "tokenized_data.append", "open", "datas.append", "pickle.load"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.total_tokens", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.histogram_tokens", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.create_data_tokenizer"], ["", "", "", "def", "histograms", "(", ")", ":", "\n", "    ", "datas", "=", "[", "]", "\n", "avg", "=", "[", "]", "\n", "print", "(", "\"Reading Cute Pickle...\"", ")", "\n", "for", "i", ",", "pkl", "in", "enumerate", "(", "DATA_PICKLES", ")", ":", "\n", "        ", "with", "open", "(", "pkl", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "datas", ".", "append", "(", "pickle", ".", "load", "(", "f", ")", ")", "\n", "\n", "# Tokenize it and put it in a nice dict", "\n", "", "", "print", "(", "\"Tokenizing...\"", ")", "\n", "tokenized_data", "=", "[", "]", "\n", "for", "i", ",", "pkl", "in", "enumerate", "(", "DATA_PICKLES", ")", ":", "\n", "        ", "a", ",", "av", "=", "create_data_tokenizer", "(", "datas", "[", "i", "]", ")", "\n", "avg", ".", "append", "(", "av", ")", "\n", "tokenized_data", ".", "append", "(", "a", ")", "\n", "", "print", "(", "\"Performing data analysis...\"", ")", "\n", "# print the number of tokens", "\n", "total_tokens", "(", "tokenized_data", ",", "avg", ")", "\n", "histogram_tokens", "(", "tokenized_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.statistics.statistics": [[235, 262], ["os.path.join", "print", "enumerate", "len", "open", "json.load", "enumerate", "print", "db_read_string_from_file", "db_read_string_from_file", "enumerate", "print", "is_fake_loop", "len"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.is_fake_loop"], ["", "def", "statistics", "(", "config", ")", ":", "\n", "    ", "path_to_db", "=", "config", "[", "\"data_dir\"", "]", "\n", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "num_pragma", "=", "0", "\n", "DIRECTIVES", "=", "[", "\"reduction\"", ",", "\"private\"", ",", "\"dynamic\"", ",", "\"shared\"", ",", "\"lastprivate\"", ",", "\"firstprivate\"", ",", "\"collapse\"", "]", "\n", "num_occur", "=", "[", "0", "]", "*", "len", "(", "DIRECTIVES", ")", "\n", "total", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "        ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "            ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "is_fake_loop", "(", "code", ")", "and", "pragma", "!=", "\"\"", "or", "pragma", "==", "\"\"", ":", "# code is a full line", "\n", "                ", "continue", "\n", "\n", "", "total", "=", "total", "+", "1", "\n", "for", "i", ",", "clause", "in", "enumerate", "(", "DIRECTIVES", ")", ":", "\n", "                ", "if", "clause", "in", "pragma", ":", "\n", "                    ", "num_occur", "[", "i", "]", "=", "num_occur", "[", "i", "]", "+", "1", "\n", "", "", "", "", "print", "(", "\"Total directives: \"", ",", "total", ")", "\n", "for", "i", ",", "clause", "in", "enumerate", "(", "DIRECTIVES", ")", ":", "\n", "        ", "print", "(", "\"Number of \"", ",", "clause", ",", "\" :\"", ",", "num_occur", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.global_parameters.Data.__init__": [[13, 23], ["None"], "methods", ["None"], ["        ", "self", ".", "pragma", "=", "pragma_node", "\n", "self", ".", "for_node", "=", "node", "\n", "self", ".", "inner_nodes", "=", "[", "]", "\n", "\n", "", "def", "set_inner_nodes", "(", "self", ",", "inner", ")", ":", "\n", "        ", "self", ".", "inner_nodes", "=", "inner", "\n", "\n", "", "def", "has_openmp", "(", "self", ")", ":", "\n", "        ", "coord", "=", "\"%s\"", "%", "self", ".", "pragma", ".", "coord", "\n", "if", "coord", "==", "\"None\"", ":", "\n", "            ", "return", "False", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.main.get_compar_test_set": [[26, 70], ["Classifier.Data", "data.test_labels.copy", "data.test.copy", "data.test_ids.copy", "range", "print", "open", "json.load", "enumerate", "len", "range", "len", "len", "enumerate", "gp.Data.test.pop", "gp.Data.test_labels.pop", "gp.Data.test_ids.pop", "print", "ids.append", "db_read_string_from_file", "ids.append", "len"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file"], ["full_project_name", "=", "os", ".", "path", ".", "basename", "(", "folder_path", ")", "+", "\"_\"", "+", "indir", "[", "0", "]", "+", "\"_\"", "+", "file_name", "+", "\"_\"", "+", "str", "(", "index", ")", "\n", "return", "full_project_name", "\n", "\n", "\n", "", "def", "create_files", "(", "override", ")", ":", "\n", "    ", "num_pragma", "=", "0", "\n", "if", "override", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "PRAGMA_FILES", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "PRAGMA_FILES", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "f", "=", "open", "(", "gp", ".", "PRAGMA_FILES", ",", "\"r\"", ")", "\n", "num_pragma", "=", "f", ".", "readlines", "(", ")", "\n", "if", "not", "num_pragma", ":", "\n", "                    ", "num_pragma", "=", "0", "\n", "", "else", ":", "\n", "                    ", "num_pragma", "=", "int", "(", "num_pragma", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Hmm\"", ")", "\n", "", "", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "GOOD_FILE", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "GOOD_FILE", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "BAD_FILE", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "BAD_FILE", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "gp", ".", "LOG_FILE", ")", ":", "\n", "            ", "os", ".", "remove", "(", "gp", ".", "LOG_FILE", ")", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "gp", ".", "LOG_FILE", ")", ":", "\n", "        ", "f", "=", "open", "(", "gp", ".", "LOG_FILE", ",", "\"w\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "return", "num_pragma", "\n", "\n", "\n", "", "def", "main", "(", "repos_path", ",", "override", ")", ":", "\n", "    ", "parser", "=", "extract_for", ".", "FileParser", "(", ")", "\n", "db", "=", "database", ".", "Database", "(", "gp", ".", "DB_PATH", ",", "gp", ".", "JSON_PATH", ",", "override", "=", "override", ")", "\n", "num_pragma", "=", "create_files", "(", "override", ")", "# The log, the parsed files, the failed files", "\n", "repos", "=", "os", ".", "listdir", "(", "repos_path", ")", "\n", "\n", "\n", "for", "i", ",", "folder", "in", "enumerate", "(", "repos", ")", ":", "\n", "        ", "folder", "=", "os", ".", "path", ".", "join", "(", "repos_path", ",", "folder", ")", "\n", "if", "i", "%", "50", "==", "0", ":", "\n", "            ", "print", "(", "\"################################## FINISHED ANOTHER 50 REPOS #####################################\"", ")", "\n", "print", "(", "\"PROGRESS:\"", ",", "i", "*", "100", "/", "len", "(", "repos", ")", ",", "\"%\"", ")", "\n", "# LOGGER", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.main.reshuffle_data": [[72, 106], ["range", "range", "range", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "len", "df[].append", "df[].append", "len", "df[].append", "df[].append", "len", "df[].append", "df[].append", "isinstance", "data.train.tolist", "data.val.tolist", "data.test.tolist", "data.train_labels.tolist", "data.val_labels.tolist", "data.test_labels.tolist"], "function", ["None"], ["            ", "print", "(", "folder", ",", "\": exists. skipping\"", ")", "\n", "continue", "\n", "", "print", "(", "\"Working on:\"", ",", "folder", ")", "\n", "files_of_project", ",", "header_files", "=", "get_files_from_repo", "(", "folder", ")", "\n", "inserted_file", "=", "True", "\n", "# Notes for this loop:", "\n", "# 1) Unfortently the code first builds the AST and extracts all the directives and only then it checks if it exists in the DB", "\n", "for", "file", "in", "files_of_project", ":", "\n", "            ", "file_name", "=", "os", ".", "path", ".", "basename", "(", "file", ")", "\n", "\n", "################### LOGIC OF \"DO WE WANT TO PARSE THIS FILE?\" ##################", "\n", "found", "=", "False", "\n", "for", "f", "in", "gp", ".", "EXCLUDE_FOLDERS", ":", "\n", "                ", "if", "file", ".", "__contains__", "(", "f", ")", ":", "\n", "                    ", "found", "=", "True", "\n", "break", "\n", "", "", "if", "file", "in", "gp", ".", "EXCLUDE_FILES", "or", "found", ":", "\n", "                ", "continue", "\n", "", "number_pragmas_parser", "=", "check_openmp_pragma", "(", "file", ")", "\n", "if", "number_pragmas_parser", "<=", "0", ":", "\n", "                ", "print", "(", "\"REEM CHECKER: No pragma found in file: \"", ",", "file", ")", "\n", "continue", "\n", "", "project_name", "=", "get_project_name", "(", "folder", ",", "file_name", ",", "0", ")", "\n", "if", "db", ".", "check_if_repo_exists", "(", "project_name", ")", ":", "\n", "                ", "print", "(", "\"File:\"", ",", "file_name", ",", "\"exists in the project.\"", ")", "\n", "continue", "\n", "################### LOGIC OF \"DO WE WANT TO PARSE THIS FILE?\" ##################", "\n", "\n", "######### C PYTHON PARSER ################", "\n", "", "prep_file", "(", "file", ")", "\n", "list_of_pragmafor", ",", "num_pragmas_cparser", "=", "parser", ".", "parse", "(", "file", ",", "header_files", ")", "# List of PragmaForTuple[0:n]", "\n", "if", "not", "list_of_pragmafor", ":", "\n", "                ", "print", "(", "\"C_AST: No pragma found in file\"", ")", "\n", "\n", "continue", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.predict.predict": [[8, 43], ["model.load_state_dict", "enumerate", "sklearn.metrics.classification_report", "print", "print", "open", "open.writelines", "open.close", "torch.load", "open", "enumerate", "r.to", "torch.no_grad", "model", "np.argmax.detach().cpu().numpy", "numpy.argmax", "total_preds.extend", "path.split", "path.split", "open.writelines", "id.tolist.tolist", "enumerate", "np.argmax.detach().cpu", "total_ids.append", "str", "np.argmax.detach", "str", "str"], "function", ["None"], ["def", "predict", "(", "model", ",", "device", ",", "test_dataloader", ",", "test_y", ",", "path", ",", "test_to_show", ")", ":", "\n", "    ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ")", "\n", "total_preds", "=", "[", "]", "\n", "total_ids", "=", "[", "]", "\n", "# get predictions for test data", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "test_dataloader", ")", ":", "\n", "        ", "batch", "=", "[", "r", ".", "to", "(", "device", ")", "for", "r", "in", "batch", "]", "\n", "sent_id", ",", "mask", ",", "labels", "=", "batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# preds = model(test_seq.to(device), test_mask.to(device))was", "\n", "            ", "preds", "=", "model", "(", "sent_id", ",", "mask", ")", "\n", "preds", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "total_preds", ".", "extend", "(", "preds", ")", "\n", "for", "id", "in", "sent_id", ":", "\n", "                ", "id", "=", "id", ".", "tolist", "(", ")", "\n", "for", "i", ",", "id2", "in", "enumerate", "(", "test_to_show", "[", "'input_ids'", "]", ")", ":", "\n", "# print(\"FROM DATALOADER:\", id)", "\n", "# print(\"FROM TEST TO SHOW\", id2)", "\n", "                    ", "if", "id2", "==", "id", ":", "\n", "# print(\"Found a similar id\")", "\n", "                        ", "total_ids", ".", "append", "(", "test_to_show", "[", "'id'", "]", "[", "i", "]", ")", "\n", "break", "\n", "", "", "", "", "", "cls_rpt", "=", "classification_report", "(", "test_y", ",", "total_preds", ")", "\n", "print", "(", "cls_rpt", ")", "\n", "result_name", "=", "path", ".", "split", "(", "\".pt\"", ")", "[", "0", "]", "+", "\"_report.txt\"", "\n", "print", "(", "result_name", ")", "\n", "f", "=", "open", "(", "result_name", ",", "\"w\"", ")", "\n", "f", ".", "writelines", "(", "cls_rpt", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "result_name", "=", "path", ".", "split", "(", "\".pt\"", ")", "[", "0", "]", "+", "\"_full_results.txt\"", "\n", "with", "open", "(", "result_name", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "v", "in", "enumerate", "(", "total_ids", ")", ":", "\n", "            ", "f", ".", "writelines", "(", "\"id: \"", "+", "str", "(", "total_ids", "[", "i", "]", ")", "+", "' predicted: '", "+", "str", "(", "total_preds", "[", "i", "]", ")", "+", "\" real: \"", "+", "str", "(", "test_y", "[", "i", "]", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.tokenizer.deepscc_tokenizer": [[10, 30], ["transformers.AutoTokenizer.from_pretrained", "AutoTokenizer.from_pretrained.batch_encode_plus", "AutoTokenizer.from_pretrained.batch_encode_plus"], "function", ["None"], ["def", "deepscc_tokenizer", "(", "data", ",", "max_len", "=", "150", ",", "pt_model", "=", "\"NTUYG/DeepSCC-RoBERTa\"", ")", ":", "\n", "# model_pretained_name = \"NTUYG/DeepSCC-RoBERTa\"  # 'bert-base-uncased'", "\n", "# model_pretained_name = 'bert-base-uncased'", "\n", "    ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pt_model", ")", "\n", "if", "max_len", "==", "0", ":", "\n", "        ", "tokenized", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "data", ",", "\n", "# max_length = max_len,", "\n", "pad_to_max_length", "=", "True", ",", "\n", "truncation", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "        ", "tokenized", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "data", ",", "\n", "max_length", "=", "max_len", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "truncation", "=", "True", "\n", ")", "\n", "\n", "", "return", "tokenized", ",", "tokenizer", ".", "vocab_size", "\n", "", ""]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.compar_results.check_has_function": [[38, 46], ["open", "pickle.load"], "function", ["None"], ["def", "check_has_function", "(", "file_data_key", ")", ":", "\n", "    ", "pickle_path", "=", "file_data_key", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "with", "open", "(", "pickle_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pkl", ".", "load", "(", "f", ")", "\n", "", "if", "data", ".", "inner_nodes", "==", "[", "]", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.__init__": [[47, 52], ["Classifier.Data"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "clause", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "data", "=", "gp", ".", "Data", "(", ")", "\n", "self", ".", "df", "=", "{", "'label'", ":", "[", "]", ",", "'text'", ":", "[", "]", ",", "'id'", ":", "[", "]", "}", "\n", "self", ".", "clause", "=", "clause", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.get_pragma": [[53, 67], ["print", "exit"], "methods", ["None"], ["", "def", "get_pragma", "(", "self", ",", "pragma_text", ")", ":", "\n", "        ", "if", "self", ".", "clause", "==", "\"\"", ":", "\n", "            ", "if", "pragma_text", "==", "\"\"", ":", "\n", "                ", "return", "0", "\n", "", "else", ":", "\n", "                ", "return", "1", "\n", "", "", "else", ":", "\n", "            ", "if", "pragma_text", "==", "\"\"", ":", "\n", "                ", "print", "(", "\"ERROR, shouldn't reach this if-clause\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "self", ".", "clause", "in", "pragma_text", ":", "\n", "                ", "return", "1", "\n", "", "else", ":", "\n", "                ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.parse_database": [[69, 93], ["print", "os.path.join", "print", "print", "open", "json.load", "enumerate", "len", "print", "db_read_string_from_file", "db_read_string_from_file", "data_creator.DataCreator.get_pragma", "data_creator.DataCreator.df[].append", "data_creator.DataCreator.df[].append", "data_creator.DataCreator.df[].append", "data_creator.should_add_pragma", "data_creator.get_code_from_pickle", "len"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.get_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.should_add_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.get_code_from_pickle"], ["", "", "", "def", "parse_database", "(", "self", ",", "path_to_db", ")", ":", "\n", "        ", "print", "(", "\"AS SIMPLE TEXT\"", ")", "\n", "if", "self", ".", "clause", ":", "\n", "            ", "print", "(", "\"WITH CLAUSE\"", ",", "self", ".", "clause", ")", "\n", "", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "\n", "num_pragma", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "                ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                    ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "if", "not", "key", "==", "\"key\"", ":", "\n", "                    ", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "not", "should_add_pragma", "(", "file_data", "[", "key", "]", ",", "self", ".", "clause", ")", ":", "\n", "                        ", "continue", "\n", "", "pragma", "=", "self", ".", "get_pragma", "(", "pragma", ")", "\n", "self", ".", "df", "[", "'label'", "]", ".", "append", "(", "pragma", ")", "\n", "self", ".", "df", "[", "'text'", "]", ".", "append", "(", "get_code_from_pickle", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", ")", ")", "\n", "self", ".", "df", "[", "'id'", "]", ".", "append", "(", "file_data", "[", "key", "]", "[", "\"id\"", "]", ")", "\n", "", "", "", "print", "(", "\"NUMBER OF SET\"", ",", "len", "(", "self", ".", "df", "[", "'text'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.split_and_tokenize_data": [[94, 152], ["enumerate", "print", "print", "print", "print", "print", "open", "pickle.load", "data_creator.DataCreator.data.train_ids.append", "data_creator.DataCreator.data.train.append", "data_creator.DataCreator.data.train_labels.append", "data_creator.DataCreator.data.val_ids.append", "data_creator.DataCreator.data.val.append", "data_creator.DataCreator.data.val_labels.append", "data_creator.DataCreator.data.test_ids.append", "data_creator.DataCreator.data.test.append", "data_creator.DataCreator.data.test_labels.append"], "methods", ["None"], ["", "def", "split_and_tokenize_data", "(", "self", ")", ":", "\n", "\n", "        ", "with", "open", "(", "\"../data/as_text_25.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "for", "i", ",", "val", "in", "enumerate", "(", "self", ".", "df", "[", "'id'", "]", ")", ":", "\n", "            ", "if", "val", "in", "data", ".", "train_ids", ":", "\n", "                ", "self", ".", "data", ".", "train_ids", ".", "append", "(", "val", ")", "\n", "self", ".", "data", ".", "train", ".", "append", "(", "self", ".", "df", "[", "'text'", "]", "[", "i", "]", ")", "\n", "self", ".", "data", ".", "train_labels", ".", "append", "(", "self", ".", "df", "[", "'label'", "]", "[", "i", "]", ")", "\n", "", "elif", "val", "in", "data", ".", "val_ids", ":", "\n", "                ", "self", ".", "data", ".", "val_ids", ".", "append", "(", "val", ")", "\n", "self", ".", "data", ".", "val", ".", "append", "(", "self", ".", "df", "[", "'text'", "]", "[", "i", "]", ")", "\n", "self", ".", "data", ".", "val_labels", ".", "append", "(", "self", ".", "df", "[", "'label'", "]", "[", "i", "]", ")", "\n", "", "elif", "val", "in", "data", ".", "test_ids", ":", "\n", "                ", "self", ".", "data", ".", "test_ids", ".", "append", "(", "val", ")", "\n", "self", ".", "data", ".", "test", ".", "append", "(", "self", ".", "df", "[", "'text'", "]", "[", "i", "]", ")", "\n", "self", ".", "data", ".", "test_labels", ".", "append", "(", "self", ".", "df", "[", "'label'", "]", "[", "i", "]", ")", "\n", "\n", "# pack ids", "\n", "#", "\n", "# data = []", "\n", "# for i in range(len(self.df['text'])):", "\n", "#     data.append([self.df['text'][i], self.df['id'][i]])", "\n", "# data_train, temp_text, self.data.train_labels, temp_labels = train_test_split(data, self.df['label'],", "\n", "#                                                                     random_state = 2018,", "\n", "#                                                                     test_size = 0.25,", "\n", "#                                                                     stratify = self.df['label'])", "\n", "# # From the temp we extract the val and the test 50% of the 30% which is 15% of data each", "\n", "# data_val, data_test, self.data.val_labels, self.data.test_labels = train_test_split(temp_text, temp_labels,", "\n", "#                                                                 random_state = 2018,", "\n", "#                                                                 test_size = 0.5,", "\n", "#                                                                 stratify = temp_labels)", "\n", "# # unpack ids", "\n", "# for i, dat in enumerate(data_train):", "\n", "#     self.data.train.append(dat[0])", "\n", "#     self.data.train_ids.append(dat[1])", "\n", "#", "\n", "# for i, dat in enumerate(data_val):", "\n", "#     self.data.val.append(dat[0])", "\n", "#     self.data.val_ids.append(dat[1])", "\n", "#", "\n", "# for i, dat in enumerate(data_test):", "\n", "#     self.data.test.append(dat[0])", "\n", "#     self.data.test_ids.append(dat[1])", "\n", "#", "\n", "# if not isinstance(self.data.train, list):", "\n", "#     self.data.train = self.data.train.tolist()", "\n", "#     self.data.val = self.data.val.tolist()", "\n", "#     self.data.test = self.data.test.tolist()", "\n", "#     self.data.train_labels = self.data.train_labels.tolist()", "\n", "#     self.data.val_labels = self.data.val_labels.tolist()", "\n", "#     self.data.test_labels = self.data.test_labels.tolist()", "\n", "\n", "", "", "print", "(", "\"Examples:\"", ")", "\n", "print", "(", "self", ".", "data", ".", "train_ids", "[", "100", "]", ",", "self", ".", "data", ".", "train_labels", "[", "100", "]", ",", "self", ".", "data", ".", "train", "[", "100", "]", ")", "\n", "print", "(", "self", ".", "data", ".", "train_ids", "[", "567", "]", ",", "self", ".", "data", ".", "train_labels", "[", "567", "]", ",", "self", ".", "data", ".", "train", "[", "567", "]", ")", "\n", "print", "(", "self", ".", "data", ".", "train_ids", "[", "2500", "]", ",", "self", ".", "data", ".", "train_labels", "[", "2500", "]", ",", "self", ".", "data", ".", "train", "[", "2500", "]", ")", "\n", "print", "(", "self", ".", "data", ".", "train_ids", "[", "7000", "]", ",", "self", ".", "data", ".", "train_labels", "[", "7000", "]", ",", "self", ".", "data", ".", "train", "[", "7000", "]", ")", "\n", "# print(self.data.train_ids[11000], self.data.train_labels[11000], self.data.train[11000])", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorLeClair.__init__": [[159, 163], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "df", "=", "{", "}", "\n", "self", ".", "data", "=", "{", "}", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorLeClair.parse_database": [[164, 192], ["print", "os.path.join", "print", "open", "json.load", "enumerate", "len", "print", "db_read_string_from_file", "db_read_string_from_file", "db_read_string_from_file.replace", "db_read_string_from_file.replace", "db_read_string_from_file.replace", "db_read_string_from_file.replace", "data_creator.DataCreatorLeClair.df[].append", "data_creator.DataCreatorLeClair.df[].append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file"], ["", "def", "parse_database", "(", "self", ",", "path_to_db", ")", ":", "\n", "        ", "print", "(", "\"AS LECLAIR\"", ")", "\n", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "col", "=", "[", "'label'", ",", "'text'", "]", "\n", "self", ".", "df", "=", "{", "'label'", ":", "[", "]", ",", "'text'", ":", "[", "]", "}", "\n", "num", "=", "0", "\n", "num_pragma", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "                ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                    ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "if", "not", "key", "==", "\"key\"", ":", "\n", "                    ", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "pragma", "==", "\"\"", ":", "\n", "                        ", "continue", "\n", "", "if", "len", "(", "code", ")", ">", "50", ":", "\n", "                        ", "num", "=", "num", "+", "1", "\n", "", "pragma", ".", "replace", "(", "'pragma'", ",", "''", ")", "\n", "pragma", ".", "replace", "(", "'omp'", ",", "''", ")", "\n", "pragma", ".", "replace", "(", "'parallel'", ",", "''", ")", "\n", "pragma", ".", "replace", "(", "'for'", ",", "''", ")", "\n", "self", ".", "df", "[", "'label'", "]", ".", "append", "(", "pragma", ")", "\n", "self", ".", "df", "[", "'text'", "]", ".", "append", "(", "code", ")", "\n", "", "", "", "print", "(", "num", ",", "len", "(", "self", ".", "df", "[", "'label'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorLeClair.split_and_tokenize_data": [[193, 217], ["sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split"], "methods", ["None"], ["", "def", "split_and_tokenize_data", "(", "self", ")", ":", "\n", "\n", "\n", "\n", "        ", "train_text", ",", "temp_text", ",", "train_labels", ",", "temp_labels", "=", "train_test_split", "(", "self", ".", "df", "[", "'text'", "]", ",", "self", ".", "df", "[", "'label'", "]", ",", "\n", "random_state", "=", "2018", ",", "\n", "test_size", "=", "0.3", ")", "\n", "# From the temp we extract the val and the test 50% of the 30% which is 15% of data each", "\n", "val_text", ",", "test_text", ",", "val_labels", ",", "test_labels", "=", "train_test_split", "(", "temp_text", ",", "temp_labels", ",", "\n", "random_state", "=", "2018", ",", "\n", "test_size", "=", "0.5", ")", "\n", "# train_text, dat_vocab_size = deepscc_tokenizer(train_text, 50)  # max_len'", "\n", "# train_labels, com_vocab_size = deepscc_tokenizer(train_labels, 50)  # max_len", "\n", "# val_text, vocab_size = deepscc_tokenizer(val_text, 50)  # max_len", "\n", "# val_labels, vocab_size = deepscc_tokenizer(val_labels, 50)  # max_len", "\n", "# test_text, vocab_size = deepscc_tokenizer(test_text, 50)  # max_len", "\n", "# test_labels, vocab_size = deepscc_tokenizer(test_labels, 50)  # max_len'", "\n", "\n", "self", ".", "data", "[", "'ctrain'", "]", "=", "train_labels", "\n", "self", ".", "data", "[", "'cval'", "]", "=", "val_labels", "\n", "self", ".", "data", "[", "'ctest'", "]", "=", "test_labels", "\n", "self", ".", "data", "[", "'dtrain'", "]", "=", "train_text", "\n", "self", ".", "data", "[", "'dval'", "]", "=", "val_text", "\n", "self", ".", "data", "[", "'dtest'", "]", "=", "test_text", "\n", "# self.data['dat_vocab_size'] = dat_vocab_size", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorFakePragmaAndNormalize.parse_database": [[222, 250], ["print", "os.path.join", "print", "open", "json.load", "enumerate", "db_read_string_from_file", "db_read_string_from_file", "data_creator.DataCreatorFakePragmaAndNormalize.get_pragma", "data_creator.DataCreatorFakePragmaAndNormalize.df[].append", "data_creator.DataCreatorFakePragmaAndNormalize.df[].append", "data_creator.DataCreatorFakePragmaAndNormalize.df[].append", "print", "data_creator.should_add_pragma", "data_creator.normalize_code_as_string", "len"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.get_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.should_add_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.normalize_code_as_string"], ["    ", "def", "parse_database", "(", "self", ",", "path_to_db", ")", ":", "\n", "        ", "\"\"\"\n        :param input: input file -- should be the pickle or the json\n        :param output: the output file (pickle of dict)\n        :return: nothing\n        \"\"\"", "\n", "print", "(", "\"AS NORMALIZED TEXT\"", ")", "\n", "if", "self", ".", "clause", ":", "\n", "            ", "print", "(", "\"WITH CLAUSE\"", ",", "self", ".", "clause", ")", "\n", "", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "num_pragma", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "                ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                    ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "not", "should_add_pragma", "(", "file_data", "[", "key", "]", ",", "self", ".", "clause", ")", ":", "\n", "                    ", "continue", "\n", "", "pragma", "=", "self", ".", "get_pragma", "(", "pragma", ")", "\n", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "self", ".", "df", "[", "'text'", "]", ".", "append", "(", "normalize_code_as_string", "(", "pickle_file", ")", ")", "\n", "self", ".", "df", "[", "'label'", "]", ".", "append", "(", "pragma", ")", "\n", "self", ".", "df", "[", "'id'", "]", ".", "append", "(", "file_data", "[", "key", "]", "[", "\"id\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorAST.parse_database": [[253, 284], ["print", "os.path.join", "print", "open", "json.load", "enumerate", "db_read_string_from_file", "db_read_string_from_file", "data_creator.DataCreatorAST.get_pragma", "data_creator.DataCreatorAST.df[].append", "data_creator.DataCreatorAST.df[].append", "data_creator.DataCreatorAST.df[].append", "print", "data_creator.should_add_pragma", "data_creator.code_as_ast", "len"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.get_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.should_add_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.code_as_ast"], ["    ", "def", "parse_database", "(", "self", ",", "path_to_db", ")", ":", "\n", "        ", "print", "(", "\"AS SIMPLE AST\"", ")", "\n", "if", "self", ".", "clause", ":", "\n", "            ", "print", "(", "\"WITH CLAUSE\"", ",", "self", ".", "clause", ")", "\n", "", "\"\"\"\n        :param input: input file -- should be the pickle or the json\n        :param output: the output file (pickle of dict)\n        :return: nothing\n        \"\"\"", "\n", "long_pragma", "=", "0", "\n", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "num_pragma", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "                ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                    ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "not", "should_add_pragma", "(", "file_data", "[", "key", "]", ",", "self", ".", "clause", ")", ":", "\n", "                    ", "continue", "\n", "", "pragma", "=", "self", ".", "get_pragma", "(", "pragma", ")", "\n", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "self", ".", "df", "[", "'text'", "]", ".", "append", "(", "code_as_ast", "(", "pickle_file", ")", ")", "\n", "self", ".", "df", "[", "'label'", "]", ".", "append", "(", "pragma", ")", "\n", "self", ".", "df", "[", "'id'", "]", ".", "append", "(", "file_data", "[", "key", "]", "[", "\"id\"", "]", ")", "\n", "\n", "num_pragma", "=", "num_pragma", "+", "1", "\n", "# exit(1)", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorASTNormalized.parse_database": [[288, 328], ["print", "os.path.join", "print", "print", "print", "print", "print", "print", "print", "print", "open", "json.load", "enumerate", "db_read_string_from_file", "db_read_string_from_file", "data_creator.DataCreatorASTNormalized.get_pragma", "data_creator.DataCreatorASTNormalized.df[].append", "data_creator.DataCreatorASTNormalized.df[].append", "data_creator.DataCreatorASTNormalized.df[].append", "print", "data_creator.should_add_pragma", "data_creator.normalize_code_as_ast", "len"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreator.get_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.should_add_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.normalize_code_as_ast"], ["    ", "def", "parse_database", "(", "self", ",", "path_to_db", ")", ":", "\n", "        ", "from", "transformers", "import", "AutoTokenizer", "\n", "print", "(", "\"AS NORMALIZED AST\"", ")", "\n", "if", "self", ".", "clause", ":", "\n", "            ", "print", "(", "\"WITH CLAUSE\"", ",", "self", ".", "clause", ")", "\n", "", "\"\"\"\n        :param input: input file -- should be the pickle or the json\n        :param output: the output file (pickle of dict)\n        :return: nothing\n        \"\"\"", "\n", "long_pragma", "=", "0", "\n", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "num_pragma", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "                ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                    ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "not", "should_add_pragma", "(", "file_data", "[", "key", "]", ",", "self", ".", "clause", ")", ":", "\n", "                    ", "continue", "\n", "", "pragma", "=", "self", ".", "get_pragma", "(", "pragma", ")", "\n", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "self", ".", "df", "[", "'text'", "]", ".", "append", "(", "normalize_code_as_ast", "(", "pickle_file", ")", ")", "\n", "self", ".", "df", "[", "'label'", "]", ".", "append", "(", "pragma", ")", "\n", "self", ".", "df", "[", "'id'", "]", ".", "append", "(", "file_data", "[", "key", "]", "[", "\"id\"", "]", ")", "\n", "\n", "num_pragma", "=", "num_pragma", "+", "1", "\n", "# exit(1)", "\n", "", "", "print", "(", "\"Number of total directives:\"", ",", "num_pragma", ")", "\n", "print", "(", "\"Examples:\"", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "100", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "100", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "567", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "567", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "2500", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "2500", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "7000", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "7000", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "9000", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "9000", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorASTClause.__init__": [[331, 335], ["Classifier.Data"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "clause", ")", ":", "\n", "        ", "self", ".", "df", "=", "{", "'label'", ":", "[", "]", ",", "'text'", ":", "[", "]", ",", "'id'", ":", "[", "]", "}", "\n", "self", ".", "data", "=", "gp", ".", "Data", "(", ")", "\n", "self", ".", "clause", "=", "clause", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorASTClause.parse_database": [[336, 378], ["os.path.join", "print", "print", "print", "print", "print", "print", "print", "open", "json.load", "enumerate", "db_read_string_from_file", "db_read_string_from_file", "print", "data_creator.should_add_pragma", "data_creator.DataCreatorASTClause.df[].append", "data_creator.DataCreatorASTClause.df[].append", "data_creator.DataCreatorASTClause.df[].append", "data_creator.normalize_code_as_ast", "len"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.should_add_pragma", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.normalize_code_as_ast"], ["", "def", "parse_database", "(", "self", ",", "path_to_db", ")", ":", "\n", "        ", "from", "transformers", "import", "AutoTokenizer", "\n", "\n", "\"\"\"\n        :param input: input file -- should be the pickle or the json\n        :param output: the output file (pickle of dict)\n        :return: nothing\n        \"\"\"", "\n", "\n", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "num_pragma", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "            ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "self", ".", "df", "=", "{", "'label'", ":", "[", "]", ",", "'text'", ":", "[", "]", "}", "\n", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "                ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                    ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "self", ".", "clause", "in", "pragma", ":", "\n", "                    ", "pragma", "=", "1", "\n", "", "else", ":", "\n", "                    ", "pragma", "=", "0", "\n", "", "if", "should_add_pragma", "(", "file_data", "[", "key", "]", ")", "or", "pragma", "==", "\"\"", ":", "# code is a full line", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "self", ".", "df", "[", "'text'", "]", ".", "append", "(", "normalize_code_as_ast", "(", "pickle_file", ")", ")", "\n", "self", ".", "df", "[", "'label'", "]", ".", "append", "(", "pragma", ")", "\n", "self", ".", "df", "[", "'id'", "]", ".", "append", "(", "file_data", "[", "key", "]", "[", "\"id\"", "]", ")", "\n", "\n", "# exit(1)", "\n", "", "", "", "print", "(", "\"Number of directives:\"", ",", "num_pragma", ")", "\n", "print", "(", "\"Examples:\"", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "100", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "100", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "567", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "567", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "2500", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "2500", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "7000", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "7000", "]", ")", "\n", "print", "(", "self", ".", "df", "[", "'label'", "]", "[", "11000", "]", ",", "self", ".", "df", "[", "'text'", "]", "[", "11000", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.should_add_pragma": [[380, 401], ["db_read_string_from_file", "db_read_string_from_file", "ForPragmaExtractor.get_length_ast", "open", "pickle.load", "data_creator.is_fake_loop", "data_creator.is_fake_loop"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.get_length_ast", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.is_fake_loop", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.is_fake_loop"], ["", "", "def", "should_add_pragma", "(", "file_data_key", ",", "clause", ")", ":", "\n", "    ", "pragma", "=", "db_read_string_from_file", "(", "file_data_key", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data_key", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "pickle_file", "=", "file_data_key", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "", "max_len_ast", "=", "visitor", ".", "get_length_ast", "(", "for_ast", ")", "\n", "if", "max_len_ast", ">", "should_add_pragma", ".", "max_ast", ":", "\n", "        ", "should_add_pragma", ".", "counter", "=", "should_add_pragma", ".", "counter", "+", "1", "\n", "return", "False", "\n", "", "if", "not", "clause", ":", "\n", "        ", "if", "is_fake_loop", "(", "code", ")", "and", "pragma", "!=", "\"\"", ":", "# code is a full line", "\n", "            ", "should_add_pragma", ".", "counter", "=", "should_add_pragma", ".", "counter", "+", "1", "\n", "return", "False", "\n", "", "return", "True", "\n", "", "else", ":", "# if we are given a clause as input, we don't add non-openmp directives", "\n", "        ", "if", "is_fake_loop", "(", "code", ")", "or", "pragma", "==", "\"\"", ":", "# code is a full line or doesn't contain the clause", "\n", "            ", "should_add_pragma", ".", "counter", "=", "should_add_pragma", ".", "counter", "+", "1", "\n", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.normalize_code_as_ast": [[403, 430], ["open", "pickle.load", "id_v.reset", "id_v.visit", "replacer.reset", "replacer.visit", "open", "for_ast.show", "open", "f.readlines", "a.strip"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "", "def", "normalize_code_as_ast", "(", "pickle_file", ")", ":", "\n", "# print (pickle_file)", "\n", "    ", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "# for_ast.show()", "\n", "# print(normalize_code_as_string.generator.visit(for_ast))", "\n", "# for_ast.show()", "\n", "# counts in an array the name and identifiers of the code", "\n", "id_v", ".", "reset", "(", ")", "\n", "id_v", ".", "visit", "(", "for_ast", ")", "\n", "# Replace the names..", "\n", "replacer", ".", "reset", "(", "id_v", ".", "ids", ",", "id_v", ".", "array", ",", "\n", "id_v", ".", "struct", ",", "id_v", ".", "func", ")", "\n", "replacer", ".", "visit", "(", "for_ast", ")", "\n", "with", "open", "(", "'temp.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for_ast", ".", "show", "(", "buf", "=", "f", ")", "\n", "", "with", "open", "(", "'temp.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ast", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "ast_no_whitespaces", "=", "[", "a", ".", "strip", "(", ")", "for", "a", "in", "ast", "]", "# kill all whitespaces", "\n", "# print(ast_no_whitespaces)", "\n", "# print(normalize_code_as_string.generator.visit(for_ast))", "\n", "\n", "# print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")", "\n", "ast_one_line", "=", "\" \"", "+", "\" \"", ".", "join", "(", "ast_no_whitespaces", ")", "\n", "return", "ast_one_line", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.code_as_ast": [[432, 445], ["open", "pickle.load", "open", "for_ast.show", "open", "f.readlines", "a.strip"], "function", ["None"], ["", "", "def", "code_as_ast", "(", "pickle_file", ")", ":", "\n", "# print (pickle_file)", "\n", "    ", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "with", "open", "(", "'temp.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for_ast", ".", "show", "(", "buf", "=", "f", ")", "\n", "", "with", "open", "(", "'temp.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ast", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "ast_no_whitespaces", "=", "[", "a", ".", "strip", "(", ")", "for", "a", "in", "ast", "]", "# kill all whitespaces and \\n", "\n", "ast_one_line", "=", "\" \"", "+", "\" \"", ".", "join", "(", "ast_no_whitespaces", ")", "\n", "return", "ast_one_line", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.normalize_code_as_string": [[447, 461], ["open", "pickle.load", "id_v.reset", "id_v.visit", "replacer.reset", "replacer.visit", "generator.visit"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "", "def", "normalize_code_as_string", "(", "pickle_file", ")", ":", "\n", "# print (pickle_file)", "\n", "    ", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "# for_ast.show()", "\n", "# counts in an array the name and identifiers of the code", "\n", "id_v", ".", "reset", "(", ")", "\n", "id_v", ".", "visit", "(", "for_ast", ")", "\n", "# Replace the names..", "\n", "replacer", ".", "reset", "(", "id_v", ".", "ids", ",", "id_v", ".", "array", ",", "\n", "id_v", ".", "struct", ",", "id_v", ".", "func", ")", "\n", "replacer", ".", "visit", "(", "for_ast", ")", "\n", "return", "generator", ".", "visit", "(", "for_ast", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.get_code_from_pickle": [[463, 468], ["open", "pickle.load", "generator.visit"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "", "def", "get_code_from_pickle", "(", "pickle_file", ")", ":", "\n", "    ", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "return", "generator", ".", "visit", "(", "for_ast", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.get_function_from_pickle": [[469, 476], ["open", "pickle.load", "generator.visit"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "", "def", "get_function_from_pickle", "(", "pickle_file", ")", ":", "\n", "    ", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "code_data", "=", "\"\"", "\n", "for", "n", "in", "pragmafor_tuple", ".", "inner_nodes", ":", "\n", "            ", "code_data", "=", "code_data", "+", "\"\\n\"", "+", "generator", ".", "visit", "(", "n", ")", "\n", "", "return", "code_data", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.initialize_pycparser": [[478, 481], ["None"], "function", ["None"], ["", "", "def", "initialize_pycparser", "(", ")", ":", "\n", "    ", "from", "pycparser", "import", "parse_file", ",", "c_ast", ",", "c_generator", "\n", "should_add_pragma", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.is_fake_loop": [[483, 489], ["code_directive.split.split", "len", "code_directive[].strip", "code_directive[].strip"], "function", ["None"], ["", "def", "is_fake_loop", "(", "code_directive", ")", ":", "\n", "    ", "code_directive", "=", "code_directive", ".", "split", "(", "\"\\n\"", ")", "\n", "# print(len(code_directive))", "\n", "if", "len", "(", "code_directive", ")", "<", "4", "and", "(", "code_directive", "[", "1", "]", ".", "strip", "(", ")", "==", "''", "or", "code_directive", "[", "1", "]", ".", "strip", "(", ")", "==", "';'", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.data_creator": [[491, 532], ["data_creator.initialize_pycparser", "time.time", "print", "data_creator.DataCreatorASTNormalized.parse_database", "data_creator.DataCreator.split_and_tokenize_data", "print", "print", "print", "print", "print", "print", "print", "print", "exit", "data_creator.DataCreator", "data_creator.DataCreatorFakePragmaAndNormalize", "data_creator.DataCreatorAST", "data_creator.DataCreatorASTNormalized", "open", "pickle.dump", "len", "len", "len", "len", "time.time", "len", "len"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.initialize_pycparser", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorASTClause.parse_database", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.DataCreatorLeClair.split_and_tokenize_data"], ["", "def", "data_creator", "(", "config", ")", ":", "\n", "    ", "if", "config", "[", "'data_type'", "]", "not", "in", "DATA_CHOICES", ":", "\n", "        ", "print", "(", "\"WRONG DATA TYPE\"", ")", "\n", "print", "(", "\"Choose: \"", ",", "DATA_CHOICES", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "should_add_pragma", ".", "max_ast", "=", "config", "[", "\"max_ast\"", "]", "\n", "should_add_pragma", ".", "clause", "=", "config", "[", "\"clause\"", "]", "\n", "path_to_db", "=", "config", "[", "\"data_dir\"", "]", "\n", "parse_type", "=", "config", "[", "\"data_type\"", "]", "\n", "save", "=", "config", "[", "\"save\"", "]", "\n", "initialize_pycparser", "(", ")", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Creating Data with max:\"", ",", "should_add_pragma", ".", "max_ast", ")", "\n", "# we create a dictionairy that has the text and label from the DB", "\n", "# as test as normalized as ast as ast_normalized", "\n", "if", "parse_type", "==", "DATA_CHOICES", "[", "0", "]", ":", "\n", "        ", "creator", "=", "DataCreator", "(", "config", "[", "\"clause\"", "]", ")", "\n", "", "if", "parse_type", "==", "DATA_CHOICES", "[", "1", "]", ":", "\n", "        ", "creator", "=", "DataCreatorFakePragmaAndNormalize", "(", "config", "[", "\"clause\"", "]", ")", "\n", "", "if", "parse_type", "==", "DATA_CHOICES", "[", "2", "]", ":", "\n", "        ", "creator", "=", "DataCreatorAST", "(", "config", "[", "\"clause\"", "]", ")", "\n", "", "if", "parse_type", "==", "DATA_CHOICES", "[", "3", "]", ":", "\n", "        ", "creator", "=", "DataCreatorASTNormalized", "(", "config", "[", "\"clause\"", "]", ")", "\n", "\n", "", "creator", ".", "parse_database", "(", "path_to_db", ")", "\n", "creator", ".", "split_and_tokenize_data", "(", ")", "\n", "\n", "new_json", "=", "save", "\n", "with", "open", "(", "new_json", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pkl", ".", "dump", "(", "creator", ".", "data", ",", "f", ")", "\n", "\n", "", "print", "(", "\"Number of Training set:\"", ",", "len", "(", "creator", ".", "data", ".", "train", ")", ")", "\n", "print", "(", "\"Number of Valid set:\"", ",", "len", "(", "creator", ".", "data", ".", "val", ")", ")", "\n", "print", "(", "\"Number of Test set:\"", ",", "len", "(", "creator", ".", "data", ".", "test", ")", ")", "\n", "num_directives1", "=", "[", "a", "for", "a", "in", "creator", ".", "data", ".", "train_labels", "if", "a", "==", "1", "]", "\n", "num_directives2", "=", "[", "a", "for", "a", "in", "creator", ".", "data", ".", "val_labels", "if", "a", "==", "1", "]", "\n", "num_directives3", "=", "[", "a", "for", "a", "in", "creator", ".", "data", ".", "test_labels", "if", "a", "==", "1", "]", "\n", "print", "(", "\"Number of Directives:\"", ",", "len", "(", "num_directives1", ")", "+", "len", "(", "num_directives2", ")", "+", "len", "(", "num_directives3", ")", ")", "\n", "print", "(", "\"Number of Directives Removed:\"", ",", "should_add_pragma", ".", "counter", ")", "\n", "print", "(", "\"Elapsed time:\"", ",", "time", ".", "time", "(", ")", "-", "t0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.statistics": [[534, 564], ["os.path.join", "matplotlib.hist", "print", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.show", "len", "open", "json.load", "enumerate", "n.max", "db_read_string_from_file", "db_read_string_from_file", "max_len_ast.append", "print", "open", "pickle.load", "ForPragmaExtractor.get_length_ast", "len"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.get_length_ast"], ["", "def", "statistics", "(", "config", ")", ":", "\n", "    ", "path_to_db", "=", "config", "[", "\"data_dir\"", "]", "\n", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "DIRECTIVES", "=", "[", "\"reduction\"", ",", "\"private\"", ",", "\"dynamic\"", ",", "\"shared\"", ",", "\"lastprivate\"", ",", "\"firstprivate\"", ",", "\"collapse\"", "]", "\n", "num_occur", "=", "[", "0", "]", "*", "len", "(", "DIRECTIVES", ")", "\n", "total", "=", "0", "\n", "max_len_ast", "=", "[", "]", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "        ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "            ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "\n", "", "max_len_ast", ".", "append", "(", "visitor", ".", "get_length_ast", "(", "for_ast", ")", ")", "\n", "\n", "", "", "n", ",", "bins", ",", "patches", "=", "plt", ".", "hist", "(", "x", "=", "max_len_ast", ",", "bins", "=", "'auto'", ",", "color", "=", "'#0504aa'", ",", "\n", "alpha", "=", "0.7", ",", "rwidth", "=", "0.85", ")", "\n", "print", "(", "\"MAX FREQ:\"", ",", "n", ".", "max", "(", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Length AST'", ")", "\n", "plt", ".", "ylabel", "(", "'Occurences'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.statistics2": [[568, 595], ["os.path.join", "print", "enumerate", "len", "open", "json.load", "enumerate", "print", "db_read_string_from_file", "db_read_string_from_file", "enumerate", "print", "data_creator.is_fake_loop", "len"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.is_fake_loop"], ["", "def", "statistics2", "(", "config", ")", ":", "\n", "    ", "path_to_db", "=", "config", "[", "\"data_dir\"", "]", "\n", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "num_pragma", "=", "0", "\n", "DIRECTIVES", "=", "[", "\"reduction\"", ",", "\"private\"", ",", "\"dynamic\"", ",", "\"shared\"", ",", "\"lastprivate\"", ",", "\"firstprivate\"", ",", "\"collapse\"", "]", "\n", "num_occur", "=", "[", "0", "]", "*", "len", "(", "DIRECTIVES", ")", "\n", "total", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "        ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "            ", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "", "pragma", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_OPENMP", "]", ")", "\n", "code", "=", "db_read_string_from_file", "(", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_CODE", "]", ")", "\n", "if", "is_fake_loop", "(", "code", ")", "and", "pragma", "!=", "\"\"", "or", "pragma", "==", "\"\"", ":", "# code is a full line", "\n", "                ", "continue", "\n", "\n", "", "total", "=", "total", "+", "1", "\n", "for", "i", ",", "clause", "in", "enumerate", "(", "DIRECTIVES", ")", ":", "\n", "                ", "if", "clause", "in", "pragma", ":", "\n", "                    ", "num_occur", "[", "i", "]", "=", "num_occur", "[", "i", "]", "+", "1", "\n", "", "", "", "", "print", "(", "\"Total directives: \"", ",", "total", ")", "\n", "for", "i", ",", "clause", "in", "enumerate", "(", "DIRECTIVES", ")", ":", "\n", "        ", "print", "(", "\"Number of \"", ",", "clause", ",", "\" :\"", ",", "num_occur", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.train.train": [[7, 42], ["float", "open", "open.close", "range", "print", "train.train_epoch", "train.evaluate", "train_losses.append", "valid_losses.append", "print", "print", "print", "save.split", "torch.save", "open", "open.writelines", "open.writelines", "model.state_dict"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.train.train_epoch", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.train.evaluate"], ["def", "train", "(", "model", ",", "epochs", ",", "train_dataloader", ",", "device", ",", "cross_entropy", ",", "optimizer", ",", "val_dataloader", ",", "save", ")", ":", "\n", "    ", "train_losses", "=", "[", "]", "\n", "valid_losses", "=", "[", "]", "\n", "# set initial loss to infinite", "\n", "best_valid_loss", "=", "float", "(", "'inf'", ")", "\n", "result_name", "=", "save", ".", "split", "(", "\".pt\"", ")", "[", "0", "]", "+", "\".txt\"", "\n", "f", "=", "open", "(", "result_name", ",", "\"w\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "# for each epoch", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "\n", "        ", "print", "(", "'\\n Epoch {:} / {:}'", ".", "format", "(", "epoch", "+", "1", ",", "epochs", ")", ")", "\n", "\n", "# train model", "\n", "train_loss", ",", "_", "=", "train_epoch", "(", "model", ",", "train_dataloader", ",", "device", ",", "cross_entropy", ",", "optimizer", ")", "\n", "\n", "# evaluate model", "\n", "valid_loss", ",", "acc_score", "=", "evaluate", "(", "model", ",", "val_dataloader", ",", "device", ",", "cross_entropy", ")", "\n", "\n", "# save the best model", "\n", "if", "valid_loss", "<", "best_valid_loss", ":", "\n", "            ", "best_valid_loss", "=", "valid_loss", "\n", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save", ")", "\n", "\n", "# append training and validation loss", "\n", "", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "valid_losses", ".", "append", "(", "valid_loss", ")", "\n", "\n", "print", "(", "f'\\nTraining Loss: {train_loss:.3f}'", ")", "\n", "print", "(", "f'Validation Loss: {valid_loss:.3f}'", ")", "\n", "print", "(", "f'Accuracy: {acc_score:.3f}'", ")", "\n", "with", "open", "(", "result_name", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "writelines", "(", "f'{train_loss:.3f} {valid_loss:.3f} {acc_score:.3f}'", ")", "\n", "f", ".", "writelines", "(", "\"\\n\"", ")", "\n", "# f = open(\"results.txt\", \"a\")", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.train.train_epoch": [[47, 102], ["model.train", "enumerate", "numpy.concatenate", "model.zero_grad", "model", "cross_entropy", "cross_entropy.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "preds.detach().cpu().numpy.detach().cpu().numpy", "np.concatenate.append", "len", "print", "r.to", "cross_entropy.item", "model.parameters", "preds.detach().cpu().numpy.detach().cpu", "len", "preds.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.train.train"], ["", "", "", "def", "train_epoch", "(", "model", ",", "train_dataloader", ",", "device", ",", "cross_entropy", ",", "optimizer", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "\n", "total_loss", ",", "total_accuracy", "=", "0", ",", "0", "\n", "\n", "# empty list to save model predictions", "\n", "total_preds", "=", "[", "]", "\n", "# iterate over batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "\n", "# progress update after every 50 batches.", "\n", "        ", "if", "step", "%", "50", "==", "0", "and", "not", "step", "==", "0", ":", "\n", "            ", "print", "(", "'  Batch {:>5,}  of  {:>5,}.'", ".", "format", "(", "step", ",", "len", "(", "train_dataloader", ")", ")", ")", "\n", "\n", "# push the batch to gpu", "\n", "", "batch", "=", "[", "r", ".", "to", "(", "device", ")", "for", "r", "in", "batch", "]", "\n", "\n", "sent_id", ",", "mask", ",", "labels", "=", "batch", "\n", "\n", "# clear previously calculated gradients", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "# get model predictions for the current batch", "\n", "preds", "=", "model", "(", "sent_id", ",", "mask", ")", "\n", "\n", "# compute the loss between actual and predicted values", "\n", "loss", "=", "cross_entropy", "(", "preds", ",", "labels", ")", "\n", "\n", "# add on to the total loss", "\n", "total_loss", "=", "total_loss", "+", "loss", ".", "item", "(", ")", "\n", "\n", "# backward pass to calculate the gradients", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# clip the the gradients to 1.0. It helps in preventing the exploding gradient problem", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "\n", "# update parameters", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# model predictions are stored on GPU. So, push it to CPU", "\n", "preds", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# append the model predictions", "\n", "total_preds", ".", "append", "(", "preds", ")", "\n", "\n", "# compute the training loss of the epoch", "\n", "", "avg_loss", "=", "total_loss", "/", "len", "(", "train_dataloader", ")", "\n", "\n", "# predictions are in the form of (no. of batches, size of batch, no. of classes).", "\n", "# reshape the predictions in form of (number of samples, no. of classes)", "\n", "total_preds", "=", "np", ".", "concatenate", "(", "total_preds", ",", "axis", "=", "0", ")", "\n", "\n", "# returns the loss and predictions", "\n", "return", "avg_loss", ",", "total_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.train.evaluate": [[106, 158], ["print", "model.eval", "time.time", "enumerate", "numpy.concatenate", "len", "len", "print", "t.to", "torch.no_grad", "model", "cross_entropy", "preds.detach().cpu().numpy.detach().cpu().numpy", "labels.detach().cpu().numpy", "np.concatenate.append", "time.time", "cross_entropy.item", "sklearn.metrics.accuracy_score", "len", "preds.detach().cpu().numpy.detach().cpu", "labels.detach().cpu", "numpy.argmax", "preds.detach().cpu().numpy.detach", "labels.detach"], "function", ["None"], ["", "def", "evaluate", "(", "model", ",", "val_dataloader", ",", "device", ",", "cross_entropy", ")", ":", "\n", "    ", "print", "(", "\"\\nEvaluating...\"", ")", "\n", "\n", "# deactivate dropout layers", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "total_loss", ",", "total_accuracy", "=", "0", ",", "0", "\n", "acc_score", "=", "0", "\n", "# empty list to save the model predictions", "\n", "total_preds", "=", "[", "]", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "# iterate over batches", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "val_dataloader", ")", ":", "\n", "\n", "# Progress update every 50 batches.", "\n", "        ", "if", "step", "%", "50", "==", "0", "and", "not", "step", "==", "0", ":", "\n", "# Calculate elapsed time in minutes.", "\n", "            ", "elapsed", "=", "time", ".", "time", "(", ")", "-", "t0", "\n", "\n", "# Report progress.", "\n", "print", "(", "'  Batch {:>5,}  of  {:>5,}.'", ".", "format", "(", "step", ",", "len", "(", "val_dataloader", ")", ")", ")", "\n", "\n", "# push the batch to gpu", "\n", "", "batch", "=", "[", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", "]", "\n", "\n", "sent_id", ",", "mask", ",", "labels", "=", "batch", "\n", "\n", "# deactivate autograd", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "# model predictions", "\n", "            ", "preds", "=", "model", "(", "sent_id", ",", "mask", ")", "\n", "\n", "# compute the validation loss between actual and predicted values", "\n", "loss", "=", "cross_entropy", "(", "preds", ",", "labels", ")", "\n", "\n", "total_loss", "=", "total_loss", "+", "loss", ".", "item", "(", ")", "\n", "\n", "# model predictions are stored on GPU. So, push it to CPU", "\n", "preds", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels_acc", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# print(\"Accuracy:\", accuracy_score(labels_acc, np.argmax(preds, axis = 1)))", "\n", "acc_score", "=", "acc_score", "+", "accuracy_score", "(", "labels_acc", ",", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", ")", "\n", "total_preds", ".", "append", "(", "preds", ")", "\n", "# compute the validation loss of the epoch", "\n", "", "", "avg_loss", "=", "total_loss", "/", "len", "(", "val_dataloader", ")", "\n", "acc_score", "=", "acc_score", "/", "len", "(", "val_dataloader", ")", "\n", "# reshape the predictions in form of (number of samples, no. of classes)", "\n", "total_preds", "=", "np", ".", "concatenate", "(", "total_preds", ",", "axis", "=", "0", ")", "\n", "\n", "return", "avg_loss", ",", "acc_score", "", "", ""]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.get_dataset_test": [[37, 99], ["os.path.join", "ForPragmaExtractor.database.Database", "print", "os.path.join", "os.path.join", "open", "json.load", "enumerate", "open", "pickle.load", "os.path.abspath", "os.path.abspath", "ForPragmaExtractor.database.Database.check_if_repo_exists", "create_compar_dataset.prep_code_as_string", "range", "ForPragmaExtractor.global_parameters.PragmaForTuple", "ForPragmaExtractor.global_parameters.PragmaForTuple.set_inner_nodes", "ForPragmaExtractor.database.Database.insert", "create_compar_dataset.prep_code_as_string", "print", "pycparser.c_ast.Pragma", "print", "print", "open", "pickle.load", "create_compar_dataset.exeute_autoparallel_p4a", "create_compar_dataset.exeute_autoparallel", "print"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.check_if_repo_exists", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.prep_code_as_string", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.set_inner_nodes", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.insert", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.prep_code_as_string", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.exeute_autoparallel_p4a", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.exeute_autoparallel"], ["def", "get_dataset_test", "(", "path_to_pickle", ",", "path_to_db", ",", "path_to_new_db", ",", "override", ",", "p4a", ")", ":", "\n", "    ", "if", "p4a", "==", "False", ":", "\n", "        ", "with", "open", "(", "path_to_pickle", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "dataset", "=", "pkl", ".", "load", "(", "f", ")", "\n", "test_data", "=", "dataset", ".", "test", "\n", "valid_data", "=", "dataset", ".", "val", "\n", "test_label", "=", "dataset", ".", "test_labels", "\n", "valid_label", "=", "dataset", ".", "val_labels", "\n", "valid_ids", "=", "dataset", ".", "val_ids", "\n", "test_ids", "=", "dataset", ".", "test_ids", "\n", "", "", "else", ":", "\n", "        ", "test_ids", "=", "[", "]", "\n", "\n", "", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "db", "=", "Database", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "path_to_new_db", ")", ",", "\"database\"", ")", "\n", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "path_to_new_db", ")", ",", "\"database.json\"", ")", ",", "override", ")", "\n", "failed", "=", "0", "\n", "sucess", "=", "0", "\n", "error", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "        ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "            ", "if", "file_data", "[", "key", "]", "[", "\"id\"", "]", "in", "test_ids", "or", "test_ids", "==", "[", "]", ":", "\n", "                ", "if", "db", ".", "check_if_repo_exists", "(", "key", ")", ":", "\n", "                    ", "continue", "\n", "", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "code_as_string", "=", "prep_code_as_string", "(", "file_data", ",", "key", ")", "\n", "\n", "pragma", "=", "\"!\"", "\n", "prefix", "=", "\"*\"", "\n", "for", "kk", "in", "range", "(", "2", ")", ":", "\n", "                    ", "code_as_string", "=", "prep_code_as_string", "(", "file_data", ",", "key", ",", "prefix", ")", "\n", "if", "p4a", ":", "\n", "                        ", "pragma", "=", "exeute_autoparallel_p4a", "(", "code_as_string", ")", "\n", "", "else", ":", "\n", "                        ", "pragma", "=", "exeute_autoparallel", "(", "code_as_string", ")", "\n", "", "prefix", "=", "prefix", "+", "\"*\"", "\n", "if", "pragma", "!=", "\"!\"", ":", "\n", "                        ", "print", "(", "\"Fixed problem!\"", ")", "\n", "break", "\n", "", "", "if", "pragma", "==", "\"!\"", ":", "\n", "                    ", "print", "(", "\"Compiler failed\"", ")", "\n", "error", "=", "error", "+", "1", "\n", "continue", "\n", "", "if", "pragma", "==", "\"\"", ":", "\n", "                    ", "pragma", "=", "c_ast", ".", "Pragma", "(", "pragma", ")", "\n", "pragma", ".", "string", "=", "\"\"", "\n", "failed", "=", "failed", "+", "1", "\n", "print", "(", "\"Failed\"", ")", "\n", "", "else", ":", "\n", "                    ", "sucess", "=", "sucess", "+", "1", "\n", "print", "(", "\"Success!\"", ")", "\n", "", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "inner_nodes", "=", "pragmafor_tuple", ".", "inner_nodes", "\n", "", "pragma_for_tup", "=", "PragmaForTuple", "(", "pragma", ",", "for_ast", ")", "\n", "pragma_for_tup", ".", "set_inner_nodes", "(", "inner_nodes", ")", "\n", "db", ".", "insert", "(", "pragma_for_tup", ",", "key", ",", "file_data", "[", "key", "]", "[", "\"id\"", "]", ")", "\n", "", "", "", "print", "(", "\"Errors:\"", ",", "error", ",", "\" out of \"", ",", "failed", "+", "sucess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.create_db": [[101, 134], ["os.path.join", "ForPragmaExtractor.database.Database", "os.path.join", "os.path.join", "open", "json.load", "enumerate", "os.path.abspath", "os.path.abspath", "print", "print", "print", "Classifier.data_creator.get_code_from_pickle", "create_compar_dataset.exeute_autoparallel", "ForPragmaExtractor.global_parameters.PragmaForTuple", "ForPragmaExtractor.global_parameters.PragmaForTuple.set_inner_nodes", "ForPragmaExtractor.database.Database.insert", "pycparser.c_ast.Pragma", "open", "pickle.load", "len"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.get_code_from_pickle", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.exeute_autoparallel", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.global_parameters.PragmaForTupleRegular.set_inner_nodes", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.database.Database.insert"], ["", "def", "create_db", "(", "path_to_db", ",", "path_to_new_db", ",", "override", ")", ":", "\n", "    ", "json_file_name", "=", "os", ".", "path", ".", "join", "(", "path_to_db", ",", "\"database.json\"", ")", "\n", "db", "=", "Database", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "path_to_new_db", ")", ",", "\"database\"", ")", "\n", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "path_to_new_db", ")", ",", "\"database.json\"", ")", ",", "override", ")", "\n", "failed", "=", "0", "\n", "sucess", "=", "0", "\n", "with", "open", "(", "json_file_name", ",", "'r'", ")", "as", "file", ":", "\n", "# First we load existing data into a dict.", "\n", "        ", "file_data", "=", "json", ".", "load", "(", "file", ")", "\n", "# Join new_data with file_data inside emp_details", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "file_data", ")", ":", "\n", "            ", "if", "i", "%", "50", "==", "0", ":", "\n", "                ", "print", "(", "\"Progress, completed: {0}%\"", ".", "format", "(", "i", "*", "100", "/", "len", "(", "file_data", ")", ")", ")", "\n", "print", "(", "\"Failed:\"", ",", "failed", ")", "\n", "print", "(", "\"Success:\"", ",", "sucess", ")", "\n", "", "if", "not", "key", "==", "\"key\"", ":", "\n", "                ", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "\n", "code_as_string", "=", "get_code_from_pickle", "(", "pickle_file", ")", "\n", "pragma", "=", "exeute_autoparallel", "(", "code_as_string", ")", "\n", "if", "pragma", "==", "\"\"", ":", "\n", "                    ", "pragma", "=", "c_ast", ".", "Pragma", "(", "pragma", ")", "\n", "pragma", ".", "string", "=", "\"\"", "\n", "failed", "=", "failed", "+", "1", "\n", "", "else", ":", "\n", "                    ", "sucess", "=", "sucess", "+", "1", "\n", "", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "inner_nodes", "=", "pragmafor_tuple", ".", "inner_nodes", "\n", "", "pragma_for_tup", "=", "PragmaForTuple", "(", "pragma", ",", "for_ast", ")", "\n", "pragma_for_tup", ".", "set_inner_nodes", "(", "inner_nodes", ")", "\n", "db", ".", "insert", "(", "pragma_for_tup", ",", "key", ",", "file_data", "[", "key", "]", "[", "\"id\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.prep_code_as_string": [[136, 160], ["Classifier.data_creator.get_code_from_pickle", "ForPragmaExtractor.CounterIdVisitor", "visitor.CounterIdVisitor.reset", "visitor.CounterIdVisitor.visit", "ForPragmaExtractor.ReplaceIdsVisitor", "visitor.ReplaceIdsVisitor.reset", "create_compar_dataset.construct_variable_decl", "create_compar_dataset.construct_variable_decl", "create_compar_dataset.construct_variable_decl", "open", "pickle.load", "Classifier.data_creator.get_function_from_pickle"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.get_code_from_pickle", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.ForLoopChecker.reset", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.construct_variable_decl", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.construct_variable_decl", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.construct_variable_decl", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.data_creator.get_function_from_pickle"], ["", "", "", "", "def", "prep_code_as_string", "(", "file_data", ",", "key", ",", "prefix", "=", "\"*\"", ")", ":", "\n", "    ", "pickle_file", "=", "file_data", "[", "key", "]", "[", "gp", ".", "KEY_PICKLE", "]", "\n", "# print(\"WORKING ON\", key)", "\n", "code_as_string", "=", "get_code_from_pickle", "(", "pickle_file", ")", "\n", "id_visitor", "=", "visitor", ".", "CounterIdVisitor", "(", ")", "\n", "id_visitor", ".", "reset", "(", ")", "\n", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "pragmafor_tuple", "=", "pkl", ".", "load", "(", "f", ")", "#", "\n", "for_ast", "=", "pragmafor_tuple", ".", "for_node", "\n", "", "id_visitor", ".", "visit", "(", "for_ast", ")", "\n", "# code_as_string = \"int main() {\\n\" + code_as_string + \"\\n}\\n\"", "\n", "real_ids", "=", "visitor", ".", "ReplaceIdsVisitor", "(", "\"a\"", ",", "\"a\"", ",", "\"a\"", ",", "\"a\"", ")", "\n", "real_ids", ".", "reset", "(", "id_visitor", ".", "ids", ",", "id_visitor", ".", "array", ",", "id_visitor", ".", "struct", ",", "id_visitor", ".", "func", ")", "\n", "\n", "decl", "=", "\"int\"", "\n", "decl", "=", "construct_variable_decl", "(", "real_ids", ".", "var", ",", "decl", ")", "\n", "decl", "=", "decl", "+", "\"int\"", "\n", "decl", "=", "construct_variable_decl", "(", "real_ids", ".", "array", ",", "decl", ",", "prefix", "=", "prefix", ")", "\n", "decl", "=", "decl", "+", "\"int\"", "\n", "decl", "=", "construct_variable_decl", "(", "real_ids", ".", "struct", ",", "decl", ",", "prefix", "=", "prefix", ")", "\n", "\n", "code_as_string", "=", "\"int main() {\\n\"", "+", "decl", "+", "\"\\n\"", "+", "code_as_string", "+", "\"\\n}\\n\"", "\n", "code_as_string", "=", "code_as_string", "+", "\"\\n\"", "+", "get_function_from_pickle", "(", "pickle_file", ")", "\n", "return", "code_as_string", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.construct_variable_decl": [[162, 172], ["len", "isinstance"], "function", ["None"], ["", "def", "construct_variable_decl", "(", "ids", ",", "code", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "if", "len", "(", "ids", ")", "==", "0", ":", "\n", "# print(\"EMPTY CODE\")", "\n", "        ", "return", "code", "+", "\";\\n\"", "\n", "", "for", "id", "in", "ids", ":", "\n", "        ", "if", "isinstance", "(", "id", ",", "str", ")", ":", "\n", "            ", "code", "=", "code", "+", "\" \"", "+", "prefix", "+", "id", "+", "\", \"", "\n", "\n", "", "", "code", "=", "code", "[", "0", ":", "-", "2", "]", "+", "\";\\n\"", "\n", "return", "code", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.exeute_autoparallel": [[174, 208], ["os.path.isdir", "subprocess.Popen", "sub_process.Popen.communicate", "sub_process.Popen.wait", "os.path.join", "pycparser.parse_file", "ForPragmaExtractor.PragmaForVisitor", "visitor.PragmaForVisitor.visit", "shutil.rmtree", "open", "f.writelines", "os.path.isdir", "len", "print"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "def", "exeute_autoparallel", "(", "code_as_string", ")", ":", "\n", "# returns the pragma", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "'cetus_output'", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "'cetus_output'", ")", "\n", "\n", "", "with", "open", "(", "\"tmp.c\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "# f.writelines(\"int main() {\\n\")", "\n", "        ", "f", ".", "writelines", "(", "code_as_string", "+", "\"\\n\"", ")", "\n", "# f.writelines(\"}\\n\")", "\n", "# print(code_as_string)", "\n", "", "process", "=", "sub_process", ".", "Popen", "(", "[", "'cetus'", ",", "'-alias=3'", ",", "'-preprocessor=cpp -C -I/home/reemh/CLPP/fake_headers '", ",", "'tmp.c'", "]", ",", "stdout", "=", "sub_process", ".", "PIPE", ",", "stderr", "=", "sub_process", ".", "PIPE", ")", "\n", "out", ",", "err", "=", "process", ".", "communicate", "(", ")", "\n", "process", ".", "wait", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'cetus_output'", ")", ":", "\n", "# print(err)", "\n", "        ", "return", "\"!\"", "\n", "\n", "# if err != \"\":", "\n", "#     print(\"Error:\", err)", "\n", "#     return \"\"", "\n", "# print(out)", "\n", "", "file", "=", "os", ".", "path", ".", "join", "(", "\"cetus_output/\"", ",", "\"tmp.c\"", ")", "\n", "cpp_args", "=", "[", "'-nostdinc'", ",", "'-E'", ",", "r'-I'", "+", "FAKE_HEADER_PATH", "]", "\n", "ast", "=", "parse_file", "(", "file", ",", "use_cpp", "=", "True", ",", "cpp_path", "=", "'mpicc'", ",", "cpp_args", "=", "cpp_args", ")", "\n", "# Get openmp pragma..", "\n", "pragma_for_visit", "=", "visitor", ".", "PragmaForVisitor", "(", ")", "\n", "pragma_for_visit", ".", "visit", "(", "ast", ")", "\n", "pragmas", "=", "pragma_for_visit", ".", "pragmas", "\n", "\n", "if", "len", "(", "pragmas", ")", "!=", "1", ":", "# no pragma", "\n", "        ", "return", "\"\"", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Compiler Success!\"", ")", "\n", "return", "pragmas", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.create_compar_dataset.exeute_autoparallel_p4a": [[210, 247], ["os.system", "subprocess.Popen", "sub_process.Popen.communicate", "sub_process.Popen.wait", "os.path.join", "pycparser.parse_file", "ForPragmaExtractor.PragmaForVisitor", "visitor.PragmaForVisitor.visit", "open", "f.writelines", "os.path.isfile", "print", "print", "exit", "len", "print"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.ForPragmaExtractor.visitors.Visitor.visit"], ["", "", "def", "exeute_autoparallel_p4a", "(", "code_as_string", ")", ":", "\n", "# returns the pragma", "\n", "    ", "os", ".", "system", "(", "'rm -rf P4A* && rm tmp.p4a.c'", ")", "\n", "\n", "with", "open", "(", "\"tmp.c\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "# f.writelines(\"int main() {\\n\")", "\n", "        ", "f", ".", "writelines", "(", "code_as_string", "+", "\"\\n\"", ")", "\n", "# f.writelines(\"}\\n\")", "\n", "# print(code_as_string)", "\n", "", "process", "=", "sub_process", ".", "Popen", "(", "[", "'p4a'", ",", "'-O'", ",", "'-I/home/reemh/CLPP/fake_headers '", ",", "'--no-pointer-aliasing'", ",", "'tmp.c'", "]", "\n", ",", "stdout", "=", "sub_process", ".", "PIPE", ",", "stderr", "=", "sub_process", ".", "PIPE", ")", "#, shell=True)", "\n", "\n", "out", ",", "err", "=", "process", ".", "communicate", "(", ")", "\n", "process", ".", "wait", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "'tmp.p4a.c'", ")", ":", "\n", "        ", "print", "(", "\"Compiler failed...\"", ")", "\n", "print", "(", "out", ",", "err", ")", "\n", "exit", "(", "1", ")", "\n", "return", "\"!\"", "\n", "\n", "# if err != \"\":", "\n", "#     print(\"Error:\", err)", "\n", "#     return \"\"", "\n", "# print(out)", "\n", "", "file", "=", "os", ".", "path", ".", "join", "(", "'tmp.p4a.c'", ")", "\n", "cpp_args", "=", "[", "'-nostdinc'", ",", "'-E'", ",", "r'-I'", "+", "FAKE_HEADER_PATH", "]", "\n", "ast", "=", "parse_file", "(", "file", ",", "use_cpp", "=", "True", ",", "cpp_path", "=", "'mpicc'", ",", "cpp_args", "=", "cpp_args", ")", "\n", "# Get openmp pragma..", "\n", "pragma_for_visit", "=", "visitor", ".", "PragmaForVisitor", "(", ")", "\n", "pragma_for_visit", ".", "visit", "(", "ast", ")", "\n", "pragmas", "=", "pragma_for_visit", ".", "pragmas", "\n", "\n", "if", "len", "(", "pragmas", ")", "!=", "1", ":", "# no pragma", "\n", "        ", "return", "\"\"", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Compiler Success!\"", ")", "\n", "return", "pragmas", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.model.BERT_Arch.__init__": [[13, 32], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.model.BERT_Arch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert", ")", ":", "\n", "        ", "super", "(", "BERT_Arch", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "bert", "=", "bert", "\n", "\n", "# dropout layer", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "\n", "# relu activation function", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "# dense layer 1", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "768", ",", "512", ")", "\n", "\n", "# dense layer 2 (Output layer)", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "512", ",", "2", ")", "\n", "\n", "# softmax activation function", "\n", "self", ".", "softmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.model.BERT_Arch.forward": [[34, 51], ["model.BERT_Arch.bert", "model.BERT_Arch.fc1", "model.BERT_Arch.relu", "model.BERT_Arch.dropout", "model.BERT_Arch.fc2", "model.BERT_Arch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sent_id", ",", "mask", ")", ":", "\n", "# pass the inputs to the model", "\n", "        ", "_", ",", "cls_hs", "=", "self", ".", "bert", "(", "sent_id", ",", "attention_mask", "=", "mask", ",", "return_dict", "=", "False", ")", "\n", "\n", "x", "=", "self", ".", "fc1", "(", "cls_hs", ")", "\n", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "# output layer", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "\n", "\n", "# apply softmax activation", "\n", "x", "=", "self", ".", "softmax", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.db_read_string_from_file": [[6, 12], ["open", "f.readlines"], "function", ["None"], ["def", "db_read_string_from_file", "(", "file_path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "return", "\"\"", ".", "join", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "", "except", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.get_pragma_clause": [[14, 24], ["pragma.split().count", "utils.find_word", "utils.get_parenthese_scope", "print", "exit", "pragma.split"], "function", ["home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.find_word", "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.get_parenthese_scope"], ["", "", "def", "get_pragma_clause", "(", "pragma", ",", "clause", ")", ":", "\n", "    ", "num_clause", "=", "pragma", ".", "split", "(", "' '", ")", ".", "count", "(", "clause", "+", "'('", ")", "\n", "if", "num_clause", ">", "1", ":", "\n", "        ", "print", "(", "\"Two directives\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "pos", "=", "find_word", "(", "pragma", ",", "clause", ")", "\n", "if", "pos", "==", "-", "1", ":", "\n", "        ", "return", "\"\"", "\n", "", "pos_start", ",", "pos_end", "=", "get_parenthese_scope", "(", "pragma", ",", "start", "=", "pos", ")", "\n", "return", "(", "clause", "+", "pragma", "[", "pos_start", ":", "pos_end", "+", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.find_word": [[26, 31], ["range", "len", "len"], "function", ["None"], ["", "def", "find_word", "(", "line", ",", "word", ",", "start", "=", "0", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "start", ",", "len", "(", "line", ")", ")", ":", "\n", "        ", "if", "line", "[", "i", ":", "i", "+", "len", "(", "word", ")", "]", "==", "word", ":", "\n", "            ", "return", "i", "\n", "", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.get_parenthese_scope": [[33, 54], ["range", "len", "stack.append", "len", "stack.pop", "len", "len"], "function", ["None"], ["", "def", "get_parenthese_scope", "(", "line", ",", "start", "=", "0", ")", ":", "\n", "    ", "stack", "=", "[", "]", "\n", "in_sograim", "=", "\"\"", "\n", "start_parenthese", "=", "0", "\n", "end_parenthese", "=", "0", "\n", "for", "i", "in", "range", "(", "start", ",", "len", "(", "line", ")", ")", ":", "\n", "        ", "letter", "=", "line", "[", "i", "]", "\n", "if", "letter", "==", "\"(\"", ":", "# good, we found the start of sograim", "\n", "            ", "if", "len", "(", "stack", ")", "==", "0", ":", "# No sograim was found yet, this is the first one...", "\n", "                ", "start_parenthese", "=", "i", "\n", "", "stack", ".", "append", "(", "\"(\"", ")", "\n", "\n", "continue", "\n", "", "elif", "letter", "==", "\")\"", ":", "\n", "            ", "stack", ".", "pop", "(", ")", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "# Empty", "\n", "                ", "end_parenthese", "=", "i", "\n", "return", "start_parenthese", ",", "end_parenthese", "\n", "", "", "elif", "len", "(", "stack", ")", "!=", "0", ":", "# Stack has to be filled with the relevant word for us to add it to the sograim...", "\n", "            ", "in_sograim", "+=", "letter", "\n", "", "", "return", "start_parenthese", ",", "end_parenthese", "\n", "\n"]], "home.repos.pwc.inspect_result.scientific-computing-lab-nrcn_pragformer.Model.utils.read_pickle_data": [[55, 59], ["open", "pickle.load"], "function", ["None"], ["", "def", "read_pickle_data", "(", "pickle_file", ")", ":", "\n", "    ", "with", "open", "(", "pickle_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "return", "data", "", "", "", ""]]}