{"home.repos.pwc.inspect_result.shunjiu_sstod.None.evaluate.validate_metric": [[1, 28], ["results.items", "list", "bs_target.split.split", "range", "len", "filter", "len", "len", "list.split", "len", "len", "len"], "function", ["None"], ["def", "validate_metric", "(", "results", ")", ":", "\n", "    ", "joint_acc", "=", "0.0", "\n", "slot_acc", "=", "0.0", "\n", "dialog_succ", "=", "0.0", "\n", "total_turn_num", "=", "0.0", "\n", "for", "name", ",", "dialog", "in", "results", ".", "items", "(", ")", ":", "\n", "        ", "for", "turn", "in", "dialog", "[", "'turns'", "]", ":", "\n", "            ", "bs_target", "=", "turn", "[", "'bs'", "]", "\n", "bs_gen", "=", "turn", "[", "'bs_gen'", "]", "\n", "joint_acc", "+=", "bs_gen", "==", "bs_target", "\n", "\n", "bs_gen", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "''", ",", "bs_gen", ".", "split", "(", "','", ")", ")", ")", "\n", "bs_target", "=", "bs_target", ".", "split", "(", "','", ")", "\n", "iter_slot_acc", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "bs_target", ")", ")", ":", "\n", "                ", "if", "i", "<", "len", "(", "bs_gen", ")", ":", "\n", "                    ", "iter_slot_acc", "+=", "bs_gen", "[", "i", "]", "==", "bs_target", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "if", "len", "(", "bs_target", ")", ">", "0", ":", "\n", "                ", "slot_acc", "+=", "iter_slot_acc", "/", "len", "(", "bs_target", ")", "\n", "", "else", ":", "\n", "                ", "slot_acc", "+=", "1", "if", "len", "(", "bs_gen", ")", "==", "0", "else", "0", "\n", "", "total_turn_num", "+=", "1", "\n", "\n", "", "dialog_succ", "+=", "''", ".", "join", "(", "bs_gen", ")", ".", "replace", "(", "','", ",", "''", ")", "==", "dialog", "[", "'goal'", "]", "\n", "", "return", "joint_acc", "/", "total_turn_num", ",", "slot_acc", "/", "total_turn_num", ",", "dialog_succ", "/", "len", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.evaluate.validation_metric_gpt": [[29, 64], ["dataloader.read_data", "state_gen.split.split", "state_label.split.split", "range", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.read_data"], ["", "def", "validation_metric_gpt", "(", "data_path", ",", "dataloader", ",", "results", ")", ":", "\n", "    ", "data", "=", "dataloader", ".", "read_data", "(", "data_path", ")", "\n", "# block acc, state acc, success", "\n", "total_turn_num", "=", "0", "\n", "block_acc", "=", "0", "\n", "slot_acc", "=", "0", "\n", "success", "=", "0", "\n", "total_data", "=", "0", "\n", "for", "turn", "in", "results", ":", "\n", "        ", "dial_id", "=", "turn", "[", "'dial_id'", "]", "\n", "last_turn_num", "=", "len", "(", "data", "[", "dial_id", "]", "[", "'log'", "]", ")", "-", "1", "\n", "turn_num", "=", "turn", "[", "'turn_num'", "]", "\n", "total_turn_num", "+=", "1", "\n", "state_gen", "=", "turn", "[", "'bspn_gen'", "]", "\n", "state_label", "=", "turn", "[", "'bspn'", "]", "\n", "block_acc", "+=", "(", "state_gen", "==", "state_label", ")", "\n", "state_gen", "=", "state_gen", ".", "split", "(", "','", ")", "\n", "state_label", "=", "state_label", ".", "split", "(", "','", ")", "\n", "iter_slot_acc", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "state_label", ")", ")", ":", "\n", "            ", "if", "i", "<", "len", "(", "state_gen", ")", ":", "\n", "                ", "iter_slot_acc", "+=", "state_gen", "[", "i", "]", "==", "state_label", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "", "", "if", "len", "(", "state_label", ")", ">", "0", ":", "\n", "            ", "slot_acc", "+=", "iter_slot_acc", "/", "len", "(", "state_label", ")", "\n", "", "else", ":", "\n", "            ", "slot_acc", "+=", "1", "if", "len", "(", "state_gen", ")", "==", "0", "else", "0", "\n", "\n", "", "if", "turn_num", "==", "last_turn_num", ":", "\n", "            ", "total_data", "+=", "1", "\n", "goal", "=", "data", "[", "dial_id", "]", "[", "'goal'", "]", "\n", "if", "''", ".", "join", "(", "state_gen", ")", ".", "replace", "(", "','", ",", "''", ")", "==", "goal", ":", "\n", "                ", "success", "+=", "1", "\n", "", "", "", "return", "block_acc", "/", "total_turn_num", ",", "slot_acc", "/", "total_turn_num", ",", "success", "/", "total_data", "", "", ""]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.add_special_tokens": [[41, 59], ["special_tokens.extend", "tokenizer.add_special_tokens", "special_tokens.append"], "function", ["home.repos.pwc.inspect_result.shunjiu_sstod.None.train.add_special_tokens"], ["def", "add_special_tokens", "(", "tokenizer", ")", ":", "\n", "    ", "\"\"\"\n        add special tokens to gpt tokenizer\n        serves a similar role of Vocab.construt()\n        make a dict of special tokens\n    \"\"\"", "\n", "\n", "special_tokens", "=", "[", "]", "\n", "action", "=", "ontology", ".", "all_acts", "\n", "for", "word", "in", "action", ":", "\n", "        ", "word", "=", "'['", "+", "word", "+", "']'", "\n", "special_tokens", ".", "append", "(", "word", ")", "\n", "\n", "", "special_tokens_list", "=", "ontology", ".", "special_tokens", "\n", "special_tokens", ".", "extend", "(", "special_tokens_list", ")", "\n", "special_tokens_dict", "=", "{", "'additional_special_tokens'", ":", "special_tokens", "}", "\n", "tokenizer", ".", "add_special_tokens", "(", "special_tokens_dict", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.add_torch_input": [[61, 67], ["torch.from_numpy().long", "torch.from_numpy().long", "contexts_tensor.to.to", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "add_torch_input", "(", "inputs", ",", "device", ")", ":", "\n", "# to tensor and to device", "\n", "    ", "contexts_tensor", "=", "torch", ".", "from_numpy", "(", "inputs", "[", "'contexts_np'", "]", ")", ".", "long", "(", ")", "\n", "contexts_tensor", "=", "contexts_tensor", ".", "to", "(", "device", ")", "\n", "inputs", "[", "'contexts_tensor'", "]", "=", "contexts_tensor", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.add_torch_input_eval": [[68, 73], ["torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "add_torch_input_eval", "(", "inputs", ",", "device", ")", ":", "\n", "# inputs: context", "\n", "    ", "inputs", "[", "'context_tensor'", "]", "=", "torch", ".", "tensor", "(", "\n", "[", "inputs", "[", "'context'", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.calculate_loss_and_accuracy": [[75, 92], ["lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "nn.CrossEntropyLoss.", "labels[].contiguous.ne", "shift_labels.ne.long().sum().item", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size", "shift_labels.ne.long().sum", "shift_labels.ne.long"], "function", ["None"], ["", "def", "calculate_loss_and_accuracy", "(", "outputs", ",", "labels", ")", ":", "\n", "    ", "lm_logits", "=", "outputs", "[", "0", "]", "\n", "\n", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "pad_id", "=", "0", "\n", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "pad_id", ",", "reduction", "=", "'sum'", ")", "\n", "loss", "=", "loss_fct", "(", "\n", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "# avg loss", "\n", "not_ignore", "=", "shift_labels", ".", "ne", "(", "pad_id", ")", "\n", "num_targets", "=", "not_ignore", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "loss", "/=", "num_targets", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.train": [[94, 150], ["dataloader.get_batches", "range", "time.time", "optimizer.zero_grad", "dataloader.get_nontranspose_data_iterator", "enumerate", "logging.info", "train.save_model", "dataloader.convert_batch_session", "model.train", "train.add_torch_input", "model", "train.calculate_loss_and_accuracy", "calculate_loss_and_accuracy.backward", "calculate_loss_and_accuracy.item", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "utils.utils.log_first_inputs", "model.parameters", "optimizer.step", "optimizer.zero_grad", "scheduler.step", "logging.info", "tokenizer.decode", "time.time"], "function", ["home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.get_batches", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.get_nontranspose_data_iterator", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.save_model", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.convert_batch_session", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.train", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.add_torch_input", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.calculate_loss_and_accuracy", "home.repos.pwc.inspect_result.shunjiu_sstod.utils.utils.log_first_inputs"], ["", "def", "train", "(", "args", ",", "dataloader", ",", "dev_dataloader", ",", "model", ",", "tokenizer", ",", "writer", ",", "optimizer", ",", "scheduler", ",", "num_train_steps", ",", "device", ")", ":", "\n", "    ", "log_inputs", "=", "2", "\n", "global_step", "=", "0", "\n", "all_batches", "=", "dataloader", ".", "get_batches", "(", "args", ".", "train_batch_size", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "epoch_step", "=", "0", "\n", "tr_loss", "=", "0.0", "\n", "logging_loss", "=", "0.0", "\n", "btm", "=", "time", ".", "time", "(", ")", "\n", "oom_time", "=", "0", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "train_iterator", "=", "dataloader", ".", "get_nontranspose_data_iterator", "(", "all_batches", ")", "\n", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "train_iterator", ")", ":", "\n", "# train", "\n", "            ", "inputs", "=", "dataloader", ".", "convert_batch_session", "(", "batch", ")", "\n", "model", ".", "train", "(", ")", "\n", "if", "log_inputs", ">", "0", ":", "\n", "                ", "log_first_inputs", "(", "{", "'input'", ":", "tokenizer", ".", "decode", "(", "inputs", "[", "'contexts'", "]", "[", "0", "]", ")", "}", ")", "\n", "log_inputs", "-=", "1", "\n", "\n", "# to tensor", "\n", "", "inputs", "=", "add_torch_input", "(", "inputs", ",", "device", ")", "\n", "outputs", "=", "model", "(", "inputs", "[", "'contexts_tensor'", "]", ")", "\n", "loss", "=", "calculate_loss_and_accuracy", "(", "\n", "outputs", ",", "labels", "=", "inputs", "[", "'contexts_tensor'", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip_grad_norm", ")", "\n", "epoch_step", "+=", "1", "\n", "\n", "# step, wrt gradient_accumulation_steps, clip grad norm", "\n", "if", "(", "epoch_step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "(", "epoch_step", "+", "1", "==", "num_train_steps", ")", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "if", "scheduler", "is", "not", "None", ":", "\n", "                    ", "scheduler", ".", "step", "(", ")", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "# global_step: actual step the optimizer took", "\n", "global_step", "+=", "1", "\n", "\n", "logs", "=", "{", "}", "\n", "# logging: loss, lr... after certain amount of steps", "\n", "if", "args", ".", "report_interval", ">", "0", "and", "global_step", "%", "args", ".", "report_interval", "==", "0", ":", "\n", "                    ", "loss_scalar", "=", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "report_interval", "\n", "logging_loss", "=", "tr_loss", "\n", "logs", "[", "'loss'", "]", "=", "loss_scalar", "\n", "logging", ".", "info", "(", "\n", "'Global step: {}, epoch step: {}, interval loss: {:.4f}'", ".", "format", "(", "\n", "global_step", ",", "epoch_step", ",", "loss_scalar", "\n", ")", ")", "\n", "\n", "", "", "", "logging", ".", "info", "(", "'Train epoch time: {:.2f} min, epoch loss: {:.4f}'", ".", "format", "(", "\n", "(", "time", ".", "time", "(", ")", "-", "btm", ")", "/", "60", ",", "tr_loss", ")", ")", "\n", "\n", "# save model after every epoch", "\n", "save_model", "(", "args", ".", "exp_path", ",", "epoch", ",", "tr_loss", "/", "epoch_step", ",", "model", ",", "tokenizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.validate": [[152, 261], ["logging.info", "time.time", "dataloader.wrap_result_lm", "os.path.join", "evaluate.validation_metric_gpt", "logging.info", "torch.no_grad", "torch.no_grad", "enumerate", "tqdm.tqdm", "enumerate", "dataloader.convert_turn_eval", "train.add_torch_input_eval", "len", "tokenizer.convert_tokens_to_ids", "torch.tensor().to", "torch.tensor().to", "len", "model.generate", "outputs[].cpu().numpy().tolist", "torch.tensor().to", "torch.tensor().to", "len", "model.generate", "outputs_db[].cpu().numpy().tolist", "result_collection.update", "train.decode_generated_kdpn", "model.generate", "outputs[].cpu().numpy().tolist", "train.decode_generated_kdpn", "train.decode_outputs_cc", "tokenizer.tokenize", "train.decode_generated_bspn_act", "dataloader.kb.act_to_DBPointer", "tokenizer.convert_tokens_to_ids", "train.decode_generated_resp", "dataloader.inverse_transpose_turn", "len", "model.generate_correct_char", "torch.tensor", "torch.tensor", "outputs[].cpu().numpy", "logging.info", "logging.info", "tokenizer.decode", "tokenizer.tokenize", "torch.tensor", "torch.tensor", "outputs_db[].cpu().numpy", "logging.info", "logging.info", "outputs[].cpu().numpy", "tokenizer.encode", "str", "tokenizer.decode", "tokenizer.encode", "str", "tokenizer.decode", "tokenizer.encode", "outputs[].cpu", "outputs_db[].cpu", "outputs[].cpu", "tokenizer.encode", "tokenizer.encode"], "function", ["home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.wrap_result_lm", "home.repos.pwc.inspect_result.shunjiu_sstod.None.evaluate.validation_metric_gpt", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.convert_turn_eval", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.add_torch_input_eval", "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.generate", "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.generate", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_generated_kdpn", "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.generate", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_generated_kdpn", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_outputs_cc", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_generated_bspn_act", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.DataBase.DB.act_to_DBPointer", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_generated_resp", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.inverse_transpose_turn", "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.generate_correct_char"], ["", "", "def", "validate", "(", "args", ",", "dataloader", ",", "model", ",", "tokenizer", ",", "db", ",", "device", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"**** Running Evaluation ****\"", ")", "\n", "\n", "eval_data", "=", "dataloader", ".", "data", "\n", "btm", "=", "time", ".", "time", "(", ")", "\n", "result_collection", "=", "{", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "dial_idx", ",", "dialog", "in", "enumerate", "(", "tqdm", "(", "eval_data", ")", ")", ":", "\n", "            ", "pv_turn", "=", "{", "}", "\n", "for", "turn_idx", ",", "turn", "in", "enumerate", "(", "dialog", ")", ":", "\n", "                ", "first_turn", "=", "(", "turn_idx", "==", "0", ")", "\n", "inputs", "=", "dataloader", ".", "convert_turn_eval", "(", "turn", ",", "pv_turn", ",", "first_turn", ")", "\n", "inputs", "=", "add_torch_input_eval", "(", "inputs", ",", "device", ")", "\n", "\n", "context_length", "=", "len", "(", "inputs", "[", "'context'", "]", ")", "\n", "\n", "# generate kd_snippets", "\n", "if", "args", ".", "use_true_curr_kdpn", ":", "\n", "                    ", "outputs", "=", "turn", "[", "'kdpn'", "]", "\n", "kdpn_gen", ",", "decoded_kdpn", "=", "decode_generated_kdpn", "(", "tokenizer", ",", "outputs", ")", "\n", "", "else", ":", "\n", "                    ", "max_len", "=", "40", "\n", "outputs", "=", "model", ".", "generate", "(", "input_ids", "=", "inputs", "[", "'context_tensor'", "]", ",", "\n", "max_length", "=", "context_length", "+", "max_len", ",", "temperature", "=", "0.7", ",", "\n", "pad_token_id", "=", "0", ",", "\n", "eos_token_id", "=", "tokenizer", ".", "encode", "(", "'<eos_k>'", ")", "[", "1", "]", ")", "\n", "generated", "=", "outputs", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "kdpn_gen", ",", "decoded_kdpn", "=", "decode_generated_kdpn", "(", "tokenizer", ",", "generated", "[", "context_length", "-", "1", ":", "]", ")", "\n", "\n", "# generate correct_char and score", "\n", "", "if", "args", ".", "use_true_curr_kp", ":", "\n", "                    ", "outputs", "=", "turn", "[", "'cc'", "]", "\n", "decoded_cc", "=", "decode_outputs_cc", "(", "tokenizer", ",", "outputs", ")", "\n", "", "else", ":", "\n", "                    ", "decoded_cc", "=", "model", ".", "generate_correct_char", "(", "decoded_kdpn", ")", "if", "len", "(", "decoded_kdpn", ")", "else", "''", "\n", "\n", "", "ccs", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_c>'", "+", "decoded_cc", "+", "'<eos_c>'", ")", ")", "\n", "inputs", "[", "'context_tensor'", "]", "=", "torch", ".", "tensor", "(", "[", "inputs", "[", "'context'", "]", "[", ":", "-", "1", "]", "+", "kdpn_gen", "+", "ccs", "\n", "+", "tokenizer", ".", "encode", "(", "'<sos_b>'", ",", "\n", "add_special_tokens", "=", "False", ")", "]", ")", ".", "to", "(", "device", ")", "\n", "context_length", "=", "len", "(", "inputs", "[", "'context_tensor'", "]", "[", "0", "]", ")", "\n", "# generate bspn, act, response", "\n", "outputs", "=", "model", ".", "generate", "(", "input_ids", "=", "inputs", "[", "'context_tensor'", "]", ",", "\n", "max_length", "=", "context_length", "+", "80", ",", "temperature", "=", "0.7", ",", "\n", "# top_p=0.9, num_beams=4,", "\n", "pad_token_id", "=", "0", ",", "\n", "eos_token_id", "=", "tokenizer", ".", "encode", "(", "'<eos_a>'", ")", "[", "1", "]", ")", "\n", "generated_bsa", "=", "outputs", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "generated_bsa", "=", "generated_bsa", "[", "context_length", "-", "1", ":", "]", "\n", "try", ":", "\n", "                    ", "bspn_gen", ",", "aspn_gen", "=", "decode_generated_bspn_act", "(", "tokenizer", ",", "generated_bsa", ")", "\n", "", "except", "ValueError", "as", "exception", ":", "\n", "                    ", "logging", ".", "info", "(", "str", "(", "exception", ")", ")", "\n", "logging", ".", "info", "(", "tokenizer", ".", "decode", "(", "generated_bsa", ")", ")", "\n", "aspn_gen", ",", "bspn_gen", "=", "[", "]", ",", "[", "]", "\n", "\n", "# query DB", "\n", "", "if", "args", ".", "use_true_db_pointer", ":", "\n", "                    ", "db", "=", "turn", "[", "'db'", "]", "\n", "", "else", ":", "\n", "\n", "                    ", "db_results", "=", "dataloader", ".", "kb", ".", "act_to_DBPointer", "(", "tokenizer", ".", "decode", "(", "aspn_gen", "[", "1", ":", "-", "1", "]", ")", ")", "\n", "db", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "\n", "tokenizer", ".", "tokenize", "(", "'<sos_db> '", "+", "db_results", "+", "' <eos_db>'", ")", ")", "\n", "", "inputs", "[", "'context_tensor_db'", "]", "=", "torch", ".", "tensor", "(", "\n", "[", "inputs", "[", "'context'", "]", "[", ":", "-", "1", "]", "+", "kdpn_gen", "+", "ccs", "+", "generated_bsa", "+", "db", "+", "tokenizer", ".", "encode", "(", "\n", "'<sos_r>'", ",", "add_special_tokens", "=", "False", ")", "]", ")", ".", "to", "(", "\n", "device", ")", "\n", "\n", "context_length", "=", "len", "(", "inputs", "[", "'context_tensor_db'", "]", "[", "0", "]", ")", "\n", "outputs_db", "=", "model", ".", "generate", "(", "input_ids", "=", "inputs", "[", "'context_tensor_db'", "]", ",", "\n", "max_length", "=", "context_length", "+", "40", ",", "temperature", "=", "0.7", ",", "\n", "# top_p=0.9, num_beams=4,", "\n", "pad_token_id", "=", "0", ",", "\n", "eos_token_id", "=", "tokenizer", ".", "encode", "(", "'<eos_r>'", ")", "[", "1", "]", ")", "\n", "\n", "generated_r", "=", "outputs_db", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "generated_r", "=", "generated_r", "[", "context_length", "-", "1", ":", "]", "\n", "try", ":", "\n", "                    ", "resp_gen", "=", "decode_generated_resp", "(", "tokenizer", ",", "generated_r", ")", "\n", "decoded", "=", "{", "'kdpn'", ":", "kdpn_gen", ",", "'cc'", ":", "ccs", ",", "'bspn'", ":", "bspn_gen", ",", "'aspn'", ":", "aspn_gen", ",", "'resp'", ":", "resp_gen", "}", "\n", "", "except", "ValueError", "as", "exception", ":", "\n", "                    ", "logging", ".", "info", "(", "str", "(", "exception", ")", ")", "\n", "logging", ".", "info", "(", "tokenizer", ".", "decode", "(", "generated_r", ")", ")", "\n", "decoded", "=", "{", "'kdpn'", ":", "[", "]", ",", "'resp'", ":", "[", "]", ",", "'cc'", ":", "[", "]", ",", "'bspn'", ":", "[", "]", ",", "'aspn'", ":", "[", "]", "}", "\n", "\n", "", "turn", "[", "'resp_gen'", "]", "=", "decoded", "[", "'resp'", "]", "\n", "turn", "[", "'kdpn_gen'", "]", "=", "turn", "[", "'kdpn'", "]", "if", "args", ".", "use_true_curr_kdpn", "else", "decoded", "[", "'kdpn'", "]", "\n", "turn", "[", "'cc_gen'", "]", "=", "turn", "[", "'cc'", "]", "if", "args", ".", "use_true_curr_kp", "else", "decoded", "[", "'cc'", "]", "\n", "turn", "[", "'bspn_gen'", "]", "=", "decoded", "[", "'bspn'", "]", "\n", "turn", "[", "'aspn_gen'", "]", "=", "decoded", "[", "'aspn'", "]", "\n", "\n", "pv_turn", "[", "'labels'", "]", "=", "inputs", "[", "'labels'", "]", "# all true previous context", "\n", "pv_turn", "[", "'resp'", "]", "=", "decoded", "[", "'resp'", "]", "\n", "pv_turn", "[", "'bspn'", "]", "=", "decoded", "[", "'bspn'", "]", "\n", "pv_turn", "[", "'kdpn'", "]", "=", "turn", "[", "'kdpn'", "]", "if", "args", ".", "use_true_curr_kdpn", "else", "decoded", "[", "'kdpn'", "]", "\n", "pv_turn", "[", "'cc'", "]", "=", "turn", "[", "'cc'", "]", "if", "args", ".", "use_true_curr_kp", "else", "decoded", "[", "'cc'", "]", "\n", "pv_turn", "[", "'db'", "]", "=", "turn", "[", "'db'", "]", "if", "args", ".", "use_true_db_pointer", "else", "db", "\n", "pv_turn", "[", "'aspn'", "]", "=", "decoded", "[", "'aspn'", "]", "\n", "\n", "result_collection", ".", "update", "(", "\n", "dataloader", ".", "inverse_transpose_turn", "(", "dialog", ")", ")", "\n", "\n", "", "", "", "results", ",", "_", "=", "dataloader", ".", "wrap_result_lm", "(", "result_collection", ")", "\n", "data_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'test.json'", ")", "\n", "joint_acc", ",", "slot_acc", ",", "success", "=", "validation_metric_gpt", "(", "data_path", ",", "dataloader", ",", "results", ")", "\n", "logging", ".", "info", "(", "'test'", "+", "' results: joint_acc: {:.2f}\\tslot_acc: {:.2f}\\tsuccess: {:.2f}'", "\n", ".", "format", "(", "joint_acc", "*", "100", ",", "slot_acc", "*", "100", ",", "success", "*", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_generated_kdpn": [[263, 282], ["tokenizer.decode", "decoded_gen.strip().split.strip().split", "tokenizer.encode", "tokenizer.encode", "tokenizer.encode", "generated.index", "generated.index", "decoded_gen.strip().split.remove", "len", "decoded_gen.strip().split.strip"], "function", ["None"], ["", "def", "decode_generated_kdpn", "(", "tokenizer", ",", "generated", ")", ":", "\n", "    ", "sos_k_id", "=", "tokenizer", ".", "encode", "(", "'<sos_k>'", ")", "[", "1", "]", "\n", "eos_k_id", "=", "tokenizer", ".", "encode", "(", "'<eos_k>'", ")", "[", "1", "]", "\n", "kd_id", "=", "tokenizer", ".", "encode", "(", "'<kd>'", ")", "[", "1", "]", "\n", "if", "sos_k_id", "in", "generated", ":", "\n", "        ", "sos_k_idx", "=", "generated", ".", "index", "(", "sos_k_id", ")", "\n", "", "else", ":", "\n", "        ", "sos_k_idx", "=", "1", "\n", "", "if", "eos_k_id", "in", "generated", ":", "\n", "        ", "eos_k_idx", "=", "generated", ".", "index", "(", "eos_k_id", ")", "\n", "", "else", ":", "\n", "        ", "eos_k_idx", "=", "len", "(", "generated", ")", "-", "1", "\n", "", "kspn_gen", "=", "generated", "[", "sos_k_idx", ":", "eos_k_idx", "+", "1", "]", "\n", "decoded_gen", "=", "tokenizer", ".", "decode", "(", "kspn_gen", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "decoded_gen", "=", "decoded_gen", ".", "strip", "(", ")", ".", "split", "(", "'<kd>'", ")", "\n", "if", "''", "in", "decoded_gen", ":", "\n", "        ", "decoded_gen", ".", "remove", "(", "''", ")", "\n", "", "return", "kspn_gen", ",", "decoded_gen", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_outputs_cc": [[284, 292], ["tokenizer.decode", "cc.append"], "function", ["None"], ["", "def", "decode_outputs_cc", "(", "tokenizer", ",", "outputs", ")", ":", "\n", "    ", "cc", "=", "[", "]", "\n", "for", "output", "in", "outputs", ":", "\n", "        ", "char", "=", "tokenizer", ".", "decode", "(", "output", ")", "\n", "if", "char", "==", "'<sos_c>'", "or", "char", "==", "'<eos_c>'", ":", "\n", "            ", "continue", "\n", "", "cc", ".", "append", "(", "char", ")", "\n", "", "return", "' '", ".", "join", "(", "cc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_generated_bspn_act": [[294, 310], ["generated.index", "tokenizer.encode", "tokenizer.encode", "generated.index", "logging.info", "len", "tokenizer.decode"], "function", ["None"], ["", "def", "decode_generated_bspn_act", "(", "tokenizer", ",", "generated", ")", ":", "\n", "    ", "\"\"\"decode generated\"\"\"", "\n", "eos_b_id", "=", "tokenizer", ".", "encode", "(", "'<eos_b>'", ")", "[", "1", "]", "\n", "eos_a_id", "=", "tokenizer", ".", "encode", "(", "'<eos_a>'", ")", "[", "1", "]", "\n", "\n", "# eos_a may not exists if gpt2 generated repetitive words", "\n", "if", "eos_a_id", "in", "generated", ":", "\n", "        ", "eos_a_idx", "=", "generated", ".", "index", "(", "eos_a_id", ")", "\n", "", "else", ":", "\n", "        ", "eos_a_idx", "=", "len", "(", "generated", ")", "-", "1", "\n", "logging", ".", "info", "(", "'eos_a not in generated: '", "+", "tokenizer", ".", "decode", "(", "generated", ")", ")", "\n", "\n", "", "eos_b_idx", "=", "generated", ".", "index", "(", "eos_b_id", ")", "\n", "bspn_gen", "=", "generated", "[", ":", "eos_b_idx", "+", "1", "]", "\n", "aspn_gen", "=", "generated", "[", "eos_b_idx", "+", "1", ":", "eos_a_idx", "+", "1", "]", "\n", "return", "bspn_gen", ",", "aspn_gen", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.decode_generated_resp": [[312, 319], ["tokenizer.encode", "generated.index", "len"], "function", ["None"], ["", "def", "decode_generated_resp", "(", "tokenizer", ",", "generated", ")", ":", "\n", "    ", "eos_r_id", "=", "tokenizer", ".", "encode", "(", "'<eos_r>'", ")", "[", "1", "]", "\n", "if", "eos_r_id", "in", "generated", ":", "\n", "        ", "eos_r_idx", "=", "generated", ".", "index", "(", "eos_r_id", ")", "\n", "", "else", ":", "\n", "        ", "eos_r_idx", "=", "len", "(", "generated", ")", "-", "1", "\n", "", "return", "generated", "[", ":", "eos_r_idx", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.save_model": [[320, 332], ["os.path.join", "logging.info", "os.path.join", "torch.save", "torch.save", "os.path.exists", "os.mkdir", "hasattr", "model_to_save.state_dict"], "function", ["None"], ["", "def", "save_model", "(", "exp_path", ",", "epoch", ",", "loss", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "exp_path", ",", "'epoch{}_trloss{:.2f}'", ".", "format", "(", "epoch", "+", "1", ",", "loss", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "save_path", ")", "\n", "", "logging", ".", "info", "(", "'Saving model checkpoint to %s'", ",", "save_path", ")", "\n", "\n", "# save model", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'pytorch_model.bin'", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "# save tokenizer", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.load_model": [[335, 339], ["os.path.join", "torch.load", "torch.load", "model.load_state_dict"], "function", ["None"], ["", "def", "load_model", "(", "model", ",", "save_path", ")", ":", "\n", "    ", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'pytorch_model.bin'", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "load_state_dict", "(", "ckpt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.main": [[340, 420], ["config.parser.parse_args", "logger.info", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "reader.DataBase.DB", "transformers.AutoTokenizer.from_pretrained", "train.add_special_tokens", "models.model.UBAR_plus.to", "utils.optim.Optim", "torch.utils.tensorboard.SummaryWriter", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "ValueError", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "ValueError", "os.mkdir", "models.model.UBAR_plus", "models.model.UBAR_plus", "train.load_model", "UBARDataset", "UBARDataset", "int", "utils.optim.Optim.get_optimizer_scheduler", "logger.info", "models.model.UBAR_plus.train", "train.train", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "bool", "os.path.exists", "UBARDataset", "models.model.UBAR_plus.eval", "train.validate", "len"], "function", ["home.repos.pwc.inspect_result.shunjiu_sstod.None.train.add_special_tokens", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.load_model", "home.repos.pwc.inspect_result.shunjiu_sstod.utils.optim.Optim.get_optimizer_scheduler", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.train", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.train", "home.repos.pwc.inspect_result.shunjiu_sstod.None.train.validate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "n_gpu", "=", "0", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "n_gpu", "=", "1", "\n", "", "", "else", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "n_gpu", "=", "1", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "", "logger", ".", "info", "(", "\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", ")", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "args", ".", "mode", "not", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"At least one of `do_train` or `do_eval` must be True.\"", ")", "\n", "\n", "# if os.path.exists(args.exp_path) and os.listdir(args.exp_path):", "\n", "#     raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.exp_path))", "\n", "# os.makedirs(args.exp_path, exist_ok=True)", "\n", "", "if", "args", ".", "mode", "==", "'train'", "and", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "exp_path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "exp_path", ")", "\n", "\n", "", "db", "=", "DB", "(", "args", ".", "db_path", ",", "args", ".", "tfidf_path", ")", "\n", "\n", "# prepare tokenizer and model", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model_path", ")", "\n", "add_special_tokens", "(", "tokenizer", ")", "\n", "if", "args", ".", "mode", "==", "'train'", ":", "\n", "        ", "model", "=", "UBAR_plus", "(", "args", ",", "tokenizer", ",", "device", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "UBAR_plus", "(", "args", ",", "tokenizer", ",", "device", ")", "\n", "load_model", "(", "model", ",", "args", ".", "eval_load_path", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "optim", "=", "Optim", "(", "learning_rate", "=", "args", ".", "learning_rate", ")", "\n", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "'./log'", ")", "\n", "\n", "# prepare dataset", "\n", "train_dataset", "=", "None", "\n", "num_train_steps", "=", "None", "\n", "if", "args", ".", "mode", "==", "'train'", ":", "\n", "        ", "from", "reader", ".", "Dataset", "import", "UBARDataset", "\n", "train_dataset", "=", "UBARDataset", "(", "args", ",", "tokenizer", ",", "args", ".", "data_dir", ",", "'train'", ",", "db", ")", "\n", "dev_dataset", "=", "UBARDataset", "(", "args", ",", "tokenizer", ",", "args", ".", "data_dir", ",", "'dev'", ",", "db", ")", "\n", "num_train_steps", "=", "int", "(", "len", "(", "train_dataset", ")", "*", "args", ".", "num_train_epochs", "/", "args", ".", "train_batch_size", "/", "args", ".", "gradient_accumulation_steps", ")", "\n", "optimizer", ",", "scheduler", "=", "optim", ".", "get_optimizer_scheduler", "(", "model", ",", "num_train_steps", ")", "\n", "\n", "logger", ".", "info", "(", "'start training...'", ")", "\n", "\n", "# train", "\n", "model", ".", "train", "(", ")", "\n", "train", "(", "args", ",", "\n", "dataloader", "=", "train_dataset", ",", "\n", "dev_dataloader", "=", "dev_dataset", ",", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "writer", "=", "writer", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "num_train_steps", "=", "num_train_steps", ",", "\n", "device", "=", "device", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "'test'", ":", "\n", "        ", "from", "reader", ".", "Dataset", "import", "UBARDataset", "\n", "test_data", "=", "UBARDataset", "(", "args", ",", "tokenizer", ",", "args", ".", "data_dir", ",", "'test'", ",", "db", ")", "\n", "model", ".", "eval", "(", ")", "\n", "validate", "(", "args", ",", "test_data", ",", "model", ",", "tokenizer", ",", "db", ",", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.utils.optim.Optim.__init__": [[8, 15], ["params.get", "params.get", "params.get", "params.get", "params.get"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "params", "=", "kwargs", "\n", "self", ".", "lr", "=", "params", ".", "get", "(", "'learning_rate'", ",", "1e-4", ")", "\n", "self", ".", "method", "=", "params", ".", "get", "(", "'method'", ",", "'adamw'", ")", "\n", "self", ".", "weight_decay", "=", "params", ".", "get", "(", "'weight_decay'", ",", "0.0", ")", "\n", "self", ".", "lr_decay", "=", "params", ".", "get", "(", "'lr_decay'", ",", "0.0", ")", "\n", "self", ".", "warmup_steps", "=", "params", ".", "get", "(", "'warmup_steps'", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.utils.optim.Optim.get_optimizer_scheduler": [[16, 39], ["transformers.optimization.get_linear_schedule_with_warmup", "torch.optim.SGD", "int", "torch.optim.Adam", "transformers.optimization.AdamW", "RuntimeError", "model.named_parameters", "model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "get_optimizer_scheduler", "(", "self", ",", "model", ",", "t_total", ")", ":", "\n", "        ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adamw'", ":", "\n", "# optimizer = optim.AdamW(optimizer_grouped_parameters, lr=self.lr)", "\n", "            ", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "", "num_warmup_steps", "=", "self", ".", "warmup_steps", "if", "self", ".", "warmup_steps", ">=", "0", "else", "int", "(", "t_total", "*", "0.2", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "num_warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "return", "optimizer", ",", "scheduler", "\n", "", "", ""]], "home.repos.pwc.inspect_result.shunjiu_sstod.utils.utils.log_first_inputs": [[10, 14], ["logging.info", "log_dict.items", "logging.info"], "function", ["None"], []], "home.repos.pwc.inspect_result.shunjiu_sstod.utils.utils.padSeqs_gpt": [[16, 47], ["len", "numpy.max", "enumerate", "lengths.append", "numpy.ones", "numpy.asarray", "len", "len", "print", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.shunjiu_sstod.utils.utils.padSeqs": [[49, 100], ["len", "numpy.max", "tuple", "enumerate", "hasattr", "ValueError", "lengths.append", "min", "numpy.asarray", "hasattr", "ValueError", "len", "len", "len", "print", "ValueError", "numpy.ones", "ValueError", "ValueError", "str", "numpy.asarray", "len", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.shunjiu_sstod.utils.utils.maskedNll": [[101, 123], ["target.data.ne", "isinstance", "isinstance", "torch.gather().squeeze", "torch.masked_select", "torch.autograd.Variable", "seq.size", "torch.gather", "torch.sum", "target.unsqueeze"], "function", ["None"], []], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.DataBase.DB.__init__": [[18, 21], ["DataBase.DB.read_db"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.reader.DataBase.DB.read_db"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "tfidf_path", ")", ":", "\n", "        ", "self", ".", "db", "=", "[", "]", "\n", "self", ".", "read_db", "(", "path", ")", "\n", "# self.vectorizer, self.weight = self.load_tf_idf_vector(tfidf_path)", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.DataBase.DB.read_db": [[23, 41], ["db_file[].items", "open", "json.load", "DataBase.DB.db.append", "DataBase.DB.db.append", "DataBase.DB.word2kd[].append"], "methods", ["None"], ["", "def", "read_db", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "db_file", "=", "json", ".", "load", "(", "f", ")", "\n", "", "for", "word", ",", "descs", "in", "db_file", "[", "'nameDict'", "]", ".", "items", "(", ")", ":", "\n", "            ", "word_descs", "=", "descs", "[", "'word'", "]", "\n", "struct_descs", "=", "descs", "[", "'pack'", "]", "\n", "for", "desc", "in", "word_descs", ":", "\n", "                ", "self", ".", "db", ".", "append", "(", "(", "word", ",", "'word'", ",", "desc", ")", ")", "\n", "\n", "", "for", "desc", "in", "struct_descs", ":", "\n", "                ", "self", ".", "db", ".", "append", "(", "(", "word", ",", "'pack'", ",", "desc", ")", ")", "\n", "\n", "", "", "self", ".", "word2kd", "=", "{", "}", "\n", "for", "kd", "in", "self", ".", "db", ":", "\n", "            ", "if", "kd", "[", "0", "]", "in", "self", ".", "word2kd", ":", "\n", "                ", "self", ".", "word2kd", "[", "kd", "[", "0", "]", "]", ".", "append", "(", "kd", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "word2kd", "[", "kd", "[", "0", "]", "]", "=", "[", "kd", "[", "2", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.DataBase.DB.act_to_DBPointer": [[79, 105], ["action[].strip", "action.index", "action.index", "len", "len", "random.choice", "db_pointer.append"], "methods", ["None"], ["", "", "", "def", "act_to_DBPointer", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"\n        Select a knowledge for a sub-slot.\n        \"\"\"", "\n", "if", "'['", "in", "action", ":", "\n", "            ", "act_s_idx", "=", "action", ".", "index", "(", "'['", ")", "\n", "", "else", ":", "\n", "            ", "act_s_idx", "=", "0", "\n", "", "if", "']'", "in", "action", ":", "\n", "            ", "act_e_idx", "=", "action", ".", "index", "(", "']'", ")", "\n", "", "else", ":", "\n", "            ", "act_e_idx", "=", "len", "(", "action", ")", "-", "1", "\n", "", "act", "=", "action", "[", "act_s_idx", "+", "1", ":", "act_e_idx", "]", "\n", "param", "=", "action", "[", "act_e_idx", "+", "1", ":", "]", ".", "strip", "(", ")", "\n", "if", "action", "not", "in", "ontology", ".", "action", ":", "\n", "            ", "return", "''", "\n", "", "db_pointer", "=", "[", "]", "\n", "if", "act", "==", "'explicit_confirm'", ":", "\n", "            ", "for", "w", "in", "param", ":", "\n", "                ", "if", "w", "in", "self", ".", "word2kd", ":", "\n", "                    ", "db", "=", "random", ".", "choice", "(", "self", ".", "word2kd", "[", "w", "]", ")", "\n", "db_pointer", ".", "append", "(", "db", ")", "\n", "", "", "", "db_results", "=", "';'", ".", "join", "(", "db_pointer", ")", "\n", "if", "len", "(", "db_results", ")", ">", "40", ":", "\n", "            ", "db_results", "=", "db_results", "[", ":", "40", "]", "\n", "", "return", "db_results", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.data_util.read_name_dialog_from_file": [[4, 71], ["data_json.items", "dialog[].append", "len", "dict", "data_iter[].append", "kd_span.append", "copy.deepcopy", "len", "correct_char_list.append", "len", "db.append"], "function", ["None"], ["def", "read_name_dialog_from_file", "(", "data_json", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "for", "name", ",", "dialog", "in", "data_json", ".", "items", "(", ")", ":", "\n", "        ", "data_iter", "=", "{", "'goal'", ":", "dialog", "[", "'goal_value'", "]", "[", "'name'", "]", ",", "'log'", ":", "[", "]", ",", "'results'", ":", "dialog", "[", "'results'", "]", "}", "\n", "turn", "=", "0", "\n", "turn_num", "=", "0", "\n", "assert", "'staff'", "in", "dialog", "[", "'turns'", "]", "[", "0", "]", "\n", "if", "'staff'", "not", "in", "dialog", "[", "'turns'", "]", "[", "-", "1", "]", ":", "\n", "            ", "dialog", "[", "'turns'", "]", ".", "append", "(", "{", "\n", "'staff'", ":", "'\u597d\u7684\uff0c\u518d\u89c1'", ",", "\n", "'staff_label'", ":", "[", "{", "\n", "'action'", ":", "\"bye\"", ",", "\n", "\"param-knowledge\"", ":", "[", "]", ",", "\n", "\"param-name\"", ":", "None", "\n", "}", "]", ",", "\n", "'staff_state'", ":", "dialog", "[", "'turns'", "]", "[", "-", "1", "]", "[", "'user_state'", "]", "\n", "}", ")", "\n", "\n", "", "turn", "+=", "1", "\n", "data_turn_iter", "=", "{", "}", "\n", "while", "turn", "<", "len", "(", "dialog", "[", "'turns'", "]", ")", ":", "\n", "            ", "data_turn_iter", "[", "'user'", "]", "=", "dialog", "[", "'turns'", "]", "[", "turn", "]", "[", "'user'", "]", "\n", "user_label", "=", "dialog", "[", "'turns'", "]", "[", "turn", "]", "[", "'user_label'", "]", "[", "0", "]", "\n", "# data_turn_iter['user_act'] = user_label['action']", "\n", "\n", "kd_span", "=", "[", "]", "\n", "asr_char", "=", "{", "}", "\n", "for", "kd", "in", "user_label", "[", "'param-knowledge'", "]", ":", "\n", "                ", "correct_char", "=", "kd", "[", "'correct_char'", "]", "\n", "char_knowledge", "=", "[", "t", "[", "'string'", "]", "for", "t", "in", "kd", "[", "'knowledge'", "]", "]", "\n", "kd_span", ".", "append", "(", "(", "correct_char", ",", "' '", ".", "join", "(", "char_knowledge", ")", ")", ")", "\n", "\n", "", "data_turn_iter", "[", "'asr_char'", "]", "=", "dict", "(", "asr_char", ")", "\n", "data_turn_iter", "[", "'kdpn'", "]", "=", "''", "\n", "correct_char_list", "=", "[", "]", "\n", "for", "kd", "in", "kd_span", ":", "\n", "                ", "if", "len", "(", "kd", "[", "1", "]", ")", ">", "0", ":", "\n", "                    ", "data_turn_iter", "[", "'kdpn'", "]", "+=", "' <kd> '", "+", "kd", "[", "1", "]", "\n", "correct_char_list", ".", "append", "(", "kd", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "data_turn_iter", "[", "'kdpn'", "]", "+=", "''", "\n", "", "", "data_turn_iter", "[", "'correct_char'", "]", "=", "','", ".", "join", "(", "correct_char_list", ")", "\n", "\n", "turn", "+=", "1", "\n", "data_turn_iter", "[", "'sys'", "]", "=", "dialog", "[", "'turns'", "]", "[", "turn", "]", "[", "'staff'", "]", "\n", "staff_label", "=", "dialog", "[", "'turns'", "]", "[", "turn", "]", "[", "'staff_label'", "]", "[", "0", "]", "\n", "sys_action", "=", "staff_label", "[", "'action'", "]", "\n", "data_turn_iter", "[", "'bs'", "]", "=", "','", ".", "join", "(", "[", "sample", "[", "'char'", "]", "for", "sample", "in", "dialog", "[", "'turns'", "]", "[", "turn", "]", "[", "'staff_state'", "]", "]", ")", "\n", "\n", "db", "=", "[", "]", "\n", "action_param", "=", "''", "\n", "for", "knowledge", "in", "staff_label", "[", "'param-knowledge'", "]", ":", "\n", "                ", "char", "=", "knowledge", "[", "'char'", "]", "\n", "action_param", "+=", "char", "\n", "kd", "=", "' '", ".", "join", "(", "[", "kd", "[", "'string'", "]", "for", "kd", "in", "knowledge", "[", "'knowledge'", "]", "]", ")", "\n", "if", "len", "(", "kd", ")", ">", "0", ":", "\n", "                    ", "db", ".", "append", "(", "char", "+", "':'", "+", "kd", ")", "\n", "", "", "data_turn_iter", "[", "'sys_act'", "]", "=", "sys_action", "\n", "data_turn_iter", "[", "'sys_act_param'", "]", "=", "action_param", "\n", "data_turn_iter", "[", "'db'", "]", "=", "db", "\n", "data_turn_iter", "[", "'turn_num'", "]", "=", "turn_num", "\n", "data_iter", "[", "'log'", "]", ".", "append", "(", "copy", ".", "deepcopy", "(", "data_turn_iter", ")", ")", "\n", "turn", "+=", "1", "\n", "turn_num", "+=", "1", "\n", "", "data", "[", "name", "]", "=", "data_iter", "\n", "\n", "", "return", "data", "", "", ""]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.__init__": [[16, 22], ["torch.utils.data.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.kb.tf_idf_kd.Tf_idf.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "_BaseDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "None", "\n", "self", ".", "db", "=", "None", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "set_stats", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset._bucket_by_turn": [[23, 38], ["collections.OrderedDict", "len", "turn_bucket[].append", "logging.debug", "sorted", "del_l.append", "turn_bucket.items", "len"], "methods", ["None"], ["", "def", "_bucket_by_turn", "(", "self", ",", "encoded_data", ")", ":", "\n", "        ", "turn_bucket", "=", "{", "}", "\n", "for", "dial", "in", "encoded_data", ":", "\n", "            ", "turn_len", "=", "len", "(", "dial", ")", "\n", "if", "turn_len", "not", "in", "turn_bucket", ":", "\n", "                ", "turn_bucket", "[", "turn_len", "]", "=", "[", "]", "\n", "", "turn_bucket", "[", "turn_len", "]", ".", "append", "(", "dial", ")", "\n", "", "del_l", "=", "[", "]", "\n", "for", "k", "in", "turn_bucket", ":", "\n", "            ", "if", "k", ">=", "5", ":", "\n", "                ", "del_l", ".", "append", "(", "k", ")", "\n", "", "logging", ".", "debug", "(", "\"bucket %d instance %d\"", "%", "(", "k", ",", "len", "(", "turn_bucket", "[", "k", "]", ")", ")", ")", "\n", "# for k in del_l:", "\n", "#    turn_bucket.pop(k)", "\n", "", "return", "OrderedDict", "(", "sorted", "(", "turn_bucket", ".", "items", "(", ")", ",", "key", "=", "lambda", "i", ":", "i", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset._construct_mini_batch": [[39, 57], ["batch.append", "len", "all_batches.append", "len", "len", "all_batches.append", "all_batches[].extend", "all_batches.append"], "methods", ["None"], ["", "def", "_construct_mini_batch", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "        ", "all_batches", "=", "[", "]", "\n", "batch", "=", "[", "]", "\n", "for", "dial", "in", "data", ":", "\n", "            ", "batch", ".", "append", "(", "dial", ")", "\n", "if", "len", "(", "batch", ")", "==", "batch_size", ":", "\n", "# print('batch size: %d, batch num +1'%(len(batch)))", "\n", "                ", "all_batches", ".", "append", "(", "batch", ")", "\n", "batch", "=", "[", "]", "\n", "# if remainder > 1/2 batch_size, just put them in the previous batch, otherwise form a new batch", "\n", "# print('last batch size: %d, batch num +1'%(len(batch)))", "\n", "", "", "if", "len", "(", "batch", ")", ">", "0.5", "*", "batch_size", ":", "\n", "            ", "all_batches", ".", "append", "(", "batch", ")", "\n", "", "elif", "len", "(", "all_batches", ")", ":", "\n", "            ", "all_batches", "[", "-", "1", "]", ".", "extend", "(", "batch", ")", "\n", "", "else", ":", "\n", "            ", "all_batches", ".", "append", "(", "batch", ")", "\n", "", "return", "all_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.transpose_batch": [[58, 71], ["len", "range", "dial_batch.append", "turn_l[].append"], "methods", ["None"], ["", "def", "transpose_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "dial_batch", "=", "[", "]", "\n", "turn_num", "=", "len", "(", "batch", "[", "0", "]", ")", "\n", "for", "turn", "in", "range", "(", "turn_num", ")", ":", "\n", "            ", "turn_l", "=", "{", "}", "\n", "for", "dial", "in", "batch", ":", "\n", "                ", "this_turn", "=", "dial", "[", "turn", "]", "\n", "for", "k", "in", "this_turn", ":", "\n", "                    ", "if", "k", "not", "in", "turn_l", ":", "\n", "                        ", "turn_l", "[", "k", "]", "=", "[", "]", "\n", "", "turn_l", "[", "k", "]", ".", "append", "(", "this_turn", "[", "k", "]", ")", "\n", "", "", "dial_batch", ".", "append", "(", "turn_l", ")", "\n", "", "return", "dial_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.get_nontranspose_data_iterator": [[72, 75], ["enumerate"], "methods", ["None"], ["", "def", "get_nontranspose_data_iterator", "(", "self", ",", "all_batches", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "all_batches", ")", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.inverse_transpose_turn": [[76, 96], ["len", "range", "turn.items", "dialogs[].append", "torch.utils.data.Dataset._BaseDataset.db.pointerBack"], "methods", ["None"], ["", "", "def", "inverse_transpose_turn", "(", "self", ",", "turn_list", ")", ":", "\n", "        ", "\"\"\"\n        eval, one dialog at a time\n        \"\"\"", "\n", "dialogs", "=", "{", "}", "\n", "turn_num", "=", "len", "(", "turn_list", ")", "\n", "dial_id", "=", "turn_list", "[", "0", "]", "[", "'dial_id'", "]", "\n", "dialogs", "[", "dial_id", "]", "=", "[", "]", "\n", "for", "turn_idx", "in", "range", "(", "turn_num", ")", ":", "\n", "            ", "dial_turn", "=", "{", "}", "\n", "turn", "=", "turn_list", "[", "turn_idx", "]", "\n", "for", "key", ",", "value", "in", "turn", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "==", "'dial_id'", ":", "\n", "                    ", "continue", "\n", "", "if", "key", "==", "'pointer'", "and", "self", ".", "db", "is", "not", "None", ":", "\n", "                    ", "turn_domain", "=", "turn", "[", "'turn_domain'", "]", "[", "-", "1", "]", "\n", "value", "=", "self", ".", "db", ".", "pointerBack", "(", "value", ",", "turn_domain", ")", "\n", "", "dial_turn", "[", "key", "]", "=", "value", "\n", "", "dialogs", "[", "dial_id", "]", ".", "append", "(", "dial_turn", ")", "\n", "", "return", "dialogs", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.inverse_transpose_batch": [[97, 119], ["len", "enumerate", "range", "turn_batch.items", "dialogs[].append", "torch.utils.data.Dataset._BaseDataset.db.pointerBack"], "methods", ["None"], ["", "def", "inverse_transpose_batch", "(", "self", ",", "turn_batch_list", ")", ":", "\n", "        ", "\"\"\"\n        :param turn_batch_list: list of transpose dial batch\n        \"\"\"", "\n", "dialogs", "=", "{", "}", "\n", "total_turn_num", "=", "len", "(", "turn_batch_list", ")", "\n", "# initialize", "\n", "for", "idx_in_batch", ",", "dial_id", "in", "enumerate", "(", "turn_batch_list", "[", "0", "]", "[", "'dial_id'", "]", ")", ":", "\n", "            ", "dialogs", "[", "dial_id", "]", "=", "[", "]", "\n", "for", "turn_n", "in", "range", "(", "total_turn_num", ")", ":", "\n", "                ", "dial_turn", "=", "{", "}", "\n", "turn_batch", "=", "turn_batch_list", "[", "turn_n", "]", "\n", "for", "key", ",", "v_list", "in", "turn_batch", ".", "items", "(", ")", ":", "\n", "                    ", "if", "key", "==", "'dial_id'", ":", "\n", "                        ", "continue", "\n", "", "value", "=", "v_list", "[", "idx_in_batch", "]", "\n", "if", "key", "==", "'pointer'", "and", "self", ".", "db", "is", "not", "None", ":", "\n", "                        ", "turn_domain", "=", "turn_batch", "[", "'turn_domain'", "]", "[", "idx_in_batch", "]", "[", "-", "1", "]", "\n", "value", "=", "self", ".", "db", ".", "pointerBack", "(", "value", ",", "turn_domain", ")", "\n", "", "dial_turn", "[", "key", "]", "=", "value", "\n", "", "dialogs", "[", "dial_id", "]", ".", "append", "(", "dial_turn", ")", "\n", "", "", "return", "dialogs", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.__getitem__": [[120, 122], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.__len__": [[123, 125], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset.collate_fn": [[126, 128], ["None"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "data_batch", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.__init__": [[131, 139], ["torch.utils.data.Dataset._BaseDataset.__init__", "torch.utils.data.Dataset.UBARDataset._load_data"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.kb.tf_idf_kd.Tf_idf.__init__", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset._load_data"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "tokenizer", ",", "data_path", ",", "mode", ",", "kb", ")", ":", "\n", "        ", "super", "(", "UBARDataset", ",", "self", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "kb", "=", "kb", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "args", ".", "mode", "=", "mode", "\n", "self", ".", "pad_token_id", "=", "0", "\n", "self", ".", "_load_data", "(", "data_path", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset._load_data": [[140, 158], ["os.path.join", "os.path.exists", "logging.info", "os.path.join", "torch.utils.data.Dataset.UBARDataset.read_data", "torch.utils.data.Dataset.UBARDataset._get_seqs", "json.dump", "copy.deepcopy", "random.shuffle", "logging.info", "json.load", "copy.deepcopy", "random.shuffle", "open", "open"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.read_data", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset._get_seqs"], ["", "def", "_load_data", "(", "self", ",", "data_path", ",", "mode", ")", ":", "\n", "        ", "encoded_file_list", "=", "{", "'train'", ":", "'train.encoded.UBARdata.json'", ",", "'dev'", ":", "'dev.encoded.UBARdata.json'", ",", "\n", "'test'", ":", "'test.encoded.UBARdata.json'", "}", "\n", "encoded_file", "=", "encoded_file_list", "[", "mode", "]", "\n", "encoded_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "encoded_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "encoded_file", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'Encoding data and save the encoded data in {}'", ".", "format", "(", "encoded_file", ")", ")", "\n", "raw_data_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "mode", "+", "'.json'", ")", "\n", "dialogs", "=", "self", ".", "read_data", "(", "raw_data_path", ")", "\n", "encoded_data", "=", "self", ".", "_get_seqs", "(", "dialogs", ")", "\n", "json", ".", "dump", "(", "encoded_data", ",", "open", "(", "encoded_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ",", "indent", "=", "2", ",", "ensure_ascii", "=", "False", ")", "\n", "self", ".", "data", "=", "copy", ".", "deepcopy", "(", "encoded_data", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'loading encoded data from {}'", ".", "format", "(", "encoded_file", ")", ")", "\n", "encoded_data", "=", "json", ".", "load", "(", "open", "(", "encoded_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "self", ".", "data", "=", "copy", ".", "deepcopy", "(", "encoded_data", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.read_data": [[159, 164], ["reader.data_util.read_name_dialog_from_file", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.reader.data_util.read_name_dialog_from_file"], ["", "", "def", "read_data", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "raw_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "data_file", "=", "read_name_dialog_from_file", "(", "raw_data", ")", "\n", "return", "data_file", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset._get_seqs": [[165, 198], ["dialogs.items", "enumerate", "data_list.append", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "encoded_dial.append", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "torch.utils.data.Dataset.UBARDataset.tokenizer.convert_tokens_to_ids", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize", "torch.utils.data.Dataset.UBARDataset.tokenizer.tokenize"], "methods", ["None"], ["", "def", "_get_seqs", "(", "self", ",", "dialogs", ")", ":", "\n", "        ", "data_list", "=", "[", "]", "\n", "for", "fn", ",", "dial", "in", "dialogs", ".", "items", "(", ")", ":", "\n", "            ", "encoded_dial", "=", "[", "]", "\n", "for", "idx", ",", "t", "in", "enumerate", "(", "dial", "[", "'log'", "]", ")", ":", "\n", "                ", "enc", "=", "{", "}", "\n", "enc", "[", "'dial_id'", "]", "=", "fn", "\n", "enc", "[", "'user'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_u> '", "+", "\n", "t", "[", "'user'", "]", "+", "' <eos_u>'", ")", ")", "\n", "enc", "[", "'resp'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_r> '", "+", "\n", "t", "[", "'sys'", "]", "+", "' <eos_r>'", ")", ")", "\n", "enc", "[", "'bspn'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_b> '", "+", "t", "[", "'bs'", "]", "+", "' <eos_b>'", ")", ")", "\n", "enc", "[", "'aspn'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_a> '", "+", "'['", "+", "\n", "t", "[", "'sys_act'", "]", "+", "']'", "+", "t", "[", "'sys_act_param'", "]", "+", "' <eos_a>'", ")", ")", "\n", "enc", "[", "'turn_num'", "]", "=", "t", "[", "'turn_num'", "]", "\n", "if", "'db'", "in", "t", ":", "\n", "                    ", "enc", "[", "'db'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_db> '", "+", "'[SEP]'", ".", "join", "(", "t", "[", "'db'", "]", ")", "+", "' <eos_db>'", ")", ")", "\n", "", "else", ":", "\n", "                    ", "enc", "[", "'db'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_db> '", "+", "' <eos_db>'", ")", ")", "\n", "", "enc", "[", "'cc'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_c> '", "+", "t", "[", "'correct_char'", "]", "+", "' <eos_c>'", ")", ")", "\n", "enc", "[", "'kdpn'", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "'<sos_k>'", "+", "t", "[", "'kdpn'", "]", "+", "'<eos_k>'", ")", ")", "\n", "\n", "encoded_dial", ".", "append", "(", "enc", ")", "\n", "", "data_list", ".", "append", "(", "encoded_dial", ")", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.convert_batch_session": [[199, 220], ["enumerate", "utils.utils.utils.padSeqs_gpt", "enumerate", "contexts.append", "context.extend"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.utils.utils.padSeqs_gpt"], ["", "def", "convert_batch_session", "(", "self", ",", "dial_batch", ")", ":", "\n", "        ", "\"\"\"\n        convert the whole session for training\n        concat [U_0, K_0, c_0, B_0, A_0, R_0, ... , U_n, K_n, c_n, B_n, A_n, R_n]\n        \"\"\"", "\n", "\n", "inputs", ",", "outputs", "=", "{", "}", ",", "{", "}", "\n", "contexts", "=", "[", "]", "\n", "\n", "cell_list", "=", "[", "'user'", ",", "'kdpn'", ",", "'cc'", ",", "'bspn'", ",", "'aspn'", ",", "'db'", ",", "'resp'", "]", "\n", "for", "idx", ",", "dial", "in", "enumerate", "(", "dial_batch", ")", ":", "\n", "            ", "context", "=", "[", "]", "\n", "for", "turn_num", ",", "turn", "in", "enumerate", "(", "dial", ")", ":", "\n", "                ", "for", "cell", "in", "cell_list", ":", "\n", "                    ", "context", ".", "extend", "(", "turn", "[", "cell", "]", ")", "\n", "", "", "contexts", ".", "append", "(", "context", ")", "\n", "\n", "", "inputs", "[", "'contexts'", "]", "=", "contexts", "\n", "inputs", "[", "'contexts_np'", "]", ",", "inputs", "[", "'lengths'", "]", "=", "utils", ".", "padSeqs_gpt", "(", "inputs", "[", "'contexts'", "]", ",", "self", ".", "pad_token_id", ")", "\n", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.get_batches": [[221, 251], ["torch.utils.data.Dataset.UBARDataset._bucket_by_turn", "torch.utils.data.Dataset.UBARDataset._construct_mini_batch", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset._bucket_by_turn", "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset._BaseDataset._construct_mini_batch"], ["", "def", "get_batches", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        compute dataset stats.\n        \"\"\"", "\n", "global", "dia_count", "\n", "log_str", "=", "''", "\n", "dial", "=", "self", ".", "data", "\n", "turn_bucket", "=", "self", ".", "_bucket_by_turn", "(", "dial", ")", "\n", "# self._shuffle_turn_bucket(turn_bucket)", "\n", "all_batches", "=", "[", "]", "\n", "\n", "num_training_steps", "=", "0", "\n", "num_turns", "=", "0", "\n", "num_dials", "=", "0", "\n", "\n", "for", "k", "in", "turn_bucket", ":", "\n", "            ", "if", "k", "==", "1", "or", "k", ">=", "17", ":", "\n", "                ", "continue", "\n", "", "batches", "=", "self", ".", "_construct_mini_batch", "(", "turn_bucket", "[", "k", "]", ",", "batch_size", ")", "\n", "log_str", "+=", "\"turn num:%d, batch num: %d last batch len: %d\\n\"", "%", "(", "\n", "k", ",", "len", "(", "batches", ")", ",", "len", "(", "batches", "[", "-", "1", "]", ")", ")", "\n", "# print(\"turn num:%d, dial num:v%d, batch num: %d, \"%(k, len(turn_bucket[k]), len(batches)))", "\n", "num_training_steps", "+=", "k", "*", "len", "(", "batches", ")", "\n", "num_turns", "+=", "k", "*", "len", "(", "turn_bucket", "[", "k", "]", ")", "\n", "num_dials", "+=", "len", "(", "turn_bucket", "[", "k", "]", ")", "\n", "all_batches", "+=", "batches", "\n", "", "log_str", "+=", "'total batch num: %d\\n'", "%", "len", "(", "all_batches", ")", "\n", "# print('total batch num: %d'%len(all_batches))", "\n", "\n", "return", "all_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.convert_turn_eval": [[252, 294], ["len", "torch.utils.data.Dataset.UBARDataset.tokenizer.encode", "torch.utils.data.Dataset.UBARDataset.tokenizer.encode"], "methods", ["None"], ["", "def", "convert_turn_eval", "(", "self", ",", "turn", ",", "pv_turn", ",", "first_turn", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        input: [all previous ubar, U_t, B_t, A_t] predict R_t\n            firts turn: [U_t, B_t, A_t] predict R_t\n\n        regarding the context, all previous ubar is too slow, try the previous ubar\n        \"\"\"", "\n", "inputs", "=", "{", "}", "\n", "\n", "context_list", "=", "[", "]", "\n", "# predict_list = []", "\n", "prompt", "=", "''", "\n", "# predict bspn aspn resp. db are not predicted. this part tbd.", "\n", "context_list", "=", "[", "'user'", "]", "\n", "# predict_list = ['bspn', 'aspn','db', 'resp']", "\n", "prompt", "=", "'<sos_k>'", "\n", "\n", "if", "first_turn", ":", "\n", "            ", "context", "=", "[", "]", "\n", "for", "c", "in", "context_list", ":", "\n", "                ", "context", "+=", "turn", "[", "c", "]", "\n", "\n", "", "inputs", "[", "'context'", "]", "=", "context", "+", "self", ".", "tokenizer", ".", "encode", "(", "prompt", ",", "add_special_tokens", "=", "False", ")", "\n", "inputs", "[", "'labels'", "]", "=", "context", "\n", "\n", "", "else", ":", "\n", "            ", "context", "=", "[", "]", "\n", "for", "c", "in", "context_list", ":", "\n", "                ", "context", "+=", "turn", "[", "c", "]", "\n", "\n", "", "pv_context", "=", "pv_turn", "[", "'labels'", "]", "+", "pv_turn", "[", "'kdpn'", "]", "+", "pv_turn", "[", "'cc'", "]", "+", "pv_turn", "[", "'bspn'", "]", "+", "pv_turn", "[", "'aspn'", "]", "+", "pv_turn", "[", "'db'", "]", "+", "pv_turn", "[", "'resp'", "]", "\n", "\n", "# prompt response, add sos_r", "\n", "inputs", "[", "'context'", "]", "=", "pv_context", "+", "context", "+", "self", ".", "tokenizer", ".", "encode", "(", "prompt", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "inputs", "[", "'labels'", "]", "=", "pv_context", "+", "context", "# use all previous ubar history", "\n", "\n", "", "if", "len", "(", "inputs", "[", "'context'", "]", ")", ">", "900", ":", "\n", "# print('len exceeds 900')", "\n", "            ", "inputs", "[", "'context'", "]", "=", "inputs", "[", "'context'", "]", "[", "-", "900", ":", "]", "\n", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.wrap_result_lm": [[295, 328], ["result_dict.items", "enumerate", "results.append", "turn.get", "torch.utils.data.Dataset.UBARDataset.tokenizer.decode", "v.split.split.split", "v.split.split.remove", "v.split.split.remove"], "methods", ["None"], ["", "def", "wrap_result_lm", "(", "self", ",", "result_dict", ",", "eos_syntax", "=", "None", ")", ":", "\n", "        ", "results", "=", "[", "]", "\n", "eos_syntax", "=", "ontology", ".", "eos_tokens", "if", "not", "eos_syntax", "else", "eos_syntax", "\n", "sos_syntax", "=", "ontology", ".", "sos_tokens", "\n", "# ground truth bs, as, ds.. generate response", "\n", "field", "=", "[", "'dial_id'", ",", "'turn_num'", ",", "'user'", ",", "'bspn_gen'", ",", "'resp_gen'", ",", "'resp'", ",", "'aspn_gen'", ",", "'aspn'", ",", "\n", "'bspn'", ",", "'kdpn'", ",", "'kdpn_gen'", ",", "'cc'", ",", "'cc_gen'", "]", "\n", "for", "dial_id", ",", "turns", "in", "result_dict", ".", "items", "(", ")", ":", "\n", "\n", "            ", "for", "turn_idx", ",", "turn", "in", "enumerate", "(", "turns", ")", ":", "\n", "                ", "entry", "=", "{", "'dial_id'", ":", "dial_id", "}", "\n", "for", "key", "in", "field", ":", "\n", "                    ", "if", "key", "in", "[", "'dial_id'", "]", ":", "\n", "                        ", "continue", "\n", "", "v", "=", "turn", ".", "get", "(", "key", ",", "''", ")", "\n", "if", "key", "in", "eos_syntax", "and", "v", "!=", "''", ":", "\n", "# remove eos tokens", "\n", "                        ", "v", "=", "self", ".", "tokenizer", ".", "decode", "(", "v", ")", "\n", "v", "=", "v", ".", "split", "(", ")", "\n", "# remove eos/sos in span", "\n", "if", "eos_syntax", "[", "key", "]", "in", "v", ":", "\n", "                            ", "v", ".", "remove", "(", "eos_syntax", "[", "key", "]", ")", "\n", "", "if", "sos_syntax", "[", "key", "]", "in", "v", ":", "\n", "                            ", "v", ".", "remove", "(", "sos_syntax", "[", "key", "]", ")", "\n", "\n", "", "v", "=", "\" \"", ".", "join", "(", "v", ")", "\n", "", "else", ":", "\n", "                        ", "pass", "# v = v", "\n", "", "entry", "[", "key", "]", "=", "v", "\n", "\n", "", "results", ".", "append", "(", "entry", ")", "\n", "\n", "", "", "return", "results", ",", "field", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.reader.Dataset.UBARDataset.__len__": [[329, 331], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.shunjiu_sstod.models.TFIDF.TfIdf.__init__": [[14, 19], ["pickle.load", "pickle.load", "json.load", "open", "open", "open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word_vectorizer", ",", "self", ".", "word_transformer", ",", "self", ".", "word_weight", "=", "pickle", ".", "load", "(", "open", "(", "'./data/kb/db_words.pkl'", ",", "'rb'", ")", ")", "\n", "self", ".", "pinyin_vectorizer", ",", "self", ".", "pinyin_transformer", ",", "self", ".", "pinyin_weight", "=", "pickle", ".", "load", "(", "\n", "open", "(", "'./data/kb/db_pinyin.pkl'", ",", "'rb'", ")", ")", "\n", "self", ".", "db", "=", "json", ".", "load", "(", "open", "(", "'./data/kb/db_key.json'", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.models.TFIDF.TfIdf.search": [[20, 41], ["TFIDF.TfIdf.word_transformer.transform", "TFIDF.TfIdf.toarray", "sklearn.metrics.pairwise.cosine_similarity", "TFIDF.TfIdf.pinyin_transformer.transform", "TFIDF.TfIdf.toarray", "sklearn.metrics.pairwise.cosine_similarity", "TFIDF.TfIdf.word_vectorizer.transform", "TFIDF.TfIdf.pinyin_vectorizer.transform", "map", "pypinyin.lazy_pinyin", "numpy.argmax", "heapq.nlargest", "enumerate"], "methods", ["None"], ["", "def", "search", "(", "self", ",", "sen", ",", "n", ":", "int", "=", "1", ",", "rate", "=", "0.09", ")", ":", "\n", "        ", "x_word", "=", "[", "' '", ".", "join", "(", "sen", ")", "]", "\n", "tf_idf", "=", "self", ".", "word_transformer", ".", "transform", "(", "self", ".", "word_vectorizer", ".", "transform", "(", "x_word", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result_word", "=", "cosine_similarity", "(", "x_test_weight", ",", "self", ".", "word_weight", ")", "\n", "\n", "x_pinyin", "=", "[", "' '", ".", "join", "(", "lazy_pinyin", "(", "sen", ")", ")", "]", "\n", "tf_idf", "=", "self", ".", "pinyin_transformer", ".", "transform", "(", "self", ".", "pinyin_vectorizer", ".", "transform", "(", "x_pinyin", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result_pinyin", "=", "cosine_similarity", "(", "x_test_weight", ",", "self", ".", "pinyin_weight", ")", "\n", "\n", "if", "n", "==", "1", ":", "\n", "            ", "result", "=", "result_word", "*", "rate", "+", "result_pinyin", "*", "(", "1", "-", "rate", ")", "\n", "re2", "=", "np", ".", "argmax", "(", "result", ",", "axis", "=", "1", ")", "[", "0", "]", "\n", "all_", "=", "[", "[", "self", ".", "db", "[", "re2", "]", ",", "result", "[", "0", "]", "[", "re2", "]", "]", "]", "\n", "", "else", ":", "\n", "            ", "result", "=", "(", "result_word", "*", "rate", "+", "result_pinyin", "*", "(", "1", "-", "rate", ")", ")", ".", "tolist", "(", ")", "[", "0", "]", "\n", "re2", "=", "map", "(", "result", ".", "index", ",", "heapq", ".", "nlargest", "(", "n", ",", "result", ")", ")", "\n", "all_", "=", "[", "[", "self", ".", "db", "[", "i", "]", ",", "result", "[", "idx", "]", "[", "i", "]", "]", "for", "idx", ",", "i", "in", "enumerate", "(", "re2", ")", "]", "\n", "# all_ = [self.db[i] for i in list(re2)]", "\n", "", "return", "all_", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.models.TFIDF.TfIdf.search_batch": [[42, 58], ["TFIDF.TfIdf.word_transformer.transform", "TFIDF.TfIdf.toarray", "sklearn.metrics.pairwise.cosine_similarity", "TFIDF.TfIdf.pinyin_transformer.transform", "TFIDF.TfIdf.toarray", "sklearn.metrics.pairwise.cosine_similarity", "torch.topk().indices.tolist", "TFIDF.TfIdf.word_vectorizer.transform", "TFIDF.TfIdf.pinyin_vectorizer.transform", "pypinyin.lazy_pinyin", "enumerate", "torch.topk", "torch.tensor"], "methods", ["None"], ["", "def", "search_batch", "(", "self", ",", "batch", ",", "n", ":", "int", "=", "1", ",", "rate", "=", "0.09", ")", ":", "\n", "        ", "x_word", "=", "[", "' '", ".", "join", "(", "sen", ")", "for", "sen", "in", "batch", "]", "\n", "tf_idf", "=", "self", ".", "word_transformer", ".", "transform", "(", "self", ".", "word_vectorizer", ".", "transform", "(", "x_word", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result_word", "=", "cosine_similarity", "(", "x_test_weight", ",", "self", ".", "word_weight", ")", "\n", "\n", "x_pinyin", "=", "[", "' '", ".", "join", "(", "lazy_pinyin", "(", "sen", ")", ")", "for", "sen", "in", "batch", "]", "\n", "tf_idf", "=", "self", ".", "pinyin_transformer", ".", "transform", "(", "self", ".", "pinyin_vectorizer", ".", "transform", "(", "x_pinyin", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result_pinyin", "=", "cosine_similarity", "(", "x_test_weight", ",", "self", ".", "pinyin_weight", ")", "\n", "\n", "result", "=", "result_word", "*", "rate", "+", "result_pinyin", "*", "(", "1", "-", "rate", ")", "\n", "re2", "=", "torch", ".", "topk", "(", "torch", ".", "tensor", "(", "result", ")", ",", "n", ")", ".", "indices", ".", "tolist", "(", ")", "\n", "all_", "=", "[", "[", "[", "self", ".", "db", "[", "i", "]", ",", "result", "[", "idx", "]", "[", "i", "]", "]", "for", "i", "in", "t_k", "]", "for", "idx", ",", "t_k", "in", "enumerate", "(", "re2", ")", "]", "\n", "candidates_word", "=", "[", "word", "[", "0", "]", "[", "0", "]", "for", "word", "in", "all_", "]", "\n", "return", "' '", ".", "join", "(", "candidates_word", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.__init__": [[10, 18], ["torch.Module.__init__", "models.TFIDF.TfIdf", "transformers.AutoModelWithLMHead.from_pretrained", "model.UBAR_plus.gpt_model.resize_token_embeddings", "len"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.kb.tf_idf_kd.Tf_idf.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "tokenizer", ",", "device", ")", ":", "\n", "        ", "super", "(", "UBAR_plus", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "kp_model", "=", "TfIdf", "(", ")", "\n", "self", ".", "gpt_model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "args", ".", "model_path", ")", "\n", "self", ".", "gpt_model", ".", "resize_token_embeddings", "(", "len", "(", "self", ".", "tokenizer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.forward": [[19, 21], ["model.UBAR_plus.gpt_model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs_ids", ")", ":", "\n", "        ", "return", "self", ".", "gpt_model", "(", "inputs_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.generate": [[22, 24], ["model.UBAR_plus.gpt_model.generate"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.generate"], ["", "def", "generate", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "gpt_model", ".", "generate", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.models.model.UBAR_plus.generate_correct_char": [[25, 31], ["model.UBAR_plus.kp_model.search_batch", "len"], "methods", ["home.repos.pwc.inspect_result.shunjiu_sstod.models.TFIDF.TfIdf.search_batch"], ["", "def", "generate_correct_char", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "\"\"\"query the database and select the most similarity chars\"\"\"", "\n", "KP_results", "=", "self", ".", "kp_model", ".", "search_batch", "(", "input_ids", ")", "\n", "if", "len", "(", "KP_results", ")", ">", "10", ":", "\n", "            ", "return", "KP_results", "[", ":", "10", "]", "\n", "", "return", "KP_results", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.kb.tf_idf_kd.Tf_idf.__init__": [[15, 35], ["json.load", "sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.TfidfTransformer", "sklearn.feature_extraction.text.TfidfTransformer.fit_transform", "sklearn.feature_extraction.text.TfidfTransformer.fit_transform.toarray", "pickle.dump", "open", "sklearn.feature_extraction.text.CountVectorizer.fit_transform", "open", "pypinyin.lazy_pinyin"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "type", "=", "'word'", ")", ":", "\n", "        ", "db", "=", "json", ".", "load", "(", "open", "(", "'knowledge_db.json'", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "\n", "if", "type", "==", "'word'", ":", "\n", "            ", "db_for_tfidf", "=", "[", "' '", ".", "join", "(", "value", ")", "for", "value", "in", "db", "]", "\n", "", "else", ":", "\n", "            ", "db_for_tfidf", "=", "[", "' '", ".", "join", "(", "lazy_pinyin", "(", "value", ")", ")", "for", "value", "in", "db", "]", "\n", "\n", "", "analyzer", "=", "'char'", "if", "type", "==", "'word'", "else", "'word'", "\n", "vectorizer", "=", "CountVectorizer", "(", "analyzer", "=", "analyzer", ",", "lowercase", "=", "False", ")", "\n", "transformer", "=", "TfidfTransformer", "(", ")", "\n", "tfidf", "=", "transformer", ".", "fit_transform", "(", "vectorizer", ".", "fit_transform", "(", "db_for_tfidf", ")", ")", "\n", "weight", "=", "tfidf", ".", "toarray", "(", ")", "\n", "self", ".", "vectorizer", "=", "vectorizer", "\n", "self", ".", "transformer", "=", "transformer", "\n", "self", ".", "weight", "=", "weight", "\n", "self", ".", "type", "=", "type", "\n", "\n", "filename", "=", "'./db_words.pkl'", "if", "type", "==", "'word'", "else", "'./db_pinyin.pkl'", "\n", "pickle", ".", "dump", "(", "[", "vectorizer", ",", "transformer", ",", "weight", "]", ",", "open", "(", "filename", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.kb.tf_idf_kd.Tf_idf.search": [[37, 48], ["tf_idf_kd.Tf_idf.transformer.transform", "tf_idf_kd.Tf_idf.toarray", "list", "map", "tf_idf_kd.Tf_idf.vectorizer.transform", "heapq.nlargest", "sklearn.metrics.pairwise.cosine_similarity", "list", "pypinyin.lazy_pinyin"], "methods", ["None"], ["", "def", "search", "(", "self", ",", "sen", ",", "n", ",", "db", ")", ":", "\n", "        ", "if", "self", ".", "type", "==", "'word'", ":", "\n", "            ", "x_test", "=", "[", "' '", ".", "join", "(", "sen", ")", "]", "\n", "", "else", ":", "\n", "            ", "x_test", "=", "[", "' '", ".", "join", "(", "lazy_pinyin", "(", "sen", ")", ")", "]", "\n", "", "tf_idf", "=", "self", ".", "transformer", ".", "transform", "(", "self", ".", "vectorizer", ".", "transform", "(", "x_test", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result", "=", "list", "(", "cosine_similarity", "(", "x_test_weight", ",", "self", ".", "weight", ")", "[", "0", "]", ")", "\n", "re2", "=", "map", "(", "result", ".", "index", ",", "heapq", ".", "nlargest", "(", "n", ",", "result", ")", ")", "\n", "all_", "=", "[", "[", "db", "[", "i", "]", ",", "result", "[", "i", "]", "]", "for", "i", "in", "list", "(", "re2", ")", "]", "\n", "return", "all_", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.kb.tf_idf_kd.search_2_idf": [[50, 66], ["word_idf[].transform", "pinyin_idf[].transform.toarray", "list", "pinyin_idf[].transform", "pinyin_idf[].transform.toarray", "list", "map", "word_idf[].transform", "pinyin_idf[].transform", "heapq.nlargest", "sklearn.metrics.pairwise.cosine_similarity", "sklearn.metrics.pairwise.cosine_similarity", "list", "pypinyin.lazy_pinyin", "numpy.array", "numpy.array"], "function", ["None"], ["", "", "def", "search_2_idf", "(", "sen", ",", "n", ",", "word_idf", ",", "pinyin_idf", ",", "rate", ",", "db", ")", ":", "\n", "    ", "x_word", "=", "[", "' '", ".", "join", "(", "sen", ")", "]", "\n", "tf_idf", "=", "word_idf", "[", "1", "]", ".", "transform", "(", "word_idf", "[", "0", "]", ".", "transform", "(", "x_word", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result_word", "=", "list", "(", "cosine_similarity", "(", "x_test_weight", ",", "word_idf", "[", "2", "]", ")", "[", "0", "]", ")", "\n", "\n", "x_pinyin", "=", "[", "' '", ".", "join", "(", "lazy_pinyin", "(", "i", ")", "[", "0", "]", "for", "i", "in", "sen", ")", "]", "\n", "tf_idf", "=", "pinyin_idf", "[", "1", "]", ".", "transform", "(", "pinyin_idf", "[", "0", "]", ".", "transform", "(", "x_pinyin", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result_pinyin", "=", "list", "(", "cosine_similarity", "(", "x_test_weight", ",", "pinyin_idf", "[", "2", "]", ")", "[", "0", "]", ")", "\n", "\n", "result", "=", "(", "np", ".", "array", "(", "result_word", ")", "*", "rate", "+", "np", ".", "array", "(", "result_pinyin", ")", "*", "(", "1", "-", "rate", ")", ")", ".", "tolist", "(", ")", "\n", "re2", "=", "map", "(", "result", ".", "index", ",", "heapq", ".", "nlargest", "(", "n", ",", "result", ")", ")", "\n", "# all_ = [[list(db.keys())[i], result[i]] for i in list(re2)]", "\n", "all_", "=", "[", "db", "[", "i", "]", "for", "i", "in", "list", "(", "re2", ")", "]", "\n", "return", "all_", "\n", "\n"]], "home.repos.pwc.inspect_result.shunjiu_sstod.kb.tf_idf_kd.search_1_idf": [[67, 77], ["word_idf[].transform", "word_idf[].transform.toarray", "list", "map", "word_idf[].transform", "heapq.nlargest", "sklearn.metrics.pairwise.cosine_similarity", "list"], "function", ["None"], ["", "def", "search_1_idf", "(", "sen", ",", "n", ",", "word_idf", ",", "db", ")", ":", "\n", "    ", "x_word", "=", "[", "' '", ".", "join", "(", "sen", ")", "]", "\n", "tf_idf", "=", "word_idf", "[", "1", "]", ".", "transform", "(", "word_idf", "[", "0", "]", ".", "transform", "(", "x_word", ")", ")", "\n", "x_test_weight", "=", "tf_idf", ".", "toarray", "(", ")", "# \u6d4b\u8bd5\u96c6TF-IDF\u6743\u91cd\u77e9\u9635", "\n", "result_word", "=", "list", "(", "cosine_similarity", "(", "x_test_weight", ",", "word_idf", "[", "2", "]", ")", "[", "0", "]", ")", "\n", "\n", "re2", "=", "map", "(", "result_word", ".", "index", ",", "heapq", ".", "nlargest", "(", "n", ",", "result_word", ")", ")", "\n", "all_", "=", "[", "[", "db", "[", "i", "]", ",", "result_word", "[", "i", "]", "]", "for", "i", "in", "list", "(", "re2", ")", "]", "\n", "# all_ = [db[i] for i in list(re2)]", "\n", "return", "all_", "\n", "\n"]]}