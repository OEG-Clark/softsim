{"home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.main.Arguments.__init__": [[16, 53], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "json.loads", "torch.device", "torch.cuda.device_count", "all", "all", "all", "main.Arguments._format_datapaths", "main.Arguments._add_extra_fields", "os.path.exists", "main.Arguments.config.endswith", "open", "torch.cuda.is_available", "hasattr", "hasattr", "hasattr", "re.sub", "types.SimpleNamespace"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.parse_args", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.main.Arguments._format_datapaths", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.main.Arguments._add_extra_fields"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "required", "=", "True", ",", "help", "=", "'Provide the JSON config path with the parameters of your experiment'", ")", "\n", "parser", ".", "add_argument", "(", "'--replicable'", ",", "action", "=", "'store_true'", ",", "help", "=", "'If provided, a seed will be used to allow replicability'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Fields expected from the command line", "\n", "self", ".", "config", "=", "os", ".", "path", ".", "join", "(", "glb", ".", "PROJ_DIR", ",", "args", ".", "config", ")", "\n", "self", ".", "replicable", "=", "args", ".", "replicable", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "self", ".", "config", ")", "and", "self", ".", "config", ".", "endswith", "(", "'.json'", ")", ",", "'The config path provided does not exist or is not a JSON file'", "\n", "\n", "# Read the parameters from the JSON file and skip comments", "\n", "with", "open", "(", "self", ".", "config", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "params", "=", "''", ".", "join", "(", "[", "re", ".", "sub", "(", "r\"//.*$\"", ",", "\"\"", ",", "line", ",", "flags", "=", "re", ".", "M", ")", "for", "line", "in", "f", "]", ")", "\n", "\n", "", "arguments", "=", "json", ".", "loads", "(", "params", ",", "object_hook", "=", "lambda", "d", ":", "Namespace", "(", "**", "d", ")", ")", "\n", "\n", "# Must-have fields expected from the JSON config file", "\n", "self", ".", "experiment", "=", "arguments", ".", "experiment", "\n", "self", ".", "data", "=", "arguments", ".", "data", "\n", "self", ".", "model", "=", "arguments", ".", "model", "\n", "self", ".", "training", "=", "arguments", ".", "training", "\n", "self", ".", "optim", "=", "self", ".", "training", ".", "optim", "\n", "\n", "# Optim Args", "\n", "self", ".", "optim", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "optim", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "# Checking that the JSON contains at least the fixed fields", "\n", "assert", "all", "(", "[", "hasattr", "(", "self", ".", "data", ".", "text", ",", "name", ")", "for", "name", "in", "{", "'train'", ",", "'dev'", ",", "'test'", "}", "]", ")", "\n", "assert", "all", "(", "[", "hasattr", "(", "self", ".", "training", ",", "name", ")", "for", "name", "in", "{", "'epochs'", ",", "'per_gpu_train_batch_size'", ",", "'per_gpu_eval_batch_size'", ",", "'optim'", "}", "]", ")", "\n", "assert", "all", "(", "[", "hasattr", "(", "self", ".", "training", ".", "optim", ",", "name", ")", "for", "name", "in", "{", "'learning_rate'", ",", "'weight_decay'", "}", "]", ")", "\n", "\n", "self", ".", "_format_datapaths", "(", ")", "\n", "self", ".", "_add_extra_fields", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.main.Arguments._format_datapaths": [[55, 71], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_format_datapaths", "(", "self", ")", ":", "\n", "        ", "self", ".", "data", ".", "directory", "=", "os", ".", "path", ".", "join", "(", "glb", ".", "PROJ_DIR", ",", "self", ".", "data", ".", "directory", ")", "\n", "\n", "self", ".", "data", ".", "text", ".", "train", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "text", ".", "train", ")", "\n", "self", ".", "data", ".", "text", ".", "dev", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "text", ".", "dev", ")", "\n", "self", ".", "data", ".", "text", ".", "test", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "text", ".", "test", ")", "\n", "\n", "if", "self", ".", "data", ".", "image", ".", "train", "is", "not", "None", ":", "\n", "            ", "self", ".", "data", ".", "image", ".", "train", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "image", ".", "train", ")", "\n", "self", ".", "data", ".", "image", ".", "dev", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "image", ".", "dev", ")", "\n", "self", ".", "data", ".", "image", ".", "test", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "image", ".", "test", ")", "\n", "\n", "", "if", "self", ".", "data", ".", "caption", ".", "train", "is", "not", "None", ":", "\n", "            ", "self", ".", "data", ".", "caption", ".", "train", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "caption", ".", "train", ")", "\n", "self", ".", "data", ".", "caption", ".", "dev", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "caption", ".", "dev", ")", "\n", "self", ".", "data", ".", "caption", ".", "test", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data", ".", "directory", ",", "self", ".", "data", ".", "caption", ".", "test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.main.Arguments._add_extra_fields": [[73, 76], ["os.path.join", "os.path.join"], "methods", ["None"], ["", "", "def", "_add_extra_fields", "(", "self", ")", ":", "\n", "        ", "self", ".", "experiment", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "glb", ".", "PROJ_DIR", ",", "self", ".", "experiment", ".", "output_dir", ",", "self", ".", "experiment", ".", "id", ")", "\n", "self", ".", "experiment", ".", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "experiment", ".", "output_dir", ",", "'checkpoint'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.main.main": [[79, 102], ["main.Arguments", "print", "print", "print", "vars().items", "print", "print", "print", "print", "src.main", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "print", "torch.cuda.manual_seed_all", "vars", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.main"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "Arguments", "(", ")", "\n", "\n", "if", "args", ".", "replicable", ":", "\n", "        ", "seed_num", "=", "123", "\n", "random", ".", "seed", "(", "seed_num", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed_num", ")", "\n", "torch", ".", "manual_seed", "(", "seed_num", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed_num", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "", "", "print", "(", "\"[LOG] {}\"", ".", "format", "(", "'='", "*", "40", ")", ")", "\n", "print", "(", "\"[LOG] {: >15}: '{}'\"", ".", "format", "(", "\"Experiment ID\"", ",", "args", ".", "experiment", ".", "id", ")", ")", "\n", "print", "(", "\"[LOG] {: >15}: '{}'\"", ".", "format", "(", "\"Description\"", ",", "args", ".", "experiment", ".", "description", ")", ")", "\n", "for", "key", ",", "val", "in", "vars", "(", "args", ".", "data", ".", "text", ")", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "\"[LOG] {: >15}: {}\"", ".", "format", "(", "key", ",", "val", ")", ")", "\n", "", "print", "(", "\"[LOG] {: >15}: '{}'\"", ".", "format", "(", "\"Modeling\"", ",", "vars", "(", "args", ".", "model", ")", ")", ")", "\n", "print", "(", "\"[LOG] {: >15}: '{}'\"", ".", "format", "(", "\"Training\"", ",", "vars", "(", "args", ".", "training", ")", ")", ")", "\n", "print", "(", "\"[LOG] {: >15}: '{}'\"", ".", "format", "(", "\"GPUs avaliable\"", ",", "args", ".", "optim", ".", "n_gpu", ")", ")", "\n", "print", "(", "\"[LOG] {}\"", ".", "format", "(", "'='", "*", "40", ")", ")", "\n", "\n", "exp", ".", "main", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.get_dataloaders": [[13, 50], ["print", "print", "print", "max", "max", "src.get_dataloader", "src.get_dataloader", "src.get_dataloader", "src.data.dataset.NERDataset", "src.data.dataset.NERDataset", "src.data.dataset.NERDataset", "len", "len", "len", "src.data.dataset.NERDatasetWithGloablImageFeatures", "src.data.dataset.NERDatasetWithGloablImageFeatures", "src.data.dataset.NERDatasetWithGloablImageFeatures", "NotImplementedError", "src.data.dataset.NERDatasetWithRegionalImageFeatures", "src.data.dataset.NERDatasetWithRegionalImageFeatures", "src.data.dataset.NERDatasetWithRegionalImageFeatures"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.get_dataloader", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.get_dataloader", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.get_dataloader"], ["def", "get_dataloaders", "(", "args", ",", "tokenizer", ")", ":", "\n", "    ", "label_scheme", "=", "args", ".", "data", ".", "label_scheme", "\n", "\n", "if", "args", ".", "data", ".", "dataset_class", "==", "'ner'", ":", "\n", "        ", "datasets", "=", "{", "\n", "'train'", ":", "NERDataset", "(", "args", ".", "data", ".", "text", ".", "train", ",", "args", ".", "data", ".", "image", ".", "train", ",", "args", ".", "data", ".", "caption", ".", "train", ",", "tokenizer", ",", "label_scheme", ")", ",", "\n", "'dev'", ":", "NERDataset", "(", "args", ".", "data", ".", "text", ".", "dev", ",", "args", ".", "data", ".", "image", ".", "dev", ",", "args", ".", "data", ".", "caption", ".", "dev", ",", "tokenizer", ",", "label_scheme", ")", ",", "\n", "'test'", ":", "NERDataset", "(", "args", ".", "data", ".", "text", ".", "test", ",", "args", ".", "data", ".", "image", ".", "test", ",", "args", ".", "data", ".", "caption", ".", "test", ",", "tokenizer", ",", "label_scheme", ")", "\n", "}", "\n", "", "elif", "args", ".", "data", ".", "dataset_class", "==", "'ner_with_global_image_features'", ":", "\n", "        ", "datasets", "=", "{", "\n", "'train'", ":", "NERDatasetWithGloablImageFeatures", "(", "args", ".", "data", ".", "text", ".", "train", ",", "args", ".", "data", ".", "image", ".", "train", ",", "args", ".", "data", ".", "caption", ".", "train", ",", "tokenizer", ",", "label_scheme", ")", ",", "\n", "'dev'", ":", "NERDatasetWithGloablImageFeatures", "(", "args", ".", "data", ".", "text", ".", "dev", ",", "args", ".", "data", ".", "image", ".", "dev", ",", "args", ".", "data", ".", "caption", ".", "dev", ",", "tokenizer", ",", "label_scheme", ")", ",", "\n", "'test'", ":", "NERDatasetWithGloablImageFeatures", "(", "args", ".", "data", ".", "text", ".", "test", ",", "args", ".", "data", ".", "image", ".", "test", ",", "args", ".", "data", ".", "caption", ".", "test", ",", "tokenizer", ",", "label_scheme", ")", "\n", "}", "\n", "", "elif", "args", ".", "data", ".", "dataset_class", "==", "'ner_with_regional_image_features'", ":", "\n", "        ", "datasets", "=", "{", "\n", "'train'", ":", "NERDatasetWithRegionalImageFeatures", "(", "args", ".", "data", ".", "text", ".", "train", ",", "args", ".", "data", ".", "image", ".", "train", ",", "args", ".", "data", ".", "caption", ".", "train", ",", "tokenizer", ",", "label_scheme", ")", ",", "\n", "'dev'", ":", "NERDatasetWithRegionalImageFeatures", "(", "args", ".", "data", ".", "text", ".", "dev", ",", "args", ".", "data", ".", "image", ".", "dev", ",", "args", ".", "data", ".", "caption", ".", "dev", ",", "tokenizer", ",", "label_scheme", ")", ",", "\n", "'test'", ":", "NERDatasetWithRegionalImageFeatures", "(", "args", ".", "data", ".", "text", ".", "test", ",", "args", ".", "data", ".", "image", ".", "test", ",", "args", ".", "data", ".", "caption", ".", "test", ",", "tokenizer", ",", "label_scheme", ")", "\n", "}", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Unexpected dataset class\"", ")", "\n", "\n", "", "print", "(", "\"[LOG] Train data size: {:,}\"", ".", "format", "(", "len", "(", "datasets", "[", "'train'", "]", ")", ")", ")", "\n", "print", "(", "\"[LOG]   Dev data size: {:,}\"", ".", "format", "(", "len", "(", "datasets", "[", "'dev'", "]", ")", ")", ")", "\n", "print", "(", "\"[LOG]  Test data size: {:,}\"", ".", "format", "(", "len", "(", "datasets", "[", "'test'", "]", ")", ")", ")", "\n", "\n", "train_batch_size", "=", "args", ".", "training", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "optim", ".", "n_gpu", ")", "\n", "eval_batch_size", "=", "args", ".", "training", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "optim", ".", "n_gpu", ")", "\n", "dataloaders", "=", "{", "\n", "'train'", ":", "utils", ".", "get_dataloader", "(", "datasets", "[", "'train'", "]", ",", "train_batch_size", ",", "shuffle", "=", "True", ")", ",", "\n", "'dev'", ":", "utils", ".", "get_dataloader", "(", "datasets", "[", "'dev'", "]", ",", "eval_batch_size", ",", "shuffle", "=", "False", ")", ",", "\n", "'test'", ":", "utils", ".", "get_dataloader", "(", "datasets", "[", "'test'", "]", ",", "eval_batch_size", ",", "shuffle", "=", "False", ")", "\n", "}", "\n", "\n", "return", "dataloaders", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.prepare_model_config": [[52, 63], ["transformers.BertConfig.from_pretrained", "len"], "function", ["None"], ["", "def", "prepare_model_config", "(", "args", ")", ":", "\n", "    ", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "model", ".", "model_name_or_path", ")", "\n", "config", ".", "model_name_or_path", "=", "args", ".", "model", ".", "model_name_or_path", "\n", "config", ".", "num_labels", "=", "len", "(", "args", ".", "data", ".", "label_scheme", ")", "\n", "config", ".", "output_attentions", "=", "args", ".", "model", ".", "output_attentions", "\n", "config", ".", "output_hidden_states", "=", "args", ".", "model", ".", "output_hidden_states", "\n", "config", ".", "visual_embedding_dim", "=", "args", ".", "data", ".", "image", ".", "embedding_dim", "\n", "config", ".", "visual_embedding_size", "=", "args", ".", "data", ".", "image", ".", "size", "\n", "config", ".", "ckpt_path", "=", "args", ".", "model", ".", "pretrained_weights", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.get_model_class": [[65, 79], ["None"], "function", ["None"], ["", "def", "get_model_class", "(", "model_name", ")", ":", "\n", "    ", "if", "model_name", "==", "'ner'", ":", "\n", "        ", "model_class", "=", "NERModel", "\n", "\n", "", "elif", "model_name", "==", "'ner_with_caption'", ":", "\n", "        ", "model_class", "=", "NERWithCaption", "\n", "\n", "", "elif", "model_name", "==", "'mner'", ":", "\n", "        ", "model_class", "=", "MNERModel", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "return", "model_class", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.get_optimizer_and_scheduler": [[81, 106], ["transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "model.named_parameters", "model.named_parameters", "any", "any"], "function", ["None"], ["", "def", "get_optimizer_and_scheduler", "(", "args", ",", "model", ",", "num_training_sampels", ")", ":", "\n", "    ", "oargs", "=", "args", ".", "optim", "\n", "\n", "if", "oargs", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "oargs", ".", "max_steps", "\n", "oargs", ".", "num_train_epochs", "=", "oargs", ".", "max_steps", "//", "(", "num_training_sampels", "//", "oargs", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "num_training_sampels", "//", "oargs", ".", "gradient_accumulation_steps", "*", "args", ".", "training", ".", "epochs", "\n", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "oargs", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "oargs", ".", "learning_rate", ",", "\n", "betas", "=", "(", "oargs", ".", "beta_1", ",", "oargs", ".", "beta_2", ")", ",", "\n", "eps", "=", "oargs", ".", "adam_epsilon", ")", "\n", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "oargs", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "\n", "return", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.print_stats": [[108, 118], ["range", "print", "len", "print", "print", "epoch_stats.metrics", "print", "sum", "len", "split.upper"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.metrics"], ["", "def", "print_stats", "(", "stats", ",", "label_scheme", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "stats", "[", "'train'", "]", ")", ")", ":", "\n", "        ", "print", "(", "f\"Epoch {i + 1} -\"", ",", "end", "=", "\" \"", ")", "\n", "for", "split", "in", "[", "'train'", ",", "'dev'", "]", ":", "\n", "            ", "epoch_stats", "=", "stats", "[", "split", "]", "[", "i", "]", "\n", "f1", ",", "_", ",", "_", "=", "epoch_stats", ".", "metrics", "(", "label_scheme", ")", "\n", "loss", "=", "sum", "(", "epoch_stats", ".", "losses", ")", "/", "len", "(", "epoch_stats", ".", "losses", ")", "\n", "print", "(", "f\"[{split.upper()}] F1: {f1 * 100:.3f} Loss: {loss:.5f}\"", ",", "end", "=", "' '", ")", "\n", "", "print", "(", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.main": [[120, 191], ["transformers.BertTokenizer.from_pretrained", "experiment.get_dataloaders", "experiment.prepare_model_config", "print", "print", "print", "print", "experiment.get_model_class", "os.path.exists", "src.input_with_timeout().strip", "print", "get_model_class().from_pretrained", "get_model_class().from_pretrained.to", "get_dataloaders.keys", "print", "src.count_params", "input().strip", "print", "experiment.print_stats", "get_model_class().from_pretrained.to", "experiment.get_optimizer_and_scheduler", "train", "experiment.print_stats", "print", "print", "print", "predict", "torch.save", "predict.loss", "predict.get_classification_report", "sorted", "print", "print", "print", "print", "print", "torch.load", "torch.load", "len", "src.input_with_timeout", "experiment.get_model_class", "os.path.join", "set", "src.input_with_timeout().strip", "predict.print_classification_report", "input", "os.path.join", "os.path.join", "report[].keys", "f1_scores.append", "f1_scores.append", "split.upper", "src.input_with_timeout"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.get_dataloaders", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.prepare_model_config", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.get_model_class", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.count_params", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.print_stats", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.get_optimizer_and_scheduler", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.train", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.print_stats", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.predict", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.loss", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.get_classification_report", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.input_with_timeout", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.src.experiment.get_model_class", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.print_classification_report", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.input_with_timeout"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "model", ".", "do_lower_case", ")", "\n", "\n", "dataloaders", "=", "get_dataloaders", "(", "args", ",", "tokenizer", ")", "\n", "\n", "config", "=", "prepare_model_config", "(", "args", ")", "\n", "\n", "model", "=", "get_model_class", "(", "args", ".", "model", ".", "name", ")", "(", "config", ")", "\n", "\n", "print", "(", "\"[LOG] \"", "+", "\"=\"", "*", "40", ")", "\n", "print", "(", "\"[LOG] Parameter count: {}\"", ".", "format", "(", "utils", ".", "count_params", "(", "model", ")", ")", ")", "\n", "print", "(", "\"[LOG] \"", "+", "\"=\"", "*", "40", ")", "\n", "print", "(", ")", "\n", "\n", "if", "args", ".", "experiment", ".", "do_training", "==", "True", ":", "\n", "        ", "confirm", "=", "'y'", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "experiment", ".", "checkpoint_dir", ")", ":", "\n", "            ", "confirm", "=", "input", "(", "'A checkpoint was detected. Do you really want to train again and override the model? [y/n]: '", ")", ".", "strip", "(", ")", "\n", "\n", "", "if", "confirm", "!=", "'y'", ":", "\n", "            ", "print", "(", "\"[LOG] Skip training\"", ")", "\n", "stats", "=", "{", "\n", "'train'", ":", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "experiment", ".", "output_dir", ",", "'train_preds_across_epochs.bin'", ")", ")", ",", "\n", "'dev'", ":", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "experiment", ".", "output_dir", ",", "'dev_preds_across_epochs.bin'", ")", ")", "\n", "}", "\n", "print_stats", "(", "stats", ",", "args", ".", "data", ".", "label_scheme", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "to", "(", "args", ".", "optim", ".", "device", ")", "\n", "optimizer", ",", "scheduler", "=", "get_optimizer_and_scheduler", "(", "args", ",", "model", ",", "len", "(", "dataloaders", "[", "'train'", "]", ")", ")", "\n", "stats", ",", "f1", ",", "global_step", "=", "train", "(", "args", ",", "model", ",", "dataloaders", ",", "optimizer", ",", "scheduler", ")", "\n", "\n", "print_stats", "(", "stats", ",", "args", ".", "data", ".", "label_scheme", ")", "\n", "print", "(", "f\"[LOG] Best dev F1: {f1:.5f}\"", ")", "\n", "print", "(", "f\"[LOG] Best global step: {global_step}\"", ")", "\n", "print", "(", ")", "\n", "\n", "", "", "if", "utils", ".", "input_with_timeout", "(", "\"Do you want to evaluate the model? [y/n]:\"", ",", "15", ",", "\"y\"", ")", ".", "strip", "(", ")", "==", "'y'", ":", "\n", "# Perform evaluation over the dev and test sets with the best checkpoint", "\n", "        ", "print", "(", "f\"[LOG] Loading model from pretrained checkpoint at {args.experiment.checkpoint_dir}\"", ")", "\n", "model", "=", "get_model_class", "(", "args", ".", "model", ".", "name", ")", ".", "from_pretrained", "(", "args", ".", "experiment", ".", "checkpoint_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "optim", ".", "device", ")", "\n", "\n", "for", "split", "in", "dataloaders", ".", "keys", "(", ")", ":", "\n", "            ", "if", "split", "==", "'train'", ":", "\n", "                ", "continue", "\n", "\n", "", "stats", "=", "predict", "(", "args", ",", "model", ",", "dataloaders", "[", "split", "]", ")", "\n", "torch", ".", "save", "(", "stats", ",", "os", ".", "path", ".", "join", "(", "args", ".", "experiment", ".", "output_dir", ",", "f'{split}_best_preds.bin'", ")", ")", "\n", "\n", "# f1, prec, recall = stats.metrics(args.data.label_scheme)", "\n", "loss", ",", "_", ",", "_", "=", "stats", ".", "loss", "(", ")", "\n", "\n", "report", "=", "stats", ".", "get_classification_report", "(", "args", ".", "data", ".", "label_scheme", ")", "\n", "classes", "=", "sorted", "(", "set", "(", "[", "label", "[", "2", ":", "]", "for", "label", "in", "args", ".", "data", ".", "label_scheme", "if", "label", "!=", "'O'", "]", ")", ")", "\n", "\n", "print", "(", "f\"\\n********** {split.upper()} RESULTS **********\\n\"", ")", "\n", "print", "(", "'\\t'", ".", "join", "(", "[", "\"Loss\"", "]", "+", "classes", "+", "[", "\"F1\"", "]", ")", ",", "end", "=", "'\\n'", ")", "\n", "print", "(", "'\\t'", ".", "join", "(", "[", "f\"{l:.4f}\"", "for", "l", "in", "[", "loss", "]", "]", ")", ",", "end", "=", "'\\t'", ")", "\n", "f1_scores", "=", "[", "]", "\n", "for", "c", "in", "classes", "+", "[", "\"micro avg\"", "]", ":", "\n", "                ", "if", "'f1-score'", "in", "report", "[", "c", "]", ".", "keys", "(", ")", ":", "\n", "                    ", "f1_scores", ".", "append", "(", "report", "[", "c", "]", "[", "'f1-score'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "f1_scores", ".", "append", "(", "0", ")", "\n", "", "", "print", "(", "'\\t'", ".", "join", "(", "[", "f\"{score * 100:.3f}\"", "for", "score", "in", "f1_scores", "]", ")", ")", "\n", "print", "(", ")", "\n", "\n", "if", "utils", ".", "input_with_timeout", "(", "\"Print class-level results? [y/n]:\"", ",", "5", ",", "\"n\"", ")", ".", "strip", "(", ")", "==", "'y'", ":", "\n", "                ", "stats", ".", "print_classification_report", "(", "report", "=", "report", ")", "\n", "", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.decode_labels": [[11, 19], ["range", "len", "range", "label_map.items", "len"], "function", ["None"], ["def", "decode_labels", "(", "label_map", ",", "encoded_labels", ")", ":", "\n", "    ", "index_to_label", "=", "{", "index", ":", "label", "for", "label", ",", "index", "in", "label_map", ".", "items", "(", ")", "}", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "encoded_labels", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "encoded_labels", "[", "i", "]", ")", ")", ":", "\n", "            ", "encoded_labels", "[", "i", "]", "[", "j", "]", "=", "index_to_label", "[", "encoded_labels", "[", "i", "]", "[", "j", "]", "]", "\n", "\n", "", "", "return", "encoded_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.track_best_model": [[21, 37], ["dev_stats.metrics", "os.makedirs", "model_to_save.save_pretrained", "torch.save", "hasattr", "os.path.join"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.metrics"], ["", "def", "track_best_model", "(", "args", ",", "model", ",", "dev_stats", ",", "best_f1", ",", "best_step", ",", "global_step", ")", ":", "\n", "    ", "curr_f1", ",", "_", ",", "_", "=", "dev_stats", ".", "metrics", "(", "args", ".", "data", ".", "label_scheme", ")", "\n", "if", "best_f1", ">=", "curr_f1", ":", "\n", "        ", "return", "best_f1", ",", "best_step", "\n", "\n", "# Save model checkpoint", "\n", "", "os", ".", "makedirs", "(", "args", ".", "experiment", ".", "checkpoint_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "experiment", ".", "checkpoint_dir", ")", "\n", "meta", "=", "{", "\n", "'args'", ":", "args", ",", "\n", "'f1'", ":", "curr_f1", ",", "\n", "'global_step'", ":", "global_step", "\n", "}", "\n", "torch", ".", "save", "(", "meta", ",", "os", ".", "path", ".", "join", "(", "args", ".", "experiment", ".", "checkpoint_dir", ",", "\"training_meta.bin\"", ")", ")", "\n", "return", "curr_f1", ",", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.predict": [[39, 64], ["torch.nn.DataParallel.eval", "src.EpochStats", "tqdm.tqdm", "torch.nn.DataParallel", "torch.nn.DataParallel.", "utils.EpochStats.step", "loss.mean.mean", "batch_dict[].to", "loss.mean.item"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.step"], ["", "def", "predict", "(", "args", ",", "model", ",", "dataloaders", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "stats", "=", "utils", ".", "EpochStats", "(", ")", "\n", "\n", "oargs", "=", "args", ".", "optim", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "oargs", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "for", "batch_dict", "in", "tqdm", "(", "dataloaders", ")", ":", "\n", "        ", "for", "field", "in", "batch_dict", ":", "\n", "            ", "if", "batch_dict", "[", "field", "]", "is", "not", "None", ":", "\n", "                ", "batch_dict", "[", "field", "]", "=", "batch_dict", "[", "field", "]", ".", "to", "(", "oargs", ".", "device", ")", "\n", "\n", "", "", "outputs", "=", "model", "(", "**", "batch_dict", ",", "wrap_scalars", "=", "oargs", ".", "n_gpu", ">", "1", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "\n", "if", "oargs", ".", "n_gpu", ">", "1", ":", "\n", "# There is one parallel loss per device", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "stats", ".", "step", "(", "scores", "=", "outputs", "[", "1", "]", ",", "target", "=", "batch_dict", "[", "'labels'", "]", ",", "mask", "=", "batch_dict", "[", "'label_mask'", "]", ",", "loss", "=", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.train": [[66, 143], ["tqdm.trange", "torch.nn.DataParallel", "int", "tqdm.trange.set_description", "os.makedirs", "torch.save", "torch.save", "epoch_desc.format", "epoch_desc.format", "src.EpochStats", "tqdm.tqdm", "enumerate", "stats[].append", "os.path.join", "os.path.join", "tqdm.trange.close", "batch_dict.keys", "torch.nn.DataParallel.", "utils.EpochStats.step", "train.track_best_model", "torch.nn.DataParallel.train", "torch.nn.DataParallel.zero_grad", "torch.nn.DataParallel.eval", "loss.mean.mean", "loss.mean.backward", "tqdm.tqdm.close", "torch.cuda.empty_cache", "gc.collect", "batch_dict[].to", "loss.mean.item", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "torch.nn.DataParallel.zero_grad", "split.title", "torch.nn.DataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.step", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.track_best_model", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.train.train", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.step", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.step"], ["", "def", "train", "(", "args", ",", "model", ",", "dataloaders", ",", "optimizer", ",", "scheduler", ")", ":", "\n", "    ", "oargs", "=", "args", ".", "optim", "\n", "\n", "# multi-gpu training", "\n", "if", "oargs", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "best_f1", ",", "best_step", "=", "0.", ",", "0", "\n", "global_step", "=", "0", "\n", "stats", "=", "{", "'train'", ":", "[", "]", ",", "'dev'", ":", "[", "]", "}", "\n", "\n", "epoch_desc", "=", "\"Epochs (Dev F1: {:.5f} at step {})\"", "\n", "epoch_iterator", "=", "trange", "(", "int", "(", "args", ".", "training", ".", "epochs", ")", ",", "desc", "=", "epoch_desc", ".", "format", "(", "best_f1", ",", "best_step", ")", ")", "\n", "\n", "for", "_", "in", "epoch_iterator", ":", "\n", "        ", "epoch_iterator", ".", "set_description", "(", "epoch_desc", ".", "format", "(", "best_f1", ",", "best_step", ")", ",", "refresh", "=", "True", ")", "\n", "\n", "for", "split", "in", "[", "'train'", ",", "'dev'", "]", ":", "\n", "            ", "epoch_stats", "=", "utils", ".", "EpochStats", "(", ")", "\n", "batch_iterator", "=", "tqdm", "(", "dataloaders", "[", "split", "]", ",", "desc", "=", "f\"{split.title()} iteration\"", ")", "\n", "# ====================================================================", "\n", "for", "step", ",", "batch_dict", "in", "enumerate", "(", "batch_iterator", ")", ":", "\n", "                ", "if", "split", "==", "'train'", ":", "\n", "                    ", "model", ".", "train", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "", "else", ":", "\n", "                    ", "model", ".", "eval", "(", ")", "\n", "\n", "", "for", "field", "in", "batch_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "batch_dict", "[", "field", "]", "is", "not", "None", ":", "\n", "                        ", "batch_dict", "[", "field", "]", "=", "batch_dict", "[", "field", "]", ".", "to", "(", "oargs", ".", "device", ")", "\n", "\n", "", "", "outputs", "=", "model", "(", "**", "batch_dict", ",", "wrap_scalars", "=", "oargs", ".", "n_gpu", ">", "1", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "\n", "if", "oargs", ".", "n_gpu", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "", "if", "oargs", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "oargs", ".", "gradient_accumulation_steps", "\n", "\n", "", "epoch_stats", ".", "step", "(", "scores", "=", "outputs", "[", "1", "]", ",", "target", "=", "batch_dict", "[", "'labels'", "]", ",", "mask", "=", "batch_dict", "[", "'label_mask'", "]", ",", "loss", "=", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "split", "==", "'train'", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "oargs", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "oargs", ".", "max_grad_norm", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "", "if", "oargs", ".", "max_steps", ">", "0", "and", "global_step", ">", "oargs", ".", "max_steps", ":", "\n", "                    ", "batch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "if", "step", "%", "50", "==", "0", ":", "\n", "                    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "_", "=", "gc", ".", "collect", "(", ")", "\n", "\n", "# ====================================================================", "\n", "", "", "stats", "[", "split", "]", ".", "append", "(", "epoch_stats", ")", "\n", "\n", "if", "split", "==", "'dev'", ":", "\n", "                ", "best_f1", ",", "best_step", "=", "track_best_model", "(", "args", ",", "model", ",", "epoch_stats", ",", "best_f1", ",", "best_step", ",", "global_step", ")", "\n", "\n", "", "", "os", ".", "makedirs", "(", "args", ".", "experiment", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "torch", ".", "save", "(", "stats", "[", "'train'", "]", ",", "os", ".", "path", ".", "join", "(", "args", ".", "experiment", ".", "output_dir", ",", "'train_preds_across_epochs.bin'", ")", ")", "\n", "torch", ".", "save", "(", "stats", "[", "'dev'", "]", ",", "os", ".", "path", ".", "join", "(", "args", ".", "experiment", ".", "output_dir", ",", "'dev_preds_across_epochs.bin'", ")", ")", "\n", "\n", "if", "oargs", ".", "max_steps", ">", "0", "and", "global_step", ">", "oargs", ".", "max_steps", ":", "\n", "            ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "return", "stats", ",", "best_f1", ",", "best_step", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.layers.InferenceLayer.__init__": [[8, 22], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "allennlp.modules.ConditionalRandomField", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "n_classes", ",", "use_crf", ")", ":", "\n", "        ", "super", "(", "InferenceLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "use_crf", "=", "use_crf", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "n_classes", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "input_dim", ",", "n_classes", ")", "\n", "\n", "if", "self", ".", "use_crf", ":", "\n", "            ", "self", ".", "crf", "=", "ConditionalRandomField", "(", "n_classes", ",", "constraints", "=", "None", ",", "include_start_end_transitions", "=", "True", ")", "\n", "# self.crf = CRF(n_classes, batch_first=True)", "\n", "", "else", ":", "\n", "            ", "self", ".", "xent", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.layers.InferenceLayer.crf_forward": [[23, 31], ["mask.long.long.long", "layers.InferenceLayer.crf.forward", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModel.forward"], ["", "", "def", "crf_forward", "(", "self", ",", "logits", ",", "target", ",", "mask", ")", ":", "\n", "        ", "mask", "=", "mask", ".", "long", "(", ")", "\n", "# best_paths = self.crf.viterbi_tags(logits, mask)", "\n", "# tags, viterbi_scores = zip(*best_paths)", "\n", "loss", "=", "-", "self", ".", "crf", ".", "forward", "(", "logits", ",", "target", ",", "mask", ")", "# neg log-likelihood loss", "\n", "loss", "=", "loss", "/", "torch", ".", "sum", "(", "mask", ")", "\n", "\n", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.layers.InferenceLayer.fc_forward": [[32, 42], ["mask.long.long.long", "logits.view", "target.view", "layers.InferenceLayer.xent", "mask.long.long.view", "logits.size"], "methods", ["None"], ["", "def", "fc_forward", "(", "self", ",", "logits", ",", "target", ",", "mask", ")", ":", "\n", "        ", "mask", "=", "mask", ".", "long", "(", ")", "\n", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "\n", "logits_", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "target_", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "loss", "=", "self", ".", "xent", "(", "logits_", "[", "mask", "]", ",", "target_", "[", "mask", "]", ")", "\n", "\n", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.layers.InferenceLayer.forward": [[43, 52], ["layers.InferenceLayer.proj", "layers.InferenceLayer.crf_forward", "layers.InferenceLayer.fc_forward"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.layers.InferenceLayer.crf_forward", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.layers.InferenceLayer.fc_forward"], ["", "def", "forward", "(", "self", ",", "vectors", ",", "targets", ",", "mask", ")", ":", "\n", "        ", "logits", "=", "self", ".", "proj", "(", "vectors", ")", "\n", "\n", "if", "self", ".", "use_crf", ":", "\n", "            ", "loss", ",", "logits", "=", "self", ".", "crf_forward", "(", "logits", ",", "targets", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "loss", ",", "logits", "=", "self", ".", "fc_forward", "(", "logits", ",", "targets", ",", "mask", ")", "\n", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERModelBase.__init__": [[14, 22], ["transformers.models.bert.modeling_bert.BertPreTrainedModel.__init__", "torch.Dropout", "torch.Dropout", "transformers.models.bert.modeling_bert.BertModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "config", ".", "model_name_or_path", ",", "\n", "output_attentions", "=", "config", ".", "output_attentions", ",", "\n", "output_hidden_states", "=", "config", ".", "output_hidden_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERModelBase.forward_bert": [[24, 32], ["model.NERModelBase.bert", "model.NERModelBase.dropout"], "methods", ["None"], ["", "def", "forward_bert", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "\n", "return", "sequence_output", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERModelBase.ner_loss": [[34, 44], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "classifier", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "ner_loss", "(", "self", ",", "classifier", ",", "sequence_output", ",", "labels", ",", "attention_mask", "=", "None", ")", ":", "\n", "        ", "if", "labels", "is", "None", ":", "\n", "            ", "loss", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "labels", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "if", "attention_mask", "is", "None", ":", "\n", "                ", "attention_mask", "=", "torch", ".", "ones", "(", "labels", ".", "shape", ",", "device", "=", "labels", ".", "device", ")", "\n", "\n", "", "loss", ",", "logits", "=", "classifier", "(", "sequence_output", ",", "labels", ",", "attention_mask", ")", "\n", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERModelBase.forward": [[46, 50], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_position_ids", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "\n", "labels", "=", "None", ",", "label_mask", "=", "None", ",", "wrap_scalars", "=", "False", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'The NERModelBase class should never execute forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERModel.__init__": [[53, 57], ["model.NERModelBase.__init__", "src.modeling.layers.InferenceLayer"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "classifier", "=", "InferenceLayer", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ",", "use_crf", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERModel.forward": [[58, 70], ["model.NERModel.forward_bert", "model.NERModel.ner_loss", "loss.unsqueeze.unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.forward_bert", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.ner_loss"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_position_ids", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "\n", "labels", "=", "None", ",", "label_mask", "=", "None", ",", "wrap_scalars", "=", "False", ")", ":", "\n", "\n", "        ", "sequence_output", "=", "self", ".", "forward_bert", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "loss", ",", "logits", "=", "self", ".", "ner_loss", "(", "self", ".", "classifier", ",", "sequence_output", ",", "labels", ",", "attention_mask", ")", "\n", "\n", "if", "wrap_scalars", ":", "\n", "            ", "loss", "=", "loss", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERWithCaption.__init__": [[73, 77], ["model.NERModelBase.__init__", "src.modeling.layers.InferenceLayer"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "classifier", "=", "InferenceLayer", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ",", "use_crf", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERWithCaption.multimodal_fusion": [[79, 83], ["model.NERWithCaption.forward_bert"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.forward_bert"], ["", "def", "multimodal_fusion", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "visual_embeddings", "=", "None", ")", ":", "\n", "        ", "sequence_output", "=", "self", ".", "forward_bert", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "return", "sequence_output", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERWithCaption.forward": [[85, 100], ["model.NERWithCaption.multimodal_fusion", "src.correct_attention_mask", "model.NERWithCaption.ner_loss", "loss.unsqueeze.unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.NERWithCaption.multimodal_fusion", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.correct_attention_mask", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.ner_loss"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_position_ids", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "\n", "labels", "=", "None", ",", "label_mask", "=", "None", ",", "next_sentence_label", "=", "None", ",", "wrap_scalars", "=", "False", ")", ":", "\n", "\n", "        ", "multimodal_output", "=", "self", ".", "multimodal_fusion", "(", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "visual_embeddings", ")", "\n", "\n", "# If captions exist, remove when computing loss", "\n", "attention_mask", "=", "utils", ".", "correct_attention_mask", "(", "input_ids", ",", "attention_mask", ")", "\n", "\n", "loss", ",", "logits", "=", "self", ".", "ner_loss", "(", "self", ".", "classifier", ",", "multimodal_output", ",", "labels", ",", "attention_mask", ")", "\n", "\n", "if", "wrap_scalars", ":", "\n", "            ", "loss", "=", "loss", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.BertEmbeddingsWithVisualEmbedding.__init__": [[107, 126], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "hasattr", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddingsWithVisualEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "#### Below are specific for encoding visual features", "\n", "\n", "# Segment and position embedding for image features", "\n", "self", ".", "token_type_embeddings_visual", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings_visual", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'visual_embedding_dim'", ")", ":", "\n", "            ", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "config", ".", "visual_embedding_dim", ",", "config", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.BertEmbeddingsWithVisualEmbedding.forward": [[127, 167], ["input_ids.size", "input_ids.size", "model.BertEmbeddingsWithVisualEmbedding.word_embeddings", "model.BertEmbeddingsWithVisualEmbedding.position_embeddings", "model.BertEmbeddingsWithVisualEmbedding.token_type_embeddings", "model.BertEmbeddingsWithVisualEmbedding.LayerNorm", "model.BertEmbeddingsWithVisualEmbedding.dropout", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "model.BertEmbeddingsWithVisualEmbedding.projection", "model.BertEmbeddingsWithVisualEmbedding.token_type_embeddings_visual", "model.BertEmbeddingsWithVisualEmbedding.position_embeddings_visual", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "visual_position_ids", "=", "None", ")", ":", "\n", "        ", "'''\n        input_ids = [batch_size, sequence_length]\n        token_type_ids = [batch_size, sequence_length]\n        visual_embedding = [batch_size, image_feature_length, image_feature_dim]\n        '''", "\n", "\n", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "device", "=", "input_ids", ".", "device", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "\n", "if", "visual_embeddings", "is", "not", "None", ":", "\n", "            ", "visual_embeddings", "=", "self", ".", "projection", "(", "visual_embeddings", ")", "\n", "\n", "token_type_embeddings_visual", "=", "self", ".", "token_type_embeddings_visual", "(", "visual_embeddings_type", ")", "\n", "\n", "# visual_position_ids = torch.zeros(*visual_embeddings.size()[:-1], dtype = torch.long)#.cuda()", "\n", "position_embeddings_visual", "=", "self", ".", "position_embeddings_visual", "(", "visual_position_ids", ")", "\n", "\n", "v_embeddings", "=", "visual_embeddings", "+", "position_embeddings_visual", "+", "token_type_embeddings_visual", "\n", "\n", "# Concate the two:", "\n", "embeddings", "=", "torch", ".", "cat", "(", "(", "embeddings", ",", "v_embeddings", ")", ",", "dim", "=", "1", ")", "# concat the visual embeddings after the attentions", "\n", "\n", "", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.VisualBertModel.__init__": [[171, 179], ["transformers.models.bert.modeling_bert.BertPreTrainedModel.__init__", "model.BertEmbeddingsWithVisualEmbedding", "transformers.models.bert.modeling_bert.BertEncoder", "transformers.models.bert.modeling_bert.BertPooler", "model.VisualBertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddingsWithVisualEmbedding", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.VisualBertModel.forward": [[180, 220], ["input_ids.size", "extended_attention_mask.to.to.to", "model.VisualBertModel.embeddings", "model.VisualBertModel.encoder", "model.VisualBertModel.pooler", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "next", "model.VisualBertModel.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "encoder_hidden_states", "=", "None", ",", "encoder_attention_mask", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "visual_position_ids", "=", "None", ")", ":", "\n", "\n", "        ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "encoder_extended_attention_mask", "=", "None", "\n", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "position_ids", "=", "position_ids", ",", "\n", "visual_embeddings", "=", "visual_embeddings", ",", "visual_embeddings_type", "=", "visual_embeddings_type", ",", "visual_position_ids", "=", "visual_position_ids", ")", "\n", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "attention_mask", "=", "extended_attention_mask", ",", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "output_attentions", "=", "self", ".", "config", ".", "output_attentions", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.__init__": [[223, 231], ["transformers.models.bert.modeling_bert.BertPreTrainedModel.__init__", "torch.Dropout", "torch.Dropout", "model.VisualBertModel", "model.MNERModelBase._load_pretrained_weights"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase._load_pretrained_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "bert", "=", "VisualBertModel", "(", "config", ")", "\n", "\n", "self", ".", "_load_pretrained_weights", "(", "config", ".", "ckpt_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase._load_pretrained_weights": [[232, 243], ["model.MNERModelBase.bert.state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "model.MNERModelBase.keys", "model.MNERModelBase.bert.load_state_dict", "print"], "methods", ["None"], ["", "def", "_load_pretrained_weights", "(", "self", ",", "ckpt_path", ")", ":", "\n", "        ", "old_state", "=", "self", ".", "bert", ".", "state_dict", "(", ")", "\n", "new_state", "=", "torch", ".", "load", "(", "ckpt_path", ")", "\n", "for", "pname", "in", "old_state", ".", "keys", "(", ")", ":", "\n", "            ", "pname_norm", "=", "'bert.bert.'", "+", "pname", "\n", "if", "pname_norm", "in", "new_state", ":", "\n", "                ", "old_state", "[", "pname", "]", "=", "new_state", "[", "pname_norm", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"[LOG] Missing: {} ({})\"", ".", "format", "(", "pname", ",", "pname_norm", ")", ")", "\n", "\n", "", "", "self", ".", "bert", ".", "load_state_dict", "(", "old_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.forward_bert": [[244, 254], ["model.MNERModelBase.bert", "model.MNERModelBase.dropout"], "methods", ["None"], ["", "def", "forward_bert", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "visual_position_ids", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "visual_embeddings", "=", "visual_embeddings", ",", "visual_embeddings_type", "=", "visual_embeddings_type", ",", "visual_position_ids", "=", "visual_position_ids", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "\n", "return", "sequence_output", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.ner_loss": [[255, 265], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "classifier", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "ner_loss", "(", "self", ",", "classifier", ",", "sequence_output", ",", "labels", ",", "attention_mask", "=", "None", ")", ":", "\n", "        ", "if", "labels", "is", "None", ":", "\n", "            ", "loss", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "labels", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "if", "attention_mask", "is", "None", ":", "\n", "                ", "attention_mask", "=", "torch", ".", "ones", "(", "labels", ".", "shape", ",", "device", "=", "labels", ".", "device", ")", "\n", "\n", "", "loss", ",", "logits", "=", "classifier", "(", "sequence_output", ",", "labels", ",", "attention_mask", ")", "\n", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.forward": [[266, 270], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "visual_position_ids", "=", "None", ",", "\n", "labels", "=", "None", ",", "label_mask", "=", "None", ",", "wrap_scalars", "=", "False", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'The NERModelBase class should never execute forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModel.__init__": [[273, 277], ["model.MNERModelBase.__init__", "src.modeling.layers.InferenceLayer"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "classifier", "=", "InferenceLayer", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ",", "use_crf", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModel.forward": [[278, 297], ["model.MNERModel.forward_bert", "src.correct_attention_mask", "model.MNERModel.ner_loss", "loss.unsqueeze.unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.forward_bert", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.correct_attention_mask", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.modeling.model.MNERModelBase.ner_loss"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "visual_embeddings", "=", "None", ",", "visual_embeddings_type", "=", "None", ",", "visual_position_ids", "=", "None", ",", "\n", "labels", "=", "None", ",", "label_mask", "=", "None", ",", "wrap_scalars", "=", "False", ")", ":", "\n", "\n", "        ", "sequence_output", "=", "self", ".", "forward_bert", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "visual_embeddings", "=", "visual_embeddings", ",", "visual_embeddings_type", "=", "visual_embeddings_type", ",", "visual_position_ids", "=", "visual_position_ids", ")", "\n", "\n", "attention_mask", "=", "utils", ".", "correct_attention_mask", "(", "input_ids", ",", "attention_mask", ")", "\n", "\n", "# Remove objects", "\n", "sequence_output", "=", "sequence_output", "[", ":", ",", ":", "labels", ".", "shape", "[", "1", "]", ",", ":", "]", "\n", "attention_mask", "=", "attention_mask", "[", ":", ",", ":", "labels", ".", "shape", "[", "1", "]", "]", "\n", "\n", "loss", ",", "logits", "=", "self", ".", "ner_loss", "(", "self", ".", "classifier", ",", "sequence_output", ",", "labels", ",", "attention_mask", ")", "\n", "\n", "if", "wrap_scalars", ":", "\n", "            ", "loss", "=", "loss", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.__init__": [[64, 71], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "sizes", "=", "[", "]", "# number of elements per step", "\n", "self", ".", "losses", "=", "[", "]", "\n", "\n", "self", ".", "probs", "=", "[", "]", "\n", "self", ".", "preds", "=", "[", "]", "\n", "self", ".", "golds", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.loss_step": [[72, 75], ["utils.EpochStats.losses.append", "utils.EpochStats.sizes.append"], "methods", ["None"], ["", "def", "loss_step", "(", "self", ",", "loss", ":", "float", ",", "batch_size", ":", "int", ")", ":", "\n", "        ", "self", ".", "losses", ".", "append", "(", "loss", ")", "\n", "self", ".", "sizes", ".", "append", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.step": [[76, 89], ["utils.EpochStats.loss_step", "scores.max", "range", "len", "len", "[].cpu().tolist", "[].cpu().tolist", "[].cpu().tolist", "utils.EpochStats.preds.append", "utils.EpochStats.golds.append", "utils.EpochStats.probs.append", "[].cpu", "[].cpu", "[].cpu"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.loss_step"], ["", "def", "step", "(", "self", ",", "scores", ",", "target", ",", "mask", ",", "loss", ")", ":", "\n", "        ", "self", ".", "loss_step", "(", "loss", ",", "len", "(", "scores", ")", ")", "\n", "\n", "probs", ",", "classes", "=", "scores", ".", "max", "(", "dim", "=", "2", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "scores", ")", ")", ":", "\n", "            ", "prob_i", "=", "probs", "[", "i", "]", "[", "mask", "[", "i", "]", "==", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "pred_i", "=", "classes", "[", "i", "]", "[", "mask", "[", "i", "]", "==", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "gold_i", "=", "target", "[", "i", "]", "[", "mask", "[", "i", "]", "==", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "self", ".", "preds", ".", "append", "(", "pred_i", ")", "# self.preds.extend(pred_i)", "\n", "self", ".", "golds", ".", "append", "(", "gold_i", ")", "# self.golds.extend(gold_i)", "\n", "self", ".", "probs", ".", "append", "(", "prob_i", ")", "# self.probs.extend(prob_i)", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.loss": [[90, 93], ["numpy.mean", "numpy.min", "numpy.max", "zip", "range"], "methods", ["None"], ["", "", "def", "loss", "(", "self", ",", "loss_type", ":", "str", "=", "''", ")", ":", "\n", "        ", "losses", "=", "self", ".", "losses", "\n", "return", "np", ".", "mean", "(", "[", "l", "for", "l", ",", "s", "in", "zip", "(", "losses", ",", "self", ".", "sizes", ")", "for", "_", "in", "range", "(", "s", ")", "]", ")", ",", "np", ".", "min", "(", "losses", ")", ",", "np", ".", "max", "(", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats._map_to_labels": [[94, 105], ["None"], "methods", ["None"], ["", "def", "_map_to_labels", "(", "self", ",", "index2label", ")", ":", "\n", "# Predictions should have been as nested list to separate predictions", "\n", "# Since we store the predictions across epochs during training, we need to wrap up this in a try except", "\n", "# so that it handles the flattened lists in case they are not nested. New runs will be nested", "\n", "        ", "try", ":", "\n", "            ", "golds", "=", "[", "[", "index2label", "[", "j", "]", "for", "j", "in", "i", "]", "for", "i", "in", "self", ".", "golds", "]", "\n", "preds", "=", "[", "[", "index2label", "[", "j", "]", "for", "j", "in", "i", "]", "for", "i", "in", "self", ".", "preds", "]", "\n", "", "except", "TypeError", ":", "\n", "            ", "golds", "=", "[", "index2label", "[", "i", "]", "for", "i", "in", "self", ".", "golds", "]", "\n", "preds", "=", "[", "index2label", "[", "i", "]", "for", "i", "in", "self", ".", "preds", "]", "\n", "", "return", "golds", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.metrics": [[106, 114], ["utils.EpochStats._map_to_labels", "seqeval.metrics.f1_score", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats._map_to_labels"], ["", "def", "metrics", "(", "self", ",", "index2label", ":", "[", "List", "[", "str", "]", ",", "Dict", "[", "int", ",", "str", "]", "]", ")", ":", "\n", "        ", "golds", ",", "preds", "=", "self", ".", "_map_to_labels", "(", "index2label", ")", "\n", "\n", "f1", "=", "f1_score", "(", "golds", ",", "preds", ")", "\n", "p", "=", "precision_score", "(", "golds", ",", "preds", ")", "\n", "r", "=", "recall_score", "(", "golds", ",", "preds", ")", "\n", "\n", "return", "f1", ",", "p", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.get_classification_report": [[115, 120], ["utils.EpochStats._map_to_labels", "seqeval.metrics.classification_report", "utils.report2dict"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats._map_to_labels", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.report2dict"], ["", "def", "get_classification_report", "(", "self", ",", "index2label", ":", "[", "List", "[", "str", "]", ",", "Dict", "[", "int", ",", "str", "]", "]", ")", ":", "\n", "        ", "golds", ",", "preds", "=", "self", ".", "_map_to_labels", "(", "index2label", ")", "\n", "\n", "cr", "=", "classification_report", "(", "golds", ",", "preds", ",", "digits", "=", "5", ")", "\n", "return", "report2dict", "(", "cr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.print_classification_report": [[121, 128], ["utils.printcr", "utils.EpochStats.get_classification_report"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.printcr", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.EpochStats.get_classification_report"], ["", "def", "print_classification_report", "(", "self", ",", "index2label", ":", "[", "List", "[", "str", "]", ",", "Dict", "[", "int", ",", "str", "]", "]", "=", "None", ",", "report", "=", "None", ")", ":", "\n", "        ", "assert", "index2label", "is", "not", "None", "or", "report", "is", "not", "None", "\n", "\n", "if", "report", "is", "None", ":", "\n", "            ", "report", "=", "self", ".", "get_classification_report", "(", "index2label", ")", "\n", "\n", "", "printcr", "(", "report", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.report2dict": [[15, 32], ["list", "cr.split", "collections.defaultdict", "enumerate", "x.strip", "len", "list.append", "float", "row.split", "row[].strip", "len", "m.strip"], "function", ["None"], ["def", "report2dict", "(", "cr", ")", ":", "\n", "# Parse rows", "\n", "    ", "tmp", "=", "list", "(", ")", "\n", "for", "row", "in", "cr", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "        ", "parsed_row", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "row", ".", "split", "(", "\"  \"", ")", "if", "len", "(", "x", ")", ">", "0", "]", "\n", "if", "len", "(", "parsed_row", ")", ">", "0", ":", "\n", "            ", "tmp", ".", "append", "(", "parsed_row", ")", "\n", "\n", "# Store in dictionary", "\n", "", "", "measures", "=", "tmp", "[", "0", "]", "\n", "\n", "D_class_data", "=", "defaultdict", "(", "dict", ")", "\n", "for", "row", "in", "tmp", "[", "1", ":", "]", ":", "\n", "        ", "class_label", "=", "row", "[", "0", "]", "\n", "for", "j", ",", "m", "in", "enumerate", "(", "measures", ")", ":", "\n", "            ", "D_class_data", "[", "class_label", "]", "[", "m", ".", "strip", "(", ")", "]", "=", "float", "(", "row", "[", "j", "+", "1", "]", ".", "strip", "(", ")", ")", "\n", "", "", "return", "D_class_data", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.printcr": [[34, 61], ["print", "print", "sorted.append", "sorted.append", "table.append", "tabulate.tabulate", "sorted", "sorted", "table.append", "report.keys", "row.append", "row.append"], "function", ["None"], ["", "def", "printcr", "(", "report", ",", "classes", "=", "None", ",", "sort_by_support", "=", "False", ")", ":", "\n", "    ", "headers", "=", "[", "'classes'", ",", "'precision'", ",", "'recall'", ",", "'f1-score'", ",", "'support'", "]", "\n", "\n", "if", "classes", "is", "None", ":", "\n", "        ", "classes", "=", "[", "k", "for", "k", "in", "report", ".", "keys", "(", ")", "if", "k", "not", "in", "{", "'macro avg'", ",", "'micro avg'", "}", "]", "\n", "\n", "if", "sort_by_support", ":", "\n", "              ", "classes", "=", "sorted", "(", "classes", ",", "key", "=", "lambda", "c", ":", "report", "[", "c", "]", "[", "'support'", "]", ",", "reverse", "=", "True", ")", "\n", "", "else", ":", "classes", "=", "sorted", "(", "classes", ")", "\n", "\n", "", "if", "'macro avg'", "not", "in", "classes", ":", "classes", ".", "append", "(", "'macro avg'", ")", "\n", "if", "'micro avg'", "not", "in", "classes", ":", "classes", ".", "append", "(", "'micro avg'", ")", "\n", "\n", "table", "=", "[", "]", "\n", "for", "c", "in", "classes", ":", "\n", "        ", "if", "c", "==", "'macro avg'", ":", "\n", "            ", "table", ".", "append", "(", "[", "]", ")", "\n", "", "row", "=", "[", "c", "]", "\n", "for", "h", "in", "headers", ":", "\n", "            ", "if", "h", "not", "in", "report", "[", "c", "]", ":", "\n", "                ", "continue", "\n", "", "if", "h", "in", "{", "'precision'", ",", "'recall'", ",", "'f1-score'", "}", ":", "\n", "                  ", "row", ".", "append", "(", "report", "[", "c", "]", "[", "h", "]", "*", "100", ")", "\n", "", "else", ":", "row", ".", "append", "(", "report", "[", "c", "]", "[", "h", "]", ")", "\n", "", "table", ".", "append", "(", "row", ")", "\n", "", "print", "(", "tabulate", "(", "table", ",", "headers", "=", "headers", ",", "floatfmt", "=", "(", "\".3f\"", ",", "\".3f\"", ",", "\".3f\"", ",", "\".3f\"", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.correct_attention_mask": [[130, 140], ["range", "range"], "function", ["None"], ["", "", "def", "correct_attention_mask", "(", "input_ids", ",", "attention_mask", ",", "sep_token_id", "=", "102", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "input_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "non_text", "=", "False", "\n", "for", "j", "in", "range", "(", "input_ids", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "non_text", ":", "\n", "                ", "attention_mask", "[", "i", "]", "[", "j", "]", "=", "0", "\n", "", "if", "input_ids", "[", "i", "]", "[", "j", "]", "==", "sep_token_id", ":", "\n", "                ", "non_text", "=", "True", "\n", "\n", "", "", "", "return", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.read_text_as_list": [[142, 166], ["open", "json.loads", "ids.append", "tokens.append", "labels.append", "image_ids.append", "open", "captions.append", "json.loads"], "function", ["None"], ["", "def", "read_text_as_list", "(", "text_dir", ",", "caption_dir", ")", ":", "\n", "    ", "ids", ",", "tokens", ",", "labels", ",", "image_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "with", "open", "(", "text_dir", ",", "'r'", ")", "as", "json_file", ":", "\n", "        ", "for", "line", "in", "json_file", ":", "\n", "            ", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "ids", ".", "append", "(", "data", "[", "'id'", "]", ")", "\n", "tokens", ".", "append", "(", "data", "[", "'tokens'", "]", ")", "\n", "labels", ".", "append", "(", "data", "[", "'label'", "]", ")", "\n", "image_ids", ".", "append", "(", "data", "[", "'image_id'", "]", ")", "\n", "\n", "", "", "if", "caption_dir", "is", "not", "None", ":", "\n", "        ", "caption_dict", "=", "{", "}", "\n", "with", "open", "(", "caption_dir", ",", "'r'", ")", "as", "json_file", ":", "\n", "            ", "for", "line", "in", "json_file", ":", "\n", "                ", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "caption_dict", "[", "data", "[", "'image_id'", "]", "]", "=", "data", "[", "'caption'", "]", "\n", "", "", "captions", "=", "[", "]", "\n", "for", "idx", "in", "image_ids", ":", "\n", "            ", "captions", ".", "append", "(", "caption_dict", "[", "idx", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "captions", "=", "None", "\n", "\n", "", "return", "ids", ",", "tokens", ",", "labels", ",", "image_ids", ",", "captions", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.read_regional_image_features_as_list": [[168, 182], ["torch.load", "utils.screen_feature", "images.append", "objects.append"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.screen_feature"], ["", "def", "read_regional_image_features_as_list", "(", "image_ids", ",", "image_dir", "=", "None", ")", ":", "\n", "    ", "if", "image_dir", "is", "not", "None", ":", "\n", "        ", "images", ",", "objects", "=", "[", "]", ",", "[", "]", "\n", "\n", "image_features", "=", "torch", ".", "load", "(", "image_dir", ")", "\n", "for", "image_id", "in", "image_ids", ":", "\n", "            ", "box_features", ",", "cls_boxes", ",", "max_conf", ",", "categories", "=", "image_features", "[", "image_id", "]", "\n", "image_feat", ",", "cls_boxes", ",", "image_loc", ",", "categories", "=", "screen_feature", "(", "box_features", ",", "cls_boxes", ",", "max_conf", ",", "categories", ")", "\n", "images", ".", "append", "(", "image_feat", ")", "\n", "objects", ".", "append", "(", "categories", ")", "\n", "", "", "else", ":", "\n", "        ", "images", ",", "objects", "=", "None", ",", "None", "\n", "\n", "", "return", "images", ",", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.read_global_image_features_as_list": [[184, 196], ["h5py.File", "torch.tensor().unsqueeze", "images.append", "torch.tensor"], "function", ["None"], ["", "def", "read_global_image_features_as_list", "(", "image_ids", ",", "image_dir", "=", "None", ")", ":", "\n", "    ", "if", "image_dir", "is", "not", "None", ":", "\n", "        ", "images", ",", "objects", "=", "[", "]", ",", "None", "\n", "\n", "image_features", "=", "h5py", ".", "File", "(", "image_dir", ",", "'r'", ")", "\n", "for", "image_id", "in", "image_ids", ":", "\n", "            ", "image_feat", "=", "torch", ".", "tensor", "(", "image_features", "[", "image_id", "]", ".", "value", ")", ".", "unsqueeze", "(", "0", ")", "\n", "images", ".", "append", "(", "image_feat", ")", "\n", "", "", "else", ":", "\n", "        ", "images", ",", "objects", "=", "None", ",", "None", "\n", "\n", "", "return", "images", ",", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.screen_feature": [[198, 212], ["numpy.arange", "numpy.arange"], "function", ["None"], ["", "def", "screen_feature", "(", "image_feat", ",", "cls_boxes", ",", "max_conf", ",", "objects", ")", ":", "\n", "    ", "image_feature_cap", "=", "10", "\n", "\n", "keep_boxes", "=", "np", ".", "arange", "(", "image_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "if", "image_feature_cap", "<", "keep_boxes", ".", "shape", "[", "0", "]", ":", "\n", "        ", "keep_boxes", "=", "np", ".", "arange", "(", "image_feature_cap", ")", "\n", "\n", "", "image_feat", "=", "image_feat", "[", "keep_boxes", "]", "\n", "cls_boxes", "=", "cls_boxes", "[", "keep_boxes", "]", "\n", "image_loc", "=", "image_feat", ".", "shape", "[", "0", "]", "\n", "objects", "=", "objects", "[", "keep_boxes", "]", "\n", "\n", "return", "image_feat", ",", "cls_boxes", ",", "image_loc", ",", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.flatten": [[214, 216], ["None"], "function", ["None"], ["", "def", "flatten", "(", "l", ")", ":", "\n", "    ", "return", "[", "i", "for", "sublist", "in", "l", "for", "i", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.count_params": [[218, 220], ["sum", "p.nelement", "model.parameters"], "function", ["None"], ["", "def", "count_params", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.get_label_map": [[222, 226], ["utils.flatten", "utils.flatten", "enumerate", "sorted", "set"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.flatten", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.flatten"], ["", "def", "get_label_map", "(", "datasets", ")", ":", "\n", "    ", "all_labels", "=", "flatten", "(", "[", "flatten", "(", "datasets", "[", "dataset", "]", ".", "labels", ")", "for", "dataset", "in", "datasets", "]", ")", "\n", "all_labels", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "sorted", "(", "set", "(", "all_labels", ")", ")", ")", "}", "\n", "return", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.rescale": [[228, 230], ["arr.min", "arr.max", "arr.min"], "function", ["None"], ["", "def", "rescale", "(", "arr", ")", ":", "\n", "    ", "return", "(", "arr", "-", "arr", ".", "min", "(", "(", "1", ",", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", ")", "/", "(", "arr", ".", "max", "(", "(", "1", ",", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", "-", "arr", ".", "min", "(", "(", "1", ",", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.get_dataloader": [[232, 236], ["torch.utils.data.DataLoader", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler"], "function", ["None"], ["", "def", "get_dataloader", "(", "dataset", ",", "batch_size", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "sampler", "=", "RandomSampler", "(", "dataset", ")", "if", "shuffle", "else", "SequentialSampler", "(", "dataset", ")", "\n", "dloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "batch_size", ",", "collate_fn", "=", "dataset", ".", "collate", ")", "\n", "return", "dloader", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.input_with_timeout": [[238, 251], ["Exception", "signal.signal", "signal.alarm", "input", "signal.alarm"], "function", ["None"], ["", "def", "input_with_timeout", "(", "prompt", ",", "timeout", ",", "default", "=", "''", ")", ":", "\n", "    ", "def", "alarm_handler", "(", "signum", ",", "frame", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Time is up!\"", ")", "\n", "", "try", ":", "\n", "# set signal handler", "\n", "        ", "signal", ".", "signal", "(", "signal", ".", "SIGALRM", ",", "alarm_handler", ")", "\n", "signal", ".", "alarm", "(", "timeout", ")", "# produce SIGALRM in `timeout` seconds", "\n", "\n", "return", "input", "(", "prompt", ")", "\n", "", "except", "Exception", "as", "ex", ":", "\n", "        ", "return", "default", "\n", "", "finally", ":", "\n", "        ", "signal", ".", "alarm", "(", "0", ")", "# cancel alarm", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetBase.__init__": [[10, 18], ["src.read_text_as_list", "dict", "dataset.NERDatasetBase._prepare_encoding_fields_from_start", "enumerate", "dataset.NERDatasetBase.index_map.items"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.read_text_as_list", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetBase._prepare_encoding_fields_from_start"], ["    ", "def", "__init__", "(", "self", ",", "text_dir", ",", "aux_text_dir", ",", "tokenizer", ":", "BertTokenizer", ",", "label_scheme", ")", ":", "\n", "        ", "self", ".", "ids", ",", "self", ".", "tokens", ",", "self", ".", "labels", ",", "self", ".", "image_ids", ",", "self", ".", "aux_text", "=", "utils", ".", "read_text_as_list", "(", "text_dir", ",", "aux_text_dir", ")", "\n", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "index_map", "=", "dict", "(", "enumerate", "(", "label_scheme", ")", ")", "\n", "self", ".", "label_map", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "self", ".", "index_map", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "_prepare_encoding_fields_from_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetBase._prepare_encoding_fields_from_start": [[19, 40], ["range", "len", "dataset.process_sample", "dataset.NERDatasetBase.tokenized.append", "dataset.NERDatasetBase.input_ids.append", "dataset.NERDatasetBase.input_msk.append", "dataset.NERDatasetBase.segment_ids.append", "dataset.NERDatasetBase.label_ids.append", "dataset.NERDatasetBase.label_msk.append"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.process_sample"], ["", "def", "_prepare_encoding_fields_from_start", "(", "self", ")", ":", "\n", "        ", "self", ".", "tokenized", "=", "[", "]", "\n", "self", ".", "input_ids", "=", "[", "]", "\n", "self", ".", "input_msk", "=", "[", "]", "\n", "self", ".", "segment_ids", "=", "[", "]", "\n", "self", ".", "label_ids", "=", "[", "]", "\n", "self", ".", "label_msk", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "ids", ")", ")", ":", "\n", "            ", "tokens", "=", "self", ".", "tokens", "[", "i", "]", "\n", "labels", "=", "self", ".", "labels", "[", "i", "]", "\n", "aux_text", "=", "self", ".", "aux_text", "[", "i", "]", "if", "self", ".", "aux_text", "is", "not", "None", "else", "None", "\n", "\n", "tokenized", ",", "input_ids", ",", "input_msk", ",", "segment_ids", ",", "label_ids", ",", "label_msk", "=", "process_sample", "(", "self", ".", "tokenizer", ",", "tokens", ",", "labels", ",", "self", ".", "label_map", ",", "aux_text", ")", "\n", "\n", "self", ".", "tokenized", ".", "append", "(", "tokenized", ")", "\n", "self", ".", "input_ids", ".", "append", "(", "input_ids", ")", "\n", "self", ".", "input_msk", ".", "append", "(", "input_msk", ")", "\n", "self", ".", "segment_ids", ".", "append", "(", "segment_ids", ")", "\n", "self", ".", "label_ids", ".", "append", "(", "label_ids", ")", "\n", "self", ".", "label_msk", ".", "append", "(", "label_msk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetBase.__len__": [[41, 43], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetBase.__getitem__": [[44, 46], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetBase.collate": [[47, 49], ["NotImplementedError"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ",", "pad_tok", "=", "0", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDataset.__init__": [[52, 55], ["dataset.NERDatasetBase.__init__"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "text_dir", ",", "image_dir", ",", "aux_text_dir", ",", "tokenizer", ":", "BertTokenizer", ",", "label_scheme", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "text_dir", ",", "aux_text_dir", ",", "tokenizer", ",", "label_scheme", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDataset.__len__": [[56, 58], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDataset.__getitem__": [[59, 67], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "input_ids", "=", "self", ".", "input_ids", "[", "index", "]", "\n", "input_msk", "=", "self", ".", "input_msk", "[", "index", "]", "\n", "segment_ids", "=", "self", ".", "segment_ids", "[", "index", "]", "\n", "label_ids", "=", "self", ".", "label_ids", "[", "index", "]", "\n", "label_msk", "=", "self", ".", "label_msk", "[", "index", "]", "\n", "\n", "return", "input_ids", ",", "input_msk", ",", "segment_ids", ",", "label_ids", ",", "label_msk", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDataset.collate": [[68, 99], ["map", "max", "range", "zip", "map", "len", "p_input_ids.append", "p_input_mask.append", "p_segment_ids.append", "p_label_ids.append", "p_label_mask.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ",", "pad_tok", "=", "0", ")", ":", "\n", "# Unwrap the batch into every field", "\n", "        ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "label_mask", "=", "map", "(", "list", ",", "zip", "(", "*", "batch", ")", ")", "\n", "\n", "# Padded variables", "\n", "p_input_ids", ",", "p_input_mask", ",", "p_segment_ids", ",", "p_label_ids", ",", "p_label_mask", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "# How much padding do we need?", "\n", "max_seq_length", "=", "max", "(", "map", "(", "len", ",", "input_ids", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "input_ids", ")", ")", ":", "\n", "            ", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", "[", "i", "]", ")", "\n", "\n", "p_input_ids", ".", "append", "(", "input_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_input_mask", ".", "append", "(", "input_mask", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_segment_ids", ".", "append", "(", "segment_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_label_ids", ".", "append", "(", "label_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_label_mask", ".", "append", "(", "label_mask", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "\n", "", "batch_dict", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "p_input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "'attention_mask'", ":", "torch", ".", "tensor", "(", "p_input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "'token_type_ids'", ":", "torch", ".", "tensor", "(", "p_segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "'visual_embeddings'", ":", "None", ",", "\n", "'visual_position_ids'", ":", "None", ",", "\n", "'visual_embeddings_type'", ":", "None", ",", "\n", "'labels'", ":", "torch", ".", "tensor", "(", "p_label_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "'label_mask'", ":", "torch", ".", "tensor", "(", "p_label_mask", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "}", "\n", "\n", "return", "batch_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithGloablImageFeatures.__init__": [[102, 107], ["dataset.NERDatasetBase.__init__", "src.read_global_image_features_as_list"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.read_global_image_features_as_list"], ["    ", "def", "__init__", "(", "self", ",", "text_dir", ",", "image_dir", ",", "aux_text_dir", ",", "tokenizer", ":", "BertTokenizer", ",", "label_scheme", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "text_dir", ",", "aux_text_dir", ",", "tokenizer", ",", "label_scheme", ")", "\n", "\n", "self", ".", "images", ",", "self", ".", "objects", "=", "utils", ".", "read_global_image_features_as_list", "(", "self", ".", "image_ids", ",", "image_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithGloablImageFeatures.__len__": [[108, 110], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithGloablImageFeatures.__getitem__": [[111, 120], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "input_ids", "=", "self", ".", "input_ids", "[", "index", "]", "\n", "input_msk", "=", "self", ".", "input_msk", "[", "index", "]", "\n", "segment_ids", "=", "self", ".", "segment_ids", "[", "index", "]", "\n", "label_ids", "=", "self", ".", "label_ids", "[", "index", "]", "\n", "label_msk", "=", "self", ".", "label_msk", "[", "index", "]", "\n", "image_ids", "=", "self", ".", "images", "[", "index", "]", "\n", "\n", "return", "input_ids", ",", "input_msk", ",", "segment_ids", ",", "label_ids", ",", "label_msk", ",", "image_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithGloablImageFeatures.collate": [[121, 154], ["map", "max", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat", "torch.tensor", "torch.tensor", "zip", "map", "len", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "len"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ",", "pad_tok", "=", "0", ")", ":", "\n", "# Unwrap the batch into every field", "\n", "        ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "label_mask", ",", "image_ids", "=", "map", "(", "list", ",", "zip", "(", "*", "batch", ")", ")", "\n", "\n", "# Padded variables", "\n", "p_input_ids", ",", "p_input_mask", ",", "p_segment_ids", ",", "p_label_ids", ",", "p_label_mask", ",", "p_image_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "# How much padding do we need?", "\n", "max_seq_length", "=", "max", "(", "map", "(", "len", ",", "input_ids", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "input_ids", ")", ")", ":", "\n", "            ", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", "[", "i", "]", ")", "\n", "\n", "p_input_ids", ".", "append", "(", "input_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_input_mask", ".", "append", "(", "input_mask", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_segment_ids", ".", "append", "(", "segment_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_label_ids", ".", "append", "(", "label_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_label_mask", ".", "append", "(", "label_mask", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "\n", "", "p_input_ids", "=", "torch", ".", "tensor", "(", "p_input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_input_mask", "=", "torch", ".", "tensor", "(", "p_input_mask", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_segment_ids", "=", "torch", ".", "tensor", "(", "p_segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_image_ids", "=", "torch", ".", "cat", "(", "image_ids", ",", "dim", "=", "0", ")", "\n", "p_label_ids", "=", "torch", ".", "tensor", "(", "p_label_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_label_mask", "=", "torch", ".", "tensor", "(", "p_label_mask", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "batch_dict", "=", "{", "\n", "'input_ids'", ":", "p_input_ids", ",", "'attention_mask'", ":", "p_input_mask", ",", "'token_type_ids'", ":", "p_segment_ids", ",", "\n", "'visual_embeddings'", ":", "p_image_ids", ",", "'visual_position_ids'", ":", "None", ",", "'visual_embeddings_type'", ":", "None", ",", "\n", "'labels'", ":", "p_label_ids", ",", "'label_mask'", ":", "p_label_mask", "\n", "}", "\n", "\n", "return", "batch_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__": [[157, 162], ["dataset.NERDatasetBase.__init__", "src.read_regional_image_features_as_list"], "methods", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__init__", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.commons.utils.read_regional_image_features_as_list"], ["    ", "def", "__init__", "(", "self", ",", "text_dir", ",", "image_dir", ",", "aux_text_dir", ",", "tokenizer", ":", "BertTokenizer", ",", "label_scheme", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "text_dir", ",", "aux_text_dir", ",", "tokenizer", ",", "label_scheme", ")", "\n", "\n", "self", ".", "images", ",", "self", ".", "objects", "=", "utils", ".", "read_regional_image_features_as_list", "(", "self", ".", "image_ids", ",", "image_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__len__": [[163, 165], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.__getitem__": [[166, 175], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "input_ids", "=", "self", ".", "input_ids", "[", "index", "]", "\n", "input_msk", "=", "self", ".", "input_msk", "[", "index", "]", "\n", "segment_ids", "=", "self", ".", "segment_ids", "[", "index", "]", "\n", "label_ids", "=", "self", ".", "label_ids", "[", "index", "]", "\n", "label_msk", "=", "self", ".", "label_msk", "[", "index", "]", "\n", "image_ids", "=", "self", ".", "images", "[", "index", "]", "\n", "\n", "return", "input_ids", ",", "input_msk", ",", "segment_ids", ",", "label_ids", ",", "label_msk", ",", "image_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.NERDatasetWithRegionalImageFeatures.collate": [[176, 231], ["map", "max", "range", "max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat", "torch.ones", "torch.zeros", "torch.tensor", "torch.tensor", "len", "torch.zeros", "range", "zip", "map", "len", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "map", "torch.cat().view", "torch.cat.append", "p_input_mask[].sum", "len", "torch.cat", "torch.zeros"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ",", "pad_tok", "=", "0", ")", ":", "\n", "# Unwrap the batch into every field", "\n", "        ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "label_mask", ",", "image_ids", "=", "map", "(", "list", ",", "zip", "(", "*", "batch", ")", ")", "\n", "\n", "# Padded variables", "\n", "p_input_ids", ",", "p_input_mask", ",", "p_segment_ids", ",", "p_label_ids", ",", "p_label_mask", ",", "p_image_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "# How much padding do we need?", "\n", "max_seq_length", "=", "max", "(", "map", "(", "len", ",", "input_ids", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "input_ids", ")", ")", ":", "\n", "            ", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", "[", "i", "]", ")", "\n", "p_input_ids", ".", "append", "(", "input_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_input_mask", ".", "append", "(", "input_mask", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_segment_ids", ".", "append", "(", "segment_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_label_ids", ".", "append", "(", "label_ids", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "p_label_mask", ".", "append", "(", "label_mask", "[", "i", "]", "+", "[", "pad_tok", "]", "*", "padding_length", ")", "\n", "\n", "# Padding regional image features", "\n", "", "max_img_length", "=", "max", "(", "map", "(", "len", ",", "image_ids", ")", ")", "\n", "\n", "for", "visual_emb", "in", "image_ids", ":", "\n", "            ", "padding_length", "=", "max_img_length", "-", "visual_emb", ".", "shape", "[", "0", "]", "\n", "visual_size", "=", "visual_emb", ".", "shape", "[", "1", "]", "\n", "visual_emb", "=", "torch", ".", "cat", "(", "[", "visual_emb", ",", "torch", ".", "zeros", "(", "padding_length", ",", "visual_size", ")", "]", ",", "dim", "=", "0", ")", ".", "view", "(", "1", ",", "max_img_length", ",", "visual_size", ")", "\n", "p_image_ids", ".", "append", "(", "visual_emb", ")", "\n", "\n", "", "p_input_ids", "=", "torch", ".", "tensor", "(", "p_input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_input_mask", "=", "torch", ".", "tensor", "(", "p_input_mask", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_segment_ids", "=", "torch", ".", "tensor", "(", "p_segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_image_ids", "=", "torch", ".", "cat", "(", "p_image_ids", ",", "dim", "=", "0", ")", "\n", "p_visual_segment_ids", "=", "torch", ".", "ones", "(", "max_img_length", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_visual_position_ids", "=", "torch", ".", "zeros", "(", "max_img_length", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_label_ids", "=", "torch", ".", "tensor", "(", "p_label_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "p_label_mask", "=", "torch", ".", "tensor", "(", "p_label_mask", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# Correct the attention mask", "\n", "batch_size", "=", "len", "(", "input_ids", ")", "\n", "txt_length", "=", "p_input_ids", ".", "shape", "[", "1", "]", "\n", "img_length", "=", "p_image_ids", ".", "shape", "[", "1", "]", "\n", "\n", "attention_mask", "=", "torch", ".", "zeros", "(", "batch_size", ",", "txt_length", "+", "img_length", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "unmask_txt_size", "=", "p_input_mask", "[", "i", "]", ".", "sum", "(", ")", "\n", "unmask_img_size", "=", "p_image_ids", "[", "i", "]", ".", "shape", "[", "0", "]", "\n", "attention_mask", "[", "i", ",", ":", "unmask_txt_size", "+", "unmask_img_size", "]", "=", "1", "\n", "\n", "", "batch_dict", "=", "{", "\n", "'input_ids'", ":", "p_input_ids", ",", "'attention_mask'", ":", "attention_mask", ",", "'token_type_ids'", ":", "p_segment_ids", ",", "\n", "'visual_embeddings'", ":", "p_image_ids", ",", "'visual_position_ids'", ":", "p_visual_position_ids", ",", "'visual_embeddings_type'", ":", "p_visual_segment_ids", ",", "\n", "'labels'", ":", "p_label_ids", ",", "'label_mask'", ":", "p_label_mask", "\n", "}", "\n", "\n", "return", "batch_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.data.dataset.process_sample": [[233, 268], ["enumerate", "tokenizer.convert_tokens_to_ids", "zip", "tokenizer.tokenize", "tokenized.extend", "label_ids.extend", "label_msk.extend", "len", "len", "tokenizer.convert_tokens_to_ids", "len", "len", "tokenizer.tokenize", "len", "len", "len", "len"], "function", ["None"], ["", "", "def", "process_sample", "(", "tokenizer", ",", "tokens", ",", "labels", ",", "label_map", ",", "aux_text", "=", "None", ")", ":", "\n", "    ", "tokenized", "=", "[", "]", "\n", "input_msk", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "label_msk", "=", "[", "]", "\n", "\n", "for", "i", ",", "(", "token", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "tokens", ",", "labels", ")", ")", ":", "\n", "        ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "if", "len", "(", "word_tokens", ")", "==", "0", ":", "\n", "            ", "word_tokens", "=", "[", "tokenizer", ".", "unk_token", "]", "\n", "", "num_subtok", "=", "len", "(", "word_tokens", ")", "-", "1", "\n", "\n", "tokenized", ".", "extend", "(", "word_tokens", ")", "\n", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "0", "]", "*", "num_subtok", ")", "\n", "label_msk", ".", "extend", "(", "[", "1", "]", "+", "[", "0", "]", "*", "num_subtok", ")", "\n", "\n", "", "tokenized", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "tokenized", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized", ")", "\n", "input_msk", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "label_ids", "=", "[", "0", "]", "+", "label_ids", "+", "[", "0", "]", "\n", "label_msk", "=", "[", "0", "]", "+", "label_msk", "+", "[", "0", "]", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "if", "aux_text", "is", "not", "None", ":", "\n", "        ", "tokenized_aux_text", "=", "tokenizer", ".", "tokenize", "(", "aux_text", ")", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "aux_text_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_aux_text", ")", "\n", "\n", "input_ids", "+=", "aux_text_ids", "\n", "input_msk", "+=", "[", "1", "]", "*", "len", "(", "aux_text_ids", ")", "\n", "label_ids", "+=", "[", "0", "]", "*", "len", "(", "aux_text_ids", ")", "\n", "label_msk", "+=", "[", "0", "]", "*", "len", "(", "aux_text_ids", ")", "\n", "segment_ids", "+=", "[", "1", "]", "*", "len", "(", "aux_text_ids", ")", "\n", "\n", "", "return", "(", "tokenized", ",", "input_ids", ",", "input_msk", ",", "segment_ids", ",", "label_ids", ",", "label_msk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.global_image_feature_extraction.global_image_feature_extraction.create_model": [[17, 40], ["torchvision.resnet152", "torch.Sequential", "torchvision.vgg16"], "function", ["None"], ["def", "create_model", "(", "name", ")", ":", "\n", "    ", "if", "name", "==", "'vgg'", ":", "\n", "        ", "model", "=", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", ".", "features", "[", ":", "29", "]", "\n", "", "elif", "name", "==", "'resnet'", ":", "\n", "        ", "backbone", "=", "models", ".", "resnet152", "(", "pretrained", "=", "True", ")", "\n", "model", "=", "nn", ".", "Sequential", "(", "\n", "backbone", ".", "conv1", ",", "\n", "backbone", ".", "bn1", ",", "\n", "backbone", ".", "relu", ",", "\n", "backbone", ".", "maxpool", ",", "\n", "backbone", ".", "layer1", ",", "\n", "backbone", ".", "layer2", ",", "\n", "backbone", ".", "layer3", ",", "\n", "backbone", ".", "layer4", "[", "0", "]", ",", "\n", "backbone", ".", "layer4", "[", "1", "]", ",", "\n", "backbone", ".", "layer4", "[", "2", "]", ".", "conv1", ",", "\n", "backbone", ".", "layer4", "[", "2", "]", ".", "bn1", ",", "\n", "backbone", ".", "layer4", "[", "2", "]", ".", "conv2", ",", "\n", "backbone", ".", "layer4", "[", "2", "]", ".", "bn2", ",", "\n", "backbone", ".", "layer4", "[", "2", "]", ".", "conv3", ",", "\n", "backbone", ".", "layer4", "[", "2", "]", ".", "bn3", ",", "\n", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.global_image_feature_extraction.global_image_feature_extraction.extract_feature": [[42, 76], ["model.eval", "torchvision.Compose", "print", "print", "h5py.File", "print", "time.time", "print", "tqdm.tqdm", "print", "print", "model", "result.data.clone().cpu().numpy.data.clone().cpu().numpy", "h5py.File.create_dataset", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize", "os.listdir", "file.endswith", "len", "PIL.Image.open().convert", "transforms.Compose.view", "len", "print", "result.data.clone().cpu().numpy.data.clone().cpu", "time.time", "PIL.Image.open", "transforms.Compose.", "result.data.clone().cpu().numpy.data.clone"], "function", ["None"], ["", "def", "extract_feature", "(", "model", ",", "images_path", ",", "image_feature_path", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "224", ",", "224", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", "\n", "]", ")", "\n", "\n", "print", "(", "\"image path: \"", ",", "images_path", ")", "\n", "print", "(", "\"image_feature_path: \"", ",", "image_feature_path", ")", "\n", "img_feature", "=", "h5py", ".", "File", "(", "image_feature_path", ",", "'w'", ")", "\n", "images_files", "=", "[", "file", "for", "file", "in", "os", ".", "listdir", "(", "images_path", ")", "if", "file", ".", "endswith", "(", "'.jpg'", ")", "]", "\n", "\n", "print", "(", "images_files", "[", ":", "10", "]", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Processing {} images\"", ".", "format", "(", "len", "(", "images_files", ")", ")", ")", "\n", "\n", "processed_count", "=", "0", "\n", "for", "item", "in", "tqdm", "(", "images_files", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "img_path", "=", "images_path", "+", "item", "\n", "img", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "tensor", "=", "transform", "(", "img", ")", ".", "view", "(", "1", ",", "3", ",", "224", ",", "224", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "img_path", ")", "\n", "", "result", "=", "model", "(", "tensor", ")", "\n", "result", "=", "result", ".", "data", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "img_feature", ".", "create_dataset", "(", "name", "=", "item", ",", "data", "=", "result", "[", "0", "]", ")", "\n", "processed_count", "+=", "1", "\n", "\n", "", "print", "(", "\"Processed images: {} / {}\"", ".", "format", "(", "processed_count", ",", "len", "(", "images_files", ")", ")", ")", "\n", "print", "(", "\"Feature extraction time: {:.1f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.parse_args": [[78, 189], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "argparse.ArgumentParser.print_help", "sys.exit"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'End-to-end inference'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg'", ",", "\n", "dest", "=", "'cfg'", ",", "\n", "help", "=", "'cfg model file (/path/to/model_config.yaml)'", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--wts'", ",", "\n", "dest", "=", "'weights'", ",", "\n", "help", "=", "'weights model file (/path/to/model_weights.pkl)'", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output_dir'", ",", "\n", "dest", "=", "'output_dir'", ",", "\n", "help", "=", "'output dir name'", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--image-ext'", ",", "\n", "dest", "=", "'image_ext'", ",", "\n", "help", "=", "'image file name extension (default: jpg)'", ",", "\n", "default", "=", "'jpg'", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--bbox_file'", ",", "\n", "help", "=", "\"csv file from bottom-up attention model\"", ",", "\n", "default", "=", "None", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--total_group'", ",", "\n", "help", "=", "\"the number of group for exracting\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--group_id'", ",", "\n", "help", "=", "\" group id for current analysis, used to shard\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--min_bboxes'", ",", "\n", "help", "=", "\" min number of bboxes\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "10", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--max_bboxes'", ",", "\n", "help", "=", "\" min number of bboxes\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "100", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--conf_thresh'", ",", "\n", "help", "=", "\" confidentce\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.2", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--total_split'", ",", "\n", "help", "=", "\" confidentce\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--one_giant_file'", ",", "\n", "help", "=", "\" confidentce\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--current_split'", ",", "\n", "help", "=", "\" confidentce\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--feat_name'", ",", "\n", "help", "=", "\" the name of the feature to extract, default: gpu_0/fc7\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"gpu_0/fc7\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'im_or_folder'", ",", "help", "=", "'image or folder of images'", ",", "default", "=", "None", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_id'", ",", "\n", "action", "=", "'store_true'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--existing'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", "\n", ")", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "1", ":", "\n", "        ", "parser", ".", "print_help", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.get_detections_from_im": [[191, 222], ["detectron.NamedCudaScope", "detectron.im_detect_bbox", "caffe2.python.workspace.FetchBlob", "caffe2.python.workspace.FetchBlob", "caffe2.python.workspace.FetchBlob", "numpy.zeros", "range", "numpy.argmax", "numpy.hstack().astype", "numpy.array", "numpy.where", "numpy.where", "len", "detectron.utils.boxes.nms", "len", "numpy.hstack", "numpy.argsort", "numpy.argsort", "detectron.core.config.cfg"], "function", ["None"], ["", "def", "get_detections_from_im", "(", "cfg", ",", "model", ",", "im", ",", "image_id", ",", "feat_blob_name", ",", "\n", "MIN_BOXES", ",", "MAX_BOXES", ",", "conf_thresh", "=", "0.2", ",", "bboxes", "=", "None", ")", ":", "\n", "\n", "    ", "with", "c2_utils", ".", "NamedCudaScope", "(", "0", ")", ":", "\n", "        ", "scores", ",", "cls_boxes", ",", "im_scale", "=", "infer_engine", ".", "im_detect_bbox", "(", "model", ",", "\n", "im", ",", "\n", "cfg", ".", "TEST", ".", "SCALE", ",", "\n", "cfg", ".", "TEST", ".", "MAX_SIZE", ",", "\n", "boxes", "=", "bboxes", ")", "\n", "\n", "box_features", "=", "workspace", ".", "FetchBlob", "(", "feat_blob_name", ")", "\n", "cls_prob", "=", "workspace", ".", "FetchBlob", "(", "\"gpu_0/cls_prob\"", ")", "\n", "rois", "=", "workspace", ".", "FetchBlob", "(", "\"gpu_0/rois\"", ")", "\n", "max_conf", "=", "np", ".", "zeros", "(", "(", "rois", ".", "shape", "[", "0", "]", ")", ")", "\n", "# unscale back to raw image space", "\n", "cls_boxes", "=", "rois", "[", ":", ",", "1", ":", "5", "]", "/", "im_scale", "\n", "\n", "for", "cls_ind", "in", "range", "(", "1", ",", "cls_prob", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "cls_scores", "=", "scores", "[", ":", ",", "cls_ind", "]", "\n", "dets", "=", "np", ".", "hstack", "(", "(", "cls_boxes", ",", "cls_scores", "[", ":", ",", "np", ".", "newaxis", "]", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "keep", "=", "np", ".", "array", "(", "nms", "(", "dets", ",", "cfg", ".", "TEST", ".", "NMS", ")", ")", "\n", "max_conf", "[", "keep", "]", "=", "np", ".", "where", "(", "cls_scores", "[", "keep", "]", ">", "max_conf", "[", "keep", "]", ",", "cls_scores", "[", "keep", "]", ",", "max_conf", "[", "keep", "]", ")", "\n", "\n", "", "keep_boxes", "=", "np", ".", "where", "(", "max_conf", ">=", "conf_thresh", ")", "[", "0", "]", "\n", "if", "len", "(", "keep_boxes", ")", "<", "MIN_BOXES", ":", "\n", "            ", "keep_boxes", "=", "np", ".", "argsort", "(", "max_conf", ")", "[", ":", ":", "-", "1", "]", "[", ":", "MIN_BOXES", "]", "\n", "", "elif", "len", "(", "keep_boxes", ")", ">", "MAX_BOXES", ":", "\n", "            ", "keep_boxes", "=", "np", ".", "argsort", "(", "max_conf", ")", "[", ":", ":", "-", "1", "]", "[", ":", "MAX_BOXES", "]", "\n", "", "objects", "=", "np", ".", "argmax", "(", "cls_prob", "[", "keep_boxes", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "return", "box_features", "[", "keep_boxes", "]", ",", "max_conf", "[", "keep_boxes", "]", ",", "cls_boxes", "[", "keep_boxes", "]", ",", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.extract_bboxes": [[234, 252], ["open", "csv.DictReader", "int", "int", "float", "float", "numpy.frombuffer().reshape", "numpy.frombuffer", "base64.b64decode"], "function", ["None"], ["", "def", "extract_bboxes", "(", "bottom_up_csv_file", ")", ":", "\n", "    ", "image_bboxes", "=", "{", "}", "\n", "\n", "with", "open", "(", "bottom_up_csv_file", ",", "\"r\"", ")", "as", "tsv_in_file", ":", "\n", "        ", "reader", "=", "csv", ".", "DictReader", "(", "tsv_in_file", ",", "delimiter", "=", "'\\t'", ",", "\n", "fieldnames", "=", "BOTTOM_UP_FIELDNAMES", ")", "\n", "for", "item", "in", "reader", ":", "\n", "            ", "item", "[", "'num_boxes'", "]", "=", "int", "(", "item", "[", "'num_boxes'", "]", ")", "\n", "image_id", "=", "int", "(", "item", "[", "'image_id'", "]", ")", "\n", "image_w", "=", "float", "(", "item", "[", "'image_w'", "]", ")", "\n", "image_h", "=", "float", "(", "item", "[", "'image_h'", "]", ")", "\n", "\n", "bbox", "=", "np", ".", "frombuffer", "(", "\n", "base64", ".", "b64decode", "(", "item", "[", "'boxes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "item", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "\n", "image_bboxes", "[", "image_id", "]", "=", "bbox", "\n", "", "", "return", "image_bboxes", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.recurse_find_image": [[255, 265], ["os.listdir", "os.listdir", "os.listdir.sort", "os.path.join", "os.path.join", "os.path.isdir", "os.path.isdir", "extract_image_features.recurse_find_image", "os.path.join.endswith", "image_list.append"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.recurse_find_image"], ["def", "recurse_find_image", "(", "folder", ",", "image_list", ",", "image_ext", ")", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "folder", ")", "\n", "files", ".", "sort", "(", ")", "\n", "for", "i", "in", "files", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "folder", ",", "i", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "            ", "recurse_find_image", "(", "path", ",", "image_list", ",", "image_ext", ")", "\n", "", "else", ":", "\n", "            ", "if", "path", ".", "endswith", "(", "image_ext", ")", ":", "\n", "                ", "image_list", ".", "append", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.main": [[267, 344], ["logging.getLogger", "detectron.core.config.merge_cfg_from_file", "detectron.utils.io.cache_url", "detectron.core.config.assert_and_infer_cfg", "detectron.initialize_model_from_cfg", "timeit.default_timer", "extract_image_features.recurse_find_image", "print", "enumerate", "numpy.array_split", "print", "extract_image_features.extract_bboxes", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "torch.load", "print", "tqdm.tqdm", "os.path.basename", "os.path.basename", "cv2.imread", "print", "torch.save", "len", "int", "extract_image_features.get_detections_from_im", "print", "len", "len", "print", "os.path.join", "os.path.join", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.savez", "[].split", "os.path.basename.split"], "function", ["home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.recurse_find_image", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.extract_bboxes", "home.repos.pwc.inspect_result.RiTUAL-UH_multimodal_NER.regional_image_feature_extraction.extract_image_features.get_detections_from_im"], ["", "", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "merge_cfg_from_file", "(", "args", ".", "cfg", ")", "\n", "cfg", ".", "NUM_GPUS", "=", "1", "\n", "args", ".", "weights", "=", "cache_url", "(", "args", ".", "weights", ",", "cfg", ".", "DOWNLOAD_CACHE", ")", "\n", "assert_and_infer_cfg", "(", "cache_urls", "=", "False", ")", "\n", "model", "=", "model_engine", ".", "initialize_model_from_cfg", "(", "args", ".", "weights", ")", "\n", "start", "=", "timeit", ".", "default_timer", "(", ")", "\n", "\n", "im_list", "=", "[", "]", "\n", "recurse_find_image", "(", "args", ".", "im_or_folder", ",", "im_list", ",", "args", ".", "image_ext", ")", "\n", "print", "(", "\"There are {} images to cache in total.\"", ".", "format", "(", "len", "(", "im_list", ")", ")", ")", "\n", "\n", "if", "args", ".", "total_split", "!=", "1", ":", "\n", "        ", "im_lists", "=", "np", ".", "array_split", "(", "im_list", ",", "args", ".", "total_split", ")", "\n", "im_list", "=", "im_lists", "[", "args", ".", "current_split", "]", "\n", "print", "(", "\"Split {}: There are currently {} images to cache.\"", ".", "format", "(", "args", ".", "current_split", ",", "len", "(", "im_list", ")", ")", ")", "\n", "\n", "# extract bboxes from bottom-up attention model", "\n", "", "image_bboxes", "=", "{", "}", "\n", "if", "args", ".", "bbox_file", "is", "not", "None", ":", "\n", "        ", "image_bboxes", "=", "extract_bboxes", "(", "args", ".", "bbox_file", ")", "\n", "\n", "", "count", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "one_giant_file", "=", "args", ".", "one_giant_file", "\n", "if", "one_giant_file", "is", "not", "None", ":", "\n", "        ", "giant_file", "=", "{", "}", "\n", "\n", "", "if", "args", ".", "existing", "is", "not", "None", ":", "\n", "        ", "giant_file", "=", "torch", ".", "load", "(", "args", ".", "existing", ")", "\n", "print", "(", "\"Loaded {}\"", ".", "format", "(", "args", ".", "existing", ")", ")", "\n", "\n", "", "for", "i", ",", "im_name", "in", "enumerate", "(", "tqdm", "(", "im_list", ")", ")", ":", "\n", "        ", "im_base_name", "=", "os", ".", "path", ".", "basename", "(", "im_name", ")", "\n", "if", "not", "args", ".", "no_id", ":", "\n", "            ", "image_id", "=", "int", "(", "im_base_name", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ")", "# for COCO", "\n", "", "else", ":", "\n", "            ", "image_id", "=", "None", "\n", "\n", "", "bbox", "=", "None", "\n", "if", "args", ".", "existing", ":", "\n", "            ", "if", "im_base_name", "in", "giant_file", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Missing {}...\"", ".", "format", "(", "im_base_name", ")", ")", "\n", "", "", "im", "=", "cv2", ".", "imread", "(", "im_name", ")", "\n", "if", "im", "is", "not", "None", ":", "\n", "            ", "outfile", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "im_base_name", ")", "+", "\".npz\"", "\n", "#lock_folder = outfile + '.lock'", "\n", "#if not os.path.exists(lock_folder) and os.path.exists(outfile):", "\n", "#    print(\"Reading {} falied!\".format(im_base_name))", "\n", "#    continue", "\n", "#if not os.path.exists(lock_folder):", "\n", "#    os.makedirs(lock_folder)", "\n", "box_features", ",", "max_conf", ",", "cls_boxes", ",", "objects", "=", "get_detections_from_im", "(", "cfg", ",", "model", ",", "im", ",", "\n", "image_id", ",", "args", ".", "feat_name", ",", "\n", "args", ".", "min_bboxes", ",", "\n", "args", ".", "max_bboxes", ",", "\n", "bboxes", "=", "bbox", ")", "\n", "if", "one_giant_file", "is", "not", "None", ":", "\n", "                ", "box_features", "=", "torch", ".", "Tensor", "(", "box_features", ")", "\n", "cls_boxes", "=", "torch", ".", "Tensor", "(", "cls_boxes", ")", "\n", "max_conf", "=", "torch", ".", "Tensor", "(", "max_conf", ")", "\n", "objects", "=", "torch", ".", "Tensor", "(", "objects", ")", "\n", "giant_file", "[", "im_base_name", "]", "=", "(", "box_features", ",", "cls_boxes", ",", "max_conf", ",", "objects", ")", "\n", "", "else", ":", "\n", "                ", "np", ".", "savez", "(", "outfile", ",", "box_features", "=", "box_features", ",", "max_conf", "=", "max_conf", ",", "cls_boxes", "=", "cls_boxes", ",", "objects", "=", "objects", ")", "\n", "#os.rmdir(lock_folder)", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"Reading {} falied!\"", ".", "format", "(", "im_base_name", ")", ")", "\n", "\n", "", "", "if", "one_giant_file", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"objects extracted:\"", ",", "len", "(", "giant_file", ")", ")", "\n", "torch", ".", "save", "(", "giant_file", ",", "one_giant_file", ")", "\n", "\n"]]}