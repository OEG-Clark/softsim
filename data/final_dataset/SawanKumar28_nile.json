{"home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.set_seed": [[64, 70], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.get_logits": [[71, 90], ["model_output.view.view", "torch.cat", "torch.cat", "torch.cat", "batch[].size", "batch[].size", "model_output.view.size", "torch.cat", "torch.cat", "torch.cat", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "evd.unsqueeze"], "function", ["None"], ["", "", "def", "get_logits", "(", "batch", ",", "model_output", ",", "exp_model", ")", ":", "\n", "    ", "if", "exp_model", "in", "[", "\"instance\"", ",", "\"append\"", ",", "\"instance_append\"", ",", "\"all_explanation\"", ",", "\"Explanation_1\"", "]", ":", "\n", "        ", "return", "model_output", "\n", "", "model_output", "=", "model_output", ".", "view", "(", "batch", "[", "0", "]", ".", "size", "(", "0", ")", ",", "batch", "[", "0", "]", ".", "size", "(", "1", ")", ",", "model_output", ".", "size", "(", "1", ")", ")", "\n", "e", ",", "c", ",", "n", "=", "0", ",", "1", ",", "2", "\n", "v1", ",", "v2", "=", "0", ",", "1", "\n", "if", "exp_model", "in", "[", "\"independent\"", ",", "\"instance_independent\"", "]", ":", "\n", "        ", "evidence_e", "=", "[", "model_output", "[", ":", ",", "e", ",", "v1", "]", "]", "\n", "evidence_c", "=", "[", "model_output", "[", ":", ",", "c", ",", "v1", "]", "]", "\n", "evidence_n", "=", "[", "model_output", "[", ":", ",", "n", ",", "v1", "]", "]", "\n", "", "elif", "exp_model", "in", "[", "\"aggregate\"", ",", "\"instance_aggregate\"", "]", ":", "\n", "        ", "evidence_e", "=", "[", "model_output", "[", ":", ",", "e", ",", "v1", "]", ",", "model_output", "[", ":", ",", "c", ",", "v2", "]", "]", "\n", "evidence_c", "=", "[", "model_output", "[", ":", ",", "e", ",", "v2", "]", ",", "model_output", "[", ":", ",", "c", ",", "v1", "]", "]", "\n", "evidence_n", "=", "[", "model_output", "[", ":", ",", "n", ",", "v1", "]", "]", "\n", "", "logits_e", ",", "logits_c", ",", "logits_n", "=", "[", "torch", ".", "cat", "(", "[", "evd", ".", "unsqueeze", "(", "-", "1", ")", "for", "evd", "in", "item", "]", ",", "1", ")", "\n", "for", "item", "in", "[", "evidence_e", ",", "evidence_c", ",", "evidence_n", "]", "]", "\n", "logits_e", ",", "logits_c", ",", "logits_n", "=", "[", "torch", ".", "logsumexp", "(", "item", ",", "1", ",", "keepdim", "=", "True", ")", "for", "item", "in", "[", "logits_e", ",", "logits_c", ",", "logits_n", "]", "]", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "logits_e", ",", "logits_c", ",", "logits_n", "]", ",", "1", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.train": [[91, 213], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_nli.set_seed", "tensorboardX.SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "tensorboardX.SummaryWriter.close", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "torch.CrossEntropyLoss", "run_nli.get_logits", "nn.CrossEntropyLoss.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "batch[].view", "batch[].view", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "batch[].size", "batch[].size", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "torch.save", "torch.save", "torch.save", "logger.info", "any", "run_nli.evaluate", "evaluate.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "tensorboardX.SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.set_seed", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.train", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.get_logits", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ".", "view", "(", "-", "1", ",", "batch", "[", "0", "]", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ".", "view", "(", "-", "1", ",", "batch", "[", "0", "]", ".", "size", "(", "-", "1", ")", ")", "}", "\n", "inputs", "[", "'token_type_ids'", "]", "=", "None", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "model_output", "=", "outputs", "[", "0", "]", "\n", "\n", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "logits", "=", "get_logits", "(", "batch", ",", "model_output", ",", "args", ".", "exp_model", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "batch", "[", "3", "]", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "'eval_{}'", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "'lr'", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'loss'", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.evaluate": [[215, 290], ["nli_utils.ExpProcessor", "run_nli.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "numpy.argmax", "nli_utils.exp_compute_metrics", "results.update", "os.path.join", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "os.path.join", "print", "numpy.savez_compressed", "open", "logger.info", "sorted", "os.path.exists", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "torch.CrossEntropyLoss", "run_nli.get_logits", "nn.CrossEntropyLoss.", "loss_fct.mean().item", "get_logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "os.path.basename().split", "os.path.splitext", "args.to_drop.split", "nli_utils.exp_compute_metrics.keys", "logger.info", "writer.write", "t.to", "batch[].view", "batch[].view", "get_logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "os.path.basename", "str", "str", "str", "batch[].size", "batch[].size", "loss_fct.mean", "get_logits.detach().cpu", "inputs[].detach().cpu", "os.path.basename", "get_logits.detach().cpu", "inputs[].detach().cpu", "os.path.dirname", "str", "get_logits.detach", "inputs[].detach", "os.path.dirname", "get_logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.load_and_cache_examples", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.exp_compute_metrics", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.get_logits"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ",", "analyze_attentions", "=", "False", ",", "eval_on_train", "=", "False", ")", ":", "\n", "    ", "processor", "=", "ExpProcessor", "(", ")", "\n", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "results", "=", "{", "}", "\n", "eval_dataset", ",", "indices", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "attentions", "=", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ".", "view", "(", "-", "1", ",", "batch", "[", "0", "]", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ".", "view", "(", "-", "1", ",", "batch", "[", "0", "]", ".", "size", "(", "-", "1", ")", ")", "}", "\n", "inputs", "[", "'token_type_ids'", "]", "=", "None", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "model_output", "=", "outputs", "[", "0", "]", "\n", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "logits", "=", "get_logits", "(", "batch", ",", "model_output", ",", "args", ".", "exp_model", ")", "\n", "tmp_eval_loss", "=", "loss_fct", "(", "logits", ",", "batch", "[", "3", "]", ")", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "nb_eval_steps", "+=", "1", "\n", "inputs", "[", "'labels'", "]", "=", "batch", "[", "3", "]", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds_", "=", "preds", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "result", "=", "compute_metrics", "(", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "if", "not", "eval_on_train", ":", "\n", "        ", "eval_dataset", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "eval_file", ")", ")", ")", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "eval_file_base", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "args", ".", "eval_file", ")", ")", "[", "0", "]", "\n", "to_drop_list", "=", "args", ".", "to_drop", ".", "split", "(", "','", ")", "if", "evaluate", "else", "[", "]", "\n", "to_drop_str", "=", "'_drop'", "+", "''", ".", "join", "(", "to_drop_list", ")", "if", "args", ".", "to_drop", "else", "''", "\n", "prediction_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'predictions_{}_{}_{}_{}{}.npz'", ".", "format", "(", "\n", "eval_dataset", ",", "\n", "eval_file_base", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "args", ".", "data_format", ")", ",", "\n", "to_drop_str", ")", ")", "\n", "print", "(", "\"Writing predictions to \"", ",", "prediction_file", ")", "\n", "np", ".", "savez_compressed", "(", "prediction_file", ",", "preds", "=", "preds", ",", "indices", "=", "indices", ",", "labels", "=", "out_label_ids", ")", "\n", "\n", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.load_and_cache_examples": [[292, 352], ["nli_utils.ExpProcessor", "os.path.split", "os.path.join", "os.path.exists", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "args.to_drop.split", "logger.info", "torch.load", "torch.load", "torch.load", "logger.info", "nli_utils.ExpProcessor.get_labels", "fn", "example_to_feature.convert_examples_to_features", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "str", "logger.info", "torch.save", "torch.save", "torch.save", "tokenizer.convert_tokens_to_ids"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor.get_labels", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.example_to_feature.convert_examples_to_features", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "ExpProcessor", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "\n", "filename", "=", "args", ".", "train_file", "if", "not", "evaluate", "else", "args", ".", "eval_file", "\n", "data_dir", ",", "filename_base", "=", "os", ".", "path", ".", "split", "(", "filename", ")", "\n", "\n", "if", "args", ".", "data_format", "==", "\"aggregate\"", ":", "data_storage_format", "=", "\"independent\"", "\n", "elif", "args", ".", "data_format", "==", "\"instance_aggregate\"", ":", "data_storage_format", "=", "\"instance_independent\"", "\n", "else", ":", "data_storage_format", "=", "args", ".", "data_format", "\n", "\n", "to_drop_list", "=", "args", ".", "to_drop", ".", "split", "(", "','", ")", "if", "evaluate", "else", "[", "]", "\n", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cached_seq{}_{}_{}_{}_{}'", ".", "format", "(", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "filename_base", ",", "\n", "data_storage_format", ",", "\n", "'drop'", "+", "args", ".", "to_drop", "if", "args", ".", "to_drop", "and", "evaluate", "else", "''", ",", "\n", "'_negs'", "if", "args", ".", "sample_negs", "and", "not", "evaluate", "else", "''", "\n", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "examples", ",", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "fn", "=", "processor", ".", "get_dev_examples", "if", "evaluate", "else", "processor", ".", "get_train_examples", "\n", "examples", "=", "fn", "(", "filename", ",", "data_format", "=", "data_storage_format", ",", "to_drop", "=", "to_drop_list", ")", "\n", "\n", "features", "=", "convert_examples_to_features", "(", "examples", ",", "\n", "tokenizer", ",", "\n", "label_list", "=", "label_list", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "sample_negatives", "=", "args", ".", "sample_negs", "if", "not", "evaluate", "else", "False", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "(", "examples", ",", "features", ")", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "features", "=", "features", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_token_type_ids", ",", "all_labels", ")", "\n", "\n", "indices", "=", "[", "example", ".", "guid", "for", "example", "in", "examples", "]", "\n", "return", "dataset", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.main": [[354, 561], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_nli.set_seed", "nli_utils.ExpProcessor", "nli_utils.ExpProcessor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "logger.info", "print", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "model_class.from_pretrained", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "model_class.from_pretrained.to", "run_nli.load_and_cache_examples", "run_nli.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "tokenizer_class.from_pretrained", "logger.info", "os.makedirs", "hasattr", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_nli.evaluate", "dict", "results.update", "bool", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.set_seed", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor.get_labels", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.run_nli.load_and_cache_examples", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.train", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input train file. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input eval file. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--exp_model\"", ",", "default", "=", "\"instance\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_format\"", ",", "default", "=", "\"instance\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--to_drop\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ")", "#comma-sep list", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--prompt_type\"", ",", "default", "=", "\"none\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Prompt given before explanation\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_annotations\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use annotations instead of generated explanations\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--sample_negs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'sample negative conjectures'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", ":", "\n", "        ", "raise", "ValueError", "(", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "args", ".", "output_dir", ")", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "processor", "=", "ExpProcessor", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "if", "args", ".", "exp_model", "in", "[", "\"independent\"", ",", "\"instance_independent\"", "]", ":", "args", ".", "model_num_outputs", "=", "1", "\n", "elif", "args", ".", "exp_model", "in", "[", "\"aggregate\"", ",", "\"instance_aggregate\"", "]", ":", "args", ".", "model_num_outputs", "=", "2", "\n", "else", ":", "args", ".", "model_num_outputs", "=", "3", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "num_labels", "=", "args", ".", "model_num_outputs", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "train_dataset", ",", "_", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "output_hidden_states", "=", "True", "\n", "model", ".", "output_attentions", "=", "True", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "global_step", ",", "analyze_attentions", "=", "True", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "'_{}'", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "print", "(", "results", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.__init__": [[11, 52], ["tokenizer.convert_tokens_to_ids", "lm_utils.TSVDataset.load_data", "os.path.exists", "print", "data.apply().to_list", "print", "print", "tokenizer.convert_tokens_to_ids", "len", "len", "open", "pickle.dump", "open", "pickle.load", "tokenizer.tokenize", "len", "tokenizer.convert_tokens_to_ids", "len", "print", "data.apply", "tokenizer.tokenize", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.load_data"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "'train'", ",", "block_size", "=", "512", ",", "get_annotations", "=", "False", ")", ":", "\n", "        ", "self", ".", "print_count", "=", "5", "\n", "self", ".", "eos_token_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "EOS_TOKEN", ")", "\n", "\n", "cached_features_file", ",", "data", "=", "self", ".", "load_data", "(", "file_path", ",", "block_size", ")", "\n", "self", ".", "data", "=", "data", "\n", "\n", "if", "get_annotations", ":", "cached_features_file", "=", "cached_features_file", "+", "'_annotated'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", ":", "\n", "            ", "print", "(", "'Loading features from'", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "examples", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "return", "\n", "\n", "", "print", "(", "'Saving features from '", ",", "file_path", ",", "' into '", ",", "cached_features_file", ")", "\n", "\n", "def", "create_example", "(", "r", ")", ":", "\n", "            ", "text1", "=", "'{} {} '", ".", "format", "(", "r", "[", "'input'", "]", ",", "EXP_TOKEN", ")", "\n", "tokenized_text1", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "tokenize", "(", "text1", ")", ")", "\n", "prompt_length", "=", "len", "(", "tokenized_text1", ")", "\n", "tokenized_text", ",", "total_length", "=", "tokenized_text1", ",", "len", "(", "tokenized_text1", ")", "\n", "if", "get_annotations", ":", "\n", "                ", "text2", "=", "r", "[", "'target'", "]", "\n", "tokenized_text2", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "tokenize", "(", "text2", ")", ")", "\n", "tokenized_text", "=", "tokenized_text1", "+", "tokenized_text2", "\n", "tokenized_text", "=", "tokenized_text", "+", "[", "self", ".", "eos_token_id", "]", "\n", "total_length", "=", "len", "(", "tokenized_text", ")", "\n", "if", "len", "(", "tokenized_text", ")", ">", "block_size", ":", "\n", "                    ", "tokenized_text", "=", "tokenized_text", "[", ":", "block_size", "]", "\n", "", "if", "len", "(", "tokenized_text", ")", "<", "block_size", ":", "\n", "                    ", "tokenized_text", "=", "tokenized_text", "+", "[", "self", ".", "eos_token_id", "]", "*", "(", "block_size", "-", "len", "(", "tokenized_text", ")", ")", "\n", "", "", "if", "self", ".", "print_count", ">", "0", ":", "\n", "                ", "print", "(", "'example: '", ",", "text1", "+", "text2", "if", "get_annotations", "else", "text1", ")", "\n", "self", ".", "print_count", "=", "self", ".", "print_count", "-", "1", "\n", "", "return", "(", "tokenized_text", ",", "prompt_length", ",", "total_length", ")", "\n", "\n", "", "self", ".", "examples", "=", "data", ".", "apply", "(", "create_example", ",", "axis", "=", "1", ")", ".", "to_list", "(", ")", "\n", "print", "(", "'Saving '", ",", "len", "(", "self", ".", "examples", ")", ",", "' examples'", ")", "\n", "with", "open", "(", "cached_features_file", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.__len__": [[53, 55], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.__getitem__": [[56, 58], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", "[", "0", "]", ")", ",", "self", ".", "examples", "[", "item", "]", "[", "1", "]", ",", "self", ".", "examples", "[", "item", "]", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.get_example_text": [[59, 61], ["None"], "methods", ["None"], ["", "def", "get_example_text", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "'prompt'", "]", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.add_explanation": [[62, 65], ["None"], "methods", ["None"], ["", "def", "add_explanation", "(", "self", ",", "index", ",", "explanation", ")", ":", "\n", "        ", "explanation_name", "=", "'Generated_Explanation'", "\n", "self", ".", "data", ".", "at", "[", "self", ".", "data", ".", "index", "[", "index", "]", ",", "explanation_name", "]", "=", "explanation", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.load_data": [[66, 73], ["os.path.isfile", "pandas.read_csv", "print", "os.path.split", "os.path.join"], "methods", ["None"], ["", "def", "load_data", "(", "self", ",", "file_path", ",", "block_size", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "data", "=", "pd", ".", "read_csv", "(", "file_path", ",", "sep", "=", "'\\t'", ",", "index_col", "=", "'pairID'", ")", "\n", "print", "(", "data", ")", "\n", "directory", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "file_path", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "'cached_lm_{}_{}'", ".", "format", "(", "block_size", ",", "filename", ")", ")", "\n", "return", "cached_features_file", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save": [[74, 76], ["lm_utils.TSVDataset.data.to_csv"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "self", ".", "data", ".", "to_csv", "(", "filename", ",", "sep", "=", "'\\t'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.example_to_feature.convert_examples_to_features": [[35, 185], ["enumerate", "transformers.file_utils.is_tf_available", "isinstance", "len", "example_to_feature.convert_examples_to_features.get_indices"], "function", ["None"], ["def", "convert_examples_to_features", "(", "examples", ",", "tokenizer", ",", "\n", "max_length", "=", "512", ",", "\n", "label_list", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "sample_negatives", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of ``InputFeatures``\n\n    Args:\n        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n        tokenizer: Instance of a tokenizer that will tokenize the examples\n        max_length: Maximum example length\n        task: GLUE task\n        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n        pad_token: Padding token\n        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n            actual values)\n\n    Returns:\n        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n        a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n    \"\"\"", "\n", "is_tf_dataset", "=", "False", "\n", "if", "is_tf_available", "(", ")", "and", "isinstance", "(", "examples", ",", "tf", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "is_tf_dataset", "=", "True", "\n", "\n", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "if", "examples", "[", "0", "]", ".", "text_b", "is", "not", "None", ":", "\n", "        ", "k", "=", "len", "(", "examples", "[", "0", "]", ".", "text_b", ")", "\n", "", "if", "sample_negatives", ":", "\n", "        ", "neg_indices", "=", "[", "np", ".", "random", ".", "choice", "(", "len", "(", "examples", ")", ",", "size", "=", "len", "(", "examples", ")", ",", "replace", "=", "False", ")", "for", "i", "in", "range", "(", "k", ")", "]", "\n", "", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d\"", "%", "(", "ex_index", ")", ")", "\n", "", "if", "is_tf_dataset", ":", "\n", "            ", "example", "=", "processor", ".", "get_example_from_tensor_dict", "(", "example", ")", "\n", "\n", "", "if", "type", "(", "example", ".", "text_a", ")", "is", "list", ":", "\n", "            ", "text_a", "=", "example", ".", "text_a", "\n", "text_b", "=", "[", "example", ".", "text_b", "]", "*", "len", "(", "text_a", ")", "\n", "", "elif", "type", "(", "example", ".", "text_b", ")", "is", "list", ":", "\n", "            ", "text_b", "=", "example", ".", "text_b", "\n", "if", "sample_negatives", ":", "\n", "                ", "label_idx", "=", "label_map", "[", "example", ".", "label", "]", "\n", "text_b_neg", "=", "[", "(", "examples", "[", "neg_indices", "[", "i", "]", "[", "ex_index", "]", "]", ")", ".", "text_b", "[", "label_idx", "]", "for", "i", "in", "range", "(", "k", ")", "]", "\n", "text_b_neg", "[", "label_idx", "]", "=", "text_b", "[", "label_idx", "]", "\n", "\n", "", "text_a", "=", "[", "example", ".", "text_a", "]", "*", "len", "(", "text_b", ")", "\n", "", "else", ":", "\n", "            ", "text_a", "=", "[", "example", ".", "text_a", "]", "\n", "text_b", "=", "[", "example", ".", "text_b", "]", "\n", "\n", "", "if", "0", ":", "#sample_negatives:", "\n", "            ", "print", "(", "'Created negative samples'", ")", "\n", "print", "(", "'Original example: label:{} text_a: {} text_b1: {}, 2: {}, 3:{}'", ".", "format", "(", "example", ".", "label", ",", "text_a", "[", "0", "]", ",", "text_b", "[", "0", "]", ",", "text_b", "[", "1", "]", ",", "text_b", "[", "2", "]", ")", ")", "\n", "print", "(", "'Converted example: text_a: {} text_b1: {}, 2: {}, 3:{}'", ".", "format", "(", "text_a", "[", "0", "]", ",", "text_b_neg", "[", "0", "]", ",", "text_b_neg", "[", "1", "]", ",", "text_b_neg", "[", "2", "]", ")", ")", "\n", "\n", "", "def", "get_indices", "(", "t1", ",", "t2", ")", ":", "\n", "            ", "out", "=", "[", "]", "\n", "for", "a", ",", "b", "in", "zip", "(", "t1", ",", "t2", ")", ":", "\n", "                ", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "\n", "a", ",", "\n", "b", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "max_length", ",", "\n", ")", "\n", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                    ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "                    ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "input_ids", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "attention_mask", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "token_type_ids", ")", ",", "max_length", ")", "\n", "out", ".", "append", "(", "(", "input_ids", ",", "attention_mask", ",", "token_type_ids", ")", ")", "\n", "\n", "", "if", "len", "(", "t1", ")", "==", "1", ":", "\n", "                ", "input_ids", ",", "attention_mask", ",", "token_type_ids", "=", "out", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "input_ids", ",", "attention_mask", ",", "token_type_ids", "=", "zip", "(", "*", "out", ")", "\n", "", "return", "input_ids", ",", "attention_mask", ",", "token_type_ids", "\n", "\n", "", "input_ids", ",", "attention_mask", ",", "token_type_ids", "=", "get_indices", "(", "text_a", ",", "text_b", ")", "\n", "if", "sample_negatives", ":", "\n", "            ", "input_ids_n", ",", "attention_mask_n", ",", "token_type_ids_n", "=", "get_indices", "(", "text_a", ",", "text_b_neg", ")", "\n", "\n", "", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "token_type_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "label", "=", "label", ")", ")", "\n", "\n", "if", "sample_negatives", ":", "\n", "            ", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids_n", ",", "\n", "attention_mask", "=", "attention_mask_n", ",", "\n", "token_type_ids", "=", "token_type_ids_n", ",", "\n", "label", "=", "label", ")", ")", "\n", "\n", "", "", "if", "is_tf_available", "(", ")", "and", "is_tf_dataset", ":", "\n", "        ", "def", "gen", "(", ")", ":", "\n", "            ", "for", "ex", "in", "features", ":", "\n", "                ", "yield", "(", "{", "'input_ids'", ":", "ex", ".", "input_ids", ",", "\n", "'attention_mask'", ":", "ex", ".", "attention_mask", ",", "\n", "'token_type_ids'", ":", "ex", ".", "token_type_ids", "}", ",", "\n", "ex", ".", "label", ")", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "gen", ",", "\n", "(", "{", "'input_ids'", ":", "tf", ".", "int32", ",", "\n", "'attention_mask'", ":", "tf", ".", "int32", ",", "\n", "'token_type_ids'", ":", "tf", ".", "int32", "}", ",", "\n", "tf", ".", "int64", ")", ",", "\n", "(", "{", "'input_ids'", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "'attention_mask'", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "'token_type_ids'", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", "}", ",", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ")", ")", "\n", "\n", "", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.set_seed": [[54, 60], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.train": [[61, 184], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "finetune_lm.set_seed", "tensorboardX.SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "tensorboardX.SummaryWriter.close", "torch.max().item", "torch.max().item", "inputs.to.to", "labels.to.to", "range", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "batch.clone().detach", "len", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "torch.max", "torch.max", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "torch.save", "torch.save", "logger.info", "any", "batch.clone", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "finetune_lm.evaluate", "evaluate.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "tensorboardX.SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.set_seed", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.train", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility (even between python 2 and 3)", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "batch", ",", "prompt_lengths", ",", "total_lengths", "=", "batch", "\n", "max_length", "=", "torch", ".", "max", "(", "total_lengths", ")", ".", "item", "(", ")", "\n", "batch", "=", "batch", "[", ":", ",", ":", "max_length", "]", "\n", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "prompt_lengths", ")", ")", ":", "\n", "                ", "labels", "[", "idx", ",", ":", "prompt_lengths", "[", "idx", "]", "]", "=", "cross_entropy_ignore_index", "\n", "", "model", ".", "train", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "'eval_{}'", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "'lr'", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'loss'", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.sample_sequence": [[185, 203], ["torch.tensor", "torch.tensor", "next_token.view.unsqueeze", "torch.no_grad", "torch.no_grad", "range", "model", "torch.argmax", "torch.argmax", "torch.cat", "torch.cat", "torch.argmax.view", "torch.argmax.item", "torch.argmax.view"], "function", ["None"], ["", "def", "sample_sequence", "(", "model", ",", "length", ",", "context", ",", "device", "=", "'cpu'", ",", "eos_token_id", "=", "None", ")", ":", "\n", "    ", "context", "=", "torch", ".", "tensor", "(", "context", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "context", "=", "context", ".", "unsqueeze", "(", "0", ")", "\n", "generated", "=", "context", "\n", "past", "=", "None", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "_", "in", "range", "(", "length", ")", ":", "\n", "#inputs = {'input_ids': context}", "\n", "#output, past = model(**inputs, past=past)", "\n", "            ", "inputs", "=", "{", "'input_ids'", ":", "generated", "}", "\n", "output", ",", "past", "=", "model", "(", "**", "inputs", ")", "\n", "next_token_logits", "=", "output", "[", "0", ",", "-", "1", ",", ":", "]", "\n", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ")", "\n", "generated", "=", "torch", ".", "cat", "(", "(", "generated", ",", "next_token", ".", "view", "(", "1", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "if", "next_token", ".", "item", "(", ")", "==", "eos_token_id", ":", "\n", "                ", "break", "\n", "", "context", "=", "next_token", ".", "view", "(", "1", ",", "1", ")", "\n", "", "", "return", "generated", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.generate": [[204, 246], ["lm_utils.TSVDataset", "torch.utils.data.DataLoader", "logger.info", "logger.info", "model.eval", "enumerate", "os.path.split", "os.path.split", "os.path.join", "lm_utils.TSVDataset.save", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "tqdm.tqdm", "batch.squeeze.squeeze", "finetune_lm.sample_sequence", "out[].tolist", "tokenizer.decode", "[].strip", "lm_utils.TSVDataset.add_explanation", "print", "os.path.normpath", "tokenizer.convert_tokens_to_ids", "[].strip.split", "len"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.sample_sequence", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.add_explanation"], ["", "def", "generate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "if", "args", ".", "length", "<", "0", "and", "model", ".", "config", ".", "max_position_embeddings", ">", "0", ":", "\n", "        ", "args", ".", "length", "=", "model", ".", "config", ".", "max_position_embeddings", "\n", "", "elif", "0", "<", "model", ".", "config", ".", "max_position_embeddings", "<", "args", ".", "length", ":", "\n", "        ", "args", ".", "length", "=", "model", ".", "config", ".", "max_position_embeddings", "# No generation bigger than model size ", "\n", "", "elif", "args", ".", "length", "<", "0", ":", "\n", "        ", "args", ".", "length", "=", "MAX_LENGTH", "# avoid infinite loop", "\n", "\n", "", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "eval_dataset", "=", "TSVDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "args", ".", "eval_data_file", ",", "\n", "block_size", "=", "args", ".", "block_size", ",", "get_annotations", "=", "False", ")", "\n", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "1", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running generation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "index", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ")", ":", "\n", "        ", "batch", ",", "prompt_lengths", ",", "total_lengths", "=", "batch", "\n", "batch", "=", "batch", ".", "squeeze", "(", ")", "\n", "out", "=", "sample_sequence", "(", "\n", "model", "=", "model", ",", "\n", "context", "=", "batch", ",", "\n", "length", "=", "args", ".", "length", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", "eos_token_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "EOS_TOKEN", ")", ",", "\n", ")", "\n", "out", "=", "out", "[", "0", ",", "len", "(", "batch", ")", ":", "]", ".", "tolist", "(", ")", "\n", "text", "=", "tokenizer", ".", "decode", "(", "out", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "text", "=", "text", ".", "split", "(", "EOS_TOKEN", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "eval_dataset", ".", "add_explanation", "(", "index", ",", "text", ")", "\n", "print", "(", "text", ")", "\n", "\n", "#save", "\n", "", "directory", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "args", ".", "eval_data_file", ")", "\n", "model_directory", ",", "model_name", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "normpath", "(", "args", ".", "output_dir", ")", ")", "\n", "output_name", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "'{}_{}'", ".", "format", "(", "model_name", ",", "filename", ")", ")", "\n", "eval_dataset", ".", "save", "(", "output_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.evaluate": [[247, 293], ["lm_utils.TSVDataset", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "tqdm.tqdm", "torch.exp", "torch.exp", "os.path.join", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "batch.to.to", "torch.tensor", "torch.tensor", "open", "logger.info", "sorted", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "str", "lm_loss.mean", "str"], "function", ["None"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "eval_dataset", "=", "TSVDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "args", ".", "eval_data_file", ",", "\n", "block_size", "=", "args", ".", "block_size", ",", "get_annotations", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "batch", ",", "prompt_lengths", ",", "total_lengths", "=", "batch", "\n", "batch", "=", "batch", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "batch", ",", "labels", "=", "batch", ")", "\n", "lm_loss", "=", "outputs", "[", "0", "]", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\n", "\"perplexity\"", ":", "perplexity", "\n", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.main": [[295, 501], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "finetune_lm.set_seed", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "logger.info", "ValueError", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "print", "tokenizer_class.from_pretrained.add_tokens", "print", "model_class.from_pretrained", "model_class.from_pretrained.resize_token_embeddings", "model_class.from_pretrained.to", "torch.distributed.barrier", "torch.distributed.barrier", "lm_utils.TSVDataset", "finetune_lm.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "model_class.from_pretrained", "model_class.from_pretrained.to", "tokenizer_class.from_pretrained", "finetune_lm.evaluate", "print", "model_class.from_pretrained", "model_class.from_pretrained.to", "tokenizer_class.from_pretrained", "finetune_lm.generate", "len", "len", "len", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "os.makedirs", "hasattr", "os.path.join", "bool", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "torch.cuda.is_available", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.set_seed", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.train", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.lm_utils.TSVDataset.save", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.evaluate", "home.repos.pwc.inspect_result.SawanKumar28_nile.None.finetune_lm.generate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "\"bert-base-cased\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--block_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the eval data file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_generate\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to generate text on the eval data file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--length\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "\"Length for generation\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_type\"", ",", "default", "=", "\"tsv\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Dataset type\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"", "\n", "\"or remove the --do_eval argument.\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", ":", "\n", "        ", "raise", "ValueError", "(", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "args", ".", "output_dir", ")", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len_single_sentence", "# Our input block size will be the max possible for the model", "\n", "", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len_single_sentence", ")", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "#Additional tokens", "\n", "        ", "print", "(", "'#tokens'", ",", "len", "(", "tokenizer", ")", ")", "\n", "new_tokens", "=", "[", "EXP_TOKEN", ",", "EOS_TOKEN", "]", "\n", "tokenizer", ".", "add_tokens", "(", "new_tokens", ")", "\n", "print", "(", "'#extended tokens'", ",", "len", "(", "tokenizer", ")", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "TSVDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "args", ".", "train_data_file", ",", "\n", "block_size", "=", "args", ".", "block_size", ",", "get_annotations", "=", "True", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "print", "(", "result", ")", "\n", "\n", "#Generation", "\n", "", "if", "args", ".", "do_generate", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "generate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor.get_train_examples": [[11, 15], ["pandas.read_csv", "nli_utils.ExpProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "filepath", ",", "data_format", "=", "\"instance\"", ",", "to_drop", "=", "[", "]", ")", ":", "\n", "        ", "data", "=", "pd", ".", "read_csv", "(", "filepath", ",", "index_col", "=", "self", ".", "index_col", ")", "\n", "examples", "=", "self", ".", "_create_examples", "(", "data", ",", "'train'", ",", "data_format", "=", "data_format", ",", "to_drop", "=", "to_drop", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor.get_dev_examples": [[16, 20], ["pandas.read_csv", "nli_utils.ExpProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "filepath", ",", "data_format", "=", "\"instance\"", ",", "to_drop", "=", "[", "]", ")", ":", "\n", "        ", "data", "=", "pd", ".", "read_csv", "(", "filepath", ",", "index_col", "=", "self", ".", "index_col", ")", "\n", "examples", "=", "self", ".", "_create_examples", "(", "data", ",", "'dev'", ",", "data_format", "=", "data_format", ",", "to_drop", "=", "to_drop", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor.get_labels": [[21, 23], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.ExpProcessor._create_examples": [[27, 63], ["labeled_examples.iterrows", "ValueError", "examples.append", "transformers.data.processors.utils.InputExample", "zip", "zip"], "methods", ["None"], ["def", "_create_examples", "(", "self", ",", "labeled_examples", ",", "set_type", ",", "data_format", "=", "\"instance\"", ",", "to_drop", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "if", "data_format", "not", "in", "self", ".", "data_formats", ":", "\n", "            ", "raise", "ValueError", "(", "\"Data format {} not supported\"", ".", "format", "(", "data_format", ")", ")", "\n", "\n", "", "if", "'explanation'", "in", "to_drop", ":", "to_drop", "=", "self", ".", "labels", "\n", "\n", "keep_labels", "=", "[", "True", "if", "l", "not", "in", "to_drop", "else", "False", "for", "l", "in", "self", ".", "labels", "]", "\n", "exp_names", "=", "[", "\"{}_explanation\"", ".", "format", "(", "l", ")", "for", "l", "in", "self", ".", "labels", "]", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "idx", ",", "le", ")", "in", "labeled_examples", ".", "iterrows", "(", ")", ":", "\n", "            ", "guid", "=", "idx", "\n", "label", "=", "le", "[", "self", ".", "gold_label", "]", "\n", "\n", "if", "data_format", "in", "[", "\"independent\"", ",", "\"instance_independent\"", "]", ":", "\n", "                ", "exp_text", "=", "[", "le", "[", "exp_name", "]", "if", "keep", "else", "\"\"", "\n", "for", "l", ",", "keep", ",", "exp_name", "in", "zip", "(", "self", ".", "labels", ",", "keep_labels", ",", "exp_names", ")", "]", "\n", "", "elif", "data_format", "in", "[", "\"append\"", ",", "\"instance_append\"", "]", ":", "\n", "                ", "exp_text", "=", "\" \"", ".", "join", "(", "[", "\"{}: {}\"", ".", "format", "(", "l", ",", "le", "[", "exp_name", "]", ")", "if", "keep", "else", "\"\"", "\n", "for", "l", ",", "keep", ",", "exp_name", "in", "zip", "(", "self", ".", "labels", ",", "keep_labels", ",", "exp_names", ")", "]", ")", "\n", "\n", "", "if", "data_format", "==", "\"instance\"", ":", "\n", "                ", "text_a", ",", "text_b", "=", "le", "[", "self", ".", "s1", "]", ",", "le", "[", "self", ".", "s2", "]", "\n", "", "elif", "data_format", "in", "[", "\"Explanation_1\"", ",", "\"all_explanation\"", "]", ":", "\n", "                ", "text_a", ",", "text_b", "=", "le", "[", "data_format", "]", ",", "None", "\n", "", "elif", "data_format", "in", "[", "\"independent\"", ",", "\"append\"", "]", ":", "\n", "                ", "text_a", ",", "text_b", "=", "exp_text", ",", "None", "\n", "", "elif", "data_format", "in", "[", "\"instance_independent\"", ",", "\"instance_append\"", "]", ":", "\n", "                ", "instance_text", "=", "\"Premise: {} Hypothesis: {}\"", ".", "format", "(", "\n", "le", "[", "self", ".", "s1", "]", ",", "le", "[", "self", ".", "s2", "]", ")", "if", "\"instance\"", "not", "in", "to_drop", "else", "\"Premise: Hypothesis:\"", "\n", "text_a", ",", "text_b", "=", "instance_text", ",", "exp_text", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.simple_accuracy": [[64, 66], ["None"], "function", ["None"], ["", "", "def", "simple_accuracy", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "return", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.exp_compute_metrics": [[67, 70], ["len", "len", "nli_utils.simple_accuracy"], "function", ["home.repos.pwc.inspect_result.SawanKumar28_nile.None.nli_utils.simple_accuracy"], ["", "def", "exp_compute_metrics", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "assert", "len", "(", "preds", ")", "==", "len", "(", "labels", ")", "\n", "return", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "labels", ")", "}", "\n", "", ""]]}