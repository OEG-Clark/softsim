{"home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.__init__": [[316, 321], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "None", "\n", "self", ".", "_iterator", "=", "None", "\n", "self", ".", "_batch_op", "=", "None", "\n", "self", ".", "_sess", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.__del__": [[322, 325], ["data_noise_in.Dataset._sess.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_sess", ":", "\n", "            ", "self", ".", "_sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.__iter__": [[326, 328], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.__next__": [[329, 336], ["data_noise_in.Dataset.get_next"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.get_next"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "b", "=", "self", ".", "get_next", "(", ")", "\n", "", "except", ":", "\n", "            ", "raise", "StopIteration", "\n", "", "else", ":", "\n", "            ", "return", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.get_next": [[339, 341], ["data_noise_in.Dataset._sess.run"], "methods", ["None"], ["def", "get_next", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sess", ".", "run", "(", "self", ".", "_batch_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.reset": [[342, 344], ["data_noise_in.Dataset._sess.run"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "feed_dict", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "_sess", ".", "run", "(", "self", ".", "_iterator", ".", "initializer", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset._bulid": [[345, 359], ["dataset.make_initializable_iterator", "data_noise_in.Dataset._iterator.get_next", "data_noise_in.session", "data_noise_in.Dataset.reset"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.get_next", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.session", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.reset"], ["", "def", "_bulid", "(", "self", ",", "dataset", ",", "sess", "=", "None", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "dataset", "\n", "\n", "self", ".", "_iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "self", ".", "_batch_op", "=", "self", ".", "_iterator", ".", "get_next", "(", ")", "\n", "if", "sess", ":", "\n", "            ", "self", ".", "_sess", "=", "sess", "\n", "", "else", ":", "\n", "            ", "self", ".", "_sess", "=", "session", "(", ")", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.dataset": [[360, 363], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.iterator": [[364, 367], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterator", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Dataset.batch_op": [[368, 371], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_op", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_op", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Celeba.__init__": [[388, 541], ["data_noise_in.Dataset.__init__", "os.path.join", "data_noise_in.Celeba._bulid", "tensorflow.image.resize_images", "tensorflow.image.resize_images", "numpy.loadtxt", "os.path.exists", "numpy.loadtxt", "data_noise_in.disk_image_batch_dataset", "len", "tensorflow.image.crop_to_bounding_box", "tensorflow.gather", "tensorflow.image.crop_to_bounding_box", "tensorflow.gather", "functools.partial", "os.path.exists", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "len", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.reduce_all", "tensorflow.reduce_all", "os.path.join", "os.path.join", "tensorflow.equal", "tensorflow.equal", "name.replace", "os.path.join", "tensorflow.gather", "tensorflow.ones_like", "tensorflow.gather", "tensorflow.zeros_like", "str", "tensorflow.gather", "tensorflow.gather", "str"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset"], ["def", "__init__", "(", "self", ",", "data_dir", ",", "atts", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "crop", "=", "True", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ")", ":", "\n", "        ", "super", "(", "Celeba", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ",", "noise", ")", ":", "\n", "            ", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "if", "is_tfrecord", ":", "\n", "                ", "label", "=", "tf", ".", "gather", "(", "label", ",", "att_id", ")", "##### 2020.02.07", "\n", "#noise = tf.gather(noise, att_id)", "\n", "", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", ",", "noise", "\n", "", "def", "map_func", "(", "img", ",", "label", ")", ":", "\n", "            ", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "if", "is_tfrecord", ":", "\n", "               ", "label", "=", "tf", ".", "gather", "(", "label", ",", "att_id", ")", "##### 2020.02.07", "\n", "#noise = tf.gather(noise, att_id)", "\n", "", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", "\n", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "feature_val", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "ones_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "zeros_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "", "list_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'list_attr_celeba.txt'", ")", "\n", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "170", "\n", "att_id", "=", "[", "Celeba", ".", "att_dict", "[", "att", "]", "for", "att", "in", "atts", "]", "#atts[filter_att]", "\n", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'celeba_tfrecords'", ",", "part", "+", "\"_\"", "+", "atts", "[", "filter_att", "]", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'celeba_tfrecords'", ",", "part", "+", "\"_\"", "+", "atts", "[", "filter_att", "]", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "40", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "", "else", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'celeba_tfrecords'", ",", "part", "+", "\"_crop_in.tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "40", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "", "if", "part", "==", "'train'", ":", "\n", "                ", "self", ".", "_img_num", "=", "182000", "\n", "", "", "else", ":", "\n", "            ", "if", "crop", ":", "\n", "                ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_align_celeba'", ")", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_align_celeba_png'", ")", "\n", "", "else", ":", "\n", "                ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_crop_celeba'", ")", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_crop_celeba_png'", ")", "\n", "\n", "", "names", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "0", "]", ",", "dtype", "=", "np", ".", "str", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "img_dir_png", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_png", ",", "name", ".", "replace", "(", "'jpg'", ",", "'png'", ")", ")", "for", "name", "in", "names", "]", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "img_dir_jpg", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "name", ")", "for", "name", "in", "names", "]", "\n", "\n", "", "att_id", "=", "[", "Celeba", ".", "att_dict", "[", "att", "]", "+", "1", "for", "att", "in", "atts", "]", "\n", "labels", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "att_id", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "if", "len", "(", "labels", ".", "shape", ")", "==", "1", ":", "\n", "                ", "labels", "=", "labels", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "# if img_resize == 64:", "\n", "#     # crop as how VAE/GAN do", "\n", "#     offset_h = 40", "\n", "#     offset_w = 15", "\n", "#     img_size = 148", "\n", "# else:", "\n", "#     offset_h = 26", "\n", "#     offset_w = 3", "\n", "#     img_size = 170", "\n", "\n", "", "offset_h", "=", "26", "\n", "offset_w", "=", "3", "\n", "img_size", "=", "170", "\n", "\n", "if", "im_no", "is", "not", "None", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "#repeat = 1", "\n", "img_paths", "=", "[", "img_paths", "[", "i", "-", "1", "]", "for", "i", "in", "im_no", "]", "\n", "labels", "=", "labels", "[", "[", "i", "-", "1", "for", "i", "in", "im_no", "]", "]", "\n", "", "elif", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "#repeat = 1", "\n", "img_paths", "=", "img_paths", "[", "182637", ":", "]", "\n", "labels", "=", "labels", "[", "182637", ":", "]", "\n", "# img_paths = img_paths[182637:182637+5000]", "\n", "# labels = labels[182637:182637+5000]", "\n", "# img_paths = img_paths[0:64]   ###temp!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!", "\n", "# labels = labels[0:64]", "\n", "", "elif", "part", "==", "'val'", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", "182000", ":", "182637", "]", "\n", "labels", "=", "labels", "[", "182000", ":", "182637", "]", "\n", "", "else", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", ":", "182000", "]", "\n", "labels", "=", "labels", "[", ":", "182000", "]", "\n", "\n", "", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "atts", "=", "atts", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "offset_h", "=", "offset_h", "\n", "self", ".", "offset_w", "=", "offset_w", "\n", "self", ".", "img_size", "=", "img_size", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Celeba.__len__": [[542, 544], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Celeba.check_attribute_conflict": [[545, 576], ["att_names.index", "data_noise_in.Celeba.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_attribute_conflict", "(", "att_batch", ",", "att_name", ",", "att_names", ")", ":", "\n", "        ", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "att_id", "=", "att_names", ".", "index", "(", "att_name", ")", "\n", "\n", "for", "att", "in", "att_batch", ":", "\n", "            ", "if", "att_name", "in", "[", "'Bald'", ",", "'Receding_Hairline'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "\n", "", "elif", "att_name", "==", "'Bangs'", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bald'", ")", "\n", "_set", "(", "att", ",", "0", ",", "'Receding_Hairline'", ")", "\n", "", "elif", "att_name", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# _set(att, 0, 'bald')", "\n", "", "", "", "elif", "att_name", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# Removed since `Mustache` and `No_Beard` are not conflict.", "\n", "# But the two attributes are not well labeled in the dataset.", "\n", "#            elif att_name in ['Mustache', 'No_Beard'] and att[att_id] == 1:", "\n", "#                for n in ['Mustache', 'No_Beard']:", "\n", "#                    if n != att_name:", "\n", "#                        _set(att, 0, n)", "\n", "\n", "", "", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Celeba.check_random_attribute_conflict": [[577, 606], ["att_names.index", "random.randint", "range", "len", "sum", "data_noise_in.Celeba.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_random_attribute_conflict", "(", "att_batch", ",", "att_names", ",", "hair_color", "=", "None", ")", ":", "\n", "        ", "\"\"\" For randomly generated attributes, tested but not used in this repo. \"\"\"", "\n", "\n", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "def", "_idx", "(", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "return", "att_names", ".", "index", "(", "att_name", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "att", "in", "att_batch", ":", "\n", "            ", "valid_atts", "=", "[", "i", "for", "i", "in", "[", "'Receding_Hairline'", ",", "'Bald'", "]", "if", "i", "in", "att_names", "]", "\n", "if", "'Bangs'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Bangs'", ")", "]", "==", "1", "and", "len", "(", "valid_atts", ")", ">", "0", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "valid_atts", "]", ")", ">", "0", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "[", "_set", "(", "att", ",", "0", ",", "i", ")", "for", "i", "in", "valid_atts", "]", "\n", "#            hair_color = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']", "\n", "", "if", "hair_color", "is", "not", "None", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "hair_color", "]", ")", ">", "1", ":", "\n", "                ", "one", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "hair_color", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hair_color", ")", ")", ":", "\n", "                    ", "_set", "(", "att", ",", "1", "if", "i", "==", "one", "else", "0", ",", "hair_color", "[", "i", "]", ")", "\n", "", "", "if", "'Straight_Hair'", "in", "att_names", "and", "'Wavy_Hair'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Straight_Hair'", ")", "]", "==", "1", "and", "att", "[", "\n", "_idx", "(", "'Wavy_Hair'", ")", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Straight_Hair'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "_set", "(", "att", ",", "0", ",", "'Wavy_Hair'", ")", "\n", "#            if 'Mustache' in att_names and 'No_Beard' in att_names and att[_idx('Mustache')] == 1 and att[_idx('No_Beard')] == 1:", "\n", "#                _set(att, 0, 'Mustache') if random.random() < 0.5 else _set(att, 0, 'No_Beard')", "\n", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Celeba.creat_tfrecord": [[607, 638], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "numpy.array", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "tensorflow.train.Int64List"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "# sess = tl.session()", "\n", "# noise = sess.run(tf.random_normal((1, 64))).astype(np.float)", "\n", "# sess.close()", "\n", "# noise = np.random.normal(0, 1, 64)", "\n", "noise_index", "=", "np", ".", "array", "(", "[", "i", "]", ")", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", ",", "\n", "'noise'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "noise_index", ")", ")", "#", "\n", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Celeba.creat_tfrecord_split_opposite_label": [[639, 679], ["range", "os.path.exists", "os.makedirs", "len", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.python_io.TFRecordWriter.write", "str", "str", "str", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.strftime", "time.time", "time.localtime", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "time.time"], "methods", ["None"], ["", "def", "creat_tfrecord_split_opposite_label", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "atts", ")", ")", ":", "\n", "            ", "att", "=", "self", ".", "atts", "[", "attribute_id", "]", "\n", "count_true", "=", "0", "\n", "count_false", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "false_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_False_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "attribute_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "elif", "label", "[", "attribute_id", "]", "==", "-", "1", ":", "\n", "                        ", "false_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_false", "=", "count_false", "+", "1", "\n", "if", "count_false", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} negative images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_false", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "\"%d negative images are processed.\"", "%", "count_false", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "false_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Celeba.creat_tfrecord_split_true_label": [[680, 711], ["range", "os.path.exists", "os.makedirs", "len", "data_noise_in.Celeba.atts.index", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "img_name.encode", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "", "", "def", "creat_tfrecord_split_true_label", "(", "self", ",", "selected_atts", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "selected_atts", ")", ")", ":", "\n", "            ", "att", "=", "selected_atts", "[", "attribute_id", "]", "\n", "att_id", "=", "self", ".", "atts", ".", "index", "(", "att", ")", "\n", "count_true", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "att", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "att", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "att_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "", "", "", "", "class", "RaFD_1608", "(", "Dataset", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.RaFD_1608.__init__": [[716, 865], ["data_noise_in.Dataset.__init__", "os.path.join", "data_noise_in.RaFD_1608._bulid", "tensorflow.image.resize_images", "tensorflow.image.resize_images", "tensorflow.image.resize_images", "numpy.loadtxt", "os.path.exists", "numpy.loadtxt", "data_noise_in.expression_div", "data_noise_in.disk_image_batch_dataset", "len", "tensorflow.image.crop_to_bounding_box", "tensorflow.image.crop_to_bounding_box", "tensorflow.image.crop_to_bounding_box", "functools.partial", "os.path.exists", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "os.path.join", "data_noise_in.tfrecord_batch_dataset_RaFD", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.reduce_all", "tensorflow.reduce_all", "os.path.join", "os.path.join", "tensorflow.equal", "tensorflow.equal", "name.replace", "os.path.join", "tensorflow.gather", "tensorflow.ones_like", "tensorflow.gather", "tensorflow.zeros_like", "str", "tensorflow.gather", "tensorflow.gather", "str"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.expression_div", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.tfrecord_batch_dataset_RaFD"], ["def", "__init__", "(", "self", ",", "data_dir", ",", "atts", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "crop", "=", "False", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ")", ":", "\n", "        ", "super", "(", "RaFD_1608", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "s_img", ",", "s_label", ",", "noise", ",", "t_label", ",", "t_img", ")", ":", "\n", "            ", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "s_img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "s_img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "", "s_img", "=", "tf", ".", "image", ".", "resize_images", "(", "s_img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "s_img", "=", "tf", ".", "clip_by_value", "(", "s_img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "s_label", "=", "(", "s_label", "+", "1", ")", "//", "2", "\n", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "t_img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "t_img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "", "t_img", "=", "tf", ".", "image", ".", "resize_images", "(", "t_img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "t_img", "=", "tf", ".", "clip_by_value", "(", "t_img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "t_label", "=", "(", "t_label", "+", "1", ")", "//", "2", "\n", "return", "s_img", ",", "s_label", ",", "noise", ",", "t_label", ",", "t_img", "\n", "", "def", "map_func", "(", "img", ",", "label", ")", ":", "\n", "            ", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "# if is_tfrecord:", "\n", "#    label = tf.gather(label, att_id)", "\n", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", "\n", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "feature_val", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "ones_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "zeros_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "", "list_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'RaFD_1608.txt'", ")", "\n", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "500", "\n", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'RaFD_1608_tfrecords'", ",", "part", "+", "\"_\"", "+", "atts", "[", "filter_att", "]", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'celeba_tfrecords'", ",", "part", "+", "\"_\"", "+", "atts", "[", "filter_att", "]", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "40", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "", "else", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'RaFD_1608_tfrecords'", ",", "part", "+", "\"_crop.tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset_RaFD", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "8", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "", "if", "part", "==", "'train'", ":", "\n", "                ", "self", ".", "_img_num", "=", "1447", "\n", "", "", "else", ":", "\n", "            ", "if", "crop", ":", "\n", "                ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'RafD_500_0.35_cam3'", ")", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_align_celeba_png'", ")", "\n", "", "else", ":", "\n", "                ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'RafD_500_0.35_cam3'", ")", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_crop_celeba_png'", ")", "\n", "\n", "", "names", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "0", "]", ",", "dtype", "=", "np", ".", "str", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "img_dir_png", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_png", ",", "name", ".", "replace", "(", "'jpg'", ",", "'png'", ")", ")", "for", "name", "in", "names", "]", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "img_dir_jpg", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "name", ")", "for", "name", "in", "names", "]", "\n", "\n", "", "labels_index", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "2", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "labels", "=", "expression_div", "(", "labels_index", ")", "\n", "# if len(labels.shape) == 1:", "\n", "#     labels = labels[:, np.newaxis]", "\n", "# if img_resize == 64:", "\n", "#     # crop as how VAE/GAN do", "\n", "#     offset_h = 40", "\n", "#     offset_w = 15", "\n", "#     img_size = 148", "\n", "# else:", "\n", "#     offset_h = 26", "\n", "#     offset_w = 3", "\n", "#     img_size = 170", "\n", "\n", "offset_h", "=", "0", "\n", "offset_w", "=", "0", "\n", "img_size", "=", "500", "\n", "\n", "if", "im_no", "is", "not", "None", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "#repeat = 1", "\n", "img_paths", "=", "[", "img_paths", "[", "i", "-", "1", "]", "for", "i", "in", "im_no", "]", "\n", "labels", "=", "labels", "[", "[", "i", "-", "1", "for", "i", "in", "im_no", "]", "]", "\n", "", "elif", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "#repeat = 1", "\n", "img_paths", "=", "img_paths", "[", "1455", ":", "]", "\n", "labels", "=", "labels", "[", "1455", ":", "]", "\n", "# img_paths = img_paths[182637:182637+5000]", "\n", "# labels = labels[182637:182637+5000]", "\n", "# img_paths = img_paths[0:64]   ###temp!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!", "\n", "# labels = labels[0:64]", "\n", "", "elif", "part", "==", "'val'", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", "1447", ":", "1455", "]", "\n", "labels", "=", "labels", "[", "1447", ":", "1455", "]", "\n", "", "else", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", ":", "1447", "]", "\n", "labels", "=", "labels", "[", ":", "1447", "]", "\n", "\n", "", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "atts", "=", "atts", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "offset_h", "=", "offset_h", "\n", "self", ".", "offset_w", "=", "offset_w", "\n", "self", ".", "img_size", "=", "img_size", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.RaFD_1608.__len__": [[866, 868], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.RaFD_1608.check_attribute_conflict": [[869, 900], ["att_names.index", "data_noise_in.RaFD_1608.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_attribute_conflict", "(", "att_batch", ",", "att_name", ",", "att_names", ")", ":", "\n", "        ", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "att_id", "=", "att_names", ".", "index", "(", "att_name", ")", "\n", "\n", "for", "att", "in", "att_batch", ":", "\n", "            ", "if", "att_name", "in", "[", "'Bald'", ",", "'Receding_Hairline'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "\n", "", "elif", "att_name", "==", "'Bangs'", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bald'", ")", "\n", "_set", "(", "att", ",", "0", ",", "'Receding_Hairline'", ")", "\n", "", "elif", "att_name", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# _set(att, 0, 'bald')", "\n", "", "", "", "elif", "att_name", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# Removed since `Mustache` and `No_Beard` are not conflict.", "\n", "# But the two attributes are not well labeled in the dataset.", "\n", "#            elif att_name in ['Mustache', 'No_Beard'] and att[att_id] == 1:", "\n", "#                for n in ['Mustache', 'No_Beard']:", "\n", "#                    if n != att_name:", "\n", "#                        _set(att, 0, n)", "\n", "\n", "", "", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.RaFD_1608.check_random_attribute_conflict": [[901, 930], ["att_names.index", "random.randint", "range", "len", "sum", "data_noise_in.RaFD_1608.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_random_attribute_conflict", "(", "att_batch", ",", "att_names", ",", "hair_color", "=", "None", ")", ":", "\n", "        ", "\"\"\" For randomly generated attributes, tested but not used in this repo. \"\"\"", "\n", "\n", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "def", "_idx", "(", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "return", "att_names", ".", "index", "(", "att_name", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "att", "in", "att_batch", ":", "\n", "            ", "valid_atts", "=", "[", "i", "for", "i", "in", "[", "'Receding_Hairline'", ",", "'Bald'", "]", "if", "i", "in", "att_names", "]", "\n", "if", "'Bangs'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Bangs'", ")", "]", "==", "1", "and", "len", "(", "valid_atts", ")", ">", "0", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "valid_atts", "]", ")", ">", "0", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "[", "_set", "(", "att", ",", "0", ",", "i", ")", "for", "i", "in", "valid_atts", "]", "\n", "#            hair_color = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']", "\n", "", "if", "hair_color", "is", "not", "None", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "hair_color", "]", ")", ">", "1", ":", "\n", "                ", "one", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "hair_color", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hair_color", ")", ")", ":", "\n", "                    ", "_set", "(", "att", ",", "1", "if", "i", "==", "one", "else", "0", ",", "hair_color", "[", "i", "]", ")", "\n", "", "", "if", "'Straight_Hair'", "in", "att_names", "and", "'Wavy_Hair'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Straight_Hair'", ")", "]", "==", "1", "and", "att", "[", "\n", "_idx", "(", "'Wavy_Hair'", ")", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Straight_Hair'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "_set", "(", "att", ",", "0", ",", "'Wavy_Hair'", ")", "\n", "#            if 'Mustache' in att_names and 'No_Beard' in att_names and att[_idx('Mustache')] == 1 and att[_idx('No_Beard')] == 1:", "\n", "#                _set(att, 0, 'Mustache') if random.random() < 0.5 else _set(att, 0, 'No_Beard')", "\n", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.RaFD_1608.creat_tfrecord": [[931, 967], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "PIL.Image.open.tobytes", "numpy.array", "img_name.encode", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "PIL.Image.open", "PIL.Image.open.tobytes", "data_noise_in.expression_div_1", "t_img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "img_path.split", "tensorflow.train.Features", "time.strftime", "time.localtime", "img_path.split", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "tensorflow.train.Int64List"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.expression_div_1"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"RaFD_1608_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"RaFD_1608_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"RaFD_1608_tfrecords\"", ",", "self", ".", "part", "+", "\"_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "s_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "s_img_raw", "=", "s_img", ".", "tobytes", "(", ")", "\n", "s_label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "noise_index", "=", "np", ".", "array", "(", "[", "i", "]", ")", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "for", "i_att", "in", "self", ".", "atts", ":", "\n", "                ", "t_img_path", "=", "img_path", ".", "split", "(", "'male_'", ")", "[", "0", "]", "+", "'male_'", "+", "i_att", "+", "'_'", "+", "img_path", ".", "split", "(", "'_'", ")", "[", "8", "]", "\n", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "t_img_path", ")", ")", "\n", "t_img_raw", "=", "t_img", ".", "tobytes", "(", ")", "\n", "t_label", "=", "expression_div_1", "(", "RaFD_1608", ".", "att_dict", "[", "i_att", "]", ")", "\n", "t_img_name", "=", "os", ".", "path", ".", "split", "(", "t_img_path", ")", "[", "1", "]", "\n", "t_img_name_byte", "=", "t_img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'s_label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "s_label", ")", ")", ",", "\n", "'s_img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "s_img_raw", "]", ")", ")", ",", "\n", "'s_img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", ",", "\n", "'t_label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "t_label", ")", ")", ",", "\n", "'t_img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "t_img_raw", "]", ")", ")", ",", "\n", "'t_img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "t_img_name_byte", "]", ")", ")", ",", "\n", "'noise'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "noise_index", ")", ")", "#", "\n", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                    ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.RaFD_1608.creat_tfrecord_split_opposite_label": [[968, 1008], ["range", "os.path.exists", "os.makedirs", "len", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.python_io.TFRecordWriter.write", "str", "str", "str", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.strftime", "time.time", "time.localtime", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "time.time"], "methods", ["None"], ["", "def", "creat_tfrecord_split_opposite_label", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "atts", ")", ")", ":", "\n", "            ", "att", "=", "self", ".", "atts", "[", "attribute_id", "]", "\n", "count_true", "=", "0", "\n", "count_false", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "false_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_False_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "attribute_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "elif", "label", "[", "attribute_id", "]", "==", "-", "1", ":", "\n", "                        ", "false_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_false", "=", "count_false", "+", "1", "\n", "if", "count_false", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} negative images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_false", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "\"%d negative images are processed.\"", "%", "count_false", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "false_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.RaFD_1608.creat_tfrecord_split_true_label": [[1009, 1040], ["range", "os.path.exists", "os.makedirs", "len", "data_noise_in.RaFD_1608.atts.index", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "img_name.encode", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "", "", "def", "creat_tfrecord_split_true_label", "(", "self", ",", "selected_atts", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "selected_atts", ")", ")", ":", "\n", "            ", "att", "=", "selected_atts", "[", "attribute_id", "]", "\n", "att_id", "=", "self", ".", "atts", ".", "index", "(", "att", ")", "\n", "count_true", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "att", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "att", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "att_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.x2y.__init__": [[1042, 1119], ["data_noise_in.Dataset.__init__", "data_noise_in.x2y._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "os.path.join", "numpy.array", "data_noise_in.disk_image_batch_dataset", "len", "enumerate", "enumerate", "tensorflow.clip_by_value", "glob.glob", "img_paths.extend", "numpy.array.extend", "glob.glob", "os.path.join", "os.path.join", "img_paths.extend", "numpy.array.extend", "img_paths.extend", "numpy.array.extend", "range", "len", "range", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset"], ["    ", "def", "__init__", "(", "self", ",", "dataset_name", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ")", ":", "\n", "        ", "super", "(", "x2y", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "256", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset_name", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "1", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "if", "part", "==", "'train'", ":", "\n", "                ", "if", "dataset_name", "==", "'apple2orange'", ":", "\n", "                    ", "self", ".", "_img_num", "=", "2014", "-", "100", "\n", "", "elif", "dataset_name", "==", "'summer2winter'", ":", "\n", "                    ", "self", ".", "_img_num", "=", "2193", "-", "100", "\n", "", "elif", "dataset_name", "==", "'horse2zebra'", ":", "\n", "                    ", "self", ".", "_img_num", "=", "2401", "-", "100", "\n", "", "", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset_name", ")", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'testA'", ",", "'testB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "*", "(", "1", "-", "i", ")", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'trainA'", ",", "'trainB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "if", "part", "==", "'val'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", ":", "50", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "*", "(", "1", "-", "i", ")", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", ":", "50", "]", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", "50", ":", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "*", "(", "1", "-", "i", ")", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", "50", ":", "]", ")", ")", "]", ")", "\n", "", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.x2y.__len__": [[1120, 1122], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.x2y.creat_tfrecord": [[1123, 1146], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.convert.convert.convert", "img.convert.convert.tobytes", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", "+", "\"_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", "+", "\"_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", "+", "\"_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name", "]", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "", "", "class", "MakeupTransfer", "(", "Dataset", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.MakeupTransfer.__init__": [[1147, 1269], ["data_noise_in.Dataset.__init__", "data_noise_in.MakeupTransfer._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.to_float", "os.path.join", "data_noise_in.tfrecord_batch_dataset_MT", "os.path.join", "numpy.array", "data_noise_in.disk_image_batch_dataset_MT", "len", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_flip_left_right", "functools.partial", "enumerate", "enumerate", "tensorflow.clip_by_value", "tensorflow.reduce_all", "tensorflow.reduce_all", "glob.glob", "img_paths.extend", "numpy.array.extend", "glob.glob", "tensorflow.reduce_max", "tensorflow.equal", "tensorflow.equal", "os.path.join", "os.path.join", "range", "range", "img_paths.extend", "img_segs_paths.extend", "numpy.array.extend", "tensorflow.gather", "tensorflow.ones_like", "tensorflow.gather", "tensorflow.zeros_like", "len", "img_seg_paths.append", "len", "img_seg_paths.append", "img_paths.extend", "img_segs_paths.extend", "numpy.array.extend", "tensorflow.gather", "tensorflow.gather", "range", "len", "range", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset_MT", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset_MT"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ",", "is_augment", "=", "False", ")", ":", "\n", "        ", "super", "(", "MakeupTransfer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "segs", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "if", "is_augment", ":", "\n", "# \u5c06\u56fe\u7247\u968f\u673a\u8fdb\u884c\u5782\u76f4\u7ffb\u8f6c", "\n", "                ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "segs", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "segs", ")", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u4eae\u5ea6", "\n", "# img = tf.image.random_brightness(img, max_delta=0.6)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u5bf9\u6bd4\u5ea6", "\n", "# img = tf.image.random_contrast(img, lower=0.1, upper=0.8)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u8272\u5ea6", "\n", "# img = tf.image.random_hue(img, max_delta=0.3)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u9971\u548c\u5ea6", "\n", "# img = tf.image.random_saturation(img, lower=0.2, upper=1.8)", "\n", "", "segs", "=", "tf", ".", "cast", "(", "segs", ",", "tf", ".", "float32", ")", "\n", "# segs = tf.reshape(segs, [batch_size, 361, 361, 1])", "\n", "#segs = tf.concat([segs, segs, segs], 2)", "\n", "segs", "=", "tf", ".", "image", ".", "resize_images", "(", "segs", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "#segs = tf.split(segs, 3, 3)", "\n", "# segs = tf.clip_by_value(segs, 0, 255) / 127.5 - 1", "\n", "segs", "=", "tf", ".", "clip_by_value", "(", "segs", ",", "0", ",", "255", ")", "\n", "segs", "=", "segs", "/", "(", "0.5", "*", "tf", ".", "reduce_max", "(", "segs", ")", ")", "-", "1", "\n", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "# label = tf.to_int32(label, name='ToInt32')", "\n", "# label = tf.one_hot(label, 2, 1, 0)", "\n", "# label = tf.to_float(label, name='ToFloat')", "\n", "# label = tf.squeeze(label)", "\n", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "label", "=", "tf", ".", "to_float", "(", "label", ",", "name", "=", "'ToFloat'", ")", "\n", "return", "img", ",", "segs", ",", "label", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "_", ",", "feature_val", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "ones_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "zeros_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "361", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'MakeupTransfer'", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset_MT", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "1", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "#", "\n", "\n", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'MakeupTransfer'", ")", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "img_seg_paths", "=", "[", "]", "\n", "img_segs_paths", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'testA'", ",", "'testB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.png'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'trainA'", ",", "'trainB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.png'", ")", ")", "\n", "if", "partAB", "==", "'trainA'", ":", "\n", "                        ", "for", "j1", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", ":", "\n", "                            ", "img_seg_paths", ".", "append", "(", "imgAB_paths", "[", "j1", "]", "[", ":", "22", "]", "+", "'segs/'", "+", "imgAB_paths", "[", "j1", "]", "[", "22", ":", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "img_seg_paths", "=", "[", "]", "\n", "for", "j2", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", ":", "\n", "                            ", "img_seg_paths", ".", "append", "(", "imgAB_paths", "[", "j2", "]", "[", ":", "22", "]", "+", "'segs/'", "+", "imgAB_paths", "[", "j2", "]", "[", "22", ":", "]", ")", "\n", "", "", "if", "part", "==", "'val'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", ":", "50", "]", ")", "\n", "img_segs_paths", ".", "extend", "(", "img_seg_paths", "[", ":", "50", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", ":", "50", "]", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", "50", ":", "]", ")", "\n", "img_segs_paths", ".", "extend", "(", "img_seg_paths", "[", "50", ":", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", "50", ":", "]", ")", ")", "]", ")", "\n", "", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset_MT", "(", "img_paths", "=", "img_paths", ",", "\n", "img_segs_paths", "=", "img_segs_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "img_segs_paths", "=", "img_segs_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "dataset_name", "=", "'MakeupTransfer'", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.MakeupTransfer.__len__": [[1270, 1272], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.MakeupTransfer.creat_tfrecord": [[1273, 1300], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.convert.convert.convert", "img.convert.convert.tobytes", "PIL.Image.open", "PIL.Image.open.tobytes", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"MakeupTransfer_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"MakeupTransfer_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"MakeupTransfer_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "img_s", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", "[", ":", "22", "]", "+", "'segs/'", "+", "img_path", "[", "22", ":", "]", ")", ")", "\n", "img_segs", "=", "img_s", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", ",", "\n", "'img_segs'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_segs", "]", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "", "", "class", "AFHQ", "(", "Dataset", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.AFHQ.__init__": [[1301, 1432], ["data_noise_in.Dataset.__init__", "data_noise_in.AFHQ._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.to_int32", "tensorflow.one_hot", "tensorflow.to_float", "tensorflow.squeeze", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.to_int32", "tensorflow.one_hot", "tensorflow.to_float", "tensorflow.squeeze", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "os.path.join", "numpy.array", "data_noise_in.disk_image_batch_dataset", "len", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_flip_left_right", "functools.partial", "enumerate", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.equal", "tensorflow.equal", "tensorflow.equal", "glob.glob", "img_paths.extend", "numpy.array.extend", "enumerate", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "os.path.join", "glob.glob", "img_paths.extend", "numpy.array.extend", "glob.glob", "img_paths.extend", "numpy.array.extend", "os.path.join", "os.path.join", "glob.glob", "img_paths.extend", "numpy.array.extend", "range", "os.path.join", "glob.glob", "img_paths.extend", "numpy.array.extend", "len", "range", "range", "os.path.join", "len", "len", "range", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ",", "is_augment", "=", "False", ")", ":", "\n", "        ", "super", "(", "AFHQ", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ",", "noise", ")", ":", "\n", "            ", "if", "is_augment", ":", "\n", "# \u5c06\u56fe\u7247\u968f\u673a\u8fdb\u884c\u5782\u76f4\u7ffb\u8f6c", "\n", "                ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u4eae\u5ea6", "\n", "# img = tf.image.random_brightness(img, max_delta=0.6)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u5bf9\u6bd4\u5ea6", "\n", "# img = tf.image.random_contrast(img, lower=0.1, upper=0.8)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u8272\u5ea6", "\n", "# img = tf.image.random_hue(img, max_delta=0.3)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u9971\u548c\u5ea6", "\n", "# img = tf.image.random_saturation(img, lower=0.2, upper=1.8)", "\n", "", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "label", "=", "tf", ".", "to_int32", "(", "label", ",", "name", "=", "'ToInt32'", ")", "\n", "label", "=", "tf", ".", "one_hot", "(", "label", ",", "3", ",", "1", ",", "0", ")", "\n", "label", "=", "tf", ".", "to_float", "(", "label", ",", "name", "=", "'ToFloat'", ")", "\n", "label", "=", "tf", ".", "squeeze", "(", "label", ")", "\n", "# label = (label + 1) // 2", "\n", "return", "img", ",", "label", ",", "noise", "\n", "", "def", "map_func", "(", "img", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "if", "is_augment", ":", "\n", "# \u5c06\u56fe\u7247\u968f\u673a\u8fdb\u884c\u5782\u76f4\u7ffb\u8f6c", "\n", "                ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u4eae\u5ea6", "\n", "# img = tf.image.random_brightness(img, max_delta=0.6)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u5bf9\u6bd4\u5ea6", "\n", "# img = tf.image.random_contrast(img, lower=0.1, upper=0.8)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u8272\u5ea6", "\n", "# img = tf.image.random_hue(img, max_delta=0.3)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u9971\u548c\u5ea6", "\n", "# img = tf.image.random_saturation(img, lower=0.2, upper=1.8)", "\n", "", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "#, tf.image.ResizeMethod.BICUBIC", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "label", "=", "tf", ".", "to_int32", "(", "label", ",", "name", "=", "'ToInt32'", ")", "\n", "label", "=", "tf", ".", "one_hot", "(", "label", ",", "3", ",", "1", ",", "0", ")", "\n", "label", "=", "tf", ".", "to_float", "(", "label", ",", "name", "=", "'ToFloat'", ")", "\n", "label", "=", "tf", ".", "squeeze", "(", "label", ")", "\n", "# label = (label + 1) // 2", "\n", "return", "img", ",", "label", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "# the function of filter", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "feature_val", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "ones_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "a", "=", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "512", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'AFHQ'", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "1", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "#", "\n", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", "# , 'AFHQ'", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'testA'", ",", "'testB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "part", "==", "'val'", ":", "\n", "                    ", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'val_cat'", ",", "'val_dog'", ",", "'val_wild'", "]", ")", ":", "# , 'val_wild'", "\n", "                        ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "i", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "elif", "part", "==", "'train_cat'", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "part", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "0", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train_dog'", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "part", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train_wild'", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "part", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "\n", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "dataset_name", "=", "'AFHQ'", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.AFHQ.__len__": [[1433, 1435], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.AFHQ.creat_tfrecord": [[1436, 1462], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.convert.convert.convert", "img.convert.convert.tobytes", "numpy.array", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "tensorflow.train.Int64List"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"AFHQ_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"AFHQ_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"AFHQ_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "noise_index", "=", "np", ".", "array", "(", "[", "i", "+", "5153", "+", "4739", "]", ")", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", ",", "\n", "'noise'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "noise_index", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Morph.__init__": [[1469, 1640], ["data_noise_in.Dataset.__init__", "os.path.join", "data_noise_in.Morph._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.to_int32", "tensorflow.to_float", "tensorflow.squeeze", "tensorflow.one_hot", "tensorflow.to_float", "tensorflow.squeeze", "os.path.join", "os.path.join", "numpy.loadtxt", "os.path.exists", "numpy.loadtxt", "data_noise_in.age_group_div_", "data_noise_in.disk_image_batch_dataset", "len", "tensorflow.image.crop_to_bounding_box", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.random_hue", "tensorflow.image.random_saturation", "functools.partial", "os.path.exists", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "os.path.exists", "tensorflow.clip_by_value", "tensorflow.equal", "tensorflow.equal", "tensorflow.equal", "os.path.join", "os.path.join", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "len", "len", "name.replace", "os.path.join", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.age_group_div_", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset"], ["def", "__init__", "(", "self", ",", "data_dir", ",", "atts", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "crop", "=", "True", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ",", "is_augment", "=", "False", ")", ":", "\n", "        ", "super", "(", "Morph", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ")", ":", "#one image", "\n", "            ", "n_cls", "=", "2", "\n", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "if", "is_augment", ":", "\n", "# \u5c06\u56fe\u7247\u968f\u673a\u8fdb\u884c\u5782\u76f4\u7ffb\u8f6c", "\n", "                ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u4eae\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_brightness", "(", "img", ",", "max_delta", "=", "0.6", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u5bf9\u6bd4\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_contrast", "(", "img", ",", "lower", "=", "0.1", ",", "upper", "=", "0.8", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u8272\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_hue", "(", "img", ",", "max_delta", "=", "0.3", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u9971\u548c\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_saturation", "(", "img", ",", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "\n", "\n", "", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "#all of them are 255?", "\n", "#                                #change!", "\n", "# label = tf.to_int32(label, name='ToInt32') #", "\n", "# label = tf.one_hot(label, n_cls, 1, 0)", "\n", "# label = tf.to_float(label, name='ToFloat')", "\n", "# label = tf.squeeze(label)", "\n", "# label = tf.to_float(label, name='ToFloat')", "\n", "\n", "label", "=", "tf", ".", "to_int32", "(", "label", ",", "name", "=", "'ToInt32'", ")", "\n", "age", "=", "label", "[", "0", "]", "\n", "gender", "=", "label", "[", "1", "]", "\n", "# age = tf.one_hot(age, n_cls, 1, 0)", "\n", "\n", "age", "=", "tf", ".", "to_float", "(", "age", ",", "name", "=", "'ToFloat'", ")", "\n", "age", "=", "tf", ".", "squeeze", "(", "age", ")", "\n", "gender", "=", "tf", ".", "one_hot", "(", "gender", ",", "2", ",", "1", ",", "0", ")", "\n", "gender", "=", "tf", ".", "to_float", "(", "gender", ",", "name", "=", "'ToFloat'", ")", "\n", "gender", "=", "tf", ".", "squeeze", "(", "gender", ")", "\n", "\n", "\n", "return", "img", ",", "gender", ",", "age", "\n", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "# the function of filter", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "feature_val", ",", "_", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "ones_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "a", "=", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "", "list_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Morph_data_shuffle_10.txt'", ")", "#txt for what", "\n", "#read data(images and labels) by tfrecord (or not)", "\n", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "300", "#170", "\n", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'morph_tfrecords'", ",", "part", "+", "\"_\"", "+", "str", "(", "filter_att", ")", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'morph_tfrecords'", ",", "part", "+", "\"_\"", "+", "str", "(", "filter_att", ")", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "len", "(", "atts", ")", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "", "else", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'morph_tfrecords'", ",", "part", "+", "\"_crop.tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "len", "(", "atts", ")", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "#the numbers of data for train", "\n", "", "if", "part", "==", "'train'", ":", "\n", "                ", "self", ".", "_img_num", "=", "46300", "\n", "", "", "else", ":", "\n", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Morph'", ")", "#  the name is named by me ?", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Morph_png'", ")", "\n", "\n", "\n", "names", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "0", "]", ",", "dtype", "=", "np", ".", "str", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "img_dir_png", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_png", ",", "name", ".", "replace", "(", "'jpg'", ",", "'png'", ")", ")", "for", "name", "in", "names", "]", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "img_dir_jpg", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "name", ")", "for", "name", "in", "names", "]", "\n", "\n", "", "att_id", "=", "[", "Morph", ".", "att_dict", "[", "att", "]", "+", "1", "for", "att", "in", "atts", "]", "\n", "labels", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "att_id", ",", "dtype", "=", "np", ".", "int64", ")", "#[:, np.newaxis]", "\n", "# if img_resize == 64:", "\n", "#     # crop as how VAE/GAN do", "\n", "#     offset_h = 40", "\n", "#     offset_w = 15", "\n", "#     img_size = 148", "\n", "# else:", "\n", "#     offset_h = 26", "\n", "#     offset_w = 3", "\n", "#     img_size = 170", "\n", "\n", "img_size", "=", "300", "# 170", "\n", "offset_h", "=", "0", "#26 #168(400)", "\n", "offset_w", "=", "0", "#3", "\n", "\n", "\n", "if", "im_no", "is", "not", "None", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "img_paths", "=", "[", "img_paths", "[", "i", "-", "1", "]", "for", "i", "in", "im_no", "]", "\n", "labels", "=", "labels", "[", "[", "i", "-", "1", "for", "i", "in", "im_no", "]", "]", "\n", "", "elif", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "img_paths", "=", "img_paths", "[", "46500", ":", "]", "#147500", "\n", "labels", "=", "labels", "[", "46500", ":", "]", "\n", "# img_paths = img_paths[182637:182637+5000]", "\n", "# labels = labels[182637:182637+5000]", "\n", "# img_paths = img_paths[0:64]                                  ###temp!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!", "\n", "# labels = labels[0:64]", "\n", "", "elif", "part", "==", "'val'", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", "46308", ":", "46500", "]", "#46397", "\n", "labels", "=", "labels", "[", "46308", ":", "46500", "]", "\n", "", "else", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", ":", "46300", "]", "# 147101", "\n", "labels", "=", "labels", "[", ":", "46300", "]", "#46300", "\n", "\n", "", "labels", "[", ":", ",", "0", "]", "=", "age_group_div_", "(", "labels", "[", ":", ",", "0", "]", ")", "#VGG16 train need labels = age_group_div_(labels)", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "atts", "=", "atts", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "offset_h", "=", "offset_h", "\n", "self", ".", "offset_w", "=", "offset_w", "\n", "self", ".", "img_size", "=", "img_size", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Morph.__len__": [[1641, 1643], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Morph.check_attribute_conflict": [[1644, 1676], ["att_names.index", "data_noise_in.Morph.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "#check for celebA , no need for Age", "\n", "def", "check_attribute_conflict", "(", "att_batch", ",", "att_name", ",", "att_names", ")", ":", "\n", "        ", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "att_id", "=", "att_names", ".", "index", "(", "att_name", ")", "\n", "\n", "for", "att", "in", "att_batch", ":", "\n", "            ", "if", "att_name", "in", "[", "'Bald'", ",", "'Receding_Hairline'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "\n", "", "elif", "att_name", "==", "'Bangs'", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bald'", ")", "\n", "_set", "(", "att", ",", "0", ",", "'Receding_Hairline'", ")", "\n", "", "elif", "att_name", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# _set(att, 0, 'bald')", "\n", "", "", "", "elif", "att_name", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# Removed since `Mustache` and `No_Beard` are not conflict.", "\n", "# But the two attributes are not well labeled in the dataset.", "\n", "#            elif att_name in ['Mustache', 'No_Beard'] and att[att_id] == 1:", "\n", "#                for n in ['Mustache', 'No_Beard']:", "\n", "#                    if n != att_name:", "\n", "#                        _set(att, 0, n)", "\n", "\n", "", "", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Morph.check_random_attribute_conflict": [[1677, 1706], ["att_names.index", "random.randint", "range", "len", "sum", "data_noise_in.Morph.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_random_attribute_conflict", "(", "att_batch", ",", "att_names", ",", "hair_color", "=", "None", ")", ":", "\n", "        ", "\"\"\" For randomly generated attributes, tested but not used in this repo. \"\"\"", "\n", "\n", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "def", "_idx", "(", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "return", "att_names", ".", "index", "(", "att_name", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "att", "in", "att_batch", ":", "\n", "            ", "valid_atts", "=", "[", "i", "for", "i", "in", "[", "'Receding_Hairline'", ",", "'Bald'", "]", "if", "i", "in", "att_names", "]", "\n", "if", "'Bangs'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Bangs'", ")", "]", "==", "1", "and", "len", "(", "valid_atts", ")", ">", "0", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "valid_atts", "]", ")", ">", "0", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "[", "_set", "(", "att", ",", "0", ",", "i", ")", "for", "i", "in", "valid_atts", "]", "\n", "#            hair_color = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']", "\n", "", "if", "hair_color", "is", "not", "None", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "hair_color", "]", ")", ">", "1", ":", "\n", "                ", "one", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "hair_color", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hair_color", ")", ")", ":", "\n", "                    ", "_set", "(", "att", ",", "1", "if", "i", "==", "one", "else", "0", ",", "hair_color", "[", "i", "]", ")", "\n", "", "", "if", "'Straight_Hair'", "in", "att_names", "and", "'Wavy_Hair'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Straight_Hair'", ")", "]", "==", "1", "and", "att", "[", "\n", "_idx", "(", "'Wavy_Hair'", ")", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Straight_Hair'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "_set", "(", "att", ",", "0", ",", "'Wavy_Hair'", ")", "\n", "#            if 'Mustache' in att_names and 'No_Beard' in att_names and att[_idx('Mustache')] == 1 and att[_idx('No_Beard')] == 1:", "\n", "#                _set(att, 0, 'Mustache') if random.random() < 0.5 else _set(att, 0, 'No_Beard')", "\n", "", "", "return", "att_batch", "\n", "#creat example file by tfrecord", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Morph.creat_tfrecord": [[1707, 1740], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "PIL.Image.open.tobytes", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.exists", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "os.path.splitext", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                ", "img_path", "=", "'.'", ".", "join", "(", "[", "os", ".", "path", ".", "splitext", "(", "img_path", ")", "[", "0", "]", ",", "'jpg'", "]", ")", "\n", "", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "#     for real_name in", "\n", "#        img = Image.open(re.match(os.path.join(img_path),real_name))", "\n", "#  img = img.crop((self.offset_w, self.offset_h, self.offset_w + self.img_size, self.offset_h + self.img_size))", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "#one tensor change [i,:]", "\n", "#label[0] = age_group_div(label[0])", "\n", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "# img_name_byte = img_name.getBytes()", "\n", "# str.encode(img_name)", "\n", "#bytes(img_name , encoding=\"utf8\")", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "#gchange!", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "# creat labels by tfrecord", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Morph.creat_tfrecord_split_opposite_label": [[1741, 1782], ["range", "os.path.exists", "os.makedirs", "len", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "img_name.getBytes", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.python_io.TFRecordWriter.write", "str", "str", "str", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.strftime", "time.time", "time.localtime", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "time.time"], "methods", ["None"], ["", "def", "creat_tfrecord_split_opposite_label", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "atts", ")", ")", ":", "\n", "            ", "att", "=", "self", ".", "atts", "[", "attribute_id", "]", "\n", "count_true", "=", "0", "\n", "count_false", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "false_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_False_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "#one tensor change [i,:]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "getBytes", "(", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "attribute_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "elif", "label", "[", "attribute_id", "]", "==", "-", "1", ":", "\n", "                        ", "false_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_false", "=", "count_false", "+", "1", "\n", "if", "count_false", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} negative images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_false", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "\"%d negative images are processed.\"", "%", "count_false", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "false_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Photo2Artworks.__init__": [[1784, 1862], ["data_noise_in.Dataset.__init__", "data_noise_in.Photo2Artworks._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "os.path.join", "data_noise_in.tfrecord_batch_dataset", "numpy.array", "data_noise_in.disk_image_batch_dataset", "len", "enumerate", "enumerate", "range", "tensorflow.clip_by_value", "glob.glob", "data_noise_in.Photo2Artworks.__init__.one_hot"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ")", ":", "\n", "        ", "super", "(", "Photo2Artworks", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "one_hot", "(", "idx", ",", "length", ")", ":", "\n", "            ", "output", "=", "[", "0", "for", "_", "in", "range", "(", "length", ")", "]", "\n", "output", "[", "idx", "]", "=", "1", "\n", "return", "output", "\n", "\n", "", "def", "_map_func", "(", "img", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "256", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Photo2Artworks'", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "5", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "if", "part", "==", "'train'", ":", "\n", "                ", "self", ".", "_img_num", "=", "525", "+", "1072", "+", "6287", "+", "562", "+", "400", "\n", "\n", "", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "data_dir", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "domains", "=", "[", "'test_photo'", ",", "'test_cezanne'", ",", "'test_monet'", ",", "'test_ukiyoe'", ",", "'test_vangogh'", "]", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "domains", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "onehot_label", "=", "one_hot", "(", "i", ",", "len", "(", "domains", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "onehot_label", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "domains", "=", "[", "'train_photo'", ",", "'train_cezanne'", ",", "'train_monet'", ",", "'train_ukiyoe'", ",", "'train_vangogh'", "]", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "domains", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "onehot_label", "=", "one_hot", "(", "i", ",", "len", "(", "domains", ")", ")", "\n", "if", "part", "==", "'train'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "onehot_label", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Photo2Artworks.__len__": [[1863, 1865], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.Photo2Artworks.creat_tfrecord": [[1866, 1897], ["data_noise_in.Photo2Artworks.creat_tfrecord.shuffle_data"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "\n", "        ", "def", "shuffle_data", "(", ")", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "_img_num", ")", "\n", "self", ".", "img_paths", "=", "np", ".", "array", "(", "self", ".", "img_paths", ")", "[", "indices", "]", "\n", "# self.img_paths = self.img_paths.tolist()", "\n", "self", ".", "labels", "=", "self", ".", "labels", "[", "indices", "]", "\n", "", "shuffle_data", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'Photo2Artworks'", "+", "\"_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'Photo2Artworks'", "+", "\"_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'Photo2Artworks'", "+", "\"_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name", "]", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.age_group_div_": [[15, 26], ["numpy.zeros", "range"], "function", ["None"], ["def", "age_group_div_", "(", "age", ")", ":", "\n", "\n", "#output = np.zeros([1,5],dtype=float)", "\n", "    ", "lens", "=", "age", ".", "shape", "[", "0", "]", "\n", "output", "=", "np", ".", "zeros", "(", "[", "lens", "]", ",", "dtype", "=", "float", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "lens", ")", ":", "\n", "        ", "if", "age", "[", "i", "]", "<=", "50", ":", "\n", "            ", "output", "[", "i", "]", "=", "0", "\n", "", "elif", "age", "[", "i", "]", ">", "50", ":", "\n", "            ", "output", "[", "i", "]", "=", "1", "\n", "", "", "return", "output", "\n", "", "def", "expression_div", "(", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.expression_div": [[26, 32], ["numpy.zeros", "range"], "function", ["None"], ["", "def", "expression_div", "(", "index", ")", ":", "\n", "    ", "lens", "=", "index", ".", "shape", "[", "0", "]", "\n", "output", "=", "np", ".", "zeros", "(", "[", "lens", ",", "8", "]", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "lens", ")", ":", "\n", "        ", "output", "[", "i", ",", "index", "[", "i", "]", "]", "=", "1", "\n", "", "return", "output", "\n", "", "def", "expression_div_1", "(", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.expression_div_1": [[32, 36], ["numpy.zeros"], "function", ["None"], ["", "def", "expression_div_1", "(", "index", ")", ":", "\n", "    ", "output", "=", "np", ".", "zeros", "(", "[", "8", "]", ",", "dtype", "=", "int", ")", "\n", "output", "[", "index", "]", "=", "1", "\n", "return", "output", "\n", "# def age_group_div_(age):", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.session": [[53, 60], ["tensorflow.ConfigProto", "tensorflow.Session"], "function", ["None"], ["", "def", "session", "(", "graph", "=", "None", ",", "allow_soft_placement", "=", "True", ",", "\n", "log_device_placement", "=", "False", ",", "allow_growth", "=", "True", ")", ":", "\n", "    ", "\"\"\"Return a Session with simple config.\"\"\"", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "allow_soft_placement", ",", "\n", "log_device_placement", "=", "log_device_placement", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "allow_growth", "\n", "return", "tf", ".", "Session", "(", "graph", "=", "graph", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.batch_dataset": [[61, 83], ["dataset.batch.repeat().prefetch", "dataset.batch.filter", "dataset.batch.map", "dataset.batch.shuffle", "dataset.batch.filter", "dataset.batch.apply", "dataset.batch.batch", "filter_fn", "tensorflow.contrib.data.batch_and_drop_remainder", "dataset.batch.repeat"], "function", ["None"], ["", "def", "batch_dataset", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "if", "filter", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter", ")", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "dataset", "=", "dataset", ".", "map", "(", "map_func", ",", "num_parallel_calls", "=", "num_threads", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "        ", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", ")", "\n", "\n", "", "if", "filter_fn", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter_fn", "(", ")", ")", "\n", "\n", "", "if", "drop_remainder", ":", "\n", "        ", "dataset", "=", "dataset", ".", "apply", "(", "tf", ".", "contrib", ".", "data", ".", "batch_and_drop_remainder", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "repeat", "(", "repeat", ")", ".", "prefetch", "(", "prefetch_batch", ")", "\n", "\n", "return", "dataset", "\n", "", "def", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.batch_dataset_MT": [[83, 105], ["dataset.batch.repeat().prefetch", "dataset.batch.filter", "dataset.batch.map", "dataset.batch.shuffle", "dataset.batch.filter", "dataset.batch.apply", "dataset.batch.batch", "filter_fn", "tensorflow.contrib.data.batch_and_drop_remainder", "dataset.batch.repeat"], "function", ["None"], ["", "def", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "if", "filter", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter", ")", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "dataset", "=", "dataset", ".", "map", "(", "map_func", ",", "num_parallel_calls", "=", "num_threads", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "        ", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", ")", "\n", "\n", "", "if", "filter_fn", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter_fn", "(", ")", ")", "\n", "\n", "", "if", "drop_remainder", ":", "\n", "        ", "dataset", "=", "dataset", ".", "apply", "(", "tf", ".", "contrib", ".", "data", ".", "batch_and_drop_remainder", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "repeat", "(", "repeat", ")", ".", "prefetch", "(", "prefetch_batch", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.disk_image_batch_dataset": [[106, 139], ["data_noise_in.batch_dataset", "tensorflow.data.Dataset.from_tensor_slices", "isinstance", "tensorflow.read_file", "tensorflow.image.decode_png", "tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices", "map_func", "tuple", "data_noise_in.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset"], ["", "def", "disk_image_batch_dataset", "(", "img_paths", ",", "batch_size", ",", "labels", "=", "None", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "if", "labels", "is", "None", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "img_paths", ")", "\n", "", "elif", "isinstance", "(", "labels", ",", "tuple", ")", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", ")", "+", "tuple", "(", "labels", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", "labels", ")", ")", "\n", "\n", "", "def", "parse_func", "(", "path", ",", "*", "label", ")", ":", "\n", "        ", "img", "=", "tf", ".", "read_file", "(", "path", ")", "\n", "img", "=", "tf", ".", "image", ".", "decode_png", "(", "img", ",", "3", ")", "#png", "\n", "return", "(", "img", ",", ")", "+", "label", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "", "def", "disk_image_batch_dataset_MT", "(", "img_paths", ",", "img_segs_paths", ",", "batch_size", ",", "labels", "=", "None", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.disk_image_batch_dataset_MT": [[139, 174], ["data_noise_in.batch_dataset_MT", "tensorflow.data.Dataset.from_tensor_slices", "isinstance", "tensorflow.read_file", "tensorflow.image.decode_png", "tensorflow.read_file", "tensorflow.image.decode_png", "tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices", "map_func", "tuple", "data_noise_in.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset_MT"], ["", "def", "disk_image_batch_dataset_MT", "(", "img_paths", ",", "img_segs_paths", ",", "batch_size", ",", "labels", "=", "None", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "if", "labels", "is", "None", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "img_paths", ")", "\n", "", "elif", "isinstance", "(", "labels", ",", "tuple", ")", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", ")", "+", "tuple", "(", "labels", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", "img_segs_paths", ",", "labels", ")", ")", "\n", "\n", "", "def", "parse_func", "(", "path", ",", "path_segs", ",", "*", "label", ")", ":", "\n", "        ", "img", "=", "tf", ".", "read_file", "(", "path", ")", "\n", "img", "=", "tf", ".", "image", ".", "decode_png", "(", "img", ",", "3", ")", "#png", "\n", "img_sges", "=", "tf", ".", "read_file", "(", "path_segs", ")", "\n", "img_sges", "=", "tf", ".", "image", ".", "decode_png", "(", "img_sges", ",", "1", ")", "# png", "\n", "return", "(", "img", ",", ")", "+", "(", "img_sges", ",", ")", "+", "label", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.tfrecord_batch_dataset": [[175, 218], ["tensorflow.data.TFRecordDataset", "data_noise_in.batch_dataset", "tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.cast", "tensorflow.reshape", "tensorflow.image.random_flip_left_right", "map_func", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "data_noise_in.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset"], ["", "def", "tfrecord_batch_dataset", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "reshape_size", "=", "170", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "tfrecord_path", ")", "\n", "\n", "# def parse_func(path, *label):", "\n", "#     img = tf.read_file(path)", "\n", "#     img = tf.image.decode_png(img, 3)", "\n", "#     return (img,) + label", "\n", "\n", "def", "parse_func", "(", "serialized_example", ")", ":", "\n", "        ", "random_flip", "=", "False", "\n", "features", "=", "tf", ".", "parse_single_example", "(", "serialized_example", ",", "features", "=", "{", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "label_len", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'noise'", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'img_name'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", "}", ")", "\n", "label", "=", "tf", ".", "cast", "(", "features", "[", "'label'", "]", ",", "tf", ".", "int32", ")", "\n", "img", "=", "tf", ".", "decode_raw", "(", "features", "[", "'img_raw'", "]", ",", "tf", ".", "uint8", ")", "\n", "noise", "=", "tf", ".", "cast", "(", "features", "[", "'noise'", "]", ",", "tf", ".", "int64", ")", "\n", "#img_name = tf.decode_raw(features['img_name'], tf.uint8)", "\n", "img", "=", "tf", ".", "reshape", "(", "img", ",", "[", "reshape_size", ",", "reshape_size", ",", "3", "]", ")", "\n", "if", "random_flip", ":", "\n", "            ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "", "return", "img", ",", "label", ",", "noise", "#, img_name", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "", "def", "tfrecord_batch_dataset_RaFD", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.tfrecord_batch_dataset_RaFD": [[218, 267], ["tensorflow.data.TFRecordDataset", "data_noise_in.batch_dataset", "tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.cast", "tensorflow.image.random_flip_left_right", "map_func", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "data_noise_in.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset"], ["", "def", "tfrecord_batch_dataset_RaFD", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "reshape_size", "=", "170", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "tfrecord_path", ")", "\n", "\n", "# def parse_func(path, *label):", "\n", "#     img = tf.read_file(path)", "\n", "#     img = tf.image.decode_png(img, 3)", "\n", "#     return (img,) + label", "\n", "\n", "def", "parse_func", "(", "serialized_example", ")", ":", "\n", "        ", "random_flip", "=", "True", "\n", "features", "=", "tf", ".", "parse_single_example", "(", "serialized_example", ",", "features", "=", "{", "'s_label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "label_len", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'noise'", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'s_img_raw'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'s_img_name'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'t_label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "label_len", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'t_img_raw'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'t_img_name'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", "\n", "}", ")", "\n", "s_label", "=", "tf", ".", "cast", "(", "features", "[", "'s_label'", "]", ",", "tf", ".", "int32", ")", "\n", "s_img", "=", "tf", ".", "decode_raw", "(", "features", "[", "'s_img_raw'", "]", ",", "tf", ".", "uint8", ")", "\n", "s_img", "=", "tf", ".", "reshape", "(", "s_img", ",", "[", "reshape_size", ",", "reshape_size", ",", "3", "]", ")", "\n", "t_label", "=", "tf", ".", "cast", "(", "features", "[", "'t_label'", "]", ",", "tf", ".", "int32", ")", "\n", "t_img", "=", "tf", ".", "decode_raw", "(", "features", "[", "'t_img_raw'", "]", ",", "tf", ".", "uint8", ")", "\n", "t_img", "=", "tf", ".", "reshape", "(", "t_img", ",", "[", "reshape_size", ",", "reshape_size", ",", "3", "]", ")", "\n", "noise", "=", "tf", ".", "cast", "(", "features", "[", "'noise'", "]", ",", "tf", ".", "int64", ")", "\n", "if", "random_flip", ":", "\n", "            ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "s_img", ")", "\n", "", "return", "s_img", ",", "s_label", ",", "noise", ",", "t_label", ",", "t_img", "#, img_name", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "", "def", "tfrecord_batch_dataset_MT", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise_in.tfrecord_batch_dataset_MT": [[267, 312], ["tensorflow.data.TFRecordDataset", "data_noise_in.batch_dataset_MT", "tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_flip_left_right", "map_func", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "data_noise_in.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset_MT"], ["", "def", "tfrecord_batch_dataset_MT", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "reshape_size", "=", "170", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "tfrecord_path", ")", "\n", "\n", "# def parse_func(path, *label):", "\n", "#     img = tf.read_file(path)", "\n", "#     img = tf.image.decode_png(img, 3)", "\n", "#     return (img,) + label", "\n", "\n", "def", "parse_func", "(", "serialized_example", ")", ":", "\n", "        ", "random_flip", "=", "False", "\n", "features", "=", "tf", ".", "parse_single_example", "(", "serialized_example", ",", "features", "=", "{", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "label_len", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'img_name'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'img_segs'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", "}", ")", "\n", "label", "=", "tf", ".", "cast", "(", "features", "[", "'label'", "]", ",", "tf", ".", "int32", ")", "\n", "img", "=", "tf", ".", "decode_raw", "(", "features", "[", "'img_raw'", "]", ",", "tf", ".", "uint8", ")", "\n", "segs", "=", "tf", ".", "decode_raw", "(", "features", "[", "'img_segs'", "]", ",", "tf", ".", "uint8", ")", "\n", "#img_name = tf.decode_raw(features['img_name'], tf.uint8)", "\n", "img", "=", "tf", ".", "reshape", "(", "img", ",", "[", "reshape_size", ",", "reshape_size", ",", "3", "]", ")", "\n", "segs", "=", "tf", ".", "reshape", "(", "segs", ",", "[", "321", ",", "321", ",", "1", "]", ")", "\n", "if", "random_flip", ":", "\n", "            ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "segs", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "segs", ")", "\n", "", "return", "img", ",", "segs", ",", "label", "#, img_name", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.__init__": [[257, 262], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "None", "\n", "self", ".", "_iterator", "=", "None", "\n", "self", ".", "_batch_op", "=", "None", "\n", "self", ".", "_sess", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.__del__": [[263, 266], ["data_noise.Dataset._sess.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_sess", ":", "\n", "            ", "self", ".", "_sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.__iter__": [[267, 269], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.__next__": [[270, 277], ["data_noise.Dataset.get_next"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.get_next"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "b", "=", "self", ".", "get_next", "(", ")", "\n", "", "except", ":", "\n", "            ", "raise", "StopIteration", "\n", "", "else", ":", "\n", "            ", "return", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.get_next": [[280, 282], ["data_noise.Dataset._sess.run"], "methods", ["None"], ["def", "get_next", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sess", ".", "run", "(", "self", ".", "_batch_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.reset": [[283, 285], ["data_noise.Dataset._sess.run"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "feed_dict", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "_sess", ".", "run", "(", "self", ".", "_iterator", ".", "initializer", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid": [[286, 300], ["dataset.make_initializable_iterator", "data_noise.Dataset._iterator.get_next", "data_noise.session", "data_noise.Dataset.reset"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.get_next", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.session", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.reset"], ["", "def", "_bulid", "(", "self", ",", "dataset", ",", "sess", "=", "None", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "dataset", "\n", "\n", "self", ".", "_iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "self", ".", "_batch_op", "=", "self", ".", "_iterator", ".", "get_next", "(", ")", "\n", "if", "sess", ":", "\n", "            ", "self", ".", "_sess", "=", "sess", "\n", "", "else", ":", "\n", "            ", "self", ".", "_sess", "=", "session", "(", ")", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.dataset": [[301, 304], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.iterator": [[305, 308], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterator", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset.batch_op": [[309, 312], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_op", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_op", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Celeba.__init__": [[329, 482], ["data_noise.Dataset.__init__", "os.path.join", "data_noise.Celeba._bulid", "tensorflow.image.resize_images", "tensorflow.image.resize_images", "numpy.loadtxt", "os.path.exists", "numpy.loadtxt", "data_noise.disk_image_batch_dataset", "len", "tensorflow.image.crop_to_bounding_box", "tensorflow.gather", "tensorflow.image.crop_to_bounding_box", "tensorflow.gather", "functools.partial", "os.path.exists", "os.path.join", "data_noise.tfrecord_batch_dataset", "os.path.join", "data_noise.tfrecord_batch_dataset", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "len", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.reduce_all", "tensorflow.reduce_all", "os.path.join", "os.path.join", "tensorflow.equal", "tensorflow.equal", "name.replace", "os.path.join", "tensorflow.gather", "tensorflow.ones_like", "tensorflow.gather", "tensorflow.zeros_like", "str", "tensorflow.gather", "tensorflow.gather", "str"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset"], ["def", "__init__", "(", "self", ",", "data_dir", ",", "atts", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "crop", "=", "True", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ")", ":", "\n", "        ", "super", "(", "Celeba", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ",", "noise", ")", ":", "\n", "            ", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "if", "is_tfrecord", ":", "\n", "                ", "label", "=", "tf", ".", "gather", "(", "label", ",", "att_id", ")", "##### 2020.02.07", "\n", "#noise = tf.gather(noise, att_id)", "\n", "", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", ",", "noise", "\n", "", "def", "map_func", "(", "img", ",", "label", ")", ":", "\n", "            ", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "if", "is_tfrecord", ":", "\n", "               ", "label", "=", "tf", ".", "gather", "(", "label", ",", "att_id", ")", "##### 2020.02.07", "\n", "#noise = tf.gather(noise, att_id)", "\n", "", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", "\n", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "feature_val", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "ones_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "zeros_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "", "list_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'list_attr_celeba.txt'", ")", "\n", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "170", "\n", "att_id", "=", "[", "Celeba", ".", "att_dict", "[", "att", "]", "for", "att", "in", "atts", "]", "#atts[filter_att]", "\n", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'celeba_tfrecords'", ",", "part", "+", "\"_\"", "+", "atts", "[", "filter_att", "]", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'celeba_tfrecords'", ",", "part", "+", "\"_\"", "+", "atts", "[", "filter_att", "]", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "40", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "", "else", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'celeba_tfrecords'", ",", "part", "+", "\"_crop.tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "40", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "", "if", "part", "==", "'train'", ":", "\n", "                ", "self", ".", "_img_num", "=", "182000", "\n", "", "", "else", ":", "\n", "            ", "if", "crop", ":", "\n", "                ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_align_celeba'", ")", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_align_celeba_png'", ")", "\n", "", "else", ":", "\n", "                ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_crop_celeba'", ")", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'img_crop_celeba_png'", ")", "\n", "\n", "", "names", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "0", "]", ",", "dtype", "=", "np", ".", "str", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "img_dir_png", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_png", ",", "name", ".", "replace", "(", "'jpg'", ",", "'png'", ")", ")", "for", "name", "in", "names", "]", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "img_dir_jpg", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "name", ")", "for", "name", "in", "names", "]", "\n", "\n", "", "att_id", "=", "[", "Celeba", ".", "att_dict", "[", "att", "]", "+", "1", "for", "att", "in", "atts", "]", "\n", "labels", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "att_id", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "if", "len", "(", "labels", ".", "shape", ")", "==", "1", ":", "\n", "                ", "labels", "=", "labels", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "# if img_resize == 64:", "\n", "#     # crop as how VAE/GAN do", "\n", "#     offset_h = 40", "\n", "#     offset_w = 15", "\n", "#     img_size = 148", "\n", "# else:", "\n", "#     offset_h = 26", "\n", "#     offset_w = 3", "\n", "#     img_size = 170", "\n", "\n", "", "offset_h", "=", "26", "\n", "offset_w", "=", "3", "\n", "img_size", "=", "170", "\n", "\n", "if", "im_no", "is", "not", "None", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "#repeat = 1", "\n", "img_paths", "=", "[", "img_paths", "[", "i", "-", "1", "]", "for", "i", "in", "im_no", "]", "\n", "labels", "=", "labels", "[", "[", "i", "-", "1", "for", "i", "in", "im_no", "]", "]", "\n", "", "elif", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "#repeat = 1", "\n", "img_paths", "=", "img_paths", "[", "182637", ":", "]", "\n", "labels", "=", "labels", "[", "182637", ":", "]", "\n", "# img_paths = img_paths[182637:182637+5000]", "\n", "# labels = labels[182637:182637+5000]", "\n", "# img_paths = img_paths[0:64]   ###temp!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!", "\n", "# labels = labels[0:64]", "\n", "", "elif", "part", "==", "'val'", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", "182000", ":", "182637", "]", "\n", "labels", "=", "labels", "[", "182000", ":", "182637", "]", "\n", "", "else", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", ":", "182000", "]", "\n", "labels", "=", "labels", "[", ":", "182000", "]", "\n", "\n", "", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "atts", "=", "atts", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "offset_h", "=", "offset_h", "\n", "self", ".", "offset_w", "=", "offset_w", "\n", "self", ".", "img_size", "=", "img_size", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Celeba.__len__": [[483, 485], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Celeba.check_attribute_conflict": [[486, 517], ["att_names.index", "data_noise.Celeba.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_attribute_conflict", "(", "att_batch", ",", "att_name", ",", "att_names", ")", ":", "\n", "        ", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "att_id", "=", "att_names", ".", "index", "(", "att_name", ")", "\n", "\n", "for", "att", "in", "att_batch", ":", "\n", "            ", "if", "att_name", "in", "[", "'Bald'", ",", "'Receding_Hairline'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "\n", "", "elif", "att_name", "==", "'Bangs'", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bald'", ")", "\n", "_set", "(", "att", ",", "0", ",", "'Receding_Hairline'", ")", "\n", "", "elif", "att_name", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# _set(att, 0, 'bald')", "\n", "", "", "", "elif", "att_name", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# Removed since `Mustache` and `No_Beard` are not conflict.", "\n", "# But the two attributes are not well labeled in the dataset.", "\n", "#            elif att_name in ['Mustache', 'No_Beard'] and att[att_id] == 1:", "\n", "#                for n in ['Mustache', 'No_Beard']:", "\n", "#                    if n != att_name:", "\n", "#                        _set(att, 0, n)", "\n", "\n", "", "", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Celeba.check_random_attribute_conflict": [[518, 547], ["att_names.index", "random.randint", "range", "len", "sum", "data_noise.Celeba.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_random_attribute_conflict", "(", "att_batch", ",", "att_names", ",", "hair_color", "=", "None", ")", ":", "\n", "        ", "\"\"\" For randomly generated attributes, tested but not used in this repo. \"\"\"", "\n", "\n", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "def", "_idx", "(", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "return", "att_names", ".", "index", "(", "att_name", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "att", "in", "att_batch", ":", "\n", "            ", "valid_atts", "=", "[", "i", "for", "i", "in", "[", "'Receding_Hairline'", ",", "'Bald'", "]", "if", "i", "in", "att_names", "]", "\n", "if", "'Bangs'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Bangs'", ")", "]", "==", "1", "and", "len", "(", "valid_atts", ")", ">", "0", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "valid_atts", "]", ")", ">", "0", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "[", "_set", "(", "att", ",", "0", ",", "i", ")", "for", "i", "in", "valid_atts", "]", "\n", "#            hair_color = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']", "\n", "", "if", "hair_color", "is", "not", "None", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "hair_color", "]", ")", ">", "1", ":", "\n", "                ", "one", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "hair_color", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hair_color", ")", ")", ":", "\n", "                    ", "_set", "(", "att", ",", "1", "if", "i", "==", "one", "else", "0", ",", "hair_color", "[", "i", "]", ")", "\n", "", "", "if", "'Straight_Hair'", "in", "att_names", "and", "'Wavy_Hair'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Straight_Hair'", ")", "]", "==", "1", "and", "att", "[", "\n", "_idx", "(", "'Wavy_Hair'", ")", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Straight_Hair'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "_set", "(", "att", ",", "0", ",", "'Wavy_Hair'", ")", "\n", "#            if 'Mustache' in att_names and 'No_Beard' in att_names and att[_idx('Mustache')] == 1 and att[_idx('No_Beard')] == 1:", "\n", "#                _set(att, 0, 'Mustache') if random.random() < 0.5 else _set(att, 0, 'No_Beard')", "\n", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Celeba.creat_tfrecord": [[548, 578], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "numpy.random.normal", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "tensorflow.train.FloatList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "# sess = tl.session()", "\n", "# noise = sess.run(tf.random_normal((1, 64))).astype(np.float)", "\n", "# sess.close()", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "64", ")", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", ",", "\n", "'noise'", ":", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "noise", ")", ")", "#", "\n", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Celeba.creat_tfrecord_split_opposite_label": [[579, 619], ["range", "os.path.exists", "os.makedirs", "len", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.python_io.TFRecordWriter.write", "str", "str", "str", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.strftime", "time.time", "time.localtime", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "time.time"], "methods", ["None"], ["", "def", "creat_tfrecord_split_opposite_label", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "atts", ")", ")", ":", "\n", "            ", "att", "=", "self", ".", "atts", "[", "attribute_id", "]", "\n", "count_true", "=", "0", "\n", "count_false", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "false_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_False_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "attribute_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "elif", "label", "[", "attribute_id", "]", "==", "-", "1", ":", "\n", "                        ", "false_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_false", "=", "count_false", "+", "1", "\n", "if", "count_false", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} negative images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_false", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "\"%d negative images are processed.\"", "%", "count_false", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "false_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Celeba.creat_tfrecord_split_true_label": [[620, 651], ["range", "os.path.exists", "os.makedirs", "len", "data_noise.Celeba.atts.index", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "img_name.encode", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "", "", "def", "creat_tfrecord_split_true_label", "(", "self", ",", "selected_atts", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "selected_atts", ")", ")", ":", "\n", "            ", "att", "=", "selected_atts", "[", "attribute_id", "]", "\n", "att_id", "=", "self", ".", "atts", ".", "index", "(", "att", ")", "\n", "count_true", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "att", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"celeba_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "att", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "att_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.x2y.__init__": [[653, 730], ["data_noise.Dataset.__init__", "data_noise.x2y._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "os.path.join", "data_noise.tfrecord_batch_dataset", "os.path.join", "numpy.array", "data_noise.disk_image_batch_dataset", "len", "enumerate", "enumerate", "tensorflow.clip_by_value", "glob.glob", "img_paths.extend", "numpy.array.extend", "glob.glob", "os.path.join", "os.path.join", "img_paths.extend", "numpy.array.extend", "img_paths.extend", "numpy.array.extend", "range", "len", "range", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset"], ["    ", "def", "__init__", "(", "self", ",", "dataset_name", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ")", ":", "\n", "        ", "super", "(", "x2y", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "256", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset_name", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "1", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "if", "part", "==", "'train'", ":", "\n", "                ", "if", "dataset_name", "==", "'apple2orange'", ":", "\n", "                    ", "self", ".", "_img_num", "=", "2014", "-", "100", "\n", "", "elif", "dataset_name", "==", "'summer2winter'", ":", "\n", "                    ", "self", ".", "_img_num", "=", "2193", "-", "100", "\n", "", "elif", "dataset_name", "==", "'horse2zebra'", ":", "\n", "                    ", "self", ".", "_img_num", "=", "2401", "-", "100", "\n", "", "", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset_name", ")", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'testA'", ",", "'testB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "*", "(", "1", "-", "i", ")", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'trainA'", ",", "'trainB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "if", "part", "==", "'val'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", ":", "50", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "*", "(", "1", "-", "i", ")", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", ":", "50", "]", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", "50", ":", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "*", "(", "1", "-", "i", ")", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", "50", ":", "]", ")", ")", "]", ")", "\n", "", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.x2y.__len__": [[731, 733], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.x2y.creat_tfrecord": [[734, 757], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.convert.convert.convert", "img.convert.convert.tobytes", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", "+", "\"_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", "+", "\"_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", "+", "\"_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name", "]", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "", "", "class", "MakeupTransfer", "(", "Dataset", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.MakeupTransfer.__init__": [[758, 880], ["data_noise.Dataset.__init__", "data_noise.MakeupTransfer._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.to_float", "os.path.join", "data_noise.tfrecord_batch_dataset_MT", "os.path.join", "numpy.array", "data_noise.disk_image_batch_dataset_MT", "len", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_flip_left_right", "functools.partial", "enumerate", "enumerate", "tensorflow.clip_by_value", "tensorflow.reduce_all", "tensorflow.reduce_all", "glob.glob", "img_paths.extend", "numpy.array.extend", "glob.glob", "tensorflow.reduce_max", "tensorflow.equal", "tensorflow.equal", "os.path.join", "os.path.join", "range", "range", "img_paths.extend", "img_segs_paths.extend", "numpy.array.extend", "tensorflow.gather", "tensorflow.ones_like", "tensorflow.gather", "tensorflow.zeros_like", "len", "img_seg_paths.append", "len", "img_seg_paths.append", "img_paths.extend", "img_segs_paths.extend", "numpy.array.extend", "tensorflow.gather", "tensorflow.gather", "range", "len", "range", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset_MT", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset_MT"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ",", "is_augment", "=", "False", ")", ":", "\n", "        ", "super", "(", "MakeupTransfer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "segs", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "if", "is_augment", ":", "\n", "# \u5c06\u56fe\u7247\u968f\u673a\u8fdb\u884c\u5782\u76f4\u7ffb\u8f6c", "\n", "                ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "segs", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "segs", ")", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u4eae\u5ea6", "\n", "# img = tf.image.random_brightness(img, max_delta=0.6)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u5bf9\u6bd4\u5ea6", "\n", "# img = tf.image.random_contrast(img, lower=0.1, upper=0.8)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u8272\u5ea6", "\n", "# img = tf.image.random_hue(img, max_delta=0.3)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u9971\u548c\u5ea6", "\n", "# img = tf.image.random_saturation(img, lower=0.2, upper=1.8)", "\n", "", "segs", "=", "tf", ".", "cast", "(", "segs", ",", "tf", ".", "float32", ")", "\n", "# segs = tf.reshape(segs, [batch_size, 361, 361, 1])", "\n", "#segs = tf.concat([segs, segs, segs], 2)", "\n", "segs", "=", "tf", ".", "image", ".", "resize_images", "(", "segs", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "#segs = tf.split(segs, 3, 3)", "\n", "# segs = tf.clip_by_value(segs, 0, 255) / 127.5 - 1", "\n", "segs", "=", "tf", ".", "clip_by_value", "(", "segs", ",", "0", ",", "255", ")", "\n", "segs", "=", "segs", "/", "(", "0.5", "*", "tf", ".", "reduce_max", "(", "segs", ")", ")", "-", "1", "\n", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "# label = tf.to_int32(label, name='ToInt32')", "\n", "# label = tf.one_hot(label, 2, 1, 0)", "\n", "# label = tf.to_float(label, name='ToFloat')", "\n", "# label = tf.squeeze(label)", "\n", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "label", "=", "tf", ".", "to_float", "(", "label", ",", "name", "=", "'ToFloat'", ")", "\n", "return", "img", ",", "segs", ",", "label", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "_", ",", "feature_val", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "ones_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "return", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ",", "tf", ".", "zeros_like", "(", "tf", ".", "gather", "(", "feature_val", ",", "feat_id", ")", ")", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "361", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'MakeupTransfer'", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset_MT", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "1", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "#", "\n", "\n", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'MakeupTransfer'", ")", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "img_seg_paths", "=", "[", "]", "\n", "img_segs_paths", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'testA'", ",", "'testB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.png'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'trainA'", ",", "'trainB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.png'", ")", ")", "\n", "if", "partAB", "==", "'trainA'", ":", "\n", "                        ", "for", "j1", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", ":", "\n", "                            ", "img_seg_paths", ".", "append", "(", "imgAB_paths", "[", "j1", "]", "[", ":", "22", "]", "+", "'segs/'", "+", "imgAB_paths", "[", "j1", "]", "[", "22", ":", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "img_seg_paths", "=", "[", "]", "\n", "for", "j2", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", ":", "\n", "                            ", "img_seg_paths", ".", "append", "(", "imgAB_paths", "[", "j2", "]", "[", ":", "22", "]", "+", "'segs/'", "+", "imgAB_paths", "[", "j2", "]", "[", "22", ":", "]", ")", "\n", "", "", "if", "part", "==", "'val'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", ":", "50", "]", ")", "\n", "img_segs_paths", ".", "extend", "(", "img_seg_paths", "[", ":", "50", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", ":", "50", "]", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", "[", "50", ":", "]", ")", "\n", "img_segs_paths", ".", "extend", "(", "img_seg_paths", "[", "50", ":", "]", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", "[", "50", ":", "]", ")", ")", "]", ")", "\n", "", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset_MT", "(", "img_paths", "=", "img_paths", ",", "\n", "img_segs_paths", "=", "img_segs_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "img_segs_paths", "=", "img_segs_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "dataset_name", "=", "'MakeupTransfer'", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.MakeupTransfer.__len__": [[881, 883], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.MakeupTransfer.creat_tfrecord": [[884, 911], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.convert.convert.convert", "img.convert.convert.tobytes", "PIL.Image.open", "PIL.Image.open.tobytes", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"MakeupTransfer_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"MakeupTransfer_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"MakeupTransfer_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "img_s", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", "[", ":", "22", "]", "+", "'segs/'", "+", "img_path", "[", "22", ":", "]", ")", ")", "\n", "img_segs", "=", "img_s", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", ",", "\n", "'img_segs'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_segs", "]", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "", "", "class", "AFHQ", "(", "Dataset", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.AFHQ.__init__": [[912, 1023], ["data_noise.Dataset.__init__", "data_noise.AFHQ._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.to_int32", "tensorflow.one_hot", "tensorflow.to_float", "tensorflow.squeeze", "os.path.join", "data_noise.tfrecord_batch_dataset", "os.path.join", "numpy.array", "data_noise.disk_image_batch_dataset", "len", "tensorflow.image.random_flip_left_right", "functools.partial", "enumerate", "tensorflow.clip_by_value", "tensorflow.equal", "tensorflow.equal", "tensorflow.equal", "glob.glob", "img_paths.extend", "numpy.array.extend", "enumerate", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "os.path.join", "glob.glob", "img_paths.extend", "numpy.array.extend", "glob.glob", "img_paths.extend", "numpy.array.extend", "os.path.join", "os.path.join", "glob.glob", "img_paths.extend", "numpy.array.extend", "range", "os.path.join", "glob.glob", "img_paths.extend", "numpy.array.extend", "len", "range", "range", "os.path.join", "len", "len", "range", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ",", "is_augment", "=", "False", ")", ":", "\n", "        ", "super", "(", "AFHQ", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "if", "is_augment", ":", "\n", "# \u5c06\u56fe\u7247\u968f\u673a\u8fdb\u884c\u5782\u76f4\u7ffb\u8f6c", "\n", "                ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u4eae\u5ea6", "\n", "# img = tf.image.random_brightness(img, max_delta=0.6)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u5bf9\u6bd4\u5ea6", "\n", "# img = tf.image.random_contrast(img, lower=0.1, upper=0.8)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u8272\u5ea6", "\n", "# img = tf.image.random_hue(img, max_delta=0.3)", "\n", "# # \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u9971\u548c\u5ea6", "\n", "# img = tf.image.random_saturation(img, lower=0.2, upper=1.8)", "\n", "", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "label", "=", "tf", ".", "to_int32", "(", "label", ",", "name", "=", "'ToInt32'", ")", "\n", "label", "=", "tf", ".", "one_hot", "(", "label", ",", "3", ",", "1", ",", "0", ")", "\n", "label", "=", "tf", ".", "to_float", "(", "label", ",", "name", "=", "'ToFloat'", ")", "\n", "label", "=", "tf", ".", "squeeze", "(", "label", ")", "\n", "# label = (label + 1) // 2", "\n", "return", "img", ",", "label", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "# the function of filter", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "feature_val", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "ones_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "a", "=", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "512", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'AFHQ'", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "1", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "#", "\n", "\n", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", "# , 'AFHQ'", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'testA'", ",", "'testB'", "]", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "(", "1", "-", "i", ")", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "part", "==", "'val'", ":", "\n", "                    ", "for", "i", ",", "partAB", "in", "enumerate", "(", "[", "'val_cat'", ",", "'val_dog'", ",", "'val_wild'", "]", ")", ":", "# , 'val_wild'", "\n", "                        ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "i", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "elif", "part", "==", "'train_cat'", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "part", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "0", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train_dog'", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "part", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "1", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "elif", "part", "==", "'train_wild'", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "part", ",", "'*.jpg'", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "[", "2", "]", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "\n", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "dataset_name", "=", "'AFHQ'", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.AFHQ.__len__": [[1024, 1026], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.AFHQ.creat_tfrecord": [[1027, 1051], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "img.convert.convert.convert", "img.convert.convert.tobytes", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"AFHQ_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"AFHQ_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"AFHQ_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Morph.__init__": [[1058, 1229], ["data_noise.Dataset.__init__", "os.path.join", "data_noise.Morph._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "tensorflow.to_int32", "tensorflow.to_float", "tensorflow.squeeze", "tensorflow.one_hot", "tensorflow.to_float", "tensorflow.squeeze", "os.path.join", "os.path.join", "numpy.loadtxt", "os.path.exists", "numpy.loadtxt", "data_noise.age_group_div_", "data_noise.disk_image_batch_dataset", "len", "tensorflow.image.crop_to_bounding_box", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.random_hue", "tensorflow.image.random_saturation", "functools.partial", "os.path.exists", "os.path.join", "data_noise.tfrecord_batch_dataset", "os.path.join", "data_noise.tfrecord_batch_dataset", "os.path.exists", "tensorflow.clip_by_value", "tensorflow.equal", "tensorflow.equal", "tensorflow.equal", "os.path.join", "os.path.join", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "len", "len", "name.replace", "os.path.join", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.age_group_div_", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset"], ["def", "__init__", "(", "self", ",", "data_dir", ",", "atts", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "crop", "=", "True", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ",", "filter_att", "=", "None", ",", "filter_pos", "=", "None", ",", "is_augment", "=", "False", ")", ":", "\n", "        ", "super", "(", "Morph", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "_map_func", "(", "img", ",", "label", ")", ":", "#one image", "\n", "            ", "n_cls", "=", "2", "\n", "if", "crop", "and", "not", "is_tfrecord", ":", "\n", "                ", "img", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "img", ",", "offset_h", ",", "offset_w", ",", "img_size", ",", "img_size", ")", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "if", "is_augment", ":", "\n", "# \u5c06\u56fe\u7247\u968f\u673a\u8fdb\u884c\u5782\u76f4\u7ffb\u8f6c", "\n", "                ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u4eae\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_brightness", "(", "img", ",", "max_delta", "=", "0.6", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u5bf9\u6bd4\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_contrast", "(", "img", ",", "lower", "=", "0.1", ",", "upper", "=", "0.8", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u8272\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_hue", "(", "img", ",", "max_delta", "=", "0.3", ")", "\n", "# \u968f\u673a\u8bbe\u7f6e\u56fe\u7247\u7684\u9971\u548c\u5ea6", "\n", "img", "=", "tf", ".", "image", ".", "random_saturation", "(", "img", ",", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "\n", "\n", "", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "#all of them are 255?", "\n", "#                                #change!", "\n", "# label = tf.to_int32(label, name='ToInt32') #", "\n", "# label = tf.one_hot(label, n_cls, 1, 0)", "\n", "# label = tf.to_float(label, name='ToFloat')", "\n", "# label = tf.squeeze(label)", "\n", "# label = tf.to_float(label, name='ToFloat')", "\n", "\n", "label", "=", "tf", ".", "to_int32", "(", "label", ",", "name", "=", "'ToInt32'", ")", "\n", "age", "=", "label", "[", "0", "]", "\n", "gender", "=", "label", "[", "1", "]", "\n", "# age = tf.one_hot(age, n_cls, 1, 0)", "\n", "\n", "age", "=", "tf", ".", "to_float", "(", "age", ",", "name", "=", "'ToFloat'", ")", "\n", "age", "=", "tf", ".", "squeeze", "(", "age", ")", "\n", "gender", "=", "tf", ".", "one_hot", "(", "gender", ",", "2", ",", "1", ",", "0", ")", "\n", "gender", "=", "tf", ".", "to_float", "(", "gender", ",", "name", "=", "'ToFloat'", ")", "\n", "gender", "=", "tf", ".", "squeeze", "(", "gender", ")", "\n", "\n", "\n", "return", "img", ",", "gender", ",", "age", "\n", "\n", "", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", ":", "# the function of filter", "\n", "            ", "def", "filter_fn", "(", "feat_id", ",", "pos", ",", "image", ",", "feature_val", ",", "_", ")", ":", "\n", "                ", "if", "pos", ":", "\n", "                    ", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "ones_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "a", "=", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "return", "tf", ".", "equal", "(", "feature_val", "[", "feat_id", "]", ",", "tf", ".", "zeros_like", "(", "feature_val", "[", "feat_id", "]", ")", ")", "\n", "\n", "", "", "def", "get_filter_fn", "(", ")", ":", "\n", "                ", "return", "partial", "(", "filter_fn", ",", "filter_att", ",", "filter_pos", ")", "\n", "", "", "else", ":", "\n", "            ", "get_filter_fn", "=", "None", "\n", "\n", "", "list_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Morph_data_shuffle_10.txt'", ")", "#txt for what", "\n", "#read data(images and labels) by tfrecord (or not)", "\n", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "300", "#170", "\n", "if", "filter_att", "is", "not", "None", "and", "filter_pos", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'morph_tfrecords'", ",", "part", "+", "\"_\"", "+", "str", "(", "filter_att", ")", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'morph_tfrecords'", ",", "part", "+", "\"_\"", "+", "str", "(", "filter_att", ")", "+", "\"_\"", "+", "str", "(", "filter_pos", ")", "+", "\"_crop.tfrecords\"", ")", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "len", "(", "atts", ")", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "", "else", ":", "\n", "                ", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'morph_tfrecords'", ",", "part", "+", "\"_crop.tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "len", "(", "atts", ")", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "#the numbers of data for train", "\n", "", "if", "part", "==", "'train'", ":", "\n", "                ", "self", ".", "_img_num", "=", "46300", "\n", "", "", "else", ":", "\n", "\n", "            ", "img_dir_jpg", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Morph'", ")", "#  the name is named by me ?", "\n", "img_dir_png", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Morph_png'", ")", "\n", "\n", "\n", "names", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "0", "]", ",", "dtype", "=", "np", ".", "str", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "img_dir_png", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_png", ",", "name", ".", "replace", "(", "'jpg'", ",", "'png'", ")", ")", "for", "name", "in", "names", "]", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "img_dir_jpg", ")", ":", "\n", "                ", "img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "name", ")", "for", "name", "in", "names", "]", "\n", "\n", "", "att_id", "=", "[", "Morph", ".", "att_dict", "[", "att", "]", "+", "1", "for", "att", "in", "atts", "]", "\n", "labels", "=", "np", ".", "loadtxt", "(", "list_file", ",", "skiprows", "=", "1", ",", "usecols", "=", "att_id", ",", "dtype", "=", "np", ".", "int64", ")", "#[:, np.newaxis]", "\n", "# if img_resize == 64:", "\n", "#     # crop as how VAE/GAN do", "\n", "#     offset_h = 40", "\n", "#     offset_w = 15", "\n", "#     img_size = 148", "\n", "# else:", "\n", "#     offset_h = 26", "\n", "#     offset_w = 3", "\n", "#     img_size = 170", "\n", "\n", "img_size", "=", "300", "# 170", "\n", "offset_h", "=", "0", "#26 #168(400)", "\n", "offset_w", "=", "0", "#3", "\n", "\n", "\n", "if", "im_no", "is", "not", "None", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "img_paths", "=", "[", "img_paths", "[", "i", "-", "1", "]", "for", "i", "in", "im_no", "]", "\n", "labels", "=", "labels", "[", "[", "i", "-", "1", "for", "i", "in", "im_no", "]", "]", "\n", "", "elif", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "img_paths", "=", "img_paths", "[", "46500", ":", "]", "#147500", "\n", "labels", "=", "labels", "[", "46500", ":", "]", "\n", "# img_paths = img_paths[182637:182637+5000]", "\n", "# labels = labels[182637:182637+5000]", "\n", "# img_paths = img_paths[0:64]                                  ###temp!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!", "\n", "# labels = labels[0:64]", "\n", "", "elif", "part", "==", "'val'", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", "46308", ":", "46500", "]", "#46397", "\n", "labels", "=", "labels", "[", "46308", ":", "46500", "]", "\n", "", "else", ":", "\n", "                ", "img_paths", "=", "img_paths", "[", ":", "46300", "]", "# 147101", "\n", "labels", "=", "labels", "[", ":", "46300", "]", "#46300", "\n", "\n", "", "labels", "[", ":", ",", "0", "]", "=", "age_group_div_", "(", "labels", "[", ":", ",", "0", "]", ")", "#VGG16 train need labels = age_group_div_(labels)", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "filter_fn", "=", "get_filter_fn", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "atts", "=", "atts", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "offset_h", "=", "offset_h", "\n", "self", ".", "offset_w", "=", "offset_w", "\n", "self", ".", "img_size", "=", "img_size", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Morph.__len__": [[1230, 1232], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Morph.check_attribute_conflict": [[1233, 1265], ["att_names.index", "data_noise.Morph.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "#check for celebA , no need for Age", "\n", "def", "check_attribute_conflict", "(", "att_batch", ",", "att_name", ",", "att_names", ")", ":", "\n", "        ", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "att_id", "=", "att_names", ".", "index", "(", "att_name", ")", "\n", "\n", "for", "att", "in", "att_batch", ":", "\n", "            ", "if", "att_name", "in", "[", "'Bald'", ",", "'Receding_Hairline'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "\n", "", "elif", "att_name", "==", "'Bangs'", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bald'", ")", "\n", "_set", "(", "att", ",", "0", ",", "'Receding_Hairline'", ")", "\n", "", "elif", "att_name", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# _set(att, 0, 'bald')", "\n", "", "", "", "elif", "att_name", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", "and", "att", "[", "att_id", "]", "==", "1", ":", "\n", "                ", "for", "n", "in", "[", "'Straight_Hair'", ",", "'Wavy_Hair'", "]", ":", "\n", "                    ", "if", "n", "!=", "att_name", ":", "\n", "                        ", "_set", "(", "att", ",", "0", ",", "n", ")", "\n", "# Removed since `Mustache` and `No_Beard` are not conflict.", "\n", "# But the two attributes are not well labeled in the dataset.", "\n", "#            elif att_name in ['Mustache', 'No_Beard'] and att[att_id] == 1:", "\n", "#                for n in ['Mustache', 'No_Beard']:", "\n", "#                    if n != att_name:", "\n", "#                        _set(att, 0, n)", "\n", "\n", "", "", "", "", "return", "att_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Morph.check_random_attribute_conflict": [[1266, 1295], ["att_names.index", "random.randint", "range", "len", "sum", "data_noise.Morph.check_attribute_conflict._set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_random_attribute_conflict", "(", "att_batch", ",", "att_names", ",", "hair_color", "=", "None", ")", ":", "\n", "        ", "\"\"\" For randomly generated attributes, tested but not used in this repo. \"\"\"", "\n", "\n", "def", "_set", "(", "att", ",", "value", ",", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "att", "[", "att_names", ".", "index", "(", "att_name", ")", "]", "=", "value", "\n", "\n", "", "", "def", "_idx", "(", "att_name", ")", ":", "\n", "            ", "if", "att_name", "in", "att_names", ":", "\n", "                ", "return", "att_names", ".", "index", "(", "att_name", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "att", "in", "att_batch", ":", "\n", "            ", "valid_atts", "=", "[", "i", "for", "i", "in", "[", "'Receding_Hairline'", ",", "'Bald'", "]", "if", "i", "in", "att_names", "]", "\n", "if", "'Bangs'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Bangs'", ")", "]", "==", "1", "and", "len", "(", "valid_atts", ")", ">", "0", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "valid_atts", "]", ")", ">", "0", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Bangs'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "[", "_set", "(", "att", ",", "0", ",", "i", ")", "for", "i", "in", "valid_atts", "]", "\n", "#            hair_color = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']", "\n", "", "if", "hair_color", "is", "not", "None", "and", "sum", "(", "[", "att", "[", "_idx", "(", "i", ")", "]", "for", "i", "in", "hair_color", "]", ")", ">", "1", ":", "\n", "                ", "one", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "hair_color", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hair_color", ")", ")", ":", "\n", "                    ", "_set", "(", "att", ",", "1", "if", "i", "==", "one", "else", "0", ",", "hair_color", "[", "i", "]", ")", "\n", "", "", "if", "'Straight_Hair'", "in", "att_names", "and", "'Wavy_Hair'", "in", "att_names", "and", "att", "[", "_idx", "(", "'Straight_Hair'", ")", "]", "==", "1", "and", "att", "[", "\n", "_idx", "(", "'Wavy_Hair'", ")", "]", "==", "1", ":", "\n", "                ", "_set", "(", "att", ",", "0", ",", "'Straight_Hair'", ")", "if", "random", ".", "random", "(", ")", "<", "0.5", "else", "_set", "(", "att", ",", "0", ",", "'Wavy_Hair'", ")", "\n", "#            if 'Mustache' in att_names and 'No_Beard' in att_names and att[_idx('Mustache')] == 1 and att[_idx('No_Beard')] == 1:", "\n", "#                _set(att, 0, 'Mustache') if random.random() < 0.5 else _set(att, 0, 'No_Beard')", "\n", "", "", "return", "att_batch", "\n", "#creat example file by tfrecord", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Morph.creat_tfrecord": [[1296, 1329], ["tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "os.path.exists", "os.makedirs", "os.path.join", "PIL.Image.open", "PIL.Image.open.tobytes", "img_name.encode", "tensorflow.train.Example", "tensorflow.python_io.TFRecordWriter.write", "os.path.join", "os.path.join", "os.path.exists", "os.path.join", "os.path.split", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.train.Features", "time.strftime", "os.path.splitext", "time.localtime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.time", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                ", "img_path", "=", "'.'", ".", "join", "(", "[", "os", ".", "path", ".", "splitext", "(", "img_path", ")", "[", "0", "]", ",", "'jpg'", "]", ")", "\n", "", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "#     for real_name in", "\n", "#        img = Image.open(re.match(os.path.join(img_path),real_name))", "\n", "#  img = img.crop((self.offset_w, self.offset_h, self.offset_w + self.img_size, self.offset_h + self.img_size))", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "#one tensor change [i,:]", "\n", "#label[0] = age_group_div(label[0])", "\n", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "# img_name_byte = img_name.getBytes()", "\n", "# str.encode(img_name)", "\n", "#bytes(img_name , encoding=\"utf8\")", "\n", "img_name_byte", "=", "img_name", ".", "encode", "(", "encoding", "=", "'utf-8'", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "#gchange!", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "# creat labels by tfrecord", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Morph.creat_tfrecord_split_opposite_label": [[1330, 1371], ["range", "os.path.exists", "os.makedirs", "len", "os.path.join", "os.path.join", "os.path.exists", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.TFRecordWriter", "enumerate", "print", "print", "print", "tensorflow.python_io.TFRecordWriter.close", "tensorflow.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open", "img.crop.crop.crop", "img.crop.crop.tobytes", "img_name.getBytes", "tensorflow.train.Example", "os.path.join", "os.path.split", "tensorflow.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tensorflow.train.Example.SerializeToString", "print", "tensorflow.python_io.TFRecordWriter.write", "str", "str", "str", "tensorflow.train.Example.SerializeToString", "print", "time.strftime", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "time.localtime", "time.strftime", "time.time", "time.localtime", "tensorflow.train.Int64List", "tensorflow.train.BytesList", "tensorflow.train.BytesList", "time.time"], "methods", ["None"], ["", "def", "creat_tfrecord_split_opposite_label", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ")", ")", "\n", "", "for", "attribute_id", "in", "range", "(", "len", "(", "atts", ")", ")", ":", "\n", "            ", "att", "=", "self", ".", "atts", "[", "attribute_id", "]", "\n", "count_true", "=", "0", "\n", "count_false", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", ":", "\n", "                ", "true_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_True_crop.tfrecords\"", ")", ")", "\n", "false_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\"morph_tfrecords\"", ",", "self", ".", "part", "+", "\"_\"", "+", "str", "(", "attribute_id", ")", "+", "\n", "\"_False_crop.tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "                    ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "crop", "(", "(", "self", ".", "offset_w", ",", "self", ".", "offset_h", ",", "self", ".", "offset_w", "+", "self", ".", "img_size", ",", "self", ".", "offset_h", "+", "self", ".", "img_size", ")", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "#one tensor change [i,:]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "img_name_byte", "=", "img_name", ".", "getBytes", "(", ")", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name_byte", "]", ")", ")", "}", ")", ")", "\n", "if", "label", "[", "attribute_id", "]", "==", "1", ":", "\n", "                        ", "true_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_true", "=", "count_true", "+", "1", "\n", "if", "count_true", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} positive images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_true", ")", ")", "\n", "", "", "elif", "label", "[", "attribute_id", "]", "==", "-", "1", ":", "\n", "                        ", "false_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count_false", "=", "count_false", "+", "1", "\n", "if", "count_false", "%", "500", "==", "0", ":", "\n", "                            ", "print", "(", "'Time:{0},{1} negative images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count_false", ")", ")", "\n", "", "", "", "print", "(", "\"%d positive images are processed.\"", "%", "count_true", ")", "\n", "print", "(", "\"%d negative images are processed.\"", "%", "count_false", ")", "\n", "print", "(", "att", "+", "' done!'", ")", "\n", "true_writer", ".", "close", "(", ")", "\n", "false_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Photo2Artworks.__init__": [[1373, 1451], ["data_noise.Dataset.__init__", "data_noise.Photo2Artworks._bulid", "tensorflow.cast", "tensorflow.image.resize_images", "os.path.join", "data_noise.tfrecord_batch_dataset", "numpy.array", "data_noise.disk_image_batch_dataset", "len", "enumerate", "enumerate", "range", "tensorflow.clip_by_value", "glob.glob", "data_noise.Photo2Artworks.__init__.one_hot"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Dataset._bulid", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "img_resize", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "\n", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "2048", ",", "repeat", "=", "-", "1", ",", "sess", "=", "None", ",", "part", "=", "'train'", ",", "\n", "im_no", "=", "None", ",", "is_tfrecord", "=", "False", ")", ":", "\n", "        ", "super", "(", "Photo2Artworks", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "one_hot", "(", "idx", ",", "length", ")", ":", "\n", "            ", "output", "=", "[", "0", "for", "_", "in", "range", "(", "length", ")", "]", "\n", "output", "[", "idx", "]", "=", "1", "\n", "return", "output", "\n", "\n", "", "def", "_map_func", "(", "img", ",", "label", ")", ":", "\n", "# img = tf.image.resize_images(img, [img_resize, img_resize]) / 127.5 - 1", "\n", "# or", "\n", "            ", "img", "=", "tf", ".", "cast", "(", "img", ",", "tf", ".", "float32", ")", "\n", "img", "=", "tf", ".", "image", ".", "resize_images", "(", "img", ",", "[", "img_resize", ",", "img_resize", "]", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "img", "=", "tf", ".", "clip_by_value", "(", "img", ",", "0", ",", "255", ")", "/", "127.5", "-", "1", "\n", "label", "=", "(", "label", "+", "1", ")", "//", "2", "\n", "return", "img", ",", "label", "\n", "\n", "", "if", "is_tfrecord", ":", "\n", "            ", "img_size", "=", "256", "\n", "tfrecord_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'Photo2Artworks'", "+", "'_tfrecords'", ",", "part", "+", "\".tfrecords\"", ")", "\n", "\n", "dataset", "=", "tfrecord_batch_dataset", "(", "tfrecord_path", "=", "tfrecord_path", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "label_len", "=", "5", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ",", "\n", "reshape_size", "=", "img_size", ")", "\n", "if", "part", "==", "'train'", ":", "\n", "                ", "self", ".", "_img_num", "=", "525", "+", "1072", "+", "6287", "+", "562", "+", "400", "\n", "\n", "", "", "else", ":", "\n", "            ", "img_dir_jpg", "=", "data_dir", "\n", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "if", "part", "==", "'test'", ":", "\n", "                ", "drop_remainder", "=", "False", "\n", "shuffle", "=", "False", "\n", "repeat", "=", "1", "\n", "domains", "=", "[", "'test_photo'", ",", "'test_cezanne'", ",", "'test_monet'", ",", "'test_ukiyoe'", ",", "'test_vangogh'", "]", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "domains", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "onehot_label", "=", "one_hot", "(", "i", ",", "len", "(", "domains", ")", ")", "\n", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "onehot_label", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "domains", "=", "[", "'train_photo'", ",", "'train_cezanne'", ",", "'train_monet'", ",", "'train_ukiyoe'", ",", "'train_vangogh'", "]", "\n", "for", "i", ",", "partAB", "in", "enumerate", "(", "domains", ")", ":", "\n", "                    ", "imgAB_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "img_dir_jpg", ",", "partAB", ",", "'*.jpg'", ")", ")", "\n", "onehot_label", "=", "one_hot", "(", "i", ",", "len", "(", "domains", ")", ")", "\n", "if", "part", "==", "'train'", ":", "\n", "                        ", "img_paths", ".", "extend", "(", "imgAB_paths", ")", "\n", "labels", ".", "extend", "(", "[", "onehot_label", "for", "_", "in", "range", "(", "len", "(", "imgAB_paths", ")", ")", "]", ")", "\n", "", "", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "dataset", "=", "disk_image_batch_dataset", "(", "img_paths", "=", "img_paths", ",", "\n", "labels", "=", "labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "prefetch_batch", "=", "prefetch_batch", ",", "\n", "drop_remainder", "=", "drop_remainder", ",", "\n", "map_func", "=", "_map_func", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "buffer_size", "=", "buffer_size", ",", "\n", "repeat", "=", "repeat", ")", "\n", "self", ".", "_img_num", "=", "len", "(", "img_paths", ")", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "", "self", ".", "_bulid", "(", "dataset", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Photo2Artworks.__len__": [[1452, 1454], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_img_num", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.Photo2Artworks.creat_tfrecord": [[1455, 1486], ["data_noise.Photo2Artworks.creat_tfrecord.shuffle_data"], "methods", ["None"], ["", "def", "creat_tfrecord", "(", "self", ")", ":", "\n", "\n", "        ", "def", "shuffle_data", "(", ")", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "_img_num", ")", "\n", "self", ".", "img_paths", "=", "np", ".", "array", "(", "self", ".", "img_paths", ")", "[", "indices", "]", "\n", "# self.img_paths = self.img_paths.tolist()", "\n", "self", ".", "labels", "=", "self", ".", "labels", "[", "indices", "]", "\n", "", "shuffle_data", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'Photo2Artworks'", "+", "\"_tfrecords\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'Photo2Artworks'", "+", "\"_tfrecords\"", ")", ")", "\n", "", "count", "=", "0", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'Photo2Artworks'", "+", "\"_tfrecords\"", ",", "self", ".", "part", "+", "\".tfrecords\"", ")", ")", "\n", "for", "i", ",", "img_path", "in", "enumerate", "(", "self", ".", "img_paths", ")", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_path", ")", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_raw", "=", "img", ".", "tobytes", "(", ")", "\n", "label", "=", "self", ".", "labels", "[", "i", ",", ":", "]", "\n", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "1", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "\n", "feature", "=", "{", "'label'", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "label", ")", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_raw", "]", ")", ")", ",", "\n", "'img_name'", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "img_name", "]", ")", ")", "}", ")", ")", "\n", "writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "if", "count", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "'Time:{0},{1} images are processed.'", ".", "format", "(", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ",", "count", ")", ")", "\n", "", "", "print", "(", "\"%d images are processed.\"", "%", "count", ")", "\n", "print", "(", "self", ".", "part", "+", "' done!'", ")", "\n", "writer", ".", "close", "(", ")", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.age_group_div_": [[15, 26], ["numpy.zeros", "range"], "function", ["None"], ["def", "age_group_div_", "(", "age", ")", ":", "\n", "\n", "#output = np.zeros([1,5],dtype=float)", "\n", "    ", "lens", "=", "age", ".", "shape", "[", "0", "]", "\n", "output", "=", "np", ".", "zeros", "(", "[", "lens", "]", ",", "dtype", "=", "float", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "lens", ")", ":", "\n", "        ", "if", "age", "[", "i", "]", "<=", "50", ":", "\n", "            ", "output", "[", "i", "]", "=", "0", "\n", "", "elif", "age", "[", "i", "]", ">", "50", ":", "\n", "            ", "output", "[", "i", "]", "=", "1", "\n", "", "", "return", "output", "\n", "# def age_group_div_(age):", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.session": [[43, 50], ["tensorflow.ConfigProto", "tensorflow.Session"], "function", ["None"], ["", "def", "session", "(", "graph", "=", "None", ",", "allow_soft_placement", "=", "True", ",", "\n", "log_device_placement", "=", "False", ",", "allow_growth", "=", "True", ")", ":", "\n", "    ", "\"\"\"Return a Session with simple config.\"\"\"", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "allow_soft_placement", ",", "\n", "log_device_placement", "=", "log_device_placement", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "allow_growth", "\n", "return", "tf", ".", "Session", "(", "graph", "=", "graph", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset": [[51, 73], ["dataset.batch.repeat().prefetch", "dataset.batch.filter", "dataset.batch.map", "dataset.batch.shuffle", "dataset.batch.filter", "dataset.batch.apply", "dataset.batch.batch", "filter_fn", "tensorflow.contrib.data.batch_and_drop_remainder", "dataset.batch.repeat"], "function", ["None"], ["", "def", "batch_dataset", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "if", "filter", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter", ")", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "dataset", "=", "dataset", ".", "map", "(", "map_func", ",", "num_parallel_calls", "=", "num_threads", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "        ", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", ")", "\n", "\n", "", "if", "filter_fn", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter_fn", "(", ")", ")", "\n", "\n", "", "if", "drop_remainder", ":", "\n", "        ", "dataset", "=", "dataset", ".", "apply", "(", "tf", ".", "contrib", ".", "data", ".", "batch_and_drop_remainder", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "repeat", "(", "repeat", ")", ".", "prefetch", "(", "prefetch_batch", ")", "\n", "\n", "return", "dataset", "\n", "", "def", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset_MT": [[73, 95], ["dataset.batch.repeat().prefetch", "dataset.batch.filter", "dataset.batch.map", "dataset.batch.shuffle", "dataset.batch.filter", "dataset.batch.apply", "dataset.batch.batch", "filter_fn", "tensorflow.contrib.data.batch_and_drop_remainder", "dataset.batch.repeat"], "function", ["None"], ["", "def", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "if", "filter", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter", ")", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "dataset", "=", "dataset", ".", "map", "(", "map_func", ",", "num_parallel_calls", "=", "num_threads", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "        ", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", ")", "\n", "\n", "", "if", "filter_fn", ":", "\n", "        ", "dataset", "=", "dataset", ".", "filter", "(", "filter_fn", "(", ")", ")", "\n", "\n", "", "if", "drop_remainder", ":", "\n", "        ", "dataset", "=", "dataset", ".", "apply", "(", "tf", ".", "contrib", ".", "data", ".", "batch_and_drop_remainder", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "repeat", "(", "repeat", ")", ".", "prefetch", "(", "prefetch_batch", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset": [[96, 129], ["data_noise.batch_dataset", "tensorflow.data.Dataset.from_tensor_slices", "isinstance", "tensorflow.read_file", "tensorflow.image.decode_png", "tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices", "map_func", "tuple", "data_noise.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset"], ["", "def", "disk_image_batch_dataset", "(", "img_paths", ",", "batch_size", ",", "labels", "=", "None", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "if", "labels", "is", "None", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "img_paths", ")", "\n", "", "elif", "isinstance", "(", "labels", ",", "tuple", ")", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", ")", "+", "tuple", "(", "labels", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", "labels", ")", ")", "\n", "\n", "", "def", "parse_func", "(", "path", ",", "*", "label", ")", ":", "\n", "        ", "img", "=", "tf", ".", "read_file", "(", "path", ")", "\n", "img", "=", "tf", ".", "image", ".", "decode_png", "(", "img", ",", "3", ")", "#png", "\n", "return", "(", "img", ",", ")", "+", "label", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "", "def", "disk_image_batch_dataset_MT", "(", "img_paths", ",", "img_segs_paths", ",", "batch_size", ",", "labels", "=", "None", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.disk_image_batch_dataset_MT": [[129, 164], ["data_noise.batch_dataset_MT", "tensorflow.data.Dataset.from_tensor_slices", "isinstance", "tensorflow.read_file", "tensorflow.image.decode_png", "tensorflow.read_file", "tensorflow.image.decode_png", "tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices", "map_func", "tuple", "data_noise.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset_MT"], ["", "def", "disk_image_batch_dataset_MT", "(", "img_paths", ",", "img_segs_paths", ",", "batch_size", ",", "labels", "=", "None", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "if", "labels", "is", "None", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "img_paths", ")", "\n", "", "elif", "isinstance", "(", "labels", ",", "tuple", ")", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", ")", "+", "tuple", "(", "labels", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "img_paths", ",", "img_segs_paths", ",", "labels", ")", ")", "\n", "\n", "", "def", "parse_func", "(", "path", ",", "path_segs", ",", "*", "label", ")", ":", "\n", "        ", "img", "=", "tf", ".", "read_file", "(", "path", ")", "\n", "img", "=", "tf", ".", "image", ".", "decode_png", "(", "img", ",", "3", ")", "#png", "\n", "img_sges", "=", "tf", ".", "read_file", "(", "path_segs", ")", "\n", "img_sges", "=", "tf", ".", "image", ".", "decode_png", "(", "img_sges", ",", "1", ")", "# png", "\n", "return", "(", "img", ",", ")", "+", "(", "img_sges", ",", ")", "+", "label", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset": [[165, 208], ["tensorflow.data.TFRecordDataset", "data_noise.batch_dataset", "tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.cast", "tensorflow.reshape", "tensorflow.image.random_flip_left_right", "map_func", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "data_noise.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset"], ["", "def", "tfrecord_batch_dataset", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "reshape_size", "=", "170", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "tfrecord_path", ")", "\n", "\n", "# def parse_func(path, *label):", "\n", "#     img = tf.read_file(path)", "\n", "#     img = tf.image.decode_png(img, 3)", "\n", "#     return (img,) + label", "\n", "\n", "def", "parse_func", "(", "serialized_example", ")", ":", "\n", "        ", "random_flip", "=", "True", "\n", "features", "=", "tf", ".", "parse_single_example", "(", "serialized_example", ",", "features", "=", "{", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "label_len", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'noise'", ":", "tf", ".", "FixedLenFeature", "(", "[", "64", "]", ",", "tf", ".", "float32", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'img_name'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", "}", ")", "\n", "label", "=", "tf", ".", "cast", "(", "features", "[", "'label'", "]", ",", "tf", ".", "int32", ")", "\n", "img", "=", "tf", ".", "decode_raw", "(", "features", "[", "'img_raw'", "]", ",", "tf", ".", "uint8", ")", "\n", "noise", "=", "tf", ".", "cast", "(", "features", "[", "'noise'", "]", ",", "tf", ".", "float32", ")", "\n", "#img_name = tf.decode_raw(features['img_name'], tf.uint8)", "\n", "img", "=", "tf", ".", "reshape", "(", "img", ",", "[", "reshape_size", ",", "reshape_size", ",", "3", "]", ")", "\n", "if", "random_flip", ":", "\n", "            ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "", "return", "img", ",", "label", ",", "noise", "#, img_name", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "", "def", "tfrecord_batch_dataset_MT", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.tfrecord_batch_dataset_MT": [[208, 253], ["tensorflow.data.TFRecordDataset", "data_noise.batch_dataset_MT", "tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_flip_left_right", "map_func", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "data_noise.disk_image_batch_dataset.parse_func"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.data_noise.batch_dataset_MT"], ["", "def", "tfrecord_batch_dataset_MT", "(", "tfrecord_path", ",", "batch_size", ",", "label_len", ",", "prefetch_batch", "=", "2", ",", "drop_remainder", "=", "True", ",", "filter", "=", "None", ",", "\n", "map_func", "=", "None", ",", "num_threads", "=", "16", ",", "shuffle", "=", "True", ",", "buffer_size", "=", "4096", ",", "repeat", "=", "-", "1", ",", "reshape_size", "=", "170", ",", "filter_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Disk image batch dataset.\n\n    This function is suitable for jpg and png files\n\n    img_paths: string list or 1-D tensor, each of which is an iamge path\n    labels: label list/tuple_of_list or tensor/tuple_of_tensor, each of which is a corresponding label\n    \"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "tfrecord_path", ")", "\n", "\n", "# def parse_func(path, *label):", "\n", "#     img = tf.read_file(path)", "\n", "#     img = tf.image.decode_png(img, 3)", "\n", "#     return (img,) + label", "\n", "\n", "def", "parse_func", "(", "serialized_example", ")", ":", "\n", "        ", "random_flip", "=", "False", "\n", "features", "=", "tf", ".", "parse_single_example", "(", "serialized_example", ",", "features", "=", "{", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "label_len", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'img_raw'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'img_name'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'img_segs'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", "}", ")", "\n", "label", "=", "tf", ".", "cast", "(", "features", "[", "'label'", "]", ",", "tf", ".", "int32", ")", "\n", "img", "=", "tf", ".", "decode_raw", "(", "features", "[", "'img_raw'", "]", ",", "tf", ".", "uint8", ")", "\n", "segs", "=", "tf", ".", "decode_raw", "(", "features", "[", "'img_segs'", "]", ",", "tf", ".", "uint8", ")", "\n", "#img_name = tf.decode_raw(features['img_name'], tf.uint8)", "\n", "img", "=", "tf", ".", "reshape", "(", "img", ",", "[", "reshape_size", ",", "reshape_size", ",", "3", "]", ")", "\n", "segs", "=", "tf", ".", "reshape", "(", "segs", ",", "[", "321", ",", "321", ",", "1", "]", ")", "\n", "if", "random_flip", ":", "\n", "            ", "img", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", "\n", "segs", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "segs", ")", "\n", "", "return", "img", ",", "segs", ",", "label", "#, img_name", "\n", "\n", "", "if", "map_func", ":", "\n", "        ", "def", "map_func_", "(", "*", "args", ")", ":", "\n", "            ", "return", "map_func", "(", "*", "parse_func", "(", "*", "args", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "map_func_", "=", "parse_func", "\n", "\n", "# dataset = dataset.map(parse_func, num_parallel_calls=num_threads) is slower", "\n", "\n", "", "dataset", "=", "batch_dataset_MT", "(", "dataset", ",", "batch_size", ",", "prefetch_batch", ",", "drop_remainder", ",", "filter", ",", "\n", "map_func_", ",", "num_threads", ",", "shuffle", ",", "buffer_size", ",", "repeat", ",", "filter_fn", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.train_arch9.matching_loss": [[20, 22], ["tensorflow.reduce_mean", "tensorflow.nn.relu", "models_712.inner_product", "models_712.inner_product"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.inner_product", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.inner_product"], ["def", "matching_loss", "(", "x1", ",", "x2", ",", "y1", ",", "y2", ",", "margin", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "relu", "(", "models", ".", "inner_product", "(", "x1", ",", "x2", ")", "-", "models", ".", "inner_product", "(", "y1", ",", "y2", ")", "+", "margin", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.inner_product": [[24, 26], ["tensorflow.reduce_sum"], "function", ["None"], ["def", "inner_product", "(", "x", ",", "y", ",", "axis", "=", "-", "1", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_sum", "(", "x", "*", "y", ",", "axis", "=", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712._concat": [[27, 39], ["tensorflow.concat", "feats.append", "feats.append", "len", "tensorflow.reshape", "tensorflow.tile", "tensorflow.image.resize_nearest_neighbor", "tflib.shape", "tflib.shape", "tflib.shape", "tflib.shape", "tflib.shape", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "def", "_concat", "(", "z", ",", "z_", ",", "_a", ")", ":", "\n", "    ", "feats", "=", "[", "z", "]", "\n", "if", "z_", "is", "not", "None", ":", "\n", "        ", "feats", ".", "append", "(", "z_", ")", "\n", "", "if", "_a", "is", "not", "None", ":", "\n", "        ", "if", "len", "(", "tl", ".", "shape", "(", "_a", ")", ")", "==", "2", ":", "\n", "            ", "_a", "=", "tf", ".", "reshape", "(", "_a", ",", "[", "-", "1", ",", "1", ",", "1", ",", "tl", ".", "shape", "(", "_a", ")", "[", "-", "1", "]", "]", ")", "\n", "_a", "=", "tf", ".", "tile", "(", "_a", ",", "[", "1", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "tl", ".", "shape", "(", "z", ")", "[", "2", "]", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "_a", "=", "tf", ".", "image", ".", "resize_nearest_neighbor", "(", "_a", ",", "[", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "tl", ".", "shape", "(", "z", ")", "[", "2", "]", "]", ")", "\n", "", "feats", ".", "append", "(", "_a", ")", "\n", "", "return", "tf", ".", "concat", "(", "feats", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.gradient_penalty": [[40, 62], ["tensorflow.name_scope", "models_712.gradient_penalty._interpolate"], "function", ["None"], ["", "def", "gradient_penalty", "(", "f", ",", "real", ",", "fake", "=", "None", ")", ":", "\n", "    ", "def", "_interpolate", "(", "a", ",", "b", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'interpolate'", ")", ":", "\n", "            ", "if", "b", "is", "None", ":", "# interpolation in DRAGAN", "\n", "                ", "beta", "=", "tf", ".", "random_uniform", "(", "shape", "=", "tf", ".", "shape", "(", "a", ")", ",", "minval", "=", "0.", ",", "maxval", "=", "1.", ")", "\n", "_", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "a", ",", "range", "(", "a", ".", "shape", ".", "ndims", ")", ")", "\n", "b", "=", "a", "+", "0.5", "*", "tf", ".", "sqrt", "(", "variance", ")", "*", "beta", "\n", "", "shape", "=", "[", "tf", ".", "shape", "(", "a", ")", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "a", ".", "shape", ".", "ndims", "-", "1", ")", "\n", "alpha", "=", "tf", ".", "random_uniform", "(", "shape", "=", "shape", ",", "minval", "=", "0.", ",", "maxval", "=", "1.", ")", "\n", "inter", "=", "a", "+", "alpha", "*", "(", "b", "-", "a", ")", "\n", "inter", ".", "set_shape", "(", "a", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "return", "inter", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "'gradient_penalty'", ")", ":", "\n", "        ", "x", "=", "_interpolate", "(", "real", ",", "fake", ")", "\n", "pred", "=", "f", "(", "x", ")", "\n", "if", "isinstance", "(", "pred", ",", "tuple", ")", ":", "\n", "            ", "pred", "=", "pred", "[", "0", "]", "\n", "", "grad", "=", "tf", ".", "gradients", "(", "pred", ",", "x", ")", "[", "0", "]", "\n", "norm", "=", "tf", ".", "norm", "(", "slim", ".", "flatten", "(", "grad", ")", ",", "axis", "=", "1", ")", "\n", "gp", "=", "tf", ".", "reduce_mean", "(", "(", "norm", "-", "1.", ")", "**", "2", ")", "\n", "return", "gp", "\n", "", "", "def", "gradient_penalty_L", "(", "f", ",", "real", ",", "fake", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.gradient_penalty_L": [[62, 84], ["tensorflow.name_scope", "models_712.gradient_penalty._interpolate"], "function", ["None"], ["", "", "def", "gradient_penalty_L", "(", "f", ",", "real", ",", "fake", "=", "None", ")", ":", "\n", "    ", "def", "_interpolate", "(", "a", ",", "b", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'interpolate'", ")", ":", "\n", "            ", "if", "b", "is", "None", ":", "# interpolation in DRAGAN", "\n", "                ", "beta", "=", "tf", ".", "random_uniform", "(", "shape", "=", "tf", ".", "shape", "(", "a", ")", ",", "minval", "=", "0.", ",", "maxval", "=", "1.", ")", "\n", "_", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "a", ",", "range", "(", "a", ".", "shape", ".", "ndims", ")", ")", "\n", "b", "=", "a", "+", "0.5", "*", "tf", ".", "sqrt", "(", "variance", ")", "*", "beta", "\n", "", "shape", "=", "[", "tf", ".", "shape", "(", "a", ")", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "a", ".", "shape", ".", "ndims", "-", "1", ")", "\n", "alpha", "=", "tf", ".", "random_uniform", "(", "shape", "=", "shape", ",", "minval", "=", "0.", ",", "maxval", "=", "1.", ")", "\n", "inter", "=", "a", "+", "alpha", "*", "(", "b", "-", "a", ")", "\n", "inter", ".", "set_shape", "(", "a", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "return", "inter", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "'gradient_penalty_L'", ")", ":", "\n", "        ", "x", "=", "_interpolate", "(", "real", ",", "fake", ")", "\n", "pred", "=", "f", "(", "x", ")", "\n", "if", "isinstance", "(", "pred", ",", "tuple", ")", ":", "\n", "            ", "pred", "=", "pred", "[", "0", "]", "\n", "", "grad", "=", "tf", ".", "gradients", "(", "pred", ",", "x", ")", "[", "0", "]", "\n", "norm", "=", "tf", ".", "norm", "(", "slim", ".", "flatten", "(", "grad", ")", ",", "axis", "=", "1", ")", "\n", "gp", "=", "tf", ".", "reduce_mean", "(", "(", "norm", "-", "1.", ")", "**", "2", ")", "\n", "return", "gp", "\n", "", "", "def", "gradient_penalty_Xreal", "(", "f", ",", "real", ",", "labels", ",", "fake", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.gradient_penalty_Xreal": [[84, 106], ["tensorflow.name_scope", "models_712.gradient_penalty._interpolate"], "function", ["None"], ["", "", "def", "gradient_penalty_Xreal", "(", "f", ",", "real", ",", "labels", ",", "fake", "=", "None", ")", ":", "\n", "    ", "def", "_interpolate", "(", "a", ",", "b", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'interpolate'", ")", ":", "\n", "            ", "if", "b", "is", "None", ":", "# interpolation in DRAGAN", "\n", "                ", "beta", "=", "tf", ".", "random_uniform", "(", "shape", "=", "tf", ".", "shape", "(", "a", ")", ",", "minval", "=", "0.", ",", "maxval", "=", "1.", ")", "\n", "_", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "a", ",", "list", "(", "range", "(", "a", ".", "shape", ".", "ndims", ")", ")", ")", "\n", "b", "=", "a", "+", "0.5", "*", "tf", ".", "sqrt", "(", "variance", ")", "*", "beta", "\n", "", "shape", "=", "[", "tf", ".", "shape", "(", "a", ")", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "a", ".", "shape", ".", "ndims", "-", "1", ")", "\n", "alpha", "=", "tf", ".", "random_uniform", "(", "shape", "=", "shape", ",", "minval", "=", "0.", ",", "maxval", "=", "1.", ")", "\n", "inter", "=", "a", "+", "alpha", "*", "(", "b", "-", "a", ")", "\n", "inter", ".", "set_shape", "(", "a", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "return", "inter", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "'gradient_penalty'", ")", ":", "\n", "        ", "x", "=", "_interpolate", "(", "real", ",", "fake", ")", "\n", "pred", "=", "f", "(", "x", ",", "l", "=", "labels", ")", "\n", "if", "isinstance", "(", "pred", ",", "tuple", ")", ":", "\n", "            ", "pred", "=", "pred", "[", "0", "]", "\n", "", "grad", "=", "tf", ".", "gradients", "(", "pred", ",", "x", ")", "[", "0", "]", "\n", "norm", "=", "tf", ".", "norm", "(", "slim", ".", "flatten", "(", "grad", ")", ",", "axis", "=", "1", ")", "\n", "gp", "=", "tf", ".", "reduce_mean", "(", "(", "norm", "-", "1.", ")", "**", "2", ")", "\n", "return", "gp", "\n", "", "", "def", "average_gradients", "(", "tower_grads", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.average_gradients": [[106, 121], ["zip", "tensorflow.concat", "tensorflow.reduce_mean", "average_grads.append", "tensorflow.expand_dims", "grads.append"], "function", ["None"], ["", "", "def", "average_gradients", "(", "tower_grads", ")", ":", "\n", "    ", "average_grads", "=", "[", "]", "\n", "for", "grad_and_vars", "in", "zip", "(", "*", "tower_grads", ")", ":", "\n", "        ", "if", "grad_and_vars", "[", "0", "]", "[", "0", "]", "is", "None", ":", "\n", "            ", "continue", "\n", "", "grads", "=", "[", "]", "\n", "for", "g", ",", "_", "in", "grad_and_vars", ":", "\n", "            ", "expend_g", "=", "tf", ".", "expand_dims", "(", "g", ",", "0", ")", "\n", "grads", ".", "append", "(", "expend_g", ")", "\n", "", "grad", "=", "tf", ".", "concat", "(", "grads", ",", "0", ")", "\n", "grad", "=", "tf", ".", "reduce_mean", "(", "grad", ",", "0", ")", "\n", "v", "=", "grad_and_vars", "[", "0", "]", "[", "1", "]", "\n", "grad_and_var", "=", "(", "grad", ",", "v", ")", "\n", "average_grads", ".", "append", "(", "grad_and_var", ")", "\n", "", "return", "average_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Genc": [[128, 148], ["functools.partial", "functools.partial", "tensorflow.variable_scope", "range", "min", "functools.partial.", "zs.append", "tensorflow.concat", "tensorflow.image.resize_bicubic"], "function", ["None"], ["", "def", "Genc", "(", "x", ",", "dim", "=", "64", ",", "n_layers", "=", "5", ",", "multi_inputs", "=", "1", ",", "is_training", "=", "True", ",", "norm", "=", "'in'", ")", ":", "\n", "    ", "if", "norm", "==", "'bn'", ":", "\n", "        ", "norm_fn", "=", "partial", "(", "batch_norm", ",", "is_training", "=", "is_training", ")", "\n", "", "elif", "norm", "==", "'in'", ":", "\n", "        ", "norm_fn", "=", "instance_norm", "\n", "", "else", ":", "\n", "        ", "norm_fn", "=", "None", "\n", "", "conv_norm_lrelu", "=", "partial", "(", "conv", ",", "normalizer_fn", "=", "norm_fn", ",", "activation_fn", "=", "lrelu", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Genc_c'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "h", ",", "w", "=", "x", ".", "shape", "[", "1", ":", "3", "]", "\n", "z", "=", "x", "\n", "zs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "d", "=", "min", "(", "dim", "*", "2", "**", "i", ",", "MAX_DIM", ")", "\n", "if", "multi_inputs", ">", "i", "and", "i", ">", "0", ":", "\n", "                ", "z", "=", "tf", ".", "concat", "(", "[", "z", ",", "tf", ".", "image", ".", "resize_bicubic", "(", "x", ",", "(", "h", "//", "(", "2", "**", "i", ")", ",", "w", "//", "(", "2", "**", "i", ")", ")", ")", "]", ",", "3", ")", "\n", "", "z", "=", "conv_norm_lrelu", "(", "z", ",", "d", ",", "4", ",", "2", ")", "\n", "zs", ".", "append", "(", "z", ")", "\n", "", "return", "zs", "[", ":", "-", "1", "]", ",", "zs", "[", "-", "1", "]", "\n", "", "", "def", "Gdec", "(", "zs", ",", "_a", ",", "res", ",", "zc", ",", "zdec_src", "=", "None", ",", "zdec_tag", "=", "None", ",", "dim", "=", "64", ",", "n_layers", "=", "5", ",", "inject_layers", "=", "0", ",", "is_training", "=", "True", ",", "one_more_conv", "=", "0", ",", "norm", "=", "'in'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Gdec": [[148, 182], ["functools.partial", "min", "functools.partial", "tensorflow.variable_scope", "models_712.FM", "models_712._concat", "range", "min", "functools.partial.", "zdec.append", "models_712._concat", "functools.partial.", "tensorflow.nn.tanh", "tensorflow.nn.tanh", "models_712.FM", "models_712.FM", "dconv", "dconv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.FM", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712._concat", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712._concat", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.FM", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.FM"], ["", "", "def", "Gdec", "(", "zs", ",", "_a", ",", "res", ",", "zc", ",", "zdec_src", "=", "None", ",", "zdec_tag", "=", "None", ",", "dim", "=", "64", ",", "n_layers", "=", "5", ",", "inject_layers", "=", "0", ",", "is_training", "=", "True", ",", "one_more_conv", "=", "0", ",", "norm", "=", "'in'", ")", ":", "\n", "    ", "if", "norm", "==", "'bn'", ":", "\n", "        ", "norm_fn", "=", "partial", "(", "batch_norm", ",", "is_training", "=", "is_training", ")", "\n", "", "elif", "norm", "==", "'in'", ":", "\n", "        ", "norm_fn", "=", "instance_norm", "\n", "", "else", ":", "\n", "        ", "norm_fn", "=", "None", "\n", "", "dconv_norm_relu", "=", "partial", "(", "dconv", ",", "normalizer_fn", "=", "norm_fn", ",", "activation_fn", "=", "relu", ")", "\n", "\n", "inject_layers", "=", "min", "(", "inject_layers", ",", "n_layers", "-", "1", ")", "\n", "\n", "zdec", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'Gdec'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "FM", "(", "zc", ",", "zs", ",", "zc", ",", "zs", ",", "_a", ")", "\n", "z", "=", "_concat", "(", "z", ",", "None", ",", "_a", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "if", "i", "<", "n_layers", "-", "1", ":", "\n", "                ", "d", "=", "min", "(", "dim", "*", "2", "**", "(", "n_layers", "-", "2", "-", "i", ")", ",", "MAX_DIM", ")", "\n", "z", "=", "dconv_norm_relu", "(", "z", ",", "d", ",", "4", ",", "2", ")", "\n", "zdec", ".", "append", "(", "z", ")", "\n", "if", "i", "<", "2", ":", "\n", "                    ", "if", "not", "zdec_src", "and", "not", "zdec_tag", ":", "\n", "                        ", "z", "=", "FM", "(", "res", "[", "n_layers", "-", "2", "-", "i", "]", ",", "z", ",", "z", ",", "z", ",", "_a", ")", "\n", "", "else", ":", "\n", "                        ", "z", "=", "FM", "(", "res", "[", "n_layers", "-", "2", "-", "i", "]", ",", "z", ",", "zdec_src", "[", "i", "]", ",", "zdec_tag", "[", "i", "]", ",", "_a", ")", "\n", "", "", "if", "inject_layers", ">", "i", ":", "\n", "                    ", "z", "=", "_concat", "(", "z", ",", "None", ",", "_a", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "one_more_conv", ":", "# add one more conv after the decoder", "\n", "                    ", "z", "=", "dconv_norm_relu", "(", "z", ",", "dim", "//", "4", ",", "4", ",", "2", ")", "\n", "x", "=", "tf", ".", "nn", ".", "tanh", "(", "dconv", "(", "z", ",", "3", ",", "one_more_conv", ")", ")", "\n", "", "else", ":", "\n", "                    ", "x", "=", "tf", ".", "nn", ".", "tanh", "(", "dconv", "(", "z", ",", "3", ",", "4", ",", "2", ")", ")", "\n", "", "", "", "return", "x", ",", "zdec", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.FM": [[183, 238], ["functools.partial", "functools.partial.", "conv", "tensorflow.layers.average_pooling2d", "tensorflow.layers.flatten", "fc", "functools.partial.", "conv", "models_712.FM.SNLM"], "function", ["None"], ["", "", "def", "FM", "(", "encf", ",", "decf", ",", "decf_src", ",", "decf_tag", ",", "attdiff", ",", "norm", "=", "'in'", ")", ":", "\n", "    ", "def", "SNLM", "(", "decf_src", ",", "decf_tag", ",", "spatialm", ")", ":", "\n", "        ", "z_src", "=", "conv", "(", "decf_src", ",", "1", ",", "4", ",", "1", ")", "\n", "z_src", "=", "tf", ".", "reshape", "(", "z_src", ",", "(", "tl", ".", "shape", "(", "z_src", ")", "[", "0", "]", ",", "tl", ".", "shape", "(", "z_src", ")", "[", "1", "]", "*", "tl", ".", "shape", "(", "z_src", ")", "[", "2", "]", ",", "tl", ".", "shape", "(", "z_src", ")", "[", "3", "]", ")", ")", "\n", "z_tag", "=", "conv", "(", "decf_tag", ",", "1", ",", "4", ",", "1", ")", "\n", "z_tag", "=", "tf", ".", "reshape", "(", "z_tag", ",", "(", "tl", ".", "shape", "(", "z_tag", ")", "[", "0", "]", ",", "tl", ".", "shape", "(", "z_tag", ")", "[", "1", "]", "*", "tl", ".", "shape", "(", "z_tag", ")", "[", "2", "]", ",", "tl", ".", "shape", "(", "z_tag", ")", "[", "3", "]", ")", ")", "\n", "z_tag", "=", "tf", ".", "transpose", "(", "z_tag", ",", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "covar", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "z_src", ",", "z_tag", ")", ")", "\n", "spatialm", "=", "tf", ".", "expand_dims", "(", "tf", ".", "layers", ".", "flatten", "(", "spatialm", ")", ",", "axis", "=", "-", "1", ")", "\n", "spatialm", "=", "tf", ".", "matmul", "(", "covar", ",", "spatialm", ")", "\n", "spatialm", "=", "tf", ".", "reshape", "(", "spatialm", ",", "(", "tl", ".", "shape", "(", "decf_src", ")", "[", "0", "]", ",", "tl", ".", "shape", "(", "decf_src", ")", "[", "1", "]", ",", "tl", ".", "shape", "(", "decf_src", ")", "[", "2", "]", ",", "1", ")", ")", "\n", "return", "spatialm", "\n", "\n", "", "def", "CNLM", "(", "decf_src", ",", "decf_tag", ",", "channelm", ")", ":", "\n", "        ", "z_src", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "decf_src", ",", "tl", ".", "shape", "(", "decf_src", ")", "[", "1", "]", ",", "1", ")", "\n", "z_src", "=", "tf", ".", "layers", ".", "flatten", "(", "z_src", ")", "\n", "z_src", "=", "fc", "(", "z_src", ",", "tl", ".", "shape", "(", "z_src", ")", "[", "-", "1", "]", ")", "\n", "z_src", "=", "tf", ".", "expand_dims", "(", "z_src", ",", "axis", "=", "-", "1", ")", "\n", "\n", "z_tag", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "decf_tag", ",", "tl", ".", "shape", "(", "decf_tag", ")", "[", "1", "]", ",", "1", ")", "\n", "z_tag", "=", "tf", ".", "layers", ".", "flatten", "(", "z_tag", ")", "\n", "z_tag", "=", "fc", "(", "z_tag", ",", "tl", ".", "shape", "(", "z_tag", ")", "[", "-", "1", "]", ")", "\n", "z_tag", "=", "tf", ".", "expand_dims", "(", "z_tag", ",", "1", ")", "\n", "\n", "covar", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "z_src", ",", "z_tag", ")", ")", "\n", "channelm", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "covar", ",", "tf", ".", "expand_dims", "(", "channelm", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "return", "channelm", "\n", "\n", "", "if", "norm", "==", "'in'", ":", "\n", "        ", "norm_fn", "=", "instance_norm", "\n", "", "else", ":", "\n", "        ", "norm_fn", "=", "None", "\n", "", "conv_norm_lrelu", "=", "partial", "(", "conv", ",", "normalizer_fn", "=", "norm_fn", ",", "activation_fn", "=", "lrelu", ")", "\n", "encz", "=", "conv_norm_lrelu", "(", "_concat", "(", "encf", ",", "None", ",", "attdiff", ")", ",", "tl", ".", "shape", "(", "encf", ")", "[", "-", "1", "]", ",", "4", ",", "1", ")", "\n", "enc_spatialm", "=", "conv", "(", "encz", ",", "1", ",", "4", ",", "1", ")", "\n", "enc_channelm", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "encz", ",", "tl", ".", "shape", "(", "encz", ")", "[", "1", "]", ",", "1", ")", "\n", "enc_channelm", "=", "tf", ".", "layers", ".", "flatten", "(", "enc_channelm", ")", "\n", "enc_channelm", "=", "fc", "(", "enc_channelm", ",", "tl", ".", "shape", "(", "enc_channelm", ")", "[", "-", "1", "]", ")", "\n", "\n", "decz", "=", "conv_norm_lrelu", "(", "_concat", "(", "decf", ",", "None", ",", "attdiff", ")", ",", "tl", ".", "shape", "(", "decf", ")", "[", "-", "1", "]", ",", "4", ",", "1", ")", "\n", "dec_spatialm", "=", "conv", "(", "decz", ",", "1", ",", "4", ",", "1", ")", "\n", "dec_spatialm", "=", "SNLM", "(", "decf_src", ",", "decf_tag", ",", "dec_spatialm", ")", "\n", "\n", "dec_channelm", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "decz", ",", "tl", ".", "shape", "(", "decz", ")", "[", "1", "]", ",", "1", ")", "\n", "dec_channelm", "=", "tf", ".", "layers", ".", "flatten", "(", "dec_channelm", ")", "\n", "dec_channelm", "=", "fc", "(", "dec_channelm", ",", "tl", ".", "shape", "(", "dec_channelm", ")", "[", "-", "1", "]", ")", "\n", "dec_channelm", "=", "CNLM", "(", "decf_src", ",", "decf_tag", ",", "dec_channelm", ")", "\n", "\n", "spatialm", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "concat", "(", "[", "enc_spatialm", ",", "dec_spatialm", "]", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", "\n", "fus_spatial", "=", "tf", ".", "expand_dims", "(", "spatialm", "[", ":", ",", ":", ",", ":", ",", "0", "]", ",", "axis", "=", "-", "1", ")", "*", "encf", "+", "tf", ".", "expand_dims", "(", "spatialm", "[", ":", ",", ":", ",", ":", ",", "1", "]", ",", "axis", "=", "-", "1", ")", "*", "decf", "\n", "channelm", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "stack", "(", "[", "enc_channelm", ",", "dec_channelm", "]", ",", "axis", "=", "2", ")", ",", "axis", "=", "-", "1", ")", "\n", "fus_channel", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "channelm", "[", ":", ",", ":", ",", "0", "]", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "*", "encf", "+", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "channelm", "[", ":", ",", ":", ",", "1", "]", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "*", "decf", "\n", "fus", "=", "conv", "(", "tf", ".", "concat", "(", "[", "fus_spatial", ",", "fus_channel", "]", ",", "axis", "=", "-", "1", ")", ",", "tl", ".", "shape", "(", "encf", ")", "[", "-", "1", "]", ",", "1", ",", "1", ")", "\n", "return", "fus", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.D": [[240, 256], ["functools.partial", "tensorflow.variable_scope", "range", "lrelu", "fc", "lrelu", "fc", "min", "functools.partial.", "fc", "fc"], "function", ["None"], ["", "def", "D", "(", "x", ",", "n_att", ",", "dim", "=", "64", ",", "fc_dim", "=", "MAX_DIM", ",", "n_layers", "=", "5", ")", ":", "\n", "    ", "conv_in_lrelu", "=", "partial", "(", "conv", ",", "normalizer_fn", "=", "instance_norm", ",", "activation_fn", "=", "lrelu", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'D'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "y", "=", "x", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "d", "=", "min", "(", "dim", "*", "2", "**", "i", ",", "MAX_DIM", ")", "\n", "y", "=", "conv_in_lrelu", "(", "y", ",", "d", ",", "4", ",", "2", ")", "\n", "\n", "", "logit_gan", "=", "lrelu", "(", "fc", "(", "y", ",", "fc_dim", ")", ")", "\n", "logit_gan", "=", "fc", "(", "logit_gan", ",", "1", ")", "\n", "\n", "logit_att", "=", "lrelu", "(", "fc", "(", "y", ",", "fc_dim", ")", ")", "\n", "logit_att", "=", "fc", "(", "logit_att", ",", "n_att", ")", "\n", "\n", "return", "logit_gan", ",", "logit_att", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.conv_adain": [[326, 335], ["conv", "models_712.conv_adain.adaptive_instance_norm"], "function", ["None"], ["", "", "def", "conv_adain", "(", "x", ",", "out_c", ",", "kernel_size", ",", "stride", ",", "s", ")", ":", "\n", "    ", "def", "adaptive_instance_norm", "(", "var", ",", "dlatent", ")", ":", "\n", "        ", "var", "=", "instance_norm", "(", "var", ",", "center", "=", "False", ",", "scale", "=", "False", ")", "\n", "style", "=", "fc", "(", "dlatent", ",", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "*", "2", ")", "\n", "style", "=", "tf", ".", "reshape", "(", "style", ",", "[", "-", "1", ",", "2", "]", "+", "[", "1", "]", "*", "(", "len", "(", "tl", ".", "shape", "(", "var", ")", ")", "-", "2", ")", "+", "[", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "]", ")", "\n", "return", "var", "*", "(", "style", "[", ":", ",", "0", "]", "+", "1", ")", "+", "style", "[", ":", ",", "1", "]", "\n", "", "x", "=", "conv", "(", "x", ",", "out_c", ",", "kernel_size", ",", "stride", ")", "\n", "x", "=", "adaptive_instance_norm", "(", "x", ",", "s", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.dconv_adain": [[336, 345], ["dconv", "models_712.conv_adain.adaptive_instance_norm"], "function", ["None"], ["", "def", "dconv_adain", "(", "x", ",", "out_c", ",", "kernel_size", ",", "stride", ",", "s", ")", ":", "\n", "    ", "def", "adaptive_instance_norm", "(", "var", ",", "dlatent", ")", ":", "\n", "        ", "var", "=", "instance_norm", "(", "var", ",", "center", "=", "False", ",", "scale", "=", "False", ")", "\n", "style", "=", "fc", "(", "dlatent", ",", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "*", "2", ")", "\n", "style", "=", "tf", ".", "reshape", "(", "style", ",", "[", "-", "1", ",", "2", "]", "+", "[", "1", "]", "*", "(", "len", "(", "tl", ".", "shape", "(", "var", ")", ")", "-", "2", ")", "+", "[", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "]", ")", "\n", "return", "var", "*", "(", "style", "[", ":", ",", "0", "]", "+", "1", ")", "+", "style", "[", ":", ",", "1", "]", "\n", "", "x", "=", "dconv", "(", "x", ",", "out_c", ",", "kernel_size", ",", "stride", ")", "\n", "x", "=", "adaptive_instance_norm", "(", "x", ",", "s", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk": [[346, 416], ["activation", "conv", "conv", "tensorflow.image.resize_images", "tensorflow.layers.average_pooling2d", "functools.partial", "tflib.shape", "functools.partial.", "models_712.ResBlk._upsample"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "def", "ResBlk", "(", "x_init", ",", "out_c", ",", "upsampling", "=", "False", ",", "downsampling", "=", "False", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "alpha", "=", "None", ",", "norm_name", "=", "None", ")", ":", "\n", "    ", "def", "_upsample", "(", "var", ")", ":", "\n", "        ", "height", ",", "width", "=", "tl", ".", "shape", "(", "var", ")", "[", "1", ":", "3", "]", "\n", "return", "tf", ".", "image", ".", "resize_images", "(", "var", ",", "(", "height", "*", "2", ",", "width", "*", "2", ")", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "\n", "", "def", "_downsample", "(", "var", ")", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "average_pooling2d", "(", "var", ",", "(", "2", ",", "2", ")", ",", "(", "2", ",", "2", ")", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "", "def", "adaptive_instance_norm", "(", "var", ",", "name", ",", "dlatent", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "var", "=", "instance_norm", "(", "var", ",", "center", "=", "False", ",", "scale", "=", "False", ")", "\n", "style", "=", "fc", "(", "dlatent", ",", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "*", "2", ")", "\n", "style", "=", "tf", ".", "reshape", "(", "style", ",", "[", "-", "1", ",", "2", "]", "+", "[", "1", "]", "*", "(", "len", "(", "tl", ".", "shape", "(", "var", ")", ")", "-", "2", ")", "+", "[", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "]", ")", "\n", "return", "var", "*", "(", "style", "[", ":", ",", "0", "]", "+", "1", ")", "+", "style", "[", ":", ",", "1", "]", "\n", "\n", "", "", "def", "spatially_adaptive_norm", "(", "var", ",", "name", ",", "dlatent", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "var", "=", "instance_norm", "(", "var", ",", "center", "=", "False", ",", "scale", "=", "False", ")", "\n", "height", ",", "width", ",", "channels", "=", "tl", ".", "shape", "(", "var", ")", "[", "1", ":", "]", "\n", "style", "=", "tf", ".", "image", ".", "resize_images", "(", "dlatent", ",", "(", "height", ",", "width", ")", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "style", "=", "relu", "(", "conv", "(", "style", ",", "128", ",", "3", ",", "1", ")", ")", "\n", "gamma", "=", "conv", "(", "style", ",", "channels", ",", "3", ",", "1", ")", "\n", "beta", "=", "conv", "(", "style", ",", "channels", ",", "3", ",", "1", ")", "\n", "return", "var", "*", "(", "1", "+", "gamma", ")", "+", "beta", "\n", "\n", "", "", "if", "norm", "==", "'adain'", "and", "s_rand", "is", "not", "None", ":", "\n", "        ", "norm_fn", "=", "partial", "(", "adaptive_instance_norm", ",", "dlatent", "=", "s_rand", ")", "\n", "", "elif", "norm", "==", "'in'", ":", "\n", "        ", "norm_fn", "=", "instance_norm", "\n", "", "elif", "norm", "==", "'spade'", "and", "s_targ", "is", "not", "None", ":", "\n", "        ", "norm_fn", "=", "partial", "(", "spatially_adaptive_norm", ",", "dlatent", "=", "s_targ", ")", "\n", "", "else", ":", "\n", "        ", "norm_fn", "=", "None", "\n", "", "in_c", "=", "tl", ".", "shape", "(", "x_init", ")", "[", "-", "1", "]", "\n", "is_shortcut_learn", "=", "(", "in_c", "!=", "out_c", ")", "or", "upsampling", "or", "downsampling", "\n", "if", "norm", "==", "'in'", ":", "\n", "        ", "x", "=", "norm_fn", "(", "x_init", ")", "\n", "", "elif", "norm", "==", "'adain'", "or", "norm", "==", "'spade'", ":", "\n", "        ", "x", "=", "norm_fn", "(", "x_init", ",", "norm_name", "+", "'_1'", ")", "\n", "", "elif", "norm", "==", "'interp'", ":", "\n", "        ", "x", "=", "alpha", "*", "spatially_adaptive_norm", "(", "x_init", ",", "norm_name", "[", "0", "]", "+", "'_1'", ",", "dlatent", "=", "s_rand", ")", "+", "(", "1", "-", "alpha", ")", "*", "spatially_adaptive_norm", "(", "x_init", ",", "norm_name", "[", "1", "]", "+", "'_1'", ",", "dlatent", "=", "s_targ", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x_init", "\n", "", "x", "=", "activation", "(", "x", ")", "\n", "if", "upsampling", ":", "\n", "        ", "x", "=", "_upsample", "(", "x", ")", "\n", "", "x", "=", "conv", "(", "x", ",", "out_c", ",", "3", ",", "1", ")", "\n", "if", "norm", "==", "'in'", ":", "\n", "        ", "x", "=", "norm_fn", "(", "x", ")", "\n", "", "elif", "norm", "==", "'adain'", "or", "norm", "==", "'spade'", ":", "\n", "        ", "x", "=", "norm_fn", "(", "x", ",", "norm_name", "+", "'_2'", ")", "\n", "", "elif", "norm", "==", "'interp'", ":", "\n", "        ", "x", "=", "alpha", "*", "spatially_adaptive_norm", "(", "x", ",", "norm_name", "[", "0", "]", "+", "'_2'", ",", "dlatent", "=", "s_rand", ")", "+", "(", "1", "-", "alpha", ")", "*", "spatially_adaptive_norm", "(", "x", ",", "norm_name", "[", "1", "]", "+", "'_2'", ",", "dlatent", "=", "s_targ", ")", "\n", "\n", "", "x", "=", "conv", "(", "activation", "(", "x", ")", ",", "out_c", ",", "3", ",", "1", ")", "\n", "if", "downsampling", ":", "\n", "        ", "x", "=", "_downsample", "(", "x", ")", "\n", "", "if", "is_shortcut_learn", ":", "\n", "        ", "if", "upsampling", ":", "\n", "            ", "x_shortcut", "=", "conv", "(", "_upsample", "(", "x_init", ")", ",", "out_c", ",", "1", ",", "1", ")", "\n", "", "elif", "downsampling", ":", "\n", "            ", "x_shortcut", "=", "_downsample", "(", "conv", "(", "x_init", ",", "out_c", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "x_shortcut", "=", "conv", "(", "x_init", ",", "out_c", ",", "1", ",", "1", ")", "\n", "", "", "else", ":", "\n", "        ", "x_shortcut", "=", "x_init", "\n", "", "return", "x", "+", "x_shortcut", "\n", "", "def", "ResBlk_interp", "(", "x_init", ",", "out_c", ",", "upsampling", "=", "False", ",", "downsampling", "=", "False", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "norm_name", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk_interp": [[416, 493], ["activation", "conv", "conv", "tensorflow.image.resize_images", "tensorflow.layers.average_pooling2d", "functools.partial", "tflib.shape", "functools.partial.", "models_712.ResBlk._upsample"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "def", "ResBlk_interp", "(", "x_init", ",", "out_c", ",", "upsampling", "=", "False", ",", "downsampling", "=", "False", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "norm_name", "=", "None", ")", ":", "\n", "    ", "def", "_upsample", "(", "var", ")", ":", "\n", "        ", "height", ",", "width", "=", "tl", ".", "shape", "(", "var", ")", "[", "1", ":", "3", "]", "\n", "return", "tf", ".", "image", ".", "resize_images", "(", "var", ",", "(", "height", "*", "2", ",", "width", "*", "2", ")", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "\n", "", "def", "_downsample", "(", "var", ")", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "average_pooling2d", "(", "var", ",", "(", "2", ",", "2", ")", ",", "(", "2", ",", "2", ")", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "", "def", "adaptive_instance_norm", "(", "var", ",", "name", ",", "dlatent", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "var", "=", "instance_norm", "(", "var", ",", "center", "=", "False", ",", "scale", "=", "False", ")", "\n", "style", "=", "fc", "(", "dlatent", ",", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "*", "2", ")", "\n", "style", "=", "tf", ".", "reshape", "(", "style", ",", "[", "-", "1", ",", "2", "]", "+", "[", "1", "]", "*", "(", "len", "(", "tl", ".", "shape", "(", "var", ")", ")", "-", "2", ")", "+", "[", "tl", ".", "shape", "(", "var", ")", "[", "-", "1", "]", "]", ")", "\n", "return", "var", "*", "(", "style", "[", ":", ",", "0", "]", "+", "1", ")", "+", "style", "[", ":", ",", "1", "]", "\n", "\n", "", "", "def", "spatially_adaptive_norm", "(", "var", ",", "name", ",", "dlatent", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "var", "=", "instance_norm", "(", "var", ",", "center", "=", "False", ",", "scale", "=", "False", ")", "\n", "height", ",", "width", ",", "channels", "=", "tl", ".", "shape", "(", "var", ")", "[", "1", ":", "]", "\n", "style", "=", "tf", ".", "image", ".", "resize_images", "(", "dlatent", ",", "(", "height", ",", "width", ")", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "style", "=", "relu", "(", "conv", "(", "style", ",", "128", ",", "3", ",", "1", ")", ")", "\n", "gamma", "=", "conv", "(", "style", ",", "channels", ",", "3", ",", "1", ")", "\n", "beta", "=", "conv", "(", "style", ",", "channels", ",", "3", ",", "1", ")", "#var * (1+gamma) + beta", "\n", "return", "var", "*", "(", "1", "+", "gamma", ")", ",", "beta", "\n", "\n", "", "", "if", "norm", "==", "'adain'", "and", "s_rand", "is", "not", "None", ":", "\n", "        ", "norm_fn", "=", "partial", "(", "adaptive_instance_norm", ",", "dlatent", "=", "s_rand", ")", "\n", "", "elif", "norm", "==", "'in'", ":", "\n", "        ", "norm_fn", "=", "instance_norm", "\n", "", "elif", "norm", "==", "'spade'", "and", "s_targ", "is", "not", "None", ":", "\n", "        ", "norm_fn", "=", "partial", "(", "spatially_adaptive_norm", ",", "dlatent", "=", "s_targ", ")", "#, dlatent_t=s_targ_t", "\n", "# norm_fn_2 = partial(spatially_adaptive_norm, dlatent=s_targ_t)", "\n", "", "else", ":", "\n", "        ", "norm_fn", "=", "None", "\n", "", "in_c", "=", "tl", ".", "shape", "(", "x_init", ")", "[", "-", "1", "]", "\n", "is_shortcut_learn", "=", "(", "in_c", "!=", "out_c", ")", "or", "upsampling", "or", "downsampling", "\n", "if", "norm", "==", "'in'", ":", "\n", "        ", "x", "=", "norm_fn", "(", "x_init", ")", "\n", "", "elif", "norm", "==", "'adain'", "or", "norm", "==", "'spade'", ":", "\n", "        ", "v", ",", "_", "=", "norm_fn", "(", "x_init", ",", "norm_name", "+", "'_1'", ",", "dlatent", "=", "s_targ_t", ")", "\n", "_", ",", "b", "=", "norm_fn", "(", "x_init", ",", "norm_name", "+", "'_1'", ",", "dlatent", "=", "s_targ", ")", "\n", "x", "=", "v", "+", "b", "\n", "", "elif", "norm", "==", "'interp'", ":", "\n", "        ", "x", "=", "alpha", "*", "spatially_adaptive_norm", "(", "x_init", ",", "norm_name", "[", "0", "]", "+", "'_1'", ",", "dlatent", "=", "s_rand", ")", "+", "(", "1", "-", "alpha", ")", "*", "spatially_adaptive_norm", "(", "x_init", ",", "norm_name", "[", "1", "]", "+", "'_1'", ",", "dlatent", "=", "s_targ", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x_init", "\n", "", "x", "=", "activation", "(", "x", ")", "\n", "if", "upsampling", ":", "\n", "        ", "x", "=", "_upsample", "(", "x", ")", "\n", "", "x", "=", "conv", "(", "x", ",", "out_c", ",", "3", ",", "1", ")", "\n", "if", "norm", "==", "'in'", ":", "\n", "        ", "x", "=", "norm_fn", "(", "x", ")", "\n", "", "elif", "norm", "==", "'adain'", "or", "norm", "==", "'spade'", ":", "\n", "# x = norm_fn(x, norm_name + '_2')", "\n", "        ", "v", ",", "_", "=", "norm_fn", "(", "x", ",", "norm_name", "+", "'_2'", ",", "dlatent", "=", "s_targ_t", ")", "\n", "_", ",", "b", "=", "norm_fn", "(", "x", ",", "norm_name", "+", "'_2'", ",", "dlatent", "=", "s_targ", ")", "\n", "x", "=", "v", "+", "b", "\n", "", "elif", "norm", "==", "'interp'", ":", "\n", "        ", "x", "=", "alpha", "*", "spatially_adaptive_norm", "(", "x", ",", "norm_name", "[", "0", "]", "+", "'_2'", ",", "dlatent", "=", "s_rand", ")", "+", "(", "1", "-", "alpha", ")", "*", "spatially_adaptive_norm", "(", "x", ",", "norm_name", "[", "1", "]", "+", "'_2'", ",", "dlatent", "=", "s_targ", ")", "\n", "\n", "", "x", "=", "conv", "(", "activation", "(", "x", ")", ",", "out_c", ",", "3", ",", "1", ")", "\n", "if", "downsampling", ":", "\n", "        ", "x", "=", "_downsample", "(", "x", ")", "\n", "", "if", "is_shortcut_learn", ":", "\n", "        ", "if", "upsampling", ":", "\n", "            ", "x_shortcut", "=", "conv", "(", "_upsample", "(", "x_init", ")", ",", "out_c", ",", "1", ",", "1", ")", "\n", "", "elif", "downsampling", ":", "\n", "            ", "x_shortcut", "=", "_downsample", "(", "conv", "(", "x_init", ",", "out_c", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "x_shortcut", "=", "conv", "(", "x_init", ",", "out_c", ",", "1", ",", "1", ")", "\n", "", "", "else", ":", "\n", "        ", "x_shortcut", "=", "x_init", "\n", "", "return", "x", "+", "x_shortcut", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Generator": [[494, 522], ["tensorflow.variable_scope", "conv", "range", "range", "range", "tanh", "models_712.ResBlk", "conv", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit", "models_712.ResBlk", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "def", "Generator", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Ggenerator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "if", "i", "<", "n_intermedblks", "//", "2", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'in'", ")", "\n", "", "else", ":", "\n", "                ", "if", "s_rand", "is", "not", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "s_rand", ",", "norm_name", "=", "'adain%d_inter'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'spade%d_inter'", "%", "i", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "n_upblks", ")", ":", "\n", "            ", "ch", "/=", "2", "\n", "if", "s_rand", "is", "not", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "s_rand", ",", "norm_name", "=", "'adain%d_up'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'spade%d_up'", "%", "i", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "z", "=", "tanh", "(", "conv", "(", "z", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Generator2": [[552, 590], ["tensorflow.variable_scope", "conv", "range", "range", "range", "tanh", "models_712.ResBlk", "conv", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "isinstance", "isinstance", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "Generator2", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "alpha", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Ggenerator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "if", "i", "<", "n_intermedblks", "//", "2", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'in'", ")", "\n", "", "else", ":", "\n", "                ", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_inter'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                    ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'targ%d_inter'", "%", "i", ")", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "n_upblks", ")", ":", "\n", "            ", "ch", "/=", "2", "\n", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_up'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'targ%d_up'", "%", "i", ")", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "z", "=", "tanh", "(", "conv", "(", "z", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "return", "z", "\n", "", "", "def", "Generator2_wRelu", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Generator2_wRelu": [[590, 631], ["tensorflow.variable_scope", "conv", "range", "range", "range", "relu", "tanh", "models_712.ResBlk", "conv", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "isinstance", "isinstance", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "Generator2_wRelu", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Ggenerator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "if", "i", "<", "n_intermedblks", "//", "2", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'in'", ")", "\n", "", "else", ":", "\n", "                ", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_inter'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                    ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'targ%d_inter'", "%", "i", ")", "\n", "# z = ResBlk_interp(z, ch, norm='spade', s_targ=s_targ, s_targ_t=s_targ_t, norm_name='targ%d_inter'%i)", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "n_upblks", ")", ":", "\n", "            ", "ch", "/=", "2", "\n", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_up'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'targ%d_up'", "%", "i", ")", "\n", "# z = ResBlk_interp(z, ch, upsampling=True, norm='spade', s_targ=s_targ, s_targ_t=s_targ_t, norm_name='targ%d_up' % i)", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "tanh", "(", "conv", "(", "z", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "return", "z", "\n", "", "", "def", "Generator2_wRelu_imation", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Generator2_wRelu_imation": [[631, 674], ["tensorflow.variable_scope", "conv", "range", "range", "range", "relu", "tensorflow.nn.sigmoid", "tanh", "models_712.ResBlk", "conv", "conv", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "isinstance", "isinstance", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "Generator2_wRelu_imation", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Ggenerator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "if", "i", "<", "n_intermedblks", "//", "2", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'in'", ")", "\n", "", "else", ":", "\n", "                ", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_inter'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                    ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'targ%d_inter'", "%", "i", ")", "\n", "# z = ResBlk_interp(z, ch, norm='spade', s_targ=s_targ, s_targ_t=s_targ_t, norm_name='targ%d_inter'%i)", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "n_upblks", ")", ":", "\n", "            ", "ch", "/=", "2", "\n", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_up'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_targ", ",", "norm_name", "=", "'targ%d_up'", "%", "i", ")", "\n", "# z = ResBlk_interp(z, ch, upsampling=True, norm='spade', s_targ=s_targ, s_targ_t=s_targ_t, norm_name='targ%d_up' % i)", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "z", "=", "relu", "(", "z", ")", "\n", "mask_img", "=", "tf", ".", "nn", ".", "sigmoid", "(", "conv", "(", "z", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "fake_img", "=", "tanh", "(", "conv", "(", "z", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "fake_img", "=", "mask_img", "*", "x", "+", "(", "1", "-", "mask_img", ")", "*", "fake_img", "\n", "return", "fake_img", ",", "mask_img", "\n", "", "", "def", "Generator2_wRelu_adain", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Generator2_wRelu_adain": [[674, 715], ["tensorflow.variable_scope", "conv", "range", "range", "range", "relu", "tanh", "models_712.ResBlk", "conv", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "isinstance", "isinstance", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "Generator2_wRelu_adain", "(", "x", ",", "s_rand", "=", "None", ",", "s_targ", "=", "None", ",", "s_targ_t", "=", "None", ",", "alpha", "=", "None", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Ggenerator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "if", "i", "<", "n_intermedblks", "//", "2", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'in'", ")", "\n", "", "else", ":", "\n", "                ", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_inter'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                    ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "s_targ", ",", "norm_name", "=", "'rand%d_inter'", "%", "i", ")", "\n", "# z = ResBlk_interp(z, ch, norm='spade', s_targ=s_targ, s_targ_t=s_targ_t, norm_name='targ%d_inter'%i)", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_inter'", "%", "i", ",", "'targ%d_inter'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "n_upblks", ")", ":", "\n", "            ", "ch", "/=", "2", "\n", "if", "s_rand", "is", "not", "None", "and", "s_targ", "is", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'spade'", ",", "s_targ", "=", "s_rand", ",", "norm_name", "=", "'rand%d_up'", "%", "i", ")", "\n", "", "elif", "s_targ", "is", "not", "None", "and", "s_rand", "is", "None", ":", "\n", "                ", "if", "isinstance", "(", "s_targ", ",", "list", ")", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_targ", "[", "0", "]", ",", "s_targ", "=", "s_targ", "[", "1", "]", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'targ%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "s_targ", ",", "norm_name", "=", "'rand%d_up'", "%", "i", ")", "\n", "# z = ResBlk_interp(z, ch, upsampling=True, norm='spade', s_targ=s_targ, s_targ_t=s_targ_t, norm_name='targ%d_up' % i)", "\n", "", "", "elif", "s_rand", "is", "not", "None", "and", "s_targ", "is", "not", "None", ":", "\n", "                ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'interp'", ",", "s_rand", "=", "s_rand", ",", "s_targ", "=", "s_targ", ",", "alpha", "=", "alpha", ",", "norm_name", "=", "[", "'rand%d_up'", "%", "i", ",", "'targ%d_up'", "%", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Please input s_rand or s_targ\\n'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "tanh", "(", "conv", "(", "z", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Generator_stargan": [[716, 734], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.tile", "tensorflow.concat", "conv", "range", "range", "range", "relu", "tanh", "models_712.ResBlk", "models_712.ResBlk", "models_712.ResBlk", "conv", "tflib.shape", "tflib.shape", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Generator_stargan", "(", "x", ",", "c", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "4", ",", "n_upblks", "=", "4", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Ggenerator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "c", "=", "tf", ".", "reshape", "(", "c", ",", "[", "-", "1", ",", "1", ",", "1", ",", "tl", ".", "shape", "(", "c", ")", "[", "-", "1", "]", "]", ")", "\n", "c", "=", "tf", ".", "tile", "(", "c", ",", "[", "1", ",", "tl", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "tl", ".", "shape", "(", "x", ")", "[", "2", "]", ",", "1", "]", ")", "\n", "z", "=", "tf", ".", "concat", "(", "[", "x", ",", "c", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "norm", "=", "'in'", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_upblks", ")", ":", "\n", "            ", "ch", "/=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "tanh", "(", "conv", "(", "z", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet": [[735, 742], ["tensorflow.variable_scope", "tensorflow.concat", "range", "fc", "relu", "fc"], "function", ["None"], ["", "", "def", "MappingNet", "(", "r", ",", "attdiff", ",", "n_layers", "=", "6", ",", "fc_dim", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "tf", ".", "concat", "(", "[", "r", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "z", "=", "relu", "(", "fc", "(", "z", ",", "fc_dim", ")", ")", "\n", "", "z", "=", "fc", "(", "z", ",", "64", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_deconv": [[743, 754], ["tensorflow.variable_scope", "tensorflow.concat", "fc", "tensorflow.reshape", "range", "relu", "conv", "models_712.ResBlk"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "MappingNet_deconv", "(", "r", ",", "attdiff", ",", "n_layers", "=", "6", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "tf", ".", "concat", "(", "[", "r", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "fc", "(", "z", ",", "2", "*", "2", "*", "ch", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "2", ",", "2", ",", "ch", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_deconv2": [[755, 778], ["tensorflow.variable_scope", "fc", "tensorflow.reshape", "range", "relu", "conv", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "tflib.shape", "tensorflow.concat", "range", "z_s.append", "tflib.shape", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "MappingNet_deconv2", "(", "r", ",", "attdiff", ",", "n_mlp", ",", "fc_dim", ",", "n_layers", "=", "6", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "n_dim_per_stream", "=", "tl", ".", "shape", "(", "r", ")", "[", "-", "1", "]", "//", "n_stream", "\n", "z_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "ri", "=", "r", "[", ":", ",", "s", "*", "n_dim_per_stream", ":", "(", "s", "+", "1", ")", "*", "n_dim_per_stream", "]", "\n", "z", "=", "tf", ".", "concat", "(", "[", "a", ",", "ri", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "z", "=", "relu", "(", "fc", "(", "z", ",", "fc_dim", ")", ")", "\n", "", "z_s", ".", "append", "(", "z", ")", "\n", "", "z", "=", "tf", ".", "add_n", "(", "z_s", ")", "\n", "\n", "", "z", "=", "fc", "(", "z", ",", "2", "*", "2", "*", "ch", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "2", ",", "2", ",", "ch", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream": [[779, 793], ["tensorflow.variable_scope", "range", "tensorflow.add_n", "tflib.shape", "tensorflow.concat", "range", "fc", "zs.append", "tflib.shape", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "MappingNet_multiStream", "(", "r", ",", "attdiff", ",", "n_layers", "=", "6", ",", "fc_dim", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "n_r", "=", "tl", ".", "shape", "(", "r", ")", "[", "-", "1", "]", "//", "n_stream", "\n", "zs", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "            ", "attdiffs", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "rs", "=", "r", "[", ":", ",", "s", "*", "n_r", ":", "(", "s", "+", "1", ")", "*", "n_r", "]", "\n", "z", "=", "tf", ".", "concat", "(", "[", "rs", ",", "attdiffs", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "                ", "z", "=", "relu", "(", "fc", "(", "z", ",", "fc_dim", ")", ")", "\n", "", "z", "=", "fc", "(", "z", ",", "64", ")", "\n", "zs", ".", "append", "(", "z", ")", "\n", "", "return", "tf", ".", "add_n", "(", "zs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv": [[794, 813], ["tensorflow.variable_scope", "fc", "tensorflow.reshape", "range", "relu", "conv", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "tflib.shape", "range", "a_s.append", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "MappingNet_multiStream_deconv", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "fc", "(", "r", ",", "4", "*", "4", "*", "ch", "*", "2", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", "*", "2", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv_wIN_wRelu": [[814, 833], ["tensorflow.variable_scope", "fc", "tensorflow.reshape", "range", "relu", "relu", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "instance_norm", "tflib.shape", "range", "a_s.append", "conv", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "MappingNet_multiStream_deconv_wIN_wRelu", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "fc", "(", "r", ",", "4", "*", "4", "*", "ch", "*", "2", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", "*", "2", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "relu", "(", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv_wIN_wRelu_concat": [[834, 844], ["tensorflow.variable_scope", "tensorflow.concat", "fc", "tensorflow.reshape", "range", "relu", "relu", "models_712.ResBlk", "instance_norm", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "MappingNet_multiStream_deconv_wIN_wRelu_concat", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "tf", ".", "concat", "(", "[", "r", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "fc", "(", "z", ",", "4", "*", "4", "*", "ch", "*", "2", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", "*", "2", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "relu", "(", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", ")", "#", "\n", "return", "z", "\n", "", "", "def", "MappingNet_multiStream_deconv_wIN_concat", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv_wIN_concat": [[844, 856], ["tensorflow.variable_scope", "tensorflow.concat", "fc", "tensorflow.reshape", "range", "relu", "instance_norm", "models_712.ResBlk", "models_712.ResBlk", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "MappingNet_multiStream_deconv_wIN_concat", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "tf", ".", "concat", "(", "[", "r", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "fc", "(", "z", ",", "4", "*", "4", "*", "ch", "*", "2", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", "*", "2", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "if", "n_layers", "==", "3", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "# relu", "\n", "return", "z", "\n", "", "", "def", "MappingNet_multiStream_deconv_wIN_concat_C", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv_wIN_concat_C": [[856, 869], ["tensorflow.variable_scope", "tensorflow.concat", "fc", "tensorflow.reshape", "range", "relu", "instance_norm", "models_712.ResBlk", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "MappingNet_multiStream_deconv_wIN_concat_C", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "tf", ".", "concat", "(", "[", "r", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "fc", "(", "z", ",", "4", "*", "4", "*", "ch", "*", "4", "*", "4", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", "*", "4", "*", "4", ")", ")", "#256*4", "\n", "ch", "=", "ch", "*", "4", "*", "4", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "ch", "=", "ch", "//", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "# z = ResBlk(z, ch, activation=relu, norm='in')", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "# relu", "\n", "return", "z", "\n", "", "", "def", "MappingNet_multiStream_deconv_shareLastConv", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv_shareLastConv": [[869, 890], ["tensorflow.variable_scope", "fc", "tensorflow.reshape", "range", "relu", "tensorflow.variable_scope", "relu", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "instance_norm", "tflib.shape", "range", "a_s.append", "conv", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "MappingNet_multiStream_deconv_shareLastConv", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "fc", "(", "r", ",", "4", "*", "4", "*", "ch", "*", "2", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", "*", "2", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'GshareConv'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "relu", "(", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", ")", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv_wIN": [[891, 910], ["tensorflow.variable_scope", "fc", "tensorflow.reshape", "range", "relu", "instance_norm", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "conv", "tflib.shape", "range", "a_s.append", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "def", "MappingNet_multiStream_deconv_wIN", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "fc", "(", "r", ",", "4", "*", "4", "*", "ch", "*", "2", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", "*", "2", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "upsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.MappingNet_multiStream_deconv1_wIN": [[911, 930], ["tensorflow.variable_scope", "relu", "tensorflow.reshape", "range", "instance_norm", "tensorflow.variable_scope", "range", "tensorflow.add_n", "fc", "relu", "conv", "tflib.shape", "range", "a_s.append", "models_712.dconv_adain", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.dconv_adain"], ["", "", "def", "MappingNet_multiStream_deconv1_wIN", "(", "r", ",", "attdiff", ",", "n_mlp", "=", "3", ",", "n_layers", "=", "4", ",", "fc_dim", "=", "64", ",", "ch", "=", "32", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gmappingnet'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "relu", "(", "fc", "(", "r", ",", "4", "*", "4", "*", "ch", ")", ")", "\n", "z", "=", "tf", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "4", ",", "4", ",", "ch", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "relu", "(", "dconv_adain", "(", "z", ",", "ch", ",", "3", ",", "2", ",", "s", "=", "a", ")", ")", "\n", "", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder": [[931, 957], ["tensorflow.variable_scope", "conv", "range", "range", "lrelu", "conv", "tensorflow.variable_scope", "range", "models_712.ResBlk", "models_712.ResBlk", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "Encoder", "(", "x", ",", "attdiff_abs", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "'Gencoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "a", "=", "attdiff_abs", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "\n", "", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "lrelu", "(", "z", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder2": [[958, 991], ["tensorflow.variable_scope", "conv", "range", "range", "models_712.ResBlk", "relu", "conv", "models_712.ResBlk", "relu", "conv", "tensorflow.variable_scope", "range", "models_712.ResBlk", "models_712.ResBlk", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "Encoder2", "(", "x", ",", "attdiff_abs", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: masked s\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "'Gencoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "a", "=", "attdiff_abs", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "\n", "", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "ch", "*=", "2", "\n", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "\n", "", "s", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adains'", ")", "\n", "s", "=", "relu", "(", "s", ")", "\n", "s", "=", "conv", "(", "s", ",", "ch", ",", "1", ",", "1", ")", "\n", "\n", "mask", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adainm'", ")", "\n", "mask", "=", "relu", "(", "mask", ")", "\n", "mask", "=", "conv", "(", "mask", ",", "1", ",", "1", ",", "1", ")", "#sigmoid(conv(mask, 1, 1, 1))", "\n", "return", "mask", "*", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder3": [[992, 1031], ["tensorflow.variable_scope", "conv", "range", "range", "relu", "relu", "tensorflow.reshape", "range", "relu", "conv", "tensorflow.variable_scope", "range", "models_712.ResBlk", "models_712.ResBlk", "tflib.shape", "conv", "fc", "models_712.ResBlk", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk"], ["", "", "def", "Encoder3", "(", "x", ",", "attdiff_abs", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: masked s\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "'Gencoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "a", "=", "attdiff_abs", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "\n", "", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "ch_ori", "=", "ch", "\n", "#### style code ####", "\n", "s", "=", "z", "\n", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "s", "=", "ResBlk", "(", "s", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "s", "=", "relu", "(", "s", ")", "\n", "h", "=", "tl", ".", "shape", "(", "s", ")", "[", "1", "]", "\n", "s", "=", "relu", "(", "conv", "(", "s", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "s", "=", "tf", ".", "reshape", "(", "fc", "(", "s", ",", "64", ")", ",", "(", "-", "1", ",", "1", ",", "1", ",", "64", ")", ")", "\n", "#### mask ####", "\n", "ch", "=", "2", "*", "ch_ori", "\n", "mask", "=", "z", "\n", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "mask", "=", "ResBlk", "(", "mask", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "mask", "=", "relu", "(", "mask", ")", "\n", "mask", "=", "conv", "(", "mask", ",", "1", ",", "1", ",", "1", ")", "\n", "return", "mask", "*", "s", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4": [[1032, 1063], ["tensorflow.variable_scope", "conv", "range", "range", "relu", "conv", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "models_712.ResBlk", "tensorflow.layers.flatten", "tflib.shape", "range", "a_s.append", "tensorflow.layers.average_pooling2d", "relu", "fc", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4", "(", "x", ",", "attdiff_abs", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff_abs", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff_abs", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "#lrelu(z)", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "", "", "def", "Encoder4_wIN_wRelu", "(", "x", ",", "attdiff_abs", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4_wIN_wRelu": [[1063, 1094], ["tensorflow.variable_scope", "conv", "range", "range", "relu", "relu", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "models_712.ResBlk", "instance_norm", "tensorflow.layers.flatten", "tflib.shape", "range", "a_s.append", "conv", "tensorflow.layers.average_pooling2d", "relu", "fc", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4_wIN_wRelu", "(", "x", ",", "attdiff_abs", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff_abs", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff_abs", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "#lrelu(z)", "\n", "z", "=", "relu", "(", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4_wIN_wRelu_concat": [[1095, 1119], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.tile", "tensorflow.concat", "conv", "range", "range", "relu", "relu", "models_712.ResBlk", "models_712.ResBlk", "instance_norm", "tensorflow.layers.flatten", "conv", "tensorflow.layers.average_pooling2d", "tflib.shape", "tflib.shape", "tflib.shape", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4_wIN_wRelu_concat", "(", "x", ",", "attdiff", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "attdiff", "=", "tf", ".", "reshape", "(", "attdiff", ",", "[", "-", "1", ",", "1", ",", "1", ",", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "]", ")", "\n", "attdiff", "=", "tf", ".", "tile", "(", "attdiff", ",", "[", "1", ",", "tl", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "tl", ".", "shape", "(", "x", ")", "[", "2", "]", ",", "1", "]", ")", "\n", "z", "=", "tf", ".", "concat", "(", "[", "x", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "#lrelu(z)", "\n", "z", "=", "relu", "(", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "", "", "def", "Encoder4_wIN_concat", "(", "x", ",", "attdiff", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4_wIN_concat": [[1119, 1143], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.tile", "tensorflow.concat", "conv", "range", "range", "relu", "instance_norm", "models_712.ResBlk", "models_712.ResBlk", "conv", "tensorflow.layers.flatten", "tensorflow.layers.average_pooling2d", "tflib.shape", "tflib.shape", "tflib.shape", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4_wIN_concat", "(", "x", ",", "attdiff", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "attdiff", "=", "tf", ".", "reshape", "(", "attdiff", ",", "[", "-", "1", ",", "1", ",", "1", ",", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "]", ")", "\n", "attdiff", "=", "tf", ".", "tile", "(", "attdiff", ",", "[", "1", ",", "tl", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "tl", ".", "shape", "(", "x", ")", "[", "2", "]", ",", "1", "]", ")", "\n", "z", "=", "tf", ".", "concat", "(", "[", "x", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "#lrelu(z)", "\n", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "", "", "def", "Encoder4_wIN_concat_wolabel", "(", "x", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4_wIN_concat_wolabel": [[1143, 1165], ["tensorflow.variable_scope", "conv", "range", "range", "relu", "instance_norm", "models_712.ResBlk", "models_712.ResBlk", "conv", "tensorflow.layers.flatten", "tensorflow.layers.average_pooling2d", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4_wIN_concat_wolabel", "(", "x", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "x", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "#lrelu(z)", "\n", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "", "", "def", "Encoder4_wIN_concat_C", "(", "x", ",", "attdiff", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4_wIN_concat_C": [[1165, 1190], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.tile", "tensorflow.concat", "conv", "range", "range", "relu", "instance_norm", "models_712.ResBlk", "models_712.ResBlk", "conv", "tensorflow.layers.flatten", "tensorflow.layers.average_pooling2d", "tflib.shape", "tflib.shape", "tflib.shape", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4_wIN_concat_C", "(", "x", ",", "attdiff", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "attdiff", "=", "tf", ".", "reshape", "(", "attdiff", ",", "[", "-", "1", ",", "1", ",", "1", ",", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "]", ")", "\n", "attdiff", "=", "tf", ".", "tile", "(", "attdiff", ",", "[", "1", ",", "tl", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "tl", ".", "shape", "(", "x", ")", "[", "2", "]", ",", "1", "]", ")", "\n", "z", "=", "tf", ".", "concat", "(", "[", "x", ",", "attdiff", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "#lrelu(z)", "\n", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4_shareLastConv": [[1191, 1223], ["tensorflow.variable_scope", "conv", "range", "range", "relu", "tensorflow.variable_scope", "relu", "tensorflow.layers.flatten", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "models_712.ResBlk", "instance_norm", "tensorflow.layers.average_pooling2d", "tflib.shape", "range", "a_s.append", "conv", "relu", "tflib.shape", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4_shareLastConv", "(", "x", ",", "attdiff_abs", ",", "name", "=", "'Gencoder'", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff_abs", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff_abs", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "#lrelu(z)", "\n", "", "with", "tf", ".", "variable_scope", "(", "'GshareConv'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "relu", "(", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", ")", "\n", "", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.IN_forEncoder": [[1224, 1228], ["tensorflow.variable_scope", "instance_norm"], "function", ["None"], ["", "def", "IN_forEncoder", "(", "x", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gencoder_IN'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "x", "=", "instance_norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.SharedLayer_forEncoder": [[1229, 1246], ["tensorflow.variable_scope", "conv", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "SharedLayer_forEncoder", "(", "x", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gsharelayer'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "channel", "=", "tl", ".", "shape", "(", "x", ")", "[", "-", "1", "]", "\n", "# x = conv(x, channel//2, 3,1, normalizer_fn=instance_norm, activation_fn=relu) #_kernel3", "\n", "# x = conv(x, channel // 2, 1, 1, normalizer_fn=instance_norm, activation_fn=relu) _kernel1", "\n", "# x = conv(x, channel // 2, 1, 1)  #kernel1_woIN_woRelu", "\n", "# weight1 = tf.get_variable('w1', shape = (channel//2,), initializer=tf.constant_initializer(0.5))  #2channelweight", "\n", "# weight2 = tf.get_variable('w2', shape=(channel // 2,), initializer=tf.constant_initializer(0.5))", "\n", "# x = weight1 * x[:,:,:,:channel//2] + weight2 * x[:,:,:,channel//2:]", "\n", "# weight = tf.get_variable('w', shape=(channel // 2,), initializer=tf.constant_initializer(0))  # channelweight", "\n", "# weight =sigmoid(weight)", "\n", "# x = weight * x[:, :, :, :channel // 2] + (1-weight) * x[:, :, :, channel // 2:]", "\n", "# weight1 = tf.get_variable('w1', shape = (1,), initializer=tf.constant_initializer(0.5))  #2weight", "\n", "# weight2 = tf.get_variable('w2', shape=(1,), initializer=tf.constant_initializer(0.5))", "\n", "# x = weight1 * x[:,:,:,:channel//2] + weight2 * x[:,:,:,channel//2:]", "\n", "x", "=", "conv", "(", "x", ",", "channel", ",", "1", ",", "1", ",", "normalizer_fn", "=", "instance_norm", ",", "activation_fn", "=", "relu", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder4_wIN": [[1249, 1280], ["tensorflow.variable_scope", "conv", "range", "range", "relu", "instance_norm", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "models_712.ResBlk", "conv", "tensorflow.layers.flatten", "tflib.shape", "range", "a_s.append", "tensorflow.layers.average_pooling2d", "relu", "fc", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder4_wIN", "(", "x", ",", "attdiff_abs", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "'Gencoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff_abs", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff_abs", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Encoder5_wIN": [[1281, 1313], ["tensorflow.variable_scope", "relu", "range", "range", "instance_norm", "tensorflow.variable_scope", "range", "tensorflow.add_n", "conv", "relu", "relu", "conv", "tensorflow.layers.flatten", "tflib.shape", "range", "a_s.append", "instance_norm", "models_712.conv_adain", "tensorflow.layers.average_pooling2d", "relu", "conv", "fc", "tflib.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.conv_adain", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Encoder5_wIN", "(", "x", ",", "attdiff_abs", ",", "name", ",", "n_downblks", "=", "4", ",", "n_intermedblks", "=", "2", ",", "n_mlp", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "'''\n\n    :param x:\n    :param attdiff_abs:\n    :param n_downblks:\n    :param n_intermedblks:\n    :param n_mlp:\n    :param ch:\n    :return: z\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "#'Gencoder'", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff_abs", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff_abs", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "4", "*", "ch", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "relu", "(", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "n_downblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "relu", "(", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "3", ",", "2", ")", ")", ")", "\n", "", "for", "i", "in", "range", "(", "n_intermedblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "relu", "(", "conv_adain", "(", "z", ",", "ch", ",", "3", ",", "1", ",", "s", "=", "a", ")", ")", "\n", "\n", "", "z", "=", "instance_norm", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "return", "z", ",", "tf", ".", "layers", ".", "flatten", "(", "tf", ".", "layers", ".", "average_pooling2d", "(", "z", ",", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Discriminator": [[1314, 1331], ["tensorflow.variable_scope", "conv", "range", "lrelu", "lrelu", "fc", "lrelu", "fc", "models_712.ResBlk", "tflib.shape", "conv", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Discriminator", "(", "x", ",", "n_att", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Discriminator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "lrelu", ",", "norm", "=", "'none'", ")", "\n", "", "z", "=", "lrelu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_gan", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_gan", "=", "fc", "(", "logit_gan", ",", "1", ")", "\n", "\n", "logit_att_feature", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_att", "=", "fc", "(", "logit_att_feature", ",", "n_att", ")", "\n", "\n", "# return logit_gan, logit_att", "\n", "return", "logit_gan", ",", "logit_att", ",", "logit_att_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Discriminator_starganV2": [[1332, 1354], ["tensorflow.variable_scope", "conv", "range", "lrelu", "lrelu", "fc", "tensorflow.reduce_sum", "tensorflow.reshape", "lrelu", "fc", "models_712.ResBlk", "tflib.shape", "conv", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Discriminator_starganV2", "(", "x", ",", "n_att", ",", "l", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Discriminator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "# , regularizer=l2_reg", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "if", "ch", ">=", "512", ":", "\n", "                ", "ch", "=", "512", "\n", "", "else", ":", "\n", "                ", "ch", "*=", "2", "\n", "", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "lrelu", ",", "norm", "=", "'none'", ")", "\n", "", "z", "=", "lrelu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_att_feature", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_att", "=", "fc", "(", "logit_att_feature", ",", "n_att", ")", "\n", "logit_att", "=", "tf", ".", "reduce_sum", "(", "logit_att", "*", "l", ",", "axis", "=", "1", ")", "# consider [N,1]", "\n", "logit_att", "=", "tf", ".", "reshape", "(", "logit_att", ",", "[", "logit_att", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "\n", "logit_gender_feature", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_gender", "=", "fc", "(", "logit_gender_feature", ",", "1", ")", "# [N,1]", "\n", "\n", "# return logit_gan, logit_att", "\n", "return", "logit_att", ",", "logit_gender", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.LatentDiscriminator": [[1355, 1368], ["functools.partial", "tensorflow.variable_scope", "lrelu", "range", "lrelu", "fc", "conv", "functools.partial.", "tflib.shape", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "LatentDiscriminator", "(", "x", ",", "n_layers", "=", "4", ",", "ch", "=", "16", ")", ":", "\n", "    ", "conv_lrelu", "=", "partial", "(", "conv", ",", "activation_fn", "=", "lrelu", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'DiscriminatorLatent'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "lrelu", "(", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "conv_lrelu", "(", "z", ",", "ch", ",", "3", ",", "2", ")", "\n", "", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_gan", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_gan", "=", "fc", "(", "logit_gan", ",", "1", ")", "\n", "\n", "return", "logit_gan", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Discriminator_multiTask": [[1369, 1394], ["tensorflow.variable_scope", "conv", "range", "lrelu", "lrelu", "fc", "range", "tensorflow.concat", "tensorflow.concat", "models_712.ResBlk", "tflib.shape", "conv", "lrelu", "lrelu", "fc", "logit_att_feature_list.append", "logit_att_list.append", "conv", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Discriminator_multiTask", "(", "x", ",", "n_att", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Discriminator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "lrelu", ",", "norm", "=", "'none'", ")", "\n", "", "z", "=", "lrelu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_gan", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_gan", "=", "fc", "(", "logit_gan", ",", "1", ")", "\n", "\n", "logit_att_list", "=", "[", "]", "\n", "logit_att_feature_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_att", ")", ":", "\n", "            ", "logit_att_feature", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_att_feature", "=", "lrelu", "(", "fc", "(", "logit_att_feature", ",", "64", ")", ")", "\n", "logit_att", "=", "fc", "(", "logit_att_feature", ",", "1", ")", "\n", "logit_att_feature_list", ".", "append", "(", "logit_att_feature", ")", "\n", "logit_att_list", ".", "append", "(", "logit_att", ")", "\n", "\n", "", "logit_att_feature", "=", "tf", ".", "concat", "(", "logit_att_feature_list", ",", "axis", "=", "-", "1", ")", "\n", "logit_att", "=", "tf", ".", "concat", "(", "logit_att_list", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "logit_gan", ",", "logit_att", ",", "logit_att_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.PatchDiscriminator": [[1395, 1411], ["tensorflow.variable_scope", "conv", "range", "lrelu", "lrelu", "conv", "lrelu", "fc", "models_712.ResBlk", "tflib.shape", "conv", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "PatchDiscriminator", "(", "x", ",", "n_att", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Discriminator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "lrelu", ",", "norm", "=", "'none'", ")", "\n", "", "z", "=", "lrelu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_gan", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", ")", "\n", "logit_gan", "=", "conv", "(", "logit_gan", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "logit_att", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_att", "=", "fc", "(", "logit_att", ",", "n_att", ")", "\n", "\n", "return", "logit_gan", ",", "logit_att", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Classifier": [[1412, 1433], ["tensorflow.variable_scope", "conv", "range", "lrelu", "lrelu", "fc", "range", "models_712.ResBlk", "tflib.shape", "conv", "fc", "fc", "final_out.append", "final_vec.append"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Classifier", "(", "x", ",", "n_att", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "final_out", "=", "[", "]", "\n", "final_vec", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'Classifier'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "lrelu", ",", "norm", "=", "'none'", ")", "\n", "", "z", "=", "lrelu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_att_feature", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "data", "=", "fc", "(", "logit_att_feature", ",", "2048", ")", "\n", "for", "i", "in", "range", "(", "n_att", ")", ":", "\n", "            ", "data_fc", "=", "fc", "(", "data", ",", "1024", ",", "scope", "=", "'fc_%d'", "%", "i", ")", "\n", "data_i", "=", "fc", "(", "data_fc", ",", "2", ",", "scope", "=", "'final_fc_%d'", "%", "i", ")", "\n", "final_out", ".", "append", "(", "data_i", ")", "\n", "final_vec", ".", "append", "(", "data_fc", ")", "\n", "# logit_att = tf.concat(final_out, 1)", "\n", "\n", "", "return", "final_out", ",", "final_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.Discriminator_withMatch": [[1434, 1453], ["tensorflow.variable_scope", "conv", "range", "lrelu", "lrelu", "fc", "lrelu", "fc", "lrelu", "fc", "models_712.ResBlk", "tflib.shape", "conv", "conv", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "Discriminator_withMatch", "(", "x", ",", "n_att", ",", "output_dim", "=", "16", "*", "2", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Discriminator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "lrelu", ",", "norm", "=", "'none'", ")", "\n", "", "z", "=", "lrelu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_gan", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_gan", "=", "fc", "(", "logit_gan", ",", "1", ")", "\n", "\n", "logit_att", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_att", "=", "fc", "(", "logit_att", ",", "n_att", ")", "\n", "\n", "logit_match", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_match", "=", "fc", "(", "logit_match", ",", "output_dim", ")", "\n", "\n", "return", "logit_gan", ",", "logit_att", ",", "logit_match", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.EncoderR": [[1454, 1467], ["tensorflow.variable_scope", "conv", "range", "relu", "lrelu", "fc", "models_712.ResBlk", "tflib.shape", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "EncoderR", "(", "x", ",", "output_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "# with tf.variable_scope('GencoderR', reuse=tf.AUTO_REUSE):", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'DencoderR'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'none'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_out", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_out", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "return", "logit_out", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.EncoderR_2": [[1468, 1481], ["tensorflow.variable_scope", "conv", "range", "relu", "lrelu", "fc", "models_712.ResBlk", "tflib.shape", "conv"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "EncoderR_2", "(", "x", ",", "style", ",", "output_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "# with tf.variable_scope('GencoderR', reuse=tf.AUTO_REUSE):", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'DencoderR'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "style", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_out", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_out", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "return", "logit_out", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.EncoderR_3": [[1482, 1506], ["tensorflow.variable_scope", "tensorflow.concat", "conv", "range", "relu", "lrelu", "fc", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "tflib.shape", "conv", "tflib.shape", "range", "a_s.append", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "EncoderR_3", "(", "x", ",", "x_src", ",", "attdiff", ",", "output_dim", ",", "n_mlp", ",", "fc_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "# with tf.variable_scope('GencoderR', reuse=tf.AUTO_REUSE):", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'DencoderR'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "tf", ".", "concat", "(", "[", "x", ",", "x_src", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_out", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_out", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "return", "logit_out", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.EncoderR_4": [[1507, 1532], ["tensorflow.variable_scope", "tensorflow.concat", "conv", "range", "relu", "lrelu", "fc", "fc", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "tflib.shape", "conv", "tflib.shape", "range", "a_s.append", "tensorflow.random_normal", "tensorflow.exp", "relu", "fc", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "EncoderR_4", "(", "x", ",", "x_src", ",", "attdiff", ",", "output_dim", ",", "n_mlp", ",", "fc_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'GencoderR'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "\n", "", "z", "=", "tf", ".", "concat", "(", "[", "x", ",", "x_src", "]", ",", "axis", "=", "-", "1", ")", "\n", "z", "=", "conv", "(", "z", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_out", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_out_mu", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "logit_out_logvar", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "logit_out", "=", "logit_out_mu", "+", "tf", ".", "random_normal", "(", "shape", "=", "tf", ".", "shape", "(", "output_dim", ")", ")", "*", "tf", ".", "exp", "(", "logit_out_logvar", ")", "\n", "return", "logit_out", ",", "logit_out_mu", ",", "logit_out_logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.EncoderR_VAE": [[1533, 1547], ["tensorflow.variable_scope", "conv", "range", "relu", "lrelu", "fc", "fc", "models_712.ResBlk", "tflib.shape", "conv", "tensorflow.random_normal", "tensorflow.exp", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "EncoderR_VAE", "(", "x", ",", "output_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'GencoderR'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'in'", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_out", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_out_mu", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "logit_out_logvar", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "logit_out", "=", "logit_out_mu", "+", "tf", ".", "random_normal", "(", "shape", "=", "tf", ".", "shape", "(", "logit_out_mu", ")", ")", "*", "tf", ".", "exp", "(", "logit_out_logvar", "/", "2", ")", "\n", "return", "logit_out", ",", "logit_out_mu", ",", "logit_out_logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.EncoderR_NoVAE": [[1560, 1581], ["tensorflow.variable_scope", "conv", "range", "relu", "lrelu", "fc", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "tflib.shape", "conv", "tflib.shape", "range", "a_s.append", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "EncoderR_NoVAE", "(", "x", ",", "attdiff", ",", "output_dim", ",", "n_mlp", ",", "fc_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'GencoderR'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_out", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_out", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "return", "logit_out", "\n", "", "", "def", "EncoderR_NoVAE_ER", "(", "x", ",", "attdiff", ",", "output_dim", ",", "n_mlp", ",", "fc_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.EncoderR_NoVAE_ER": [[1581, 1602], ["tensorflow.variable_scope", "conv", "range", "relu", "lrelu", "fc", "tensorflow.variable_scope", "range", "tensorflow.add_n", "models_712.ResBlk", "tflib.shape", "conv", "tflib.shape", "range", "a_s.append", "relu", "fc"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.ResBlk", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape"], ["", "", "def", "EncoderR_NoVAE_ER", "(", "x", ",", "attdiff", ",", "output_dim", ",", "n_mlp", ",", "fc_dim", ",", "n_resblks", "=", "6", ",", "ch", "=", "16", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'ER'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'mlp'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "n_stream", "=", "tl", ".", "shape", "(", "attdiff", ")", "[", "-", "1", "]", "\n", "a_s", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "n_stream", ")", ":", "\n", "                ", "a", "=", "attdiff", "[", ":", ",", "s", ":", "s", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "                    ", "a", "=", "relu", "(", "fc", "(", "a", ",", "fc_dim", ")", ")", "\n", "", "a_s", ".", "append", "(", "a", ")", "\n", "", "a", "=", "tf", ".", "add_n", "(", "a_s", ")", "\n", "", "z", "=", "conv", "(", "x", ",", "ch", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "n_resblks", ")", ":", "\n", "            ", "ch", "*=", "2", "\n", "z", "=", "ResBlk", "(", "z", ",", "ch", ",", "downsampling", "=", "True", ",", "activation", "=", "relu", ",", "norm", "=", "'adain'", ",", "s_rand", "=", "a", ",", "norm_name", "=", "'adain%d'", "%", "i", ")", "\n", "", "z", "=", "relu", "(", "z", ")", "\n", "h", "=", "tl", ".", "shape", "(", "z", ")", "[", "1", "]", "\n", "\n", "logit_out", "=", "lrelu", "(", "conv", "(", "z", ",", "ch", ",", "h", ",", "1", ",", "padding", "=", "'VALID'", ")", ")", "\n", "logit_out", "=", "fc", "(", "logit_out", ",", "output_dim", ")", "\n", "return", "logit_out", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.attention_HW": [[1603, 1624], ["tensorflow.variable_scope", "F_s.get_shape().as_list", "conv", "conv", "conv", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.nn.softmax", "F_s.get_shape"], "function", ["None"], ["", "", "def", "attention_HW", "(", "F_s", ",", "F_t", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gattention'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "inputs_shape", "=", "F_s", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "batchsize", ",", "height", ",", "width", ",", "C", "=", "inputs_shape", "[", "0", "]", ",", "inputs_shape", "[", "1", "]", ",", "inputs_shape", "[", "2", "]", ",", "inputs_shape", "[", "3", "]", "\n", "# height = height // 2", "\n", "# width = width // 2", "\n", "# C = C * 4", "\n", "query_conv", "=", "conv", "(", "F_s", ",", "C", ",", "1", ",", "1", ",", "padding", "=", "'VALID'", ")", "\n", "key_conv", "=", "conv", "(", "F_t", ",", "C", ",", "1", ",", "1", ",", "padding", "=", "'VALID'", ")", "\n", "value_conv", "=", "conv", "(", "F_t", ",", "C", ",", "1", ",", "1", ",", "padding", "=", "'VALID'", ")", "\n", "\n", "proj_key", "=", "tf", ".", "reshape", "(", "key_conv", ",", "[", "batchsize", ",", "width", "*", "height", ",", "-", "1", "]", ")", "\n", "proj_query", "=", "tf", ".", "transpose", "(", "(", "tf", ".", "reshape", "(", "query_conv", ",", "[", "batchsize", ",", "width", "*", "height", ",", "-", "1", "]", ")", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "energy", "=", "tf", ".", "transpose", "(", "tf", ".", "matmul", "(", "proj_key", ",", "proj_query", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "attention", "=", "tf", ".", "nn", ".", "softmax", "(", "energy", ")", "/", "8.0", "\n", "proj_value", "=", "tf", ".", "reshape", "(", "value_conv", ",", "[", "batchsize", ",", "width", "*", "height", ",", "-", "1", "]", ")", "\n", "\n", "out", "=", "tf", ".", "matmul", "(", "attention", ",", "proj_value", ")", "\n", "out", "=", "tf", ".", "reshape", "(", "out", ",", "[", "batchsize", ",", "height", ",", "width", ",", "C", "]", ")", "\n", "return", "out", "\n", "", "", "def", "attention_C", "(", "F_s", ",", "F_t", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.None.models_712.attention_C": [[1624, 1642], ["tensorflow.variable_scope", "F_s.get_shape().as_list", "conv", "conv", "conv", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.matmul", "F_s.get_shape"], "function", ["None"], ["", "", "def", "attention_C", "(", "F_s", ",", "F_t", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Gattention'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "inputs_shape", "=", "F_s", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "batchsize", ",", "height", ",", "width", ",", "C", "=", "inputs_shape", "[", "0", "]", ",", "inputs_shape", "[", "1", "]", ",", "inputs_shape", "[", "2", "]", ",", "inputs_shape", "[", "3", "]", "\n", "query_conv", "=", "conv", "(", "F_s", ",", "C", ",", "1", ",", "1", ",", "padding", "=", "'VALID'", ")", "\n", "key_conv", "=", "conv", "(", "F_t", ",", "C", ",", "1", ",", "1", ",", "padding", "=", "'VALID'", ")", "\n", "value_conv", "=", "conv", "(", "F_t", ",", "C", ",", "1", ",", "1", ",", "padding", "=", "'VALID'", ")", "\n", "\n", "proj_key", "=", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "key_conv", ",", "[", "batchsize", ",", "width", "*", "height", ",", "-", "1", "]", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "proj_query", "=", "tf", ".", "reshape", "(", "query_conv", ",", "[", "batchsize", ",", "width", "*", "height", ",", "-", "1", "]", ")", "\n", "energy", "=", "tf", ".", "transpose", "(", "tf", ".", "matmul", "(", "proj_key", ",", "proj_query", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "attention", "=", "tf", ".", "nn", ".", "softmax", "(", "energy", ")", "/", "64.0", "\n", "proj_value", "=", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "value_conv", ",", "[", "batchsize", ",", "width", "*", "height", ",", "-", "1", "]", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "out", "=", "tf", ".", "transpose", "(", "tf", ".", "matmul", "(", "attention", ",", "proj_value", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "out", "=", "tf", ".", "reshape", "(", "out", ",", "[", "batchsize", ",", "height", ",", "width", ",", "C", "]", ")", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.encode.imencode": [[11, 26], ["io.BytesIO", "PIL.Image.fromarray", "Image.fromarray.save", "io.BytesIO.getvalue", "im2uint"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.im2uint"], ["def", "imencode", "(", "image", ",", "format", "=", "'PNG'", ",", "quality", "=", "95", ")", ":", "\n", "    ", "\"\"\"Encode an [-1.0, 1.0] into byte str.\n\n    Args:\n        format: 'PNG' or 'JPEG'.\n        quality: for 'JPEG'.\n\n    Returns:\n        Byte string.\n    \"\"\"", "\n", "byte_io", "=", "io", ".", "BytesIO", "(", ")", "\n", "image", "=", "Image", ".", "fromarray", "(", "im2uint", "(", "image", ")", ")", "\n", "image", ".", "save", "(", "byte_io", ",", "format", "=", "format", ",", "quality", "=", "quality", ")", "\n", "bytes", "=", "byte_io", ".", "getvalue", "(", ")", "\n", "return", "bytes", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.encode.imdecode": [[28, 42], ["io.BytesIO", "io.BytesIO.write", "np.array", "uint2im", "PIL.Image.open"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.uint2im"], ["", "def", "imdecode", "(", "bytes", ")", ":", "\n", "    ", "\"\"\"Decode byte str to image in [-1.0, 1.0] of float64.\n\n    Args:\n        bytes: Byte string.\n\n    Returns:\n        A float64 image in [-1.0, 1.0].\n    \"\"\"", "\n", "byte_io", "=", "io", ".", "BytesIO", "(", ")", "\n", "byte_io", ".", "write", "(", "bytes", ")", "\n", "image", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "byte_io", ")", ")", "\n", "image", "=", "uint2im", "(", "image", ")", "\n", "return", "image", "\n", "", ""]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.rgb2gray": [[10, 17], ["Exception"], "function", ["None"], ["def", "rgb2gray", "(", "images", ")", ":", "\n", "    ", "if", "images", ".", "ndim", "==", "4", "or", "images", ".", "ndim", "==", "3", ":", "\n", "        ", "assert", "images", ".", "shape", "[", "-", "1", "]", "==", "3", ",", "'Channel size should be 3!'", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Wrong dimensions!'", ")", "\n", "\n", "", "return", "(", "images", "[", "...", ",", "0", "]", "*", "0.299", "+", "images", "[", "...", ",", "1", "]", "*", "0.587", "+", "images", "[", "...", ",", "2", "]", "*", "0.114", ")", ".", "astype", "(", "images", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.gray2rgb": [[19, 26], ["numpy.zeros"], "function", ["None"], ["", "def", "gray2rgb", "(", "images", ")", ":", "\n", "    ", "assert", "images", ".", "ndim", "==", "2", "or", "images", ".", "ndim", "==", "3", ",", "'Wrong dimensions!'", "\n", "rgb_imgs", "=", "np", ".", "zeros", "(", "images", ".", "shape", "+", "(", "3", ",", ")", ",", "dtype", "=", "images", ".", "dtype", ")", "\n", "rgb_imgs", "[", "...", ",", "0", "]", "=", "images", "\n", "rgb_imgs", "[", "...", ",", "1", "]", "=", "images", "\n", "rgb_imgs", "[", "...", ",", "2", "]", "=", "images", "\n", "return", "rgb_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.imresize": [[28, 44], ["scipy.misc.imresize", "im2uint"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.imresize", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.im2uint"], ["", "def", "imresize", "(", "image", ",", "size", ",", "interp", "=", "'bilinear'", ")", ":", "\n", "    ", "\"\"\"Resize an [-1.0, 1.0] image.\n\n    Args:\n        size : int, float or tuple\n            * int   - Percentage of current size.\n            * float - Fraction of current size.\n            * tuple - Size of the output image.\n\n        interp : str, optional\n            Interpolation to use for re-sizing ('nearest', 'lanczos',\n            'bilinear', 'bicubic' or 'cubic').\n    \"\"\"", "\n", "# scipy.misc.imresize should deal with uint8 image, or it would cause some", "\n", "# problem (scale the image to [0, 255])", "\n", "return", "(", "scipy", ".", "misc", ".", "imresize", "(", "im2uint", "(", "image", ")", ",", "size", ",", "interp", "=", "interp", ")", "/", "127.5", "-", "1", ")", ".", "astype", "(", "image", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.resize_images": [[46, 63], ["numpy.array", "rs_imgs.append", "transform.imresize"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.imresize"], ["", "def", "resize_images", "(", "images", ",", "size", ",", "interp", "=", "'bilinear'", ")", ":", "\n", "    ", "\"\"\"Resize batch [-1.0, 1.0] images of shape (N * H * W (* 3)).\n\n    Args:\n        size : int, float or tuple\n            * int   - Percentage of current size.\n            * float - Fraction of current size.\n            * tuple - Size of the output image.\n\n        interp : str, optional\n            Interpolation to use for re-sizing ('nearest', 'lanczos',\n            'bilinear', 'bicubic' or 'cubic').\n    \"\"\"", "\n", "rs_imgs", "=", "[", "]", "\n", "for", "img", "in", "images", ":", "\n", "        ", "rs_imgs", ".", "append", "(", "imresize", "(", "img", ",", "size", ",", "interp", ")", ")", "\n", "", "return", "np", ".", "array", "(", "rs_imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.transform.immerge": [[65, 86], ["enumerate", "numpy.zeros", "numpy.zeros"], "function", ["None"], ["", "def", "immerge", "(", "images", ",", "row", ",", "col", ",", "target", "=", "None", ")", ":", "\n", "    ", "\"\"\"Merge images into an image with (row * h) * (col * w).\n\n    `images` is in shape of N * H * W(* C=1 or 3)\n    \"\"\"", "\n", "targer_flag", "=", "1", "if", "target", "is", "not", "None", "else", "0", "\n", "h", ",", "w", "=", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", "\n", "if", "images", ".", "ndim", "==", "4", ":", "\n", "        ", "img", "=", "np", ".", "zeros", "(", "(", "h", "*", "row", "*", "(", "targer_flag", "+", "1", ")", ",", "w", "*", "col", ",", "images", ".", "shape", "[", "3", "]", ")", ")", "\n", "", "elif", "images", ".", "ndim", "==", "3", ":", "\n", "        ", "img", "=", "np", ".", "zeros", "(", "(", "h", "*", "row", ",", "w", "*", "col", ")", ")", "\n", "", "for", "idx", ",", "image", "in", "enumerate", "(", "images", ")", ":", "\n", "        ", "i", "=", "idx", "%", "col", "\n", "j", "=", "idx", "//", "col", "\n", "if", "targer_flag", ":", "\n", "            ", "img", "[", "(", "2", "*", "j", ")", "*", "h", ":", "(", "2", "*", "j", ")", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", ",", "...", "]", "=", "target", "[", "idx", "]", "\n", "img", "[", "(", "2", "*", "j", "+", "1", ")", "*", "h", ":", "(", "2", "*", "j", "+", "1", ")", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", ",", "...", "]", "=", "image", "\n", "", "else", ":", "\n", "            ", "img", "[", "j", "*", "h", ":", "j", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", ",", "...", "]", "=", "image", "\n", "\n", "", "", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.basic.imread": [[11, 40], ["isinstance", "numpy.array", "basic.imread._imread"], "function", ["None"], ["def", "imread", "(", "paths", ",", "mode", "=", "'RGB'", ")", ":", "\n", "    ", "\"\"\"Read image(s).\n\n    if `paths` is a list or tuple, then read a list of images into [-1.0, 1.0]\n    of float and return the numpy array batch in shape of N * H * W (* C)\n    if `paths` is a single str, then read an image into [-1.0, 1.0] of float\n\n    Args:\n        mode: It can be one of the following strings:\n            * 'L' (8 - bit pixels, black and white)\n            * 'P' (8 - bit pixels, mapped to any other mode using a color palette)\n            * 'RGB' (3x8 - bit pixels, true color)\n            * 'RGBA' (4x8 - bit pixels, true color with transparency mask)\n            * 'CMYK' (4x8 - bit pixels, color separation)\n            * 'YCbCr' (3x8 - bit pixels, color video format)\n            * 'I' (32 - bit signed integer pixels)\n            * 'F' (32 - bit floating point pixels)\n\n    Returns:\n        Float64 image in [-1.0, 1.0].\n    \"\"\"", "\n", "def", "_imread", "(", "path", ",", "mode", "=", "'RGB'", ")", ":", "\n", "        ", "return", "scipy", ".", "misc", ".", "imread", "(", "path", ",", "mode", "=", "mode", ")", "/", "127.5", "-", "1", "\n", "\n", "", "if", "isinstance", "(", "paths", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "images", "=", "[", "_imread", "(", "path", ",", "mode", ")", "for", "path", "in", "paths", "]", "\n", "return", "np", ".", "array", "(", "images", ")", "\n", "", "else", ":", "\n", "        ", "return", "_imread", "(", "paths", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.basic.imwrite": [[42, 48], ["scipy.misc.imsave", "numpy.array", "to_range"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.to_range"], ["", "", "def", "imwrite", "(", "image", ",", "path", ")", ":", "\n", "    ", "\"\"\"Save an [-1.0, 1.0] image.\"\"\"", "\n", "if", "image", ".", "ndim", "==", "3", "and", "image", ".", "shape", "[", "2", "]", "==", "1", ":", "# for gray image", "\n", "        ", "image", "=", "np", ".", "array", "(", "image", ",", "copy", "=", "True", ")", "\n", "image", ".", "shape", "=", "image", ".", "shape", "[", "0", ":", "2", "]", "\n", "", "return", "scipy", ".", "misc", ".", "imsave", "(", "path", ",", "to_range", "(", "image", ",", "0", ",", "255", ",", "np", ".", "uint8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.basic.imshow": [[50, 56], ["matplotlib.imshow", "numpy.array", "to_range", "matplotlib.gray"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.basic.imshow", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.to_range"], ["", "def", "imshow", "(", "image", ")", ":", "\n", "    ", "\"\"\"Show a [-1.0, 1.0] image.\"\"\"", "\n", "if", "image", ".", "ndim", "==", "3", "and", "image", ".", "shape", "[", "2", "]", "==", "1", ":", "# for gray image", "\n", "        ", "image", "=", "np", ".", "array", "(", "image", ",", "copy", "=", "True", ")", "\n", "image", ".", "shape", "=", "image", ".", "shape", "[", "0", ":", "2", "]", "\n", "", "plt", ".", "imshow", "(", "to_range", "(", "image", ")", ",", "cmap", "=", "plt", ".", "gray", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.to_range": [[8, 18], ["numpy.min", "numpy.max", "numpy.np.uint8"], "function", ["None"], ["def", "to_range", "(", "images", ",", "min_value", "=", "0.0", ",", "max_value", "=", "1.0", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Transform images from [-1.0, 1.0] to [min_value, max_value] of dtype.\"\"\"", "\n", "assert", "np", ".", "min", "(", "images", ")", ">=", "-", "1.0", "-", "1e-5", "and", "np", ".", "max", "(", "images", ")", "<=", "1.0", "+", "1e-5", "and", "(", "images", ".", "dtype", "==", "np", ".", "float32", "or", "images", ".", "dtype", "==", "np", ".", "float64", ")", ",", "(", "'The input images should be float64(32) '", "\n", "'and in the range of [-1.0, 1.0]!'", ")", "\n", "if", "dtype", "is", "None", ":", "\n", "        ", "dtype", "=", "images", ".", "dtype", "\n", "", "return", "(", "(", "images", "+", "1.", ")", "/", "2.", "*", "(", "max_value", "-", "min_value", ")", "+", "\n", "min_value", ")", ".", "astype", "(", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.uint2im": [[20, 24], ["None"], "function", ["None"], ["", "def", "uint2im", "(", "images", ")", ":", "\n", "    ", "\"\"\"Transform images from uint8 to [-1.0, 1.0] of float64.\"\"\"", "\n", "assert", "images", ".", "dtype", "==", "np", ".", "uint8", ",", "'The input images type should be uint8!'", "\n", "return", "images", "/", "127.5", "-", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.float2im": [[26, 32], ["numpy.min", "numpy.max"], "function", ["None"], ["", "def", "float2im", "(", "images", ")", ":", "\n", "    ", "\"\"\"Transform images from [0, 1.0] to [-1.0, 1.0].\"\"\"", "\n", "assert", "np", ".", "min", "(", "images", ")", ">=", "0.0", "-", "1e-5", "and", "np", ".", "max", "(", "images", ")", "<=", "1.0", "+", "1e-5", "and", "(", "images", ".", "dtype", "==", "np", ".", "float32", "or", "images", ".", "dtype", "==", "np", ".", "float64", ")", ",", "'The input images should be float64(32) and in the range of [0.0, 1.0]!'", "\n", "return", "images", "*", "2", "-", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.im2uint": [[34, 37], ["dtype.to_range"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.to_range"], ["", "def", "im2uint", "(", "images", ")", ":", "\n", "    ", "\"\"\"Transform images from [-1.0, 1.0] to uint8.\"\"\"", "\n", "return", "to_range", "(", "images", ",", "0", ",", "255", ",", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.im2float": [[39, 42], ["dtype.to_range"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.to_range"], ["", "def", "im2float", "(", "images", ")", ":", "\n", "    ", "\"\"\"Transform images from [-1.0, 1.0] to [0.0, 1.0].\"\"\"", "\n", "return", "to_range", "(", "images", ",", "0.0", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.float2uint": [[44, 50], ["numpy.min", "numpy.max"], "function", ["None"], ["", "def", "float2uint", "(", "images", ")", ":", "\n", "    ", "\"\"\"Transform images from [0, 1.0] to uint8.\"\"\"", "\n", "assert", "np", ".", "min", "(", "images", ")", ">=", "0.0", "-", "1e-5", "and", "np", ".", "max", "(", "images", ")", "<=", "1.0", "+", "1e-5", "and", "(", "images", ".", "dtype", "==", "np", ".", "float32", "or", "images", ".", "dtype", "==", "np", ".", "float64", ")", ",", "'The input images should be float64(32) and in the range of [0.0, 1.0]!'", "\n", "return", "(", "images", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.imlib.dtype.uint2float": [[52, 56], ["None"], "function", ["None"], ["", "def", "uint2float", "(", "images", ")", ":", "\n", "    ", "\"\"\"Transform images from uint8 to [0.0, 1.0] of float64.\"\"\"", "\n", "assert", "images", ".", "dtype", "==", "np", ".", "uint8", ",", "'The input images type should be uint8!'", "\n", "return", "images", "/", "255.0", "\n", "", ""]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.session": [[10, 17], ["tensorflow.ConfigProto", "tensorflow.Session"], "function", ["None"], ["def", "session", "(", "graph", "=", "None", ",", "allow_soft_placement", "=", "True", ",", "\n", "log_device_placement", "=", "False", ",", "allow_growth", "=", "True", ")", ":", "\n", "    ", "\"\"\"Return a Session with simple config.\"\"\"", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "allow_soft_placement", ",", "\n", "log_device_placement", "=", "log_device_placement", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "allow_growth", "\n", "return", "tf", ".", "Session", "(", "graph", "=", "graph", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.print_tensor": [[19, 35], ["enumerate", "isinstance", "str", "print", "type", "Exception", "str", "str", "tensor.get_shape"], "function", ["None"], ["", "def", "print_tensor", "(", "tensors", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "tensors", "=", "[", "tensors", "]", "\n", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "tensors", ")", ":", "\n", "        ", "ctype", "=", "str", "(", "type", "(", "tensor", ")", ")", "\n", "if", "'Tensor'", "in", "ctype", ":", "\n", "            ", "type_name", "=", "'Tensor'", "\n", "", "elif", "'Variable'", "in", "ctype", ":", "\n", "            ", "type_name", "=", "'Variable'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Not a Tensor or Variable!'", ")", "\n", "\n", "", "print", "(", "str", "(", "i", ")", "+", "(", "': %s(\"%s\", shape=%s, dtype=%s, device=%s)'", "\n", "%", "(", "type_name", ",", "tensor", ".", "name", ",", "str", "(", "tensor", ".", "get_shape", "(", ")", ")", ",", "\n", "tensor", ".", "dtype", ".", "name", ",", "tensor", ".", "device", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.shape": [[39, 42], ["tensor.get_shape().as_list", "tensor.get_shape"], "function", ["None"], ["def", "shape", "(", "tensor", ")", ":", "\n", "    ", "sp", "=", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "return", "[", "num", "if", "num", "is", "not", "None", "else", "-", "1", "for", "num", "in", "sp", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.summary": [[44, 95], ["tensorflow.summary.merge", "isinstance", "tensorflow.name_scope", "isinstance", "tensorflow.summary.merge", "re.sub", "re.sub", "len", "summaries.append", "tensor_collection.items", "tensorflow.summary.scalar", "tensorflow.reduce_mean", "summaries.append", "tensorflow.reduce_mean", "tensorflow.sqrt", "summaries.append", "summaries.append", "summaries.append", "summaries.append", "summaries.append", "summaries.append", "summaries.append", "tensorflow.summary.scalar", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "utils.summary._summary"], "function", ["None"], ["", "def", "summary", "(", "tensor_collection", ",", "\n", "summary_type", "=", "[", "'mean'", ",", "'stddev'", ",", "'max'", ",", "'min'", ",", "'sparsity'", ",", "'histogram'", "]", ",", "\n", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Summary.\n\n    usage:\n        1. summary(tensor)\n        2. summary([tensor_a, tensor_b])\n        3. summary({tensor_a: 'a', tensor_b: 'b})\n    \"\"\"", "\n", "def", "_summary", "(", "tensor", ",", "name", ",", "summary_type", ")", ":", "\n", "        ", "\"\"\"Attach a lot of summaries to a Tensor.\"\"\"", "\n", "if", "name", "is", "None", ":", "\n", "# Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training", "\n", "# session. This helps the clarity of presentation on tensorboard.", "\n", "            ", "name", "=", "re", ".", "sub", "(", "'%s_[0-9]*/'", "%", "'tower'", ",", "''", ",", "tensor", ".", "name", ")", "\n", "name", "=", "re", ".", "sub", "(", "':'", ",", "'-'", ",", "name", ")", "\n", "\n", "", "summaries", "=", "[", "]", "\n", "if", "len", "(", "tensor", ".", "shape", ")", "==", "0", ":", "\n", "            ", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "name", ",", "tensor", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "'mean'", "in", "summary_type", ":", "\n", "                ", "mean", "=", "tf", ".", "reduce_mean", "(", "tensor", ")", "\n", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "name", "+", "'/mean'", ",", "mean", ")", ")", "\n", "", "if", "'stddev'", "in", "summary_type", ":", "\n", "                ", "mean", "=", "tf", ".", "reduce_mean", "(", "tensor", ")", "\n", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tensor", "-", "mean", ")", ")", ")", "\n", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "name", "+", "'/stddev'", ",", "stddev", ")", ")", "\n", "", "if", "'max'", "in", "summary_type", ":", "\n", "                ", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "name", "+", "'/max'", ",", "tf", ".", "reduce_max", "(", "tensor", ")", ")", ")", "\n", "", "if", "'min'", "in", "summary_type", ":", "\n", "                ", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "name", "+", "'/min'", ",", "tf", ".", "reduce_min", "(", "tensor", ")", ")", ")", "\n", "", "if", "'sparsity'", "in", "summary_type", ":", "\n", "                ", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "name", "+", "'/sparsity'", ",", "tf", ".", "nn", ".", "zero_fraction", "(", "tensor", ")", ")", ")", "\n", "", "if", "'histogram'", "in", "summary_type", ":", "\n", "                ", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "histogram", "(", "name", ",", "tensor", ")", ")", "\n", "", "", "return", "tf", ".", "summary", ".", "merge", "(", "summaries", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "tensor_collection", ",", "(", "list", ",", "tuple", ",", "dict", ")", ")", ":", "\n", "        ", "tensor_collection", "=", "[", "tensor_collection", "]", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "scope", ",", "'summary'", ")", ":", "\n", "        ", "summaries", "=", "[", "]", "\n", "if", "isinstance", "(", "tensor_collection", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "for", "tensor", "in", "tensor_collection", ":", "\n", "                ", "summaries", ".", "append", "(", "_summary", "(", "tensor", ",", "None", ",", "summary_type", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "tensor", ",", "name", "in", "tensor_collection", ".", "items", "(", ")", ":", "\n", "                ", "summaries", ".", "append", "(", "_summary", "(", "tensor", ",", "name", ",", "summary_type", ")", ")", "\n", "", "", "return", "tf", ".", "summary", ".", "merge", "(", "summaries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.utils.counter": [[97, 105], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.assign", "tensorflow.add", "tensorflow.constant_initializer"], "function", ["None"], ["", "", "def", "counter", "(", "start", "=", "0", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'counter'", ")", ":", "\n", "        ", "counter", "=", "tf", ".", "get_variable", "(", "name", "=", "'counter'", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "start", ")", ",", "\n", "shape", "=", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "update_cnt", "=", "tf", ".", "assign", "(", "counter", ",", "tf", ".", "add", "(", "counter", ",", "1", ")", ")", "\n", "return", "counter", ",", "update_cnt", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.checkpoint.load_checkpoint": [[10, 23], ["os.path.isdir", "tensorflow.train.Saver", "tf.train.Saver.restore", "print", "tensorflow.train.latest_checkpoint"], "function", ["None"], ["def", "load_checkpoint", "(", "ckpt_dir_or_file", ",", "session", ",", "var_list", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load checkpoint.\n\n    Note:\n        This function add some useless ops to the graph. It is better\n        to use tf.train.init_from_checkpoint(...).\n    \"\"\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "ckpt_dir_or_file", ")", ":", "\n", "        ", "ckpt_dir_or_file", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "ckpt_dir_or_file", ")", "\n", "\n", "", "restorer", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", ")", "\n", "restorer", ".", "restore", "(", "session", ",", "ckpt_dir_or_file", ")", "\n", "print", "(", "' [*] Loading checkpoint succeeds! Copy variables from % s!'", "%", "ckpt_dir_or_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.checkpoint.init_from_checkpoint": [[25, 28], ["tensorflow.train.init_from_checkpoint", "print"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.checkpoint.init_from_checkpoint"], ["", "def", "init_from_checkpoint", "(", "ckpt_dir_or_file", ",", "assignment_map", "=", "{", "'/'", ":", "'/'", "}", ")", ":", "\n", "    ", "tf", ".", "train", ".", "init_from_checkpoint", "(", "ckpt_dir_or_file", ",", "assignment_map", ")", "\n", "print", "(", "' [*] Loading checkpoint succeeds! Copy variables from % s!'", "%", "ckpt_dir_or_file", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.variable.tensors_filter": [[8, 32], ["isinstance", "isinstance", "isinstance", "f_tens.append", "f_tens.append"], "function", ["None"], ["def", "tensors_filter", "(", "tensors", ",", "filters", ",", "combine_type", "=", "'or'", ")", ":", "\n", "    ", "assert", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", ",", "'`tensors` shoule be a list or tuple!'", "\n", "assert", "isinstance", "(", "filters", ",", "(", "str", ",", "list", ",", "tuple", ")", ")", ",", "'`filters` should be a string or a list(tuple) of strings!'", "\n", "assert", "combine_type", "==", "'or'", "or", "combine_type", "==", "'and'", ",", "\"`combine_type` should be 'or' or 'and'!\"", "\n", "\n", "if", "isinstance", "(", "filters", ",", "str", ")", ":", "\n", "        ", "filters", "=", "[", "filters", "]", "\n", "\n", "", "f_tens", "=", "[", "]", "\n", "for", "ten", "in", "tensors", ":", "\n", "        ", "if", "combine_type", "==", "'or'", ":", "\n", "            ", "for", "filt", "in", "filters", ":", "\n", "                ", "if", "filt", "in", "ten", ".", "name", ":", "\n", "                    ", "f_tens", ".", "append", "(", "ten", ")", "\n", "break", "\n", "", "", "", "elif", "combine_type", "==", "'and'", ":", "\n", "            ", "all_pass", "=", "True", "\n", "for", "filt", "in", "filters", ":", "\n", "                ", "if", "filt", "not", "in", "ten", ".", "name", ":", "\n", "                    ", "all_pass", "=", "False", "\n", "break", "\n", "", "", "if", "all_pass", ":", "\n", "                ", "f_tens", ".", "append", "(", "ten", ")", "\n", "", "", "", "return", "f_tens", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.variable.global_variables": [[34, 40], ["tensorflow.global_variables", "variable.tensors_filter"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.variable.global_variables", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.variable.tensors_filter"], ["", "def", "global_variables", "(", "filters", "=", "None", ",", "combine_type", "=", "'or'", ")", ":", "\n", "    ", "global_vars", "=", "tf", ".", "global_variables", "(", ")", "\n", "if", "filters", "is", "None", ":", "\n", "        ", "return", "global_vars", "\n", "", "else", ":", "\n", "        ", "return", "tensors_filter", "(", "global_vars", ",", "filters", ",", "combine_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.variable.trainable_variables": [[42, 48], ["tensorflow.trainable_variables", "variable.tensors_filter"], "function", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.variable.trainable_variables", "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.tflib.variable.tensors_filter"], ["", "", "def", "trainable_variables", "(", "filters", "=", "None", ",", "combine_type", "=", "'or'", ")", ":", "\n", "    ", "t_var", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "if", "filters", "is", "None", ":", "\n", "        ", "return", "t_var", "\n", "", "else", ":", "\n", "        ", "return", "tensors_filter", "(", "t_var", ",", "filters", ",", "combine_type", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.ops.layers.flatten_fully_connected": [[9, 40], ["tensorflow.xavier_initializer", "tensorflow.zeros_initializer", "tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.flatten"], "function", ["None"], ["def", "flatten_fully_connected", "(", "inputs", ",", "\n", "num_outputs", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "normalizer_fn", "=", "None", ",", "\n", "normalizer_params", "=", "None", ",", "\n", "weights_initializer", "=", "slim", ".", "xavier_initializer", "(", ")", ",", "\n", "weights_regularizer", "=", "None", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "biases_regularizer", "=", "None", ",", "\n", "reuse", "=", "None", ",", "\n", "variables_collections", "=", "None", ",", "\n", "outputs_collections", "=", "None", ",", "\n", "trainable", "=", "True", ",", "\n", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'flatten_fully_connected'", ",", "[", "inputs", "]", ")", ":", "\n", "        ", "if", "inputs", ".", "shape", ".", "ndims", ">", "2", ":", "\n", "            ", "inputs", "=", "slim", ".", "flatten", "(", "inputs", ")", "\n", "", "return", "slim", ".", "fully_connected", "(", "inputs", ",", "\n", "num_outputs", ",", "\n", "activation_fn", ",", "\n", "normalizer_fn", ",", "\n", "normalizer_params", ",", "\n", "weights_initializer", ",", "\n", "weights_regularizer", ",", "\n", "biases_initializer", ",", "\n", "biases_regularizer", ",", "\n", "reuse", ",", "\n", "variables_collections", ",", "\n", "outputs_collections", ",", "\n", "trainable", ",", "\n", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__init__": [[26, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "timer", "=", "timeit", ".", "default_timer", ",", "is_output", "=", "True", ",", "fmt", "=", "'s'", ")", ":", "\n", "        ", "assert", "fmt", "in", "[", "'ms'", ",", "'s'", ",", "'datetime'", "]", ",", "\"`fmt` should be 'ms', 's' or 'datetime'!\"", "\n", "self", ".", "_timer", "=", "timer", "\n", "self", ".", "_is_output", "=", "is_output", "\n", "self", ".", "_fmt", "=", "fmt", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__enter__": [[32, 36], ["timer.Timer.start"], "methods", ["home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.start"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Start the timer in the context manager scope.\"\"\"", "\n", "self", ".", "start", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__exit__": [[37, 41], ["print", "str"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "exc_traceback", ")", ":", "\n", "        ", "\"\"\"Set the end time.\"\"\"", "\n", "if", "self", ".", "_is_output", ":", "\n", "            ", "print", "(", "str", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.__str__": [[42, 47], ["str"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_fmt", "!=", "'datetime'", ":", "\n", "            ", "return", "'%s %s'", "%", "(", "self", ".", "elapsed", ",", "self", ".", "_fmt", ")", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "self", ".", "elapsed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.start": [[48, 50], ["timer.Timer._timer"], "methods", ["None"], ["", "", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "self", ".", "_timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.Timer.elapsed": [[51, 62], ["timer.Timer._timer", "datetime.timedelta"], "methods", ["None"], ["", "@", "property", "\n", "def", "elapsed", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the current elapsed time since start.\"\"\"", "\n", "e", "=", "self", ".", "_timer", "(", ")", "-", "self", ".", "start_time", "\n", "\n", "if", "self", ".", "_fmt", "==", "'ms'", ":", "\n", "            ", "return", "e", "*", "1000", "\n", "", "elif", "self", ".", "_fmt", "==", "'s'", ":", "\n", "            ", "return", "e", "\n", "", "elif", "self", ".", "_fmt", "==", "'datetime'", ":", "\n", "            ", "return", "datetime", ".", "timedelta", "(", "seconds", "=", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.timer.timer": [[64, 83], ["print", "timer.Timer", "f", "str"], "function", ["None"], ["", "", "", "def", "timer", "(", "**", "timer_kwargs", ")", ":", "\n", "    ", "\"\"\"Function decorator displaying the function execution time.\n\n    All kwargs are the arguments taken by the Timer class constructor.\n    \"\"\"", "\n", "# store Timer kwargs in local variable so the namespace isn't polluted", "\n", "# by different level args and kwargs", "\n", "\n", "def", "wrapped_f", "(", "f", ")", ":", "\n", "        ", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "fmt", "=", "'[*] function \"%(function_name)s\" execution time: %(execution_time)s [*]'", "\n", "with", "Timer", "(", "**", "timer_kwargs", ")", "as", "t", ":", "\n", "                ", "out", "=", "f", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "context", "=", "{", "'function_name'", ":", "f", ".", "__name__", ",", "'execution_time'", ":", "str", "(", "t", ")", "}", "\n", "print", "(", "fmt", "%", "context", ")", "\n", "return", "out", "\n", "", "return", "wrapped", "\n", "\n", "", "return", "wrapped_f", "\n", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.utils.add_path": [[9, 15], ["isinstance", "sys.path.insert"], "function", ["None"], ["\n", "def", "session", "(", "graph", "=", "None", ",", "allow_soft_placement", "=", "True", ",", "\n", "log_device_placement", "=", "False", ",", "allow_growth", "=", "True", ")", ":", "\n", "    ", "\"\"\"Return a Session with simple config.\"\"\"", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "allow_soft_placement", ",", "\n", "log_device_placement", "=", "log_device_placement", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "allow_growth", "\n"]], "home.repos.pwc.inspect_result.huangqiusheng_bridgegan.pylib.utils.mkdir": [[17, 23], ["isinstance", "os.path.isdir", "os.makedirs"], "function", ["None"], ["\n", "\n", "", "def", "print_tensor", "(", "tensors", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "tensors", "=", "[", "tensors", "]", "\n", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "tensors", ")", ":", "\n"]]}