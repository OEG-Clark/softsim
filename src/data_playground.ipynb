{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preprocess\n",
    "Dataset contains two parts:\n",
    "##### Repo_data:\n",
    "    unique_name: author_repo\n",
    "    {\n",
    "        'reference': reference index (str)\n",
    "        'abstract': abstract of the paper (str)\n",
    "        'tasks': task given by paper with code (list of strs)\n",
    "        ‘author’: author name\n",
    "        'url': Github repo link\n",
    "        'repo': repo name\n",
    "    }\n",
    "\n",
    "##### Final_dataset:\n",
    "    json result from cleaning\n",
    "    ...unique_name.folder.file.class.function:\n",
    "        [min_line, max_line]: the line index of the function in file\n",
    "        [all call info]: all call information\n",
    "        'function'/'method': if in a class or not\n",
    "        [inside call info]: call functions or methods in the repo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Data Info\n",
    "The dataset contains 2021 repos, with 894 total classes in various perspectives"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    }
   ],
   "source": [
    "with open('D:\\\\Projects\\\\UPM\\\\RepoUnder\\\\data\\\\matching_data.json', 'r') as f:\n",
    "    abs_data = json.load(f)\n",
    "print(len(abs_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200.448787728847\n"
     ]
    }
   ],
   "source": [
    "abs_len = 0\n",
    "for key, val in abs_data.items():\n",
    "    abs_len += len(val['abstract'])\n",
    "print(abs_len/2021)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Constituency Grammar Induction': 1, 'Deep Clustering': 6, 'Metric Learning': 13, 'Depth Estimation': 22, 'Monocular Depth Estimation': 10, '2D Human Pose Estimation': 3, '3D Human Pose Estimation': 6, '3D Human Reconstruction': 1, '3D Human Shape Estimation': 2, '3D Multi-Person Mesh Recovery': 2, '3D Multi-Person Pose Estimation': 2, 'Monocular 3D Human Pose Estimation': 1, 'Pose Estimation': 28, 'Cross-Modal Retrieval': 4, 'Music Tagging': 1, 'TAG': 8, 'Word Embeddings': 25, 'Model Selection': 7, 'Multi Label Text Classification': 2, 'Multi-Label Text Classification': 3, 'Text Classification': 25, 'Response Generation': 9, 'Self-Supervised Learning': 35, 'Session-Based Recommendations': 4, 'Counterfactual Inference': 3, 'Multi-Task Learning': 23, 'Natural Language Processing': 51, 'Populist attitude': 1, 'Crime Prediction': 2, 'Entity Alignment': 7, 'Graph Sampling': 3, 'Knowledge Graphs': 27, 'Semantic Parsing': 10, 'Active Learning': 15, 'Grammatical Error Correction': 4, 'Transfer Learning': 66, 'Image-to-Image Translation': 20, 'Translation': 107, 'Density Estimation': 7, 'Image Generation': 42, 'Unsupervised Landmark Detection': 1, 'Gaussian Processes': 12, 'Graph Classification': 7, 'Graph Reconstruction': 1, 'Graph Representation Learning': 6, 'Representation Learning': 89, 'Incremental Learning': 4, 'Person Re-Identification': 11, 'Classification': 73, 'General Classification': 115, 'Image Classification': 101, 'Data Augmentation': 70, 'MRI Reconstruction': 3, 'Object Tracking': 17, 'online learning': 14, 'Visual Object Tracking': 8, 'Visual Tracking': 7, '6D Pose Estimation using RGB': 3, 'Answer Generation': 1, 'Opinion Mining': 2, 'Question Answering': 60, 'Variational Inference': 22, 'Image Super-Resolution': 21, 'Single Image Super Resolution': 14, 'Super-Resolution': 37, 'reinforcement-learning': 119, 'Dialogue Generation': 8, 'Natural Language Inference': 24, 'Drug Discovery': 3, 'Motion Forecasting': 1, 'object-detection': 113, 'Object Detection': 117, 'Federated Learning': 12, 'Image Reconstruction': 18, 'Gesture Recognition': 3, 'Semi Supervised Text Classification': 1, 'Semi-Supervised Text Classification': 1, 'Multiple Instance Learning': 4, 'Weakly Supervised Object Detection': 1, '6D Pose Estimation': 3, 'General Classification Selection': 1, 'Decision Making': 36, 'Retinal OCT Layer Segmentation': 1, 'Domain Generalization': 18, 'Out-of-Distribution Generalization': 4, 'Grounded language learning': 2, 'Systematic Generalization': 7, 'Machine Translation': 60, 'Edge-computing': 1, 'Dimensionality Reduction': 5, 'Image Dehazing': 1, 'Traffic Prediction': 2, 'Semantic Segmentation': 123, 'Lemmatization': 1, 'Cross-Lingual Transfer': 10, 'Sentiment Analysis': 26, 'Transliteration': 3, 'Dynamic Time Warping': 3, 'Time Series': 28, 'Multi-agent Reinforcement Learning': 17, 'Visual Place Recognition': 3, 'Few-Shot Learning': 31, 'Natural Language Understanding': 24, 'NER': 15, 'Graph Matching': 4, 'Re-Ranking': 4, 'Domain Adaptation': 41, 'Knowledge Distillation': 20, 'Multi-target Domain Adaptation': 1, 'Language Modelling': 77, 'Text Generation': 25, 'Quantization': 27, 'Q-Learning': 22, 'Image Retrieval': 10, 'OOD Detection': 6, '3D Multi-Object Tracking': 1, 'Multi-Object Tracking': 7, 'Trajectory Prediction': 3, 'Causal Inference': 9, 'Fairness': 12, 'Instance Segmentation': 28, 'Semantic correspondence': 2, '2D object detection': 3, 'Video Understanding': 9, 'Anomaly Detection': 21, 'Disentanglement': 17, 'Real-Time Semantic Segmentation': 2, 'Long-range modeling': 1, 'Video Recognition': 6, 'Video Question Answering': 5, 'Visual Question Answering': 20, 'VQA': 13, 'Variational Monte Carlo': 3, 'Conversational Question Answering': 2, 'Graph Learning': 12, 'Graph structure learning': 2, 'Visual Dialog': 3, 'Lexical Normalization': 1, 'Continuous Control': 15, 'Hierarchical Reinforcement Learning': 4, 'Continual Learning': 19, 'Action Detection': 7, 'Action Localization': 4, 'Action Recognition': 16, 'Action Recognition In Videos': 2, 'Action Recognition In Videos ': 2, 'Dependency Parsing': 9, 'Morphological Disambiguation': 1, 'Code Generation': 6, 'motion prediction': 2, 'Part-Of-Speech Tagging': 4, 'Automatic Speech Recognition': 5, 'Speech Recognition': 12, 'Medical Image Segmentation': 18, 'Network Pruning': 6, 'Keyword Extraction': 1, 'Denoising': 28, 'Entity Typing': 9, 'feature selection': 8, 'Few-Shot Image Classification': 15, 'Rain Removal': 2, 'Relation Extraction': 15, 'Abstractive Text Summarization': 11, 'Structured Prediction': 10, 'Card Games': 1, 'Brain Segmentation': 2, 'Image Restoration': 8, 'Autonomous Navigation': 5, 'Autonomous Vehicles': 10, 'Scene Understanding': 10, 'Text-To-Sql': 2, 'Graph Embedding': 7, 'graph partitioning': 1, 'Adversarial Robustness': 12, '3D Object Detection': 14, 'Music Source Separation': 3, 'Multi-class Classification': 6, 'Offline RL': 4, 'Meta-Learning': 36, 'Zero-Shot Learning': 12, 'Optical Flow Estimation': 12, 'Bayesian Inference': 8, 'Multi-Agent Path Finding': 2, 'Adversarial Attack': 20, 'Adversarial Defense': 5, 'Image Compression': 9, 'Image Inpainting': 13, 'Contrastive Learning': 44, 'Cardiac Segmentation': 3, 'Unsupervised Domain Adaptation': 17, 'Pretrained Language Models': 12, 'Slot Filling': 3, 'Spoken Language Understanding': 3, 'Model extraction': 1, 'Combinatorial Optimization': 7, 'Learning-To-Rank': 4, 'Model Compression': 9, 'AMR-to-Text Generation': 1, 'Graph-to-Sequence': 1, 'Weather Forecasting': 3, 'SMAC': 2, 'Bilevel Optimization': 6, 'Neural Architecture Search': 27, 'Out-of-Distribution Detection': 7, 'Video Super-Resolution': 3, 'Deblurring': 5, 'Image Deblurring': 3, 'Imputation': 5, 'Image Denoising': 8, 'Entity Retrieval': 1, 'Mathematical Reasoning': 2, 'Math Word Problem Solving': 1, 'Scene Text Recognition': 7, 'Open World Object Detection': 1, 'Token Classification': 2, 'Inference Attack': 1, 'Object Reconstruction': 3, 'Real-World Adversarial Attack': 1, 'AutoML': 10, 'Click-Through Rate Prediction': 2, 'Salient Object Detection': 11, 'Multi-Label Classification': 8, '3D Face Reconstruction': 2, 'Face Reconstruction': 2, 'Facial Inpainting': 1, 'Chatbot': 4, 'Lesion Segmentation': 8, 'Skin Lesion Segmentation': 2, 'GZSL Video Classification': 1, 'ZSL Video Classification': 1, 'Face Generation': 5, 'Face Recognition': 13, 'Few Shot Action Recognition': 1, 'Event Extraction': 6, 'Joint Entity and Relation Extraction': 2, 'named-entity-recognition': 17, 'Named Entity Recognition': 17, 'Interactive Segmentation': 4, 'Document Summarization': 8, 'Extractive Text Summarization': 2, 'Text Summarization': 14, 'few-shot-ner': 1, 'Few-shot NER': 1, 'Neural Rendering': 4, 'Knowledge Base Question Answering': 2, 'Hyperparameter Optimization': 7, 'Interpretable Machine Learning': 2, 'Document Classification': 5, 'Traveling Salesman Problem': 5, 'Computed Tomography (CT)': 9, 'Image Registration': 7, 'Medical Image Registration': 5, 'Video Object Segmentation': 3, 'Video Segmentation': 2, 'Video Semantic Segmentation': 4, 'Visual Grounding': 3, 'Video Inpainting': 1, 'Reading Comprehension': 19, 'Keypoint Estimation': 2, 'Region Proposal': 5, 'Machine Reading Comprehension': 5, 'Object Discovery': 2, 'Visual Navigation': 4, 'Video Instance Segmentation': 3, 'Question Generation': 7, 'Inductive Bias': 20, '3D Object Detection From Stereo Images': 1, 'Autonomous Driving': 21, 'Disparity Estimation': 2, 'Stereo Depth Estimation': 1, 'Stereo Disparity Estimation': 1, 'Network Embedding': 3, 'Node Classification': 15, 'Informativeness': 5, 'Link Prediction': 13, 'Medical Diagnosis': 1, 'Text to image generation': 4, 'Text-to-Image Generation': 4, 'Sentence Classification': 3, 'Recommendation Systems': 26, 'Selection bias': 2, 'Survival Analysis': 3, 'Unsupervised Machine Translation': 1, 'Deep Attention': 1, 'Collaborative Filtering': 7, 'Feature Engineering': 9, 'Tensor Networks': 3, 'Neural Network Compression': 6, 'Referring Expression': 3, 'Breast Cancer Detection': 1, 'Fake News Detection': 3, 'Misinformation': 6, 'Mortality Prediction': 2, 'Sign Language Recognition': 3, 'Morphological Analysis': 2, 'Zero-Shot Cross-Lingual Transfer': 2, 'Bokeh Effect Rendering': 1, 'Ensemble Learning': 4, 'AMR Parsing': 2, 'Semantic Role Labeling': 9, 'Motion Planning': 2, 'Data Poisoning': 2, 'Video-Based Person Re-Identification': 2, 'Open Information Extraction': 1, 'Relation Classification': 1, 'SSIM': 10, 'Imitation Learning': 12, 'Plan2Scene': 1, 'Face Verification': 3, 'Face Reenactment': 1, 'Meeting Summarization': 1, 'Semantic Similarity': 13, 'Semantic Textual Similarity': 15, 'Sentence Embedding': 5, 'Sentence-Embedding': 5, '3D Shape Reconstruction': 5, 'graph construction': 3, 'Triple Classification': 1, 'RGB-D Salient Object Detection': 3, 'Activity Recognition': 6, 'Unsupervised Pre-training': 4, 'Zero-Shot Text-to-Image Generation': 2, 'Optical Character Recognition': 7, 'Fine-Grained Image Classification': 5, 'Graph Generation': 2, 'Panoptic Segmentation': 8, 'Entity Resolution': 1, 'Adversarial Attack Detection': 3, 'EEG': 10, 'Coreference Resolution': 7, 'Task-Oriented Dialogue Systems': 2, 'Sequential Recommendation': 2, 'motion retargeting': 1, 'Cross-Lingual Word Embeddings': 1, 'Self-Learning': 3, 'Action Classification': 6, 'Audio-Visual Active Speaker Detection': 1, 'Stereo Matching': 3, 'Video Object Detection': 1, 'Face Swapping': 4, 'Resynthesis': 1, 'Fraud Detection': 3, 'Lane Detection': 1, 'Real-Time Visual Tracking': 1, 'Room Layout Estimation': 1, 'Superpixels': 1, 'Traffic Sign Detection': 1, 'Traffic Sign Recognition': 1, 'License Plate Recognition': 1, 'Human Parsing': 2, 'Layout-to-Image Generation': 1, 'Dense Object Detection': 1, 'Single Image Deraining': 1, 'Community Detection': 3, 'MS-SSIM': 3, 'Crowd Counting': 2, 'Dynamic Link Prediction': 1, 'Edge Classification': 1, 'Masked Language Modeling': 10, 'Text Matching': 6, 'Human Activity Recognition': 1, 'Unsupervised Image-To-Image Translation': 2, 'Demosaicking': 2, 'Image Deconvolution': 2, 'Object Localization': 5, 'Weakly-Supervised Object Localization': 1, 'Compositional Zero-Shot Learning': 2, 'Conversational Response Selection': 3, 'Text Clustering': 1, 'Temporal Action Proposal Generation': 2, 'class-incremental learning': 2, 'Video Prediction': 7, 'Fact Verification': 3, 'Generalized Few-Shot Learning': 1, 'Facial Editing': 1, 'Attribute Value Extraction': 1, 'Information Retrieval': 12, 'Hate Speech Detection': 2, 'Open Set Learning': 4, 'Video Frame Interpolation': 4, 'Efficient Exploration': 5, 'Knee Osteoarthritis Prediction': 1, 'Atari Games': 8, 'Music Genre Transfer': 1, 'Style Transfer': 11, 'Learning Theory': 3, 'Font Generation': 1, 'Robot Navigation': 2, 'Geometric Matching': 2, 'Virtual Try-on': 2, 'Few-Shot Object Detection': 1, 'Color Constancy': 1, 'Visual Odometry': 2, 'Speech Synthesis': 6, 'Image Augmentation': 6, 'OpenAI Gym': 6, 'Sketch-to-Image Translation': 1, 'Camera Calibration': 1, 'Disease Prediction': 1, 'Pose Retrieval': 1, 'Saliency Prediction': 2, 'Video Generation': 7, 'Conditional Text Generation': 1, 'News Recommendation': 2, 'PointGoal Navigation': 2, 'Genre classification': 1, 'Relational Reasoning': 5, 'Scene Flow Estimation': 3, 'Head Detection': 1, 'Extractive Summarization': 2, 'Multi-Document Summarization': 3, 'Graph Mining': 2, 'Human Detection': 1, 'Person Search': 1, 'Motion Detection': 1, 'Self-Driving Cars': 2, 'Protein Structure Prediction': 1, 'Word Sense Disambiguation': 1, 'Image Captioning': 15, 'Vision and Language Navigation': 2, 'Generalized Zero-Shot Learning': 1, 'Stochastic Optimization': 4, 'Density Ratio Estimation': 1, 'Temporal Action Localization': 8, 'Action Segmentation': 2, 'Chinese Named Entity Recognition': 1, 'Hard Attention': 1, 'eXtreme-Video-Frame-Interpolation': 1, 'Prediction Intervals': 1, 'Topic Models': 3, 'Trajectory Planning': 1, 'POS': 3, 'Extreme Summarization': 2, 'Brain Tumor Segmentation': 4, 'Tumor Segmentation': 5, 'Video Classification': 7, 'RGB Salient Object Detection': 1, 'Multi-Label Learning': 2, 'Speaker Diarization': 1, 'Object Recognition': 9, 'Hand-Gesture Recognition': 1, 'Decision Making Under Uncertainty': 1, 'Distributional Reinforcement Learning': 1, 'Music Information Retrieval': 2, '3D Feature Matching': 2, 'LIDAR Semantic Segmentation': 1, 'Answer Selection': 1, 'Community Question Answering': 2, 'Question Similarity': 1, 'Dialogue State Tracking': 3, 'Sparse Learning': 1, 'Automated Theorem Proving': 1, 'Skull Stripping': 1, 'Robotic Grasping': 1, 'De-identification': 1, 'Face Age Editing': 1, 'Image Manipulation': 4, 'Multimodal Unsupervised Image-To-Image Translation': 2, 'Video Generation from a Single Image': 1, 'Depth Completion': 3, 'Texture Synthesis': 1, 'Unsupervised Anomaly Detection': 3, 'Story Completion': 1, 'Face Identification': 1, 'Change Detection': 3, 'Speaker Verification': 5, 'Binary Relation Extraction': 1, 'Image Retrieval with Multi-Modal Query': 1, 'Text-Image Retrieval': 1, 'Morphology classification': 2, 'Face Detection': 1, 'Medical Image Classification': 2, 'Pose Prediction': 3, 'Conditional Image Generation': 6, 'Car Racing': 1, 'Constituency Parsing': 2, 'Skeleton Based Action Recognition': 2, 'Point Cloud Completion': 2, 'Node Clustering': 2, 'Lesion Classification': 1, 'Skin Lesion Classification': 1, 'Learning with noisy labels': 4, 'Saliency Detection': 4, 'Video Saliency Detection': 1, 'Overall - Test': 2, 'Sleep Staging': 2, 'Seismic Inversion': 1, 'Privacy Preserving': 4, 'Document Ranking': 2, 'Unconditional Image Generation': 1, 'Chunking': 1, 'ECG Classification': 1, 'Electrocardiography (ECG)': 1, 'Line Detection': 1, 'Starcraft': 6, 'Starcraft II': 4, 'Language Acquisition': 1, 'Object Detection In Aerial Images': 3, 'Event Argument Extraction': 2, 'Spatial Interpolation': 1, 'Speaker Recognition': 3, 'Aspect-Based Sentiment Analysis': 7, 'Point Cloud Registration': 7, 'Keyphrase Generation': 2, 'Temporal Localization': 3, 'Weakly Supervised Action Localization': 2, 'Weakly-supervised Temporal Action Localization': 2, 'Weakly Supervised Temporal Action Localization': 2, 'Image Clustering': 3, 'Heterogeneous Face Recognition': 1, 'Scene Parsing': 5, 'Nested Named Entity Recognition': 2, 'Person Recognition': 1, 'Image Quality Assessment': 2, 'Load Forecasting': 1, 'Entity Linking': 4, 'Vehicle Re-Identification': 1, 'Acoustic Scene Classification': 2, 'Audio Classification': 5, 'Audio Tagging': 4, 'Instrument Recognition': 1, 'Citation Recommendation': 1, 'Boundary Detection': 1, 'Speaker Identification': 1, 'Model-based Reinforcement Learning': 2, 'Point Processes': 5, 'Two-sample testing': 3, 'Point cloud reconstruction': 1, 'Intent Detection': 1, 'Real-Time Object Detection': 2, 'Spatio-Temporal Forecasting': 1, 'Robust Design': 1, 'Lung Nodule Segmentation': 1, 'Word Alignment': 3, 'Scene Text Detection': 2, 'Method name prediction': 1, 'Semi-Supervised Image Classification': 5, 'Paraphrase Generation': 2, 'Sentence Embeddings': 6, 'Gaze Prediction': 2, 'Abstractive Dialogue Summarization': 1, 'Multi-domain Dialogue State Tracking': 1, '3D Point Cloud Classification': 2, 'Point Cloud Classification': 2, 'Lung Cancer Diagnosis': 1, 'whole slide images': 2, 'End-To-End Dialogue Modelling': 1, 'Face Hallucination': 2, '3D Part Segmentation': 1, 'Point Cloud Segmentation': 1, 'News Generation': 1, 'Keyword Spotting': 1, 'Open-Domain Question Answering': 1, 'Robust classification': 5, 'Scene Text Editing': 1, 'Event Detection': 4, 'Sound Event Detection': 4, 'Music Generation': 3, 'Parameter Prediction': 1, 'Extract Aspect': 2, 'Multimodal Sentiment Analysis': 1, 'Active Object Detection': 1, 'Visual Localization': 4, 'Deformable Medical Image Registration': 1, 'One-Shot Learning': 4, 'Low-Resource Neural Machine Translation': 1, 'Code Summarization': 3, 'Document-level Event Extraction': 1, 'Facial Action Unit Detection': 1, 'Pedestrian Detection': 2, 'Novel View Synthesis': 5, 'Feature Importance': 1, 'General Reinforcement Learning': 1, 'Survival Prediction': 2, 'Action Understanding': 1, 'Video Quality Assessment': 1, 'Text Infilling': 1, 'Speech Denoising': 1, 'Speech Enhancement': 1, '3D Room Layouts From A Single RGB Panorama': 1, 'Type prediction': 2, 'Salt-And-Pepper Noise Removal': 1, 'Knowledge Graph Completion': 4, 'MRI segmentation': 1, 'Multimodal Machine Translation': 2, 'Self-Supervised Action Recognition': 2, 'Video Reconstruction': 1, 'Multi-Source Unsupervised Domain Adaptation': 1, 'Self-Supervised Image Classification': 2, 'Table-to-Text Generation': 1, \"Montezuma's Revenge\": 1, 'Text-To-Speech Synthesis': 3, 'Data-to-Text Generation': 2, 'MULTI-VIEW LEARNING': 2, 'Automatic Post-Editing': 2, 'Logical Reasoning Question Answering': 1, 'Logical Reasoning Reading Comprehension': 1, 'Image Matting': 1, 'Video Matting': 1, 'Speech-to-Text Translation': 4, 'Continual Semantic Segmentation': 1, 'Humanitarian': 2, 'Common Sense Reasoning': 6, 'Graph Attention': 7, 'Sequential Image Classification': 1, '3D Reconstruction': 6, 'Scene Classification': 2, 'Counterfactual Explanation': 1, 'Fact Checking': 2, 'One-stage Anchor-free Oriented Object Detection': 1, 'Edge Detection': 1, 'Code Repair': 1, 'Smart Grid Prediction': 1, 'Data Summarization': 1, '3D Medical Imaging Segmentation': 2, 'Volumetric Medical Image Segmentation': 2, 'Semi-Supervised Semantic Segmentation': 6, 'Propaganda detection': 1, 'Multi-Person Pose Estimation': 3, 'Code Documentation Generation': 1, 'Sequence-to-sequence Language Modeling': 1, 'Source Code Summarization': 1, 'Keypoint Detection': 4, 'Hyperspectral Image Classification': 1, 'Speech Dereverberation': 1, 'Speech Separation': 3, '3D Semantic Segmentation': 3, 'Scene Segmentation': 2, 'Linguistic Acceptability': 1, 'Paraphrase Identification': 1, 'text-based games': 2, 'Loop Closure Detection': 1, 'Point Cloud Retrieval': 1, 'Image Enhancement': 3, 'Low-Light Image Enhancement': 2, 'Action Quality Assessment': 1, 'Fine-grained Action Recognition': 1, 'Skills Assessment': 1, 'Video Captioning': 5, 'Unsupervised Domain Expansion': 1, 'Explainable Models': 1, 'One-shot visual object segmentation': 2, 'Semi-Supervised Video Object Segmentation': 2, 'Color Image Denoising': 1, 'Grayscale Image Denoising': 1, 'Medical Image Denoising': 1, 'Subjectivity Analysis': 1, 'Text Augmentation': 1, 'Few-Shot Text Classification': 2, 'Link Property Prediction': 1, 'Entity Extraction using GAN': 1, 'Eeg Decoding': 1, 'Text based Person Retrieval': 1, 'Text based Person Search': 1, 'Story Generation': 1, 'SQL Parsing': 1, 'Time Series Forecasting': 3, 'Unsupervised Person Re-Identification': 2, 'Video Visual Relation Detection': 1, 'Video Visual Relation Tagging': 1, 'Distributed Computing': 1, 'Stance Detection': 2, 'Semantic Retrieval': 1, '3D Shape Representation': 2, 'Moment Retrieval': 4, 'Natural Language Moment Retrieval': 1, 'Meta Reinforcement Learning': 3, 'Colorization': 3, 'Temporal Knowledge Graph Completion': 1, '3D-Aware Image Synthesis': 1, 'Environmental Sound Classification': 2, 'Ad-hoc video search': 1, 'Video Retrieval': 7, 'Audio Generation': 3, 'Vector Graphics': 1, 'Data Compression': 2, 'Weakly Supervised Classification': 2, 'Time Series Prediction': 2, 'JPEG Artifact Removal': 2, 'Diachronic Word Embeddings': 1, 'Texture Classification': 1, 'Gaze Estimation': 1, 'Code Search': 1, 'Pedestrian Attribute Recognition': 1, 'Multi-Label Image Classification': 2, 'Unsupervised Image Classification': 1, 'Data Visualization': 2, 'Hypergraph Matching': 1, 'Transparent objects': 3, 'Motion Estimation': 3, 'Transparent Object Detection': 1, 'Tone Mapping': 1, 'Image Classification with Label Noise': 1, 'Multiple Sequence Alignment': 1, 'Node Property Prediction': 1, 'Compressive Sensing': 2, 'Key information extraction': 1, 'Music Modeling': 1, 'Protein Folding': 1, '3D Depth Estimation': 1, 'Human-Object Interaction Detection': 3, 'Binarization': 4, 'PICO': 1, 'Weakly supervised segmentation': 3, 'Clinical Concept Extraction': 2, 'Image-Based Localization': 1, 'Knowledge Tracing': 1, 'Multiple-choice': 4, 'Skill Mastery': 1, 'Video Grounding': 1, 'Stock Prediction': 1, '3D Scene Reconstruction': 1, 'Audio captioning': 1, 'Audio to Text Retrieval': 1, 'Text to Audio Retrieval': 1, 'Text Spotting': 2, 'Multi-hop Question Answering': 2, 'Multi-Goal Reinforcement Learning': 2, 'Muscle Tendon Junction Identification': 1, 'Multi-Armed Bandits': 1, 'Keyphrase Extraction': 1, 'Handwritten Text Recognition': 1, 'Review Generation': 1, 'Language Identification': 3, 'Citation Prediction': 1, 'Fine-Grained Visual Categorization': 1, 'News Classification': 1, 'Left Ventricle Segmentation': 1, 'Perceptual Distance': 1, 'Synthetic-to-Real Translation': 1, 'Small Object Detection': 1, 'Acoustic Modelling': 1, '3D Object Tracking': 1, 'Online Action Detection': 2, 'Multiple Object Tracking': 1, 'Breast Tumour Classification': 1, 'Cloze Test': 2, 'Scene Generation': 1, 'One-class classifier': 1, 'Music Transcription': 1, 'Referring Expression Comprehension': 1, 'Visual Commonsense Reasoning': 2, 'Visual Entailment': 1, 'Zero-Shot Cross-Modal Retrieval': 1, 'Abuse Detection': 1, 'Semi-supervised Medical Image Segmentation': 1, 'Monocular 3D Object Detection': 1, 'Explainable artificial intelligence': 1, 'Voice Conversion': 1, 'Event-based vision': 1, 'Image Cropping': 1, 'Emotion Recognition': 3, 'Online Multi-Object Tracking': 1, 'Future prediction': 1, 'Small Data Image Classification': 1, 'Few-Shot Semantic Segmentation': 2, 'Face Alignment': 3, 'Sequential Place Recognition': 1, 'Abusive Language': 1, 'Cross-Domain Few-Shot': 1, 'cross-domain few-shot learning': 1, 'Age And Gender Classification': 1, 'Weakly-Supervised Semantic Segmentation': 4, 'Topic Classification': 2, 'Human Mesh Recovery': 1, 'Entity Disambiguation': 1, 'Backdoor Attack': 1, 'Drug–drug Interaction Extraction': 1, 'Hippocampus': 1, 'Image popularity prediction': 1, 'Face Anti-Spoofing': 1, 'Policy Gradient Methods': 1, 'Graph Question Answering': 1, 'Time Series Analysis': 2, 'Multilabel Text Classification': 1, 'Medical Image Generation': 1, 'Synthetic Data Generation': 1, 'Portfolio Optimization': 1, 'Causal Discovery': 1, 'Variable Selection': 2, 'TFLM sequence generation': 1, 'Human Part Segmentation': 1, 'Additive models': 2, 'Universal Domain Adaptation': 1, 'Explanation Generation': 1, 'Visual Reasoning': 1, 'Traffic Classification': 1, 'Aspect Extraction': 2, 'Product Recommendation': 3, 'Intent Classification': 1, 'Intent Classification and Slot Filling': 1, 'Zero-Shot Intent Classification': 1, 'Zero-Shot Intent Classification and Slot Filling': 1, 'Zero-shot Slot Filling': 1, 'Mixed Reality': 2, 'Behavioural cloning': 1, 'Lipreading': 1, 'Visual Speech Recognition': 1, 'Partial Label Learning': 1, 'Passage Retrieval': 2, 'Multiple Choice Question Answering (MCQA)': 1, 'Generalization Bounds': 2, 'Voice Anti-spoofing': 1, '3D Shape Recognition': 1, 'Android Malware Detection': 1, 'Malware Classification': 2, 'Malware Detection': 2, '3D Object Reconstruction': 2, 'Group Activity Recognition': 1, 'Satire Detection': 1, 'Unsupervised Opinion Summarization': 1, 'Caricature': 1, 'Affordance Recognition': 1, 'Human-Object Interaction Concept Discovery': 1, '3D Facial Landmark Localization': 1, 'Facial Landmark Detection': 1, 'Symbolic Regression': 3, 'Video Corpus Moment Retrieval': 1, 'Multimodal Emotion Recognition': 1, 'Privacy Preserving Deep Learning': 1, '3D human pose and shape estimation': 1, 'Scene Recognition': 1, 'Sentence ReWriting': 1, 'Multi-Hop Reading Comprehension': 1, 'Self-Supervised Person Re-Identification': 1, 'Retinal Vessel Segmentation': 1, 'Audio Signal Processing': 1, 'Dictionary Learning': 2, 'Activity Prediction': 1, 'Monocular Visual Odometry': 1, 'Thermal Image Segmentation': 1, 'Image Manipulation Detection': 1, 'Multi-Speaker Source Separation': 1, 'Fault localization': 1, 'Breast Cancer Histology Image Classification': 1, 'Classification Of Breast Cancer Histology Images': 1, 'Histopathological Image Classification': 1, 'Single-View 3D Reconstruction': 2, 'Defect Detection': 1, 'Respiratory Failure': 1, 'Remaining Useful Lifetime Estimation': 1, 'Unsupervised Video Object Segmentation': 1, 'Sleep Stage Detection': 1, 'Few-Shot NLI': 1, 'Cross-Lingual Abstractive Summarization': 1, 'Brain Image Segmentation': 1, 'Talking Face Generation': 1, 'Line Segment Detection': 1, 'Extreme Multi-Label Classification': 1, 'Short Text Clustering': 1, 'Long-tail Learning': 1, 'Mutual Information Estimation': 1, 'Sentence Compression': 1, 'Matrix Completion': 1, 'Text Segmentation': 1, 'Stereo Matching Hand': 1, 'Speech Emotion Recognition': 2, '3D Hand Pose Estimation': 1, 'Hand Pose Estimation': 1, 'Anxiety Detection': 1, 'Depression Detection': 1, 'Acrobot': 1, 'Real-Time Strategy Games': 1, 'Experimental Design': 2, 'Program Synthesis': 1, 'DeepFake Detection': 1, 'Graph Ranking': 1, 'Graph Regression': 1, 'Molecular Property Prediction': 2, 'One-shot model fusion': 1, 'TGIF-Action': 1, 'TGIF-Frame': 1, 'TGIF-Transition': 1, '3D Shape Classification': 1, '3D Shape Retrieval': 1, 'Change Point Detection': 1, 'Grasp Contact Prediction': 1, 'Multimodal Deep Learning': 1, 'Cross-Lingual Natural Language Inference': 1, 'Atari Games 100k': 1, 'text similarity': 1, 'Video-Text Retrieval': 1, 'Code Translation': 1, 'Text-to-Code Generation': 1, 'Domain-IL Continual Learning': 1, 'Permuted-MNIST': 1, 'Split-CIFAR-10': 1, 'Split-MNIST': 1, 'Knowledge Graph Embedding': 1, 'Image Compression Artifact Reduction': 1, 'Image Deblocking': 1, 'Image Forensics': 1, 'JPEG Artifact Correction': 1, 'Dense Video Captioning': 1}\n"
     ]
    }
   ],
   "source": [
    "tasks = {}\n",
    "for key, val in abs_data.items():\n",
    "    for task in val['task']:\n",
    "        if task in tasks.keys():\n",
    "            tasks[task] += 1\n",
    "        else:\n",
    "            tasks[task] = 1\n",
    "\n",
    "print(tasks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Threshold Value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "['Self-Supervised Learning', 'Natural Language Processing', 'Transfer Learning', 'Translation', 'Image Generation', 'Representation Learning', 'Classification', 'General Classification', 'Image Classification', 'Data Augmentation', 'Question Answering', 'Super-Resolution', 'reinforcement-learning', 'object-detection', 'Object Detection', 'Decision Making', 'Machine Translation', 'Semantic Segmentation', 'Few-Shot Learning', 'Domain Adaptation', 'Language Modelling', 'Meta-Learning', 'Contrastive Learning']\n"
     ]
    }
   ],
   "source": [
    "imp_task = []\n",
    "for task, val in tasks.items():\n",
    "    if val >= 30:\n",
    "        imp_task.append(task)\n",
    "print(len(imp_task))\n",
    "print(imp_task)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Data Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(894)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(x, tasks.values())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jychoi118_toward_spatial_unbiased.json\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir('D:\\\\Projects\\\\UPM\\\\RepoUnder\\\\data\\\\graph')\n",
    "graph_template = choice(file_list)\n",
    "print(graph_template)\n",
    "graph_path = 'D:\\\\Projects\\\\UPM\\\\RepoUnder\\\\data\\\\graph\\\\' + graph_template\n",
    "with open(graph_path, 'r') as gf:\n",
    "    graph_data = json.load(gf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.projector.noise_regularize': [[18, 39], ['noise.mean.reshape', 'noise.mean.mean', 'torch.roll', 'torch.roll'], 'function', ['None'], ['def', 'noise_regularize', '(', 'noises', ')', ':', '\\n', '    ', 'loss', '=', '0', '\\n', '\\n', 'for', 'noise', 'in', 'noises', ':', '\\n', '        ', 'size', '=', 'noise', '.', 'shape', '[', '2', ']', '\\n', '\\n', 'while', 'True', ':', '\\n', '            ', 'loss', '=', '(', '\\n', 'loss', '\\n', '+', '(', 'noise', '*', 'torch', '.', 'roll', '(', 'noise', ',', 'shifts', '=', '1', ',', 'dims', '=', '3', ')', ')', '.', 'mean', '(', ')', '.', 'pow', '(', '2', ')', '\\n', '+', '(', 'noise', '*', 'torch', '.', 'roll', '(', 'noise', ',', 'shifts', '=', '1', ',', 'dims', '=', '2', ')', ')', '.', 'mean', '(', ')', '.', 'pow', '(', '2', ')', '\\n', ')', '\\n', '\\n', 'if', 'size', '<=', '8', ':', '\\n', '                ', 'break', '\\n', '\\n', '', 'noise', '=', 'noise', '.', 'reshape', '(', '[', '-', '1', ',', '1', ',', 'size', '//', '2', ',', '2', ',', 'size', '//', '2', ',', '2', ']', ')', '\\n', 'noise', '=', 'noise', '.', 'mean', '(', '[', '3', ',', '5', ']', ')', '\\n', 'size', '//=', '2', '\\n', '\\n', '', '', 'return', 'loss', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.projector.noise_normalize_': [[41, 47], ['noise.mean', 'noise.std', 'noise.data.add_().div_', 'noise.data.add_'], 'function', ['None'], ['', 'def', 'noise_normalize_', '(', 'noises', ')', ':', '\\n', '    ', 'for', 'noise', 'in', 'noises', ':', '\\n', '        ', 'mean', '=', 'noise', '.', 'mean', '(', ')', '\\n', 'std', '=', 'noise', '.', 'std', '(', ')', '\\n', '\\n', 'noise', '.', 'data', '.', 'add_', '(', '-', 'mean', ')', '.', 'div_', '(', 'std', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.projector.get_lr': [[49, 55], ['min', 'min', 'math.cos', 'math.cos'], 'function', ['None'], ['', '', 'def', 'get_lr', '(', 't', ',', 'initial_lr', ',', 'rampdown', '=', '0.25', ',', 'rampup', '=', '0.05', ')', ':', '\\n', '    ', 'lr_ramp', '=', 'min', '(', '1', ',', '(', '1', '-', 't', ')', '/', 'rampdown', ')', '\\n', 'lr_ramp', '=', '0.5', '-', '0.5', '*', 'math', '.', 'cos', '(', 'lr_ramp', '*', 'math', '.', 'pi', ')', '\\n', 'lr_ramp', '=', 'lr_ramp', '*', 'min', '(', '1', ',', 't', '/', 'rampup', ')', '\\n', '\\n', 'return', 'initial_lr', '*', 'lr_ramp', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.projector.latent_noise': [[57, 61], ['torch.randn_like'], 'function', ['None'], ['', 'def', 'latent_noise', '(', 'latent', ',', 'strength', ')', ':', '\\n', '    ', 'noise', '=', 'torch', '.', 'randn_like', '(', 'latent', ')', '*', 'strength', '\\n', '\\n', 'return', 'latent', '+', 'noise', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.projector.make_image': [[63, 73], ['tensor.detach().clamp_().add().div_().mul().type().permute().to().numpy', 'tensor.detach().clamp_().add().div_().mul().type().permute().to', 'tensor.detach().clamp_().add().div_().mul().type().permute', 'tensor.detach().clamp_().add().div_().mul().type', 'tensor.detach().clamp_().add().div_().mul', 'tensor.detach().clamp_().add().div_', 'tensor.detach().clamp_().add', 'tensor.detach().clamp_', 'tensor.detach'], 'function', ['None'], ['', 'def', 'make_image', '(', 'tensor', ')', ':', '\\n', '    ', 'return', '(', '\\n', 'tensor', '.', 'detach', '(', ')', '\\n', '.', 'clamp_', '(', 'min', '=', '-', '1', ',', 'max', '=', '1', ')', '\\n', '.', 'add', '(', '1', ')', '\\n', '.', 'div_', '(', '2', ')', '\\n', '.', 'mul', '(', '255', ')', '\\n', '.', 'type', '(', 'torch', '.', 'uint8', ')', '\\n', '.', 'permute', '(', '0', ',', '2', ',', '3', ',', '1', ')', '\\n', '.', 'to', '(', '\"cpu\"', ')', '\\n', '.', 'numpy', '(', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.AdaptiveAugment.__init__': [[13, 22], ['torch.tensor'], 'methods', ['None'], ['    ', 'def', '__init__', '(', 'self', ',', 'ada_aug_target', ',', 'ada_aug_len', ',', 'update_every', ',', 'device', ')', ':', '\\n', '        ', 'self', '.', 'ada_aug_target', '=', 'ada_aug_target', '\\n', 'self', '.', 'ada_aug_len', '=', 'ada_aug_len', '\\n', 'self', '.', 'update_every', '=', 'update_every', '\\n', '\\n', 'self', '.', 'ada_update', '=', '0', '\\n', 'self', '.', 'ada_aug_buf', '=', 'torch', '.', 'tensor', '(', '[', '0.0', ',', '0.0', ']', ',', 'device', '=', 'device', ')', '\\n', 'self', '.', 'r_t_stat', '=', '0', '\\n', 'self', '.', 'ada_aug_p', '=', '0', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.AdaptiveAugment.tune': [[23, 49], ['torch.no_grad', 'torch.tensor', 'distributed.reduce_sum', 'non_leaking.AdaptiveAugment.ada_aug_buf.tolist', 'min', 'non_leaking.AdaptiveAugment.ada_aug_buf.mul_', 'torch.sign().sum().item', 'max', 'torch.sign().sum', 'torch.sign'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.reduce_sum'], ['', '@', 'torch', '.', 'no_grad', '(', ')', '\\n', 'def', 'tune', '(', 'self', ',', 'real_pred', ')', ':', '\\n', '        ', 'self', '.', 'ada_aug_buf', '+=', 'torch', '.', 'tensor', '(', '\\n', '(', 'torch', '.', 'sign', '(', 'real_pred', ')', '.', 'sum', '(', ')', '.', 'item', '(', ')', ',', 'real_pred', '.', 'shape', '[', '0', ']', ')', ',', '\\n', 'device', '=', 'real_pred', '.', 'device', ',', '\\n', ')', '\\n', 'self', '.', 'ada_update', '+=', '1', '\\n', '\\n', 'if', 'self', '.', 'ada_update', '%', 'self', '.', 'update_every', '==', '0', ':', '\\n', '            ', 'self', '.', 'ada_aug_buf', '=', 'reduce_sum', '(', 'self', '.', 'ada_aug_buf', ')', '\\n', 'pred_signs', ',', 'n_pred', '=', 'self', '.', 'ada_aug_buf', '.', 'tolist', '(', ')', '\\n', '\\n', 'self', '.', 'r_t_stat', '=', 'pred_signs', '/', 'n_pred', '\\n', '\\n', 'if', 'self', '.', 'r_t_stat', '>', 'self', '.', 'ada_aug_target', ':', '\\n', '                ', 'sign', '=', '1', '\\n', '\\n', '', 'else', ':', '\\n', '                ', 'sign', '=', '-', '1', '\\n', '\\n', '', 'self', '.', 'ada_aug_p', '+=', 'sign', '*', 'n_pred', '/', 'self', '.', 'ada_aug_len', '\\n', 'self', '.', 'ada_aug_p', '=', 'min', '(', '1', ',', 'max', '(', '0', ',', 'self', '.', 'ada_aug_p', ')', ')', '\\n', 'self', '.', 'ada_aug_buf', '.', 'mul_', '(', '0', ')', '\\n', 'self', '.', 'ada_update', '=', '0', '\\n', '\\n', '', 'return', 'self', '.', 'ada_aug_p', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.GridSampleForward.forward': [[340, 348], ['torch.nn.functional.grid_sample', 'ctx.save_for_backward'], 'methods', ['None'], ['    ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', 'ctx', ',', 'input', ',', 'grid', ')', ':', '\\n', '        ', 'out', '=', 'F', '.', 'grid_sample', '(', '\\n', 'input', ',', 'grid', ',', 'mode', '=', '\"bilinear\"', ',', 'padding_mode', '=', '\"zeros\"', ',', 'align_corners', '=', 'False', '\\n', ')', '\\n', 'ctx', '.', 'save_for_backward', '(', 'input', ',', 'grid', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.GridSampleForward.backward': [[349, 355], ['GridSampleBackward.apply'], 'methods', ['None'], ['', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'grad_output', ')', ':', '\\n', '        ', 'input', ',', 'grid', '=', 'ctx', '.', 'saved_tensors', '\\n', 'grad_input', ',', 'grad_grid', '=', 'GridSampleBackward', '.', 'apply', '(', 'grad_output', ',', 'input', ',', 'grid', ')', '\\n', '\\n', 'return', 'grad_input', ',', 'grad_grid', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.GridSampleBackward.forward': [[358, 365], ['torch._C._jit_get_operation', 'torch._C._jit_get_operation.', 'ctx.save_for_backward'], 'methods', ['None'], ['    ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', 'ctx', ',', 'grad_output', ',', 'input', ',', 'grid', ')', ':', '\\n', '        ', 'op', '=', 'torch', '.', '_C', '.', '_jit_get_operation', '(', '\"aten::grid_sampler_2d_backward\"', ')', '\\n', 'grad_input', ',', 'grad_grid', '=', 'op', '(', 'grad_output', ',', 'input', ',', 'grid', ',', '0', ',', '0', ',', 'False', ')', '\\n', 'ctx', '.', 'save_for_backward', '(', 'grid', ')', '\\n', '\\n', 'return', 'grad_input', ',', 'grad_grid', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.GridSampleBackward.backward': [[366, 375], ['GridSampleForward.apply'], 'methods', ['None'], ['', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'grad_grad_input', ',', 'grad_grad_grid', ')', ':', '\\n', '        ', 'grid', ',', '=', 'ctx', '.', 'saved_tensors', '\\n', 'grad_grad_output', '=', 'None', '\\n', '\\n', 'if', 'ctx', '.', 'needs_input_grad', '[', '0', ']', ':', '\\n', '            ', 'grad_grad_output', '=', 'GridSampleForward', '.', 'apply', '(', 'grad_grad_input', ',', 'grid', ')', '\\n', '\\n', '', 'return', 'grad_grad_output', ',', 'None', ',', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat': [[67, 75], ['torch.eye().unsqueeze().repeat', 'torch.stack', 'torch.eye().unsqueeze', 'torch.eye'], 'function', ['None'], ['def', 'translate_mat', '(', 't_x', ',', 't_y', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'batch', '=', 't_x', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'mat', '=', 'torch', '.', 'eye', '(', '3', ',', 'device', '=', 'device', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'translate', '=', 'torch', '.', 'stack', '(', '(', 't_x', ',', 't_y', ')', ',', '1', ')', '\\n', 'mat', '[', ':', ',', ':', '2', ',', '2', ']', '=', 'translate', '\\n', '\\n', 'return', 'mat', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate_mat': [[77, 87], ['torch.eye().unsqueeze().repeat', 'torch.sin', 'torch.cos', 'torch.stack().view', 'torch.eye().unsqueeze', 'torch.stack', 'torch.eye'], 'function', ['None'], ['', 'def', 'rotate_mat', '(', 'theta', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'batch', '=', 'theta', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'mat', '=', 'torch', '.', 'eye', '(', '3', ',', 'device', '=', 'device', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'sin_t', '=', 'torch', '.', 'sin', '(', 'theta', ')', '\\n', 'cos_t', '=', 'torch', '.', 'cos', '(', 'theta', ')', '\\n', 'rot', '=', 'torch', '.', 'stack', '(', '(', 'cos_t', ',', '-', 'sin_t', ',', 'sin_t', ',', 'cos_t', ')', ',', '1', ')', '.', 'view', '(', 'batch', ',', '2', ',', '2', ')', '\\n', 'mat', '[', ':', ',', ':', '2', ',', ':', '2', ']', '=', 'rot', '\\n', '\\n', 'return', 'mat', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat': [[89, 97], ['torch.eye().unsqueeze().repeat', 'torch.eye().unsqueeze', 'torch.eye'], 'function', ['None'], ['', 'def', 'scale_mat', '(', 's_x', ',', 's_y', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'batch', '=', 's_x', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'mat', '=', 'torch', '.', 'eye', '(', '3', ',', 'device', '=', 'device', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'mat', '[', ':', ',', '0', ',', '0', ']', '=', 's_x', '\\n', 'mat', '[', ':', ',', '1', ',', '1', ']', '=', 's_y', '\\n', '\\n', 'return', 'mat', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate3d_mat': [[99, 107], ['torch.eye().unsqueeze().repeat', 'torch.stack', 'torch.eye().unsqueeze', 'torch.eye'], 'function', ['None'], ['', 'def', 'translate3d_mat', '(', 't_x', ',', 't_y', ',', 't_z', ')', ':', '\\n', '    ', 'batch', '=', 't_x', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'mat', '=', 'torch', '.', 'eye', '(', '4', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'translate', '=', 'torch', '.', 'stack', '(', '(', 't_x', ',', 't_y', ',', 't_z', ')', ',', '1', ')', '\\n', 'mat', '[', ':', ',', ':', '3', ',', '3', ']', '=', 'translate', '\\n', '\\n', 'return', 'mat', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate3d_mat': [[109, 128], ['torch.eye().unsqueeze', 'torch.tensor().unsqueeze', 'torch.tensor', 'torch.sin().view', 'torch.cos().view', 'torch.eye().unsqueeze().repeat', 'torch.eye', 'torch.tensor', 'torch.sin', 'torch.cos', 'torch.eye().unsqueeze', 'torch.tensor.unsqueeze', 'torch.eye'], 'function', ['None'], ['', 'def', 'rotate3d_mat', '(', 'axis', ',', 'theta', ')', ':', '\\n', '    ', 'batch', '=', 'theta', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'u_x', ',', 'u_y', ',', 'u_z', '=', 'axis', '\\n', '\\n', 'eye', '=', 'torch', '.', 'eye', '(', '3', ')', '.', 'unsqueeze', '(', '0', ')', '\\n', 'cross', '=', 'torch', '.', 'tensor', '(', '[', '(', '0', ',', '-', 'u_z', ',', 'u_y', ')', ',', '(', 'u_z', ',', '0', ',', '-', 'u_x', ')', ',', '(', '-', 'u_y', ',', 'u_x', ',', '0', ')', ']', ')', '.', 'unsqueeze', '(', '0', ')', '\\n', 'outer', '=', 'torch', '.', 'tensor', '(', 'axis', ')', '\\n', 'outer', '=', '(', 'outer', '.', 'unsqueeze', '(', '1', ')', '*', 'outer', ')', '.', 'unsqueeze', '(', '0', ')', '\\n', '\\n', 'sin_t', '=', 'torch', '.', 'sin', '(', 'theta', ')', '.', 'view', '(', '-', '1', ',', '1', ',', '1', ')', '\\n', 'cos_t', '=', 'torch', '.', 'cos', '(', 'theta', ')', '.', 'view', '(', '-', '1', ',', '1', ',', '1', ')', '\\n', '\\n', 'rot', '=', 'cos_t', '*', 'eye', '+', 'sin_t', '*', 'cross', '+', '(', '1', '-', 'cos_t', ')', '*', 'outer', '\\n', '\\n', 'eye_4', '=', 'torch', '.', 'eye', '(', '4', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'eye_4', '[', ':', ',', ':', '3', ',', ':', '3', ']', '=', 'rot', '\\n', '\\n', 'return', 'eye_4', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale3d_mat': [[130, 139], ['torch.eye().unsqueeze().repeat', 'torch.eye().unsqueeze', 'torch.eye'], 'function', ['None'], ['', 'def', 'scale3d_mat', '(', 's_x', ',', 's_y', ',', 's_z', ')', ':', '\\n', '    ', 'batch', '=', 's_x', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'mat', '=', 'torch', '.', 'eye', '(', '4', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'mat', '[', ':', ',', '0', ',', '0', ']', '=', 's_x', '\\n', 'mat', '[', ':', ',', '1', ',', '1', ']', '=', 's_y', '\\n', 'mat', '[', ':', ',', '2', ',', '2', ']', '=', 's_z', '\\n', '\\n', 'return', 'mat', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.luma_flip_mat': [[141, 149], ['torch.eye().unsqueeze().repeat', 'torch.tensor', 'i.view', 'torch.eye().unsqueeze', 'torch.ger', 'torch.eye'], 'function', ['None'], ['', 'def', 'luma_flip_mat', '(', 'axis', ',', 'i', ')', ':', '\\n', '    ', 'batch', '=', 'i', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'eye', '=', 'torch', '.', 'eye', '(', '4', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'axis', '=', 'torch', '.', 'tensor', '(', 'axis', '+', '(', '0', ',', ')', ')', '\\n', 'flip', '=', '2', '*', 'torch', '.', 'ger', '(', 'axis', ',', 'axis', ')', '*', 'i', '.', 'view', '(', '-', '1', ',', '1', ',', '1', ')', '\\n', '\\n', 'return', 'eye', '-', 'flip', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.saturation_mat': [[151, 160], ['torch.eye().unsqueeze().repeat', 'torch.tensor', 'torch.ger', 'torch.eye().unsqueeze', 'i.view', 'torch.eye'], 'function', ['None'], ['', 'def', 'saturation_mat', '(', 'axis', ',', 'i', ')', ':', '\\n', '    ', 'batch', '=', 'i', '.', 'shape', '[', '0', ']', '\\n', '\\n', 'eye', '=', 'torch', '.', 'eye', '(', '4', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ')', '\\n', 'axis', '=', 'torch', '.', 'tensor', '(', 'axis', '+', '(', '0', ',', ')', ')', '\\n', 'axis', '=', 'torch', '.', 'ger', '(', 'axis', ',', 'axis', ')', '\\n', 'saturate', '=', 'axis', '+', '(', 'eye', '-', 'axis', ')', '*', 'i', '.', 'view', '(', '-', '1', ',', '1', ',', '1', ')', '\\n', '\\n', 'return', 'saturate', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.lognormal_sample': [[162, 164], ['torch.empty().log_normal_', 'torch.empty'], 'function', ['None'], ['', 'def', 'lognormal_sample', '(', 'size', ',', 'mean', '=', '0', ',', 'std', '=', '1', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'return', 'torch', '.', 'empty', '(', 'size', ',', 'device', '=', 'device', ')', '.', 'log_normal_', '(', 'mean', '=', 'mean', ',', 'std', '=', 'std', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.category_sample': [[166, 171], ['torch.tensor', 'torch.randint', 'len'], 'function', ['None'], ['', 'def', 'category_sample', '(', 'size', ',', 'categories', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'category', '=', 'torch', '.', 'tensor', '(', 'categories', ',', 'device', '=', 'device', ')', '\\n', 'sample', '=', 'torch', '.', 'randint', '(', 'high', '=', 'len', '(', 'categories', ')', ',', 'size', '=', '(', 'size', ',', ')', ',', 'device', '=', 'device', ')', '\\n', '\\n', 'return', 'category', '[', 'sample', ']', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.uniform_sample': [[173, 175], ['torch.empty().uniform_', 'torch.empty', 'math.pi', 'math.pi', 'math.pi'], 'function', ['None'], ['', 'def', 'uniform_sample', '(', 'size', ',', 'low', ',', 'high', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'return', 'torch', '.', 'empty', '(', 'size', ',', 'device', '=', 'device', ')', '.', 'uniform_', '(', 'low', ',', 'high', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.normal_sample': [[177, 179], ['torch.empty().normal_', 'torch.empty'], 'function', ['None'], ['', 'def', 'normal_sample', '(', 'size', ',', 'mean', '=', '0', ',', 'std', '=', '1', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'return', 'torch', '.', 'empty', '(', 'size', ',', 'device', '=', 'device', ')', '.', 'normal_', '(', 'mean', ',', 'std', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.bernoulli_sample': [[181, 183], ['torch.empty().bernoulli_', 'torch.empty'], 'function', ['None'], ['', 'def', 'bernoulli_sample', '(', 'size', ',', 'p', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'return', 'torch', '.', 'empty', '(', 'size', ',', 'device', '=', 'device', ')', '.', 'bernoulli_', '(', 'p', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply': [[185, 191], ['bernoulli_sample().view', 'non_leaking.bernoulli_sample'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.bernoulli_sample'], ['', 'def', 'random_mat_apply', '(', 'p', ',', 'transform', ',', 'prev', ',', 'eye', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'size', '=', 'transform', '.', 'shape', '[', '0', ']', '\\n', 'select', '=', 'bernoulli_sample', '(', 'size', ',', 'p', ',', 'device', '=', 'device', ')', '.', 'view', '(', 'size', ',', '1', ',', '1', ')', '\\n', 'select_transform', '=', 'select', '*', 'transform', '+', '(', '1', '-', 'select', ')', '*', 'eye', '\\n', '\\n', 'return', 'select_transform', '@', 'prev', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.sample_affine': [[193, 250], ['torch.eye().unsqueeze().repeat', 'non_leaking.category_sample', 'non_leaking.scale_mat', 'non_leaking.random_mat_apply', 'non_leaking.category_sample', 'non_leaking.rotate_mat', 'non_leaking.random_mat_apply', 'non_leaking.uniform_sample', 'non_leaking.translate_mat', 'non_leaking.random_mat_apply', 'non_leaking.lognormal_sample', 'non_leaking.scale_mat', 'non_leaking.random_mat_apply', 'non_leaking.uniform_sample', 'non_leaking.rotate_mat', 'non_leaking.random_mat_apply', 'non_leaking.lognormal_sample', 'non_leaking.scale_mat', 'non_leaking.random_mat_apply', 'non_leaking.uniform_sample', 'non_leaking.rotate_mat', 'non_leaking.random_mat_apply', 'non_leaking.normal_sample', 'non_leaking.translate_mat', 'non_leaking.random_mat_apply', 'torch.ones', 'torch.round', 'torch.round', 'math.sqrt', 'torch.eye().unsqueeze', 'math.log', 'math.log', 'torch.eye'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.category_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.category_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.uniform_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.lognormal_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.uniform_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.lognormal_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.uniform_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.normal_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply'], ['', 'def', 'sample_affine', '(', 'p', ',', 'size', ',', 'height', ',', 'width', ',', 'device', '=', '\"cpu\"', ')', ':', '\\n', '    ', 'G', '=', 'torch', '.', 'eye', '(', '3', ',', 'device', '=', 'device', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'size', ',', '1', ',', '1', ')', '\\n', 'eye', '=', 'G', '\\n', '\\n', '# flip', '\\n', 'param', '=', 'category_sample', '(', 'size', ',', '(', '0', ',', '1', ')', ')', '\\n', 'Gc', '=', 'scale_mat', '(', '1', '-', '2.0', '*', 'param', ',', 'torch', '.', 'ones', '(', 'size', ')', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('flip', G, scale_mat(1 - 2.0 * param, torch.ones(size)), sep='\\\\n')\", '\\n', '\\n', '# 90 rotate', '\\n', 'param', '=', 'category_sample', '(', 'size', ',', '(', '0', ',', '3', ')', ')', '\\n', 'Gc', '=', 'rotate_mat', '(', '-', 'math', '.', 'pi', '/', '2', '*', 'param', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('90 rotate', G, rotate_mat(-math.pi / 2 * param), sep='\\\\n')\", '\\n', '\\n', '# integer translate', '\\n', 'param', '=', 'uniform_sample', '(', 'size', ',', '-', '0.125', ',', '0.125', ')', '\\n', 'param_height', '=', 'torch', '.', 'round', '(', 'param', '*', 'height', ')', '/', 'height', '\\n', 'param_width', '=', 'torch', '.', 'round', '(', 'param', '*', 'width', ')', '/', 'width', '\\n', 'Gc', '=', 'translate_mat', '(', 'param_width', ',', 'param_height', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('integer translate', G, translate_mat(param_width, param_height), sep='\\\\n')\", '\\n', '\\n', '# isotropic scale', '\\n', 'param', '=', 'lognormal_sample', '(', 'size', ',', 'std', '=', '0.2', '*', 'math', '.', 'log', '(', '2', ')', ')', '\\n', 'Gc', '=', 'scale_mat', '(', 'param', ',', 'param', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('isotropic scale', G, scale_mat(param, param), sep='\\\\n')\", '\\n', '\\n', 'p_rot', '=', '1', '-', 'math', '.', 'sqrt', '(', '1', '-', 'p', ')', '\\n', '\\n', '# pre-rotate', '\\n', 'param', '=', 'uniform_sample', '(', 'size', ',', '-', 'math', '.', 'pi', ',', 'math', '.', 'pi', ')', '\\n', 'Gc', '=', 'rotate_mat', '(', '-', 'param', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p_rot', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('pre-rotate', G, rotate_mat(-param), sep='\\\\n')\", '\\n', '\\n', '# anisotropic scale', '\\n', 'param', '=', 'lognormal_sample', '(', 'size', ',', 'std', '=', '0.2', '*', 'math', '.', 'log', '(', '2', ')', ')', '\\n', 'Gc', '=', 'scale_mat', '(', 'param', ',', '1', '/', 'param', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('anisotropic scale', G, scale_mat(param, 1 / param), sep='\\\\n')\", '\\n', '\\n', '# post-rotate', '\\n', 'param', '=', 'uniform_sample', '(', 'size', ',', '-', 'math', '.', 'pi', ',', 'math', '.', 'pi', ')', '\\n', 'Gc', '=', 'rotate_mat', '(', '-', 'param', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p_rot', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('post-rotate', G, rotate_mat(-param), sep='\\\\n')\", '\\n', '\\n', '# fractional translate', '\\n', 'param', '=', 'normal_sample', '(', 'size', ',', 'std', '=', '0.125', ')', '\\n', 'Gc', '=', 'translate_mat', '(', 'param', ',', 'param', ',', 'device', '=', 'device', ')', '\\n', 'G', '=', 'random_mat_apply', '(', 'p', ',', 'Gc', ',', 'G', ',', 'eye', ',', 'device', '=', 'device', ')', '\\n', \"# print('fractional translate', G, translate_mat(param, param), sep='\\\\n')\", '\\n', '\\n', 'return', 'G', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.sample_color': [[252, 284], ['torch.eye().unsqueeze().repeat', 'non_leaking.normal_sample', 'non_leaking.translate3d_mat', 'non_leaking.random_mat_apply', 'non_leaking.lognormal_sample', 'non_leaking.scale3d_mat', 'non_leaking.random_mat_apply', 'non_leaking.category_sample', 'non_leaking.luma_flip_mat', 'non_leaking.random_mat_apply', 'non_leaking.uniform_sample', 'non_leaking.rotate3d_mat', 'non_leaking.random_mat_apply', 'non_leaking.lognormal_sample', 'non_leaking.saturation_mat', 'non_leaking.random_mat_apply', 'math.sqrt', 'torch.eye().unsqueeze', 'math.log', 'math.log', 'torch.eye'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.normal_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate3d_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.lognormal_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale3d_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.category_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.luma_flip_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.uniform_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate3d_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.lognormal_sample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.saturation_mat', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply'], ['', 'def', 'sample_color', '(', 'p', ',', 'size', ')', ':', '\\n', '    ', 'C', '=', 'torch', '.', 'eye', '(', '4', ')', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'size', ',', '1', ',', '1', ')', '\\n', 'eye', '=', 'C', '\\n', 'axis_val', '=', '1', '/', 'math', '.', 'sqrt', '(', '3', ')', '\\n', 'axis', '=', '(', 'axis_val', ',', 'axis_val', ',', 'axis_val', ')', '\\n', '\\n', '# brightness', '\\n', 'param', '=', 'normal_sample', '(', 'size', ',', 'std', '=', '0.2', ')', '\\n', 'Cc', '=', 'translate3d_mat', '(', 'param', ',', 'param', ',', 'param', ')', '\\n', 'C', '=', 'random_mat_apply', '(', 'p', ',', 'Cc', ',', 'C', ',', 'eye', ')', '\\n', '\\n', '# contrast', '\\n', 'param', '=', 'lognormal_sample', '(', 'size', ',', 'std', '=', '0.5', '*', 'math', '.', 'log', '(', '2', ')', ')', '\\n', 'Cc', '=', 'scale3d_mat', '(', 'param', ',', 'param', ',', 'param', ')', '\\n', 'C', '=', 'random_mat_apply', '(', 'p', ',', 'Cc', ',', 'C', ',', 'eye', ')', '\\n', '\\n', '# luma flip', '\\n', 'param', '=', 'category_sample', '(', 'size', ',', '(', '0', ',', '1', ')', ')', '\\n', 'Cc', '=', 'luma_flip_mat', '(', 'axis', ',', 'param', ')', '\\n', 'C', '=', 'random_mat_apply', '(', 'p', ',', 'Cc', ',', 'C', ',', 'eye', ')', '\\n', '\\n', '# hue rotation', '\\n', 'param', '=', 'uniform_sample', '(', 'size', ',', '-', 'math', '.', 'pi', ',', 'math', '.', 'pi', ')', '\\n', 'Cc', '=', 'rotate3d_mat', '(', 'axis', ',', 'param', ')', '\\n', 'C', '=', 'random_mat_apply', '(', 'p', ',', 'Cc', ',', 'C', ',', 'eye', ')', '\\n', '\\n', '# saturation', '\\n', 'param', '=', 'lognormal_sample', '(', 'size', ',', 'std', '=', '1', '*', 'math', '.', 'log', '(', '2', ')', ')', '\\n', 'Cc', '=', 'saturation_mat', '(', 'axis', ',', 'param', ')', '\\n', 'C', '=', 'random_mat_apply', '(', 'p', ',', 'Cc', ',', 'C', ',', 'eye', ')', '\\n', '\\n', 'return', 'C', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.make_grid': [[286, 294], ['torch.empty', 'torch.linspace', 'torch.linspace().unsqueeze', 'torch.linspace'], 'function', ['None'], ['', 'def', 'make_grid', '(', 'shape', ',', 'x0', ',', 'x1', ',', 'y0', ',', 'y1', ',', 'device', ')', ':', '\\n', '    ', 'n', ',', 'c', ',', 'h', ',', 'w', '=', 'shape', '\\n', 'grid', '=', 'torch', '.', 'empty', '(', 'n', ',', 'h', ',', 'w', ',', '3', ',', 'device', '=', 'device', ')', '\\n', 'grid', '[', ':', ',', ':', ',', ':', ',', '0', ']', '=', 'torch', '.', 'linspace', '(', 'x0', ',', 'x1', ',', 'w', ',', 'device', '=', 'device', ')', '\\n', 'grid', '[', ':', ',', ':', ',', ':', ',', '1', ']', '=', 'torch', '.', 'linspace', '(', 'y0', ',', 'y1', ',', 'h', ',', 'device', '=', 'device', ')', '.', 'unsqueeze', '(', '-', '1', ')', '\\n', 'grid', '[', ':', ',', ':', ',', ':', ',', '2', ']', '=', '1', '\\n', '\\n', 'return', 'grid', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.affine_grid': [[296, 299], ['grid.view', 'mat.transpose'], 'function', ['None'], ['', 'def', 'affine_grid', '(', 'grid', ',', 'mat', ')', ':', '\\n', '    ', 'n', ',', 'h', ',', 'w', ',', '_', '=', 'grid', '.', 'shape', '\\n', 'return', '(', 'grid', '.', 'view', '(', 'n', ',', 'h', '*', 'w', ',', '3', ')', '@', 'mat', '.', 'transpose', '(', '1', ',', '2', ')', ')', '.', 'view', '(', 'n', ',', 'h', ',', 'w', ',', '2', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.get_padding': [[301, 322], ['torch.tensor', 'cp[].permute().flatten', 'pad.min.max', 'pad.min.min', 'pad.min.ceil().to', 'torch.cat().max', 'torch.tensor', 'torch.tensor', 'torch.tensor', 'cp[].permute', 'pad.min.ceil', 'torch.cat'], 'function', ['None'], ['', 'def', 'get_padding', '(', 'G', ',', 'height', ',', 'width', ',', 'kernel_size', ')', ':', '\\n', '    ', 'device', '=', 'G', '.', 'device', '\\n', '\\n', 'cx', '=', '(', 'width', '-', '1', ')', '/', '2', '\\n', 'cy', '=', '(', 'height', '-', '1', ')', '/', '2', '\\n', 'cp', '=', 'torch', '.', 'tensor', '(', '\\n', '[', '(', '-', 'cx', ',', '-', 'cy', ',', '1', ')', ',', '(', 'cx', ',', '-', 'cy', ',', '1', ')', ',', '(', 'cx', ',', 'cy', ',', '1', ')', ',', '(', '-', 'cx', ',', 'cy', ',', '1', ')', ']', ',', 'device', '=', 'device', '\\n', ')', '\\n', 'cp', '=', 'G', '@', 'cp', '.', 'T', '\\n', '\\n', 'pad_k', '=', 'kernel_size', '//', '4', '\\n', '\\n', 'pad', '=', 'cp', '[', ':', ',', ':', '2', ',', ':', ']', '.', 'permute', '(', '1', ',', '0', ',', '2', ')', '.', 'flatten', '(', '1', ')', '\\n', 'pad', '=', 'torch', '.', 'cat', '(', '(', '-', 'pad', ',', 'pad', ')', ')', '.', 'max', '(', '1', ')', '.', 'values', '\\n', 'pad', '=', 'pad', '+', 'torch', '.', 'tensor', '(', '[', 'pad_k', '*', '2', '-', 'cx', ',', 'pad_k', '*', '2', '-', 'cy', ']', '*', '2', ',', 'device', '=', 'device', ')', '\\n', 'pad', '=', 'pad', '.', 'max', '(', 'torch', '.', 'tensor', '(', '[', '0', ',', '0', ']', '*', '2', ',', 'device', '=', 'device', ')', ')', '\\n', 'pad', '=', 'pad', '.', 'min', '(', 'torch', '.', 'tensor', '(', '[', 'width', '-', '1', ',', 'height', '-', '1', ']', '*', '2', ',', 'device', '=', 'device', ')', ')', '\\n', '\\n', 'pad_x1', ',', 'pad_y1', ',', 'pad_x2', ',', 'pad_y2', '=', 'pad', '.', 'ceil', '(', ')', '.', 'to', '(', 'torch', '.', 'int32', ')', '\\n', '\\n', 'return', 'pad_x1', ',', 'pad_x2', ',', 'pad_y1', ',', 'pad_y2', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.try_sample_affine_and_pad': [[324, 337], ['non_leaking.get_padding', 'torch.nn.functional.pad', 'torch.inverse', 'non_leaking.sample_affine'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.get_padding', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.sample_affine'], ['', 'def', 'try_sample_affine_and_pad', '(', 'img', ',', 'p', ',', 'kernel_size', ',', 'G', '=', 'None', ')', ':', '\\n', '    ', 'batch', ',', '_', ',', 'height', ',', 'width', '=', 'img', '.', 'shape', '\\n', '\\n', 'G_try', '=', 'G', '\\n', '\\n', 'if', 'G', 'is', 'None', ':', '\\n', '        ', 'G_try', '=', 'torch', '.', 'inverse', '(', 'sample_affine', '(', 'p', ',', 'batch', ',', 'height', ',', 'width', ')', ')', '\\n', '\\n', '', 'pad_x1', ',', 'pad_x2', ',', 'pad_y1', ',', 'pad_y2', '=', 'get_padding', '(', 'G_try', ',', 'height', ',', 'width', ',', 'kernel_size', ')', '\\n', '\\n', 'img_pad', '=', 'F', '.', 'pad', '(', 'img', ',', '(', 'pad_x1', ',', 'pad_x2', ',', 'pad_y1', ',', 'pad_y2', ')', ',', 'mode', '=', '\"reflect\"', ')', '\\n', '\\n', 'return', 'img_pad', ',', 'G_try', ',', '(', 'pad_x1', ',', 'pad_x2', ',', 'pad_y1', ',', 'pad_y2', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat_single': [[380, 382], ['torch.tensor'], 'function', ['None'], ['def', 'scale_mat_single', '(', 's_x', ',', 's_y', ')', ':', '\\n', '    ', 'return', 'torch', '.', 'tensor', '(', '(', '(', 's_x', ',', '0', ',', '0', ')', ',', '(', '0', ',', 's_y', ',', '0', ')', ',', '(', '0', ',', '0', ',', '1', ')', ')', ',', 'dtype', '=', 'torch', '.', 'float32', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat_single': [[384, 386], ['torch.tensor'], 'function', ['None'], ['', 'def', 'translate_mat_single', '(', 't_x', ',', 't_y', ')', ':', '\\n', '    ', 'return', 'torch', '.', 'tensor', '(', '(', '(', '1', ',', '0', ',', 't_x', ')', ',', '(', '0', ',', '1', ',', 't_y', ')', ',', '(', '0', ',', '0', ',', '1', ')', ')', ',', 'dtype', '=', 'torch', '.', 'float32', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_apply_affine': [[388, 439], ['len', 'torch.as_tensor().to', 'torch.flip', 'non_leaking.try_sample_affine_and_pad', 'op.upfirdn2d', 'op.upfirdn2d', 'torch.nn.functional.affine_grid', 'grid_sample', 'op.upfirdn2d', 'op.upfirdn2d', 'non_leaking.translate_mat_single', 'torch.as_tensor().to.unsqueeze', 'torch.as_tensor().to.unsqueeze', 'non_leaking.scale_mat_single', 'non_leaking.translate_mat_single', 'non_leaking.scale_mat_single', 'G_inv[].to', 'torch.flip.unsqueeze', 'torch.flip.unsqueeze', 'torch.as_tensor', 'non_leaking.scale_mat_single', 'non_leaking.translate_mat_single', 'non_leaking.scale_mat_single'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.try_sample_affine_and_pad', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.affine_grid', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat_single', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat_single', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat_single', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat_single', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat_single', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat_single', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat_single'], ['', 'def', 'random_apply_affine', '(', 'img', ',', 'p', ',', 'G', '=', 'None', ',', 'antialiasing_kernel', '=', 'SYM6', ')', ':', '\\n', '    ', 'kernel', '=', 'antialiasing_kernel', '\\n', 'len_k', '=', 'len', '(', 'kernel', ')', '\\n', '\\n', 'kernel', '=', 'torch', '.', 'as_tensor', '(', 'kernel', ')', '.', 'to', '(', 'img', ')', '\\n', '# kernel = torch.ger(kernel, kernel).to(img)', '\\n', 'kernel_flip', '=', 'torch', '.', 'flip', '(', 'kernel', ',', '(', '0', ',', ')', ')', '\\n', '\\n', 'img_pad', ',', 'G', ',', '(', 'pad_x1', ',', 'pad_x2', ',', 'pad_y1', ',', 'pad_y2', ')', '=', 'try_sample_affine_and_pad', '(', '\\n', 'img', ',', 'p', ',', 'len_k', ',', 'G', '\\n', ')', '\\n', '\\n', 'G_inv', '=', '(', '\\n', 'translate_mat_single', '(', '(', 'pad_x1', '-', 'pad_x2', ')', '.', 'item', '(', ')', '/', '2', ',', '(', 'pad_y1', '-', 'pad_y2', ')', '.', 'item', '(', ')', '/', '2', ')', '\\n', '@', 'G', '\\n', ')', '\\n', 'up_pad', '=', '(', '\\n', '(', 'len_k', '+', '2', '-', '1', ')', '//', '2', ',', '\\n', '(', 'len_k', '-', '2', ')', '//', '2', ',', '\\n', '(', 'len_k', '+', '2', '-', '1', ')', '//', '2', ',', '\\n', '(', 'len_k', '-', '2', ')', '//', '2', ',', '\\n', ')', '\\n', 'img_2x', '=', 'upfirdn2d', '(', 'img_pad', ',', 'kernel', '.', 'unsqueeze', '(', '0', ')', ',', 'up', '=', '(', '2', ',', '1', ')', ',', 'pad', '=', '(', '*', 'up_pad', '[', ':', '2', ']', ',', '0', ',', '0', ')', ')', '\\n', 'img_2x', '=', 'upfirdn2d', '(', 'img_2x', ',', 'kernel', '.', 'unsqueeze', '(', '1', ')', ',', 'up', '=', '(', '1', ',', '2', ')', ',', 'pad', '=', '(', '0', ',', '0', ',', '*', 'up_pad', '[', '2', ':', ']', ')', ')', '\\n', 'G_inv', '=', 'scale_mat_single', '(', '2', ',', '2', ')', '@', 'G_inv', '@', 'scale_mat_single', '(', '1', '/', '2', ',', '1', '/', '2', ')', '\\n', 'G_inv', '=', 'translate_mat_single', '(', '-', '0.5', ',', '-', '0.5', ')', '@', 'G_inv', '@', 'translate_mat_single', '(', '0.5', ',', '0.5', ')', '\\n', 'batch_size', ',', 'channel', ',', 'height', ',', 'width', '=', 'img', '.', 'shape', '\\n', 'pad_k', '=', 'len_k', '//', '4', '\\n', 'shape', '=', '(', 'batch_size', ',', 'channel', ',', '(', 'height', '+', 'pad_k', '*', '2', ')', '*', '2', ',', '(', 'width', '+', 'pad_k', '*', '2', ')', '*', '2', ')', '\\n', 'G_inv', '=', '(', '\\n', 'scale_mat_single', '(', '2', '/', 'img_2x', '.', 'shape', '[', '3', ']', ',', '2', '/', 'img_2x', '.', 'shape', '[', '2', ']', ')', '\\n', '@', 'G_inv', '\\n', '@', 'scale_mat_single', '(', '1', '/', '(', '2', '/', 'shape', '[', '3', ']', ')', ',', '1', '/', '(', '2', '/', 'shape', '[', '2', ']', ')', ')', '\\n', ')', '\\n', 'grid', '=', 'F', '.', 'affine_grid', '(', 'G_inv', '[', ':', ',', ':', '2', ',', ':', ']', '.', 'to', '(', 'img_2x', ')', ',', 'shape', ',', 'align_corners', '=', 'False', ')', '\\n', 'img_affine', '=', 'grid_sample', '(', 'img_2x', ',', 'grid', ')', '\\n', 'd_p', '=', '-', 'pad_k', '*', '2', '\\n', 'down_pad', '=', '(', '\\n', 'd_p', '+', '(', 'len_k', '-', '2', '+', '1', ')', '//', '2', ',', '\\n', 'd_p', '+', '(', 'len_k', '-', '2', ')', '//', '2', ',', '\\n', 'd_p', '+', '(', 'len_k', '-', '2', '+', '1', ')', '//', '2', ',', '\\n', 'd_p', '+', '(', 'len_k', '-', '2', ')', '//', '2', ',', '\\n', ')', '\\n', 'img_down', '=', 'upfirdn2d', '(', '\\n', 'img_affine', ',', 'kernel_flip', '.', 'unsqueeze', '(', '0', ')', ',', 'down', '=', '(', '2', ',', '1', ')', ',', 'pad', '=', '(', '*', 'down_pad', '[', ':', '2', ']', ',', '0', ',', '0', ')', '\\n', ')', '\\n', 'img_down', '=', 'upfirdn2d', '(', '\\n', 'img_down', ',', 'kernel_flip', '.', 'unsqueeze', '(', '1', ')', ',', 'down', '=', '(', '1', ',', '2', ')', ',', 'pad', '=', '(', '0', ',', '0', ',', '*', 'down_pad', '[', '2', ':', ']', ')', '\\n', ')', '\\n', '\\n', 'return', 'img_down', ',', 'G', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.apply_color': [[441, 450], ['img.permute.permute', 'mat[].transpose().view', 'mat[].view', 'img.permute.permute', 'mat[].transpose'], 'function', ['None'], ['', 'def', 'apply_color', '(', 'img', ',', 'mat', ')', ':', '\\n', '    ', 'batch', '=', 'img', '.', 'shape', '[', '0', ']', '\\n', 'img', '=', 'img', '.', 'permute', '(', '0', ',', '2', ',', '3', ',', '1', ')', '\\n', 'mat_mul', '=', 'mat', '[', ':', ',', ':', '3', ',', ':', '3', ']', '.', 'transpose', '(', '1', ',', '2', ')', '.', 'view', '(', 'batch', ',', '1', ',', '3', ',', '3', ')', '\\n', 'mat_add', '=', 'mat', '[', ':', ',', ':', '3', ',', '3', ']', '.', 'view', '(', 'batch', ',', '1', ',', '1', ',', '3', ')', '\\n', 'img', '=', 'img', '@', 'mat_mul', '+', 'mat_add', '\\n', 'img', '=', 'img', '.', 'permute', '(', '0', ',', '3', ',', '1', ',', '2', ')', '\\n', '\\n', 'return', 'img', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_apply_color': [[452, 459], ['non_leaking.apply_color', 'non_leaking.sample_color', 'sample_color.to'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.apply_color', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.sample_color'], ['', 'def', 'random_apply_color', '(', 'img', ',', 'p', ',', 'C', '=', 'None', ')', ':', '\\n', '    ', 'if', 'C', 'is', 'None', ':', '\\n', '        ', 'C', '=', 'sample_color', '(', 'p', ',', 'img', '.', 'shape', '[', '0', ']', ')', '\\n', '\\n', '', 'img', '=', 'apply_color', '(', 'img', ',', 'C', '.', 'to', '(', 'img', ')', ')', '\\n', '\\n', 'return', 'img', ',', 'C', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.augment': [[461, 466], ['non_leaking.random_apply_affine', 'non_leaking.random_apply_color'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_apply_affine', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_apply_color'], ['', 'def', 'augment', '(', 'img', ',', 'p', ',', 'transform_matrix', '=', '(', 'None', ',', 'None', ')', ')', ':', '\\n', '    ', 'img', ',', 'G', '=', 'random_apply_affine', '(', 'img', ',', 'p', ',', 'transform_matrix', '[', '0', ']', ')', '\\n', 'img', ',', 'C', '=', 'random_apply_color', '(', 'img', ',', 'p', ',', 'transform_matrix', '[', '1', ']', ')', '\\n', '\\n', 'return', 'img', ',', '(', 'G', ',', 'C', ')', '\\n', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.generate.generate': [[10, 28], ['torch.no_grad', 'g_ema.eval', 'torch.randn', 'tqdm.tqdm', 'range', 'g_ema', 'range', 'math.sin', 'math.cos', 'torchvision.utils.save_image', 'sample[].unsqueeze', 'str().zfill', 'str().zfill', 'str', 'str'], 'function', ['None'], ['def', 'generate', '(', 'args', ',', 'g_ema', ',', 'device', ',', 'mean_latent', ')', ':', '\\n', '    ', 'radius', '=', '32', '\\n', 'with', 'torch', '.', 'no_grad', '(', ')', ':', '\\n', '        ', 'g_ema', '.', 'eval', '(', ')', '\\n', 'sample_z', '=', 'torch', '.', 'randn', '(', 'args', '.', 'sample', ',', 'args', '.', 'latent', ',', 'device', '=', 'device', ')', '\\n', 'for', 'i', 'in', 'tqdm', '(', 'range', '(', 'args', '.', 'pics', ')', ')', ':', '\\n', '            ', 'dh', '=', 'math', '.', 'sin', '(', '2', '*', 'math', '.', 'pi', '*', '(', 'i', '/', 'args', '.', 'pics', ')', ')', '*', 'radius', '\\n', 'dw', '=', 'math', '.', 'cos', '(', '2', '*', 'math', '.', 'pi', '*', '(', 'i', '/', 'args', '.', 'pics', ')', ')', '*', 'radius', '\\n', 'sample', ',', '_', '=', 'g_ema', '(', '\\n', '[', 'sample_z', ']', ',', 'truncation', '=', 'args', '.', 'truncation', ',', 'truncation_latent', '=', 'mean_latent', ',', 'shift_h', '=', 'dh', ',', 'shift_w', '=', 'dw', ')', '\\n', '\\n', 'for', 'j', 'in', 'range', '(', 'args', '.', 'sample', ')', ':', '\\n', '                ', 'utils', '.', 'save_image', '(', '\\n', 'sample', '[', 'j', ']', '.', 'unsqueeze', '(', '0', ')', ',', '\\n', 'f\"generate/{args.name}/{str(j).zfill(3)}_{str(i).zfill(4)}.png\"', ',', '\\n', 'nrow', '=', '1', ',', '\\n', 'normalize', '=', 'True', ',', '\\n', 'range', '=', '(', '-', '1', ',', '1', ')', ',', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_rank': [[9, 17], ['torch.distributed.get_rank', 'torch.distributed.is_available', 'torch.distributed.is_initialized'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_rank'], ['def', 'get_rank', '(', ')', ':', '\\n', '    ', 'if', 'not', 'dist', '.', 'is_available', '(', ')', ':', '\\n', '        ', 'return', '0', '\\n', '\\n', '', 'if', 'not', 'dist', '.', 'is_initialized', '(', ')', ':', '\\n', '        ', 'return', '0', '\\n', '\\n', '', 'return', 'dist', '.', 'get_rank', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.synchronize': [[19, 32], ['torch.distributed.get_world_size', 'torch.distributed.barrier', 'torch.distributed.is_available', 'torch.distributed.is_initialized'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size'], ['', 'def', 'synchronize', '(', ')', ':', '\\n', '    ', 'if', 'not', 'dist', '.', 'is_available', '(', ')', ':', '\\n', '        ', 'return', '\\n', '\\n', '', 'if', 'not', 'dist', '.', 'is_initialized', '(', ')', ':', '\\n', '        ', 'return', '\\n', '\\n', '', 'world_size', '=', 'dist', '.', 'get_world_size', '(', ')', '\\n', '\\n', 'if', 'world_size', '==', '1', ':', '\\n', '        ', 'return', '\\n', '\\n', '', 'dist', '.', 'barrier', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size': [[34, 42], ['torch.distributed.get_world_size', 'torch.distributed.is_available', 'torch.distributed.is_initialized'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size'], ['', 'def', 'get_world_size', '(', ')', ':', '\\n', '    ', 'if', 'not', 'dist', '.', 'is_available', '(', ')', ':', '\\n', '        ', 'return', '1', '\\n', '\\n', '', 'if', 'not', 'dist', '.', 'is_initialized', '(', ')', ':', '\\n', '        ', 'return', '1', '\\n', '\\n', '', 'return', 'dist', '.', 'get_world_size', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.reduce_sum': [[44, 55], ['tensor.clone.clone', 'torch.distributed.all_reduce', 'torch.distributed.is_available', 'torch.distributed.is_initialized'], 'function', ['None'], ['', 'def', 'reduce_sum', '(', 'tensor', ')', ':', '\\n', '    ', 'if', 'not', 'dist', '.', 'is_available', '(', ')', ':', '\\n', '        ', 'return', 'tensor', '\\n', '\\n', '', 'if', 'not', 'dist', '.', 'is_initialized', '(', ')', ':', '\\n', '        ', 'return', 'tensor', '\\n', '\\n', '', 'tensor', '=', 'tensor', '.', 'clone', '(', ')', '\\n', 'dist', '.', 'all_reduce', '(', 'tensor', ',', 'op', '=', 'dist', '.', 'ReduceOp', '.', 'SUM', ')', '\\n', '\\n', 'return', 'tensor', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.gather_grad': [[57, 67], ['distributed.get_world_size', 'torch.distributed.all_reduce', 'param.grad.data.div_'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size'], ['', 'def', 'gather_grad', '(', 'params', ')', ':', '\\n', '    ', 'world_size', '=', 'get_world_size', '(', ')', '\\n', '\\n', 'if', 'world_size', '==', '1', ':', '\\n', '        ', 'return', '\\n', '\\n', '', 'for', 'param', 'in', 'params', ':', '\\n', '        ', 'if', 'param', '.', 'grad', 'is', 'not', 'None', ':', '\\n', '            ', 'dist', '.', 'all_reduce', '(', 'param', '.', 'grad', '.', 'data', ',', 'op', '=', 'dist', '.', 'ReduceOp', '.', 'SUM', ')', '\\n', 'param', '.', 'grad', '.', 'data', '.', 'div_', '(', 'world_size', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.all_gather': [[69, 102], ['distributed.get_world_size', 'pickle.dumps', 'torch.ByteStorage.from_buffer', 'torch.ByteTensor().to', 'torch.IntTensor().to', 'torch.distributed.all_gather', 'max', 'torch.distributed.all_gather', 'zip', 'torch.IntTensor().to', 'int', 'tensor_list.append', 'torch.ByteTensor().to', 'torch.cat', 'data_list.append', 'torch.ByteTensor', 'torch.IntTensor', 'range', 'size.item', 'torch.ByteTensor().to', 'torch.cat.cpu().numpy().tobytes', 'pickle.loads', 'torch.IntTensor', 'torch.ByteTensor', 'torch.cat.numel', 'torch.ByteTensor', 'torch.cat.cpu().numpy', 'torch.cat.cpu'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.all_gather', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.all_gather'], ['', '', '', 'def', 'all_gather', '(', 'data', ')', ':', '\\n', '    ', 'world_size', '=', 'get_world_size', '(', ')', '\\n', '\\n', 'if', 'world_size', '==', '1', ':', '\\n', '        ', 'return', '[', 'data', ']', '\\n', '\\n', '', 'buffer', '=', 'pickle', '.', 'dumps', '(', 'data', ')', '\\n', 'storage', '=', 'torch', '.', 'ByteStorage', '.', 'from_buffer', '(', 'buffer', ')', '\\n', 'tensor', '=', 'torch', '.', 'ByteTensor', '(', 'storage', ')', '.', 'to', '(', \"'cuda'\", ')', '\\n', '\\n', 'local_size', '=', 'torch', '.', 'IntTensor', '(', '[', 'tensor', '.', 'numel', '(', ')', ']', ')', '.', 'to', '(', \"'cuda'\", ')', '\\n', 'size_list', '=', '[', 'torch', '.', 'IntTensor', '(', '[', '0', ']', ')', '.', 'to', '(', \"'cuda'\", ')', 'for', '_', 'in', 'range', '(', 'world_size', ')', ']', '\\n', 'dist', '.', 'all_gather', '(', 'size_list', ',', 'local_size', ')', '\\n', 'size_list', '=', '[', 'int', '(', 'size', '.', 'item', '(', ')', ')', 'for', 'size', 'in', 'size_list', ']', '\\n', 'max_size', '=', 'max', '(', 'size_list', ')', '\\n', '\\n', 'tensor_list', '=', '[', ']', '\\n', 'for', '_', 'in', 'size_list', ':', '\\n', '        ', 'tensor_list', '.', 'append', '(', 'torch', '.', 'ByteTensor', '(', 'size', '=', '(', 'max_size', ',', ')', ')', '.', 'to', '(', \"'cuda'\", ')', ')', '\\n', '\\n', '', 'if', 'local_size', '!=', 'max_size', ':', '\\n', '        ', 'padding', '=', 'torch', '.', 'ByteTensor', '(', 'size', '=', '(', 'max_size', '-', 'local_size', ',', ')', ')', '.', 'to', '(', \"'cuda'\", ')', '\\n', 'tensor', '=', 'torch', '.', 'cat', '(', '(', 'tensor', ',', 'padding', ')', ',', '0', ')', '\\n', '\\n', '', 'dist', '.', 'all_gather', '(', 'tensor_list', ',', 'tensor', ')', '\\n', '\\n', 'data_list', '=', '[', ']', '\\n', '\\n', 'for', 'size', ',', 'tensor', 'in', 'zip', '(', 'size_list', ',', 'tensor_list', ')', ':', '\\n', '        ', 'buffer', '=', 'tensor', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '.', 'tobytes', '(', ')', '[', ':', 'size', ']', '\\n', 'data_list', '.', 'append', '(', 'pickle', '.', 'loads', '(', 'buffer', ')', ')', '\\n', '\\n', '', 'return', 'data_list', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.reduce_loss_dict': [[104, 127], ['distributed.get_world_size', 'torch.no_grad', 'sorted', 'torch.stack', 'torch.distributed.reduce', 'loss_dict.keys', 'keys.append', 'torch.stack.append', 'torch.distributed.get_rank', 'zip'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_rank'], ['', 'def', 'reduce_loss_dict', '(', 'loss_dict', ')', ':', '\\n', '    ', 'world_size', '=', 'get_world_size', '(', ')', '\\n', '\\n', 'if', 'world_size', '<', '2', ':', '\\n', '        ', 'return', 'loss_dict', '\\n', '\\n', '', 'with', 'torch', '.', 'no_grad', '(', ')', ':', '\\n', '        ', 'keys', '=', '[', ']', '\\n', 'losses', '=', '[', ']', '\\n', '\\n', 'for', 'k', 'in', 'sorted', '(', 'loss_dict', '.', 'keys', '(', ')', ')', ':', '\\n', '            ', 'keys', '.', 'append', '(', 'k', ')', '\\n', 'losses', '.', 'append', '(', 'loss_dict', '[', 'k', ']', ')', '\\n', '\\n', '', 'losses', '=', 'torch', '.', 'stack', '(', 'losses', ',', '0', ')', '\\n', 'dist', '.', 'reduce', '(', 'losses', ',', 'dst', '=', '0', ')', '\\n', '\\n', 'if', 'dist', '.', 'get_rank', '(', ')', '==', '0', ':', '\\n', '            ', 'losses', '/=', 'world_size', '\\n', '\\n', '', 'reduced_losses', '=', '{', 'k', ':', 'v', 'for', 'k', ',', 'v', 'in', 'zip', '(', 'keys', ',', 'losses', ')', '}', '\\n', '\\n', '', 'return', 'reduced_losses', '\\n', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.InceptionV3.__init__': [[31, 128], ['torch.Module.__init__', 'sorted', 'max', 'torch.ModuleList', 'torch.ModuleList', 'torch.ModuleList', 'models.inception_v3.InceptionV3.blocks.append', 'models.inception_v3.InceptionV3.parameters', 'inception.fid_inception_v3', 'torchvision.models.inception_v3', 'torch.MaxPool2d', 'torch.MaxPool2d', 'torch.MaxPool2d', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential', 'models.inception_v3.InceptionV3.blocks.append', 'models.inception_v3.InceptionV3.blocks.append', 'models.inception_v3.InceptionV3.blocks.append', 'torch.MaxPool2d', 'torch.MaxPool2d', 'torch.MaxPool2d', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential', 'torch.AdaptiveAvgPool2d', 'torch.AdaptiveAvgPool2d', 'torch.AdaptiveAvgPool2d', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.fid_inception_v3'], ['def', '__init__', '(', 'self', ',', '\\n', 'output_blocks', '=', '[', 'DEFAULT_BLOCK_INDEX', ']', ',', '\\n', 'resize_input', '=', 'True', ',', '\\n', 'normalize_input', '=', 'True', ',', '\\n', 'requires_grad', '=', 'False', ',', '\\n', 'use_fid_inception', '=', 'True', ')', ':', '\\n', '        ', '\"\"\"Build pretrained InceptionV3\\n\\n        Parameters\\n        ----------\\n        output_blocks : list of int\\n            Indices of blocks to return features of. Possible values are:\\n                - 0: corresponds to output of first max pooling\\n                - 1: corresponds to output of second max pooling\\n                - 2: corresponds to output which is fed to aux classifier\\n                - 3: corresponds to output of final average pooling\\n        resize_input : bool\\n            If true, bilinearly resizes input to width and height 299 before\\n            feeding input to model. As the network without fully connected\\n            layers is fully convolutional, it should be able to handle inputs\\n            of arbitrary size, so resizing might not be strictly needed\\n        normalize_input : bool\\n            If true, scales the input from range (0, 1) to the range the\\n            pretrained Inception network expects, namely (-1, 1)\\n        requires_grad : bool\\n            If true, parameters of the model require gradients. Possibly useful\\n            for finetuning the network\\n        use_fid_inception : bool\\n            If true, uses the pretrained Inception model used in Tensorflow\\'s\\n            FID implementation. If false, uses the pretrained Inception model\\n            available in torchvision. The FID Inception model has different\\n            weights and a slightly different structure from torchvision\\'s\\n            Inception model. If you want to compute FID scores, you are\\n            strongly advised to set this parameter to true to get comparable\\n            results.\\n        \"\"\"', '\\n', 'super', '(', 'InceptionV3', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'resize_input', '=', 'resize_input', '\\n', 'self', '.', 'normalize_input', '=', 'normalize_input', '\\n', 'self', '.', 'output_blocks', '=', 'sorted', '(', 'output_blocks', ')', '\\n', 'self', '.', 'last_needed_block', '=', 'max', '(', 'output_blocks', ')', '\\n', '\\n', 'assert', 'self', '.', 'last_needed_block', '<=', '3', ',', \"'Last possible output block index is 3'\", '\\n', '\\n', 'self', '.', 'blocks', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', '\\n', 'if', 'use_fid_inception', ':', '\\n', '            ', 'inception', '=', 'fid_inception_v3', '(', ')', '\\n', '', 'else', ':', '\\n', '            ', 'inception', '=', 'models', '.', 'inception_v3', '(', 'pretrained', '=', 'True', ')', '\\n', '\\n', '# Block 0: input to maxpool1', '\\n', '', 'block0', '=', '[', '\\n', 'inception', '.', 'Conv2d_1a_3x3', ',', '\\n', 'inception', '.', 'Conv2d_2a_3x3', ',', '\\n', 'inception', '.', 'Conv2d_2b_3x3', ',', '\\n', 'nn', '.', 'MaxPool2d', '(', 'kernel_size', '=', '3', ',', 'stride', '=', '2', ')', '\\n', ']', '\\n', 'self', '.', 'blocks', '.', 'append', '(', 'nn', '.', 'Sequential', '(', '*', 'block0', ')', ')', '\\n', '\\n', '# Block 1: maxpool1 to maxpool2', '\\n', 'if', 'self', '.', 'last_needed_block', '>=', '1', ':', '\\n', '            ', 'block1', '=', '[', '\\n', 'inception', '.', 'Conv2d_3b_1x1', ',', '\\n', 'inception', '.', 'Conv2d_4a_3x3', ',', '\\n', 'nn', '.', 'MaxPool2d', '(', 'kernel_size', '=', '3', ',', 'stride', '=', '2', ')', '\\n', ']', '\\n', 'self', '.', 'blocks', '.', 'append', '(', 'nn', '.', 'Sequential', '(', '*', 'block1', ')', ')', '\\n', '\\n', '# Block 2: maxpool2 to aux classifier', '\\n', '', 'if', 'self', '.', 'last_needed_block', '>=', '2', ':', '\\n', '            ', 'block2', '=', '[', '\\n', 'inception', '.', 'Mixed_5b', ',', '\\n', 'inception', '.', 'Mixed_5c', ',', '\\n', 'inception', '.', 'Mixed_5d', ',', '\\n', 'inception', '.', 'Mixed_6a', ',', '\\n', 'inception', '.', 'Mixed_6b', ',', '\\n', 'inception', '.', 'Mixed_6c', ',', '\\n', 'inception', '.', 'Mixed_6d', ',', '\\n', 'inception', '.', 'Mixed_6e', ',', '\\n', ']', '\\n', 'self', '.', 'blocks', '.', 'append', '(', 'nn', '.', 'Sequential', '(', '*', 'block2', ')', ')', '\\n', '\\n', '# Block 3: aux classifier to final avgpool', '\\n', '', 'if', 'self', '.', 'last_needed_block', '>=', '3', ':', '\\n', '            ', 'block3', '=', '[', '\\n', 'inception', '.', 'Mixed_7a', ',', '\\n', 'inception', '.', 'Mixed_7b', ',', '\\n', 'inception', '.', 'Mixed_7c', ',', '\\n', 'nn', '.', 'AdaptiveAvgPool2d', '(', 'output_size', '=', '(', '1', ',', '1', ')', ')', '\\n', ']', '\\n', 'self', '.', 'blocks', '.', 'append', '(', 'nn', '.', 'Sequential', '(', '*', 'block3', ')', ')', '\\n', '\\n', '', 'for', 'param', 'in', 'self', '.', 'parameters', '(', ')', ':', '\\n', '            ', 'param', '.', 'requires_grad', '=', 'requires_grad', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.InceptionV3.forward': [[129, 164], ['enumerate', 'torch.interpolate', 'torch.interpolate', 'torch.interpolate', 'block', 'outp.append'], 'methods', ['None'], ['', '', 'def', 'forward', '(', 'self', ',', 'inp', ')', ':', '\\n', '        ', '\"\"\"Get Inception feature maps\\n\\n        Parameters\\n        ----------\\n        inp : torch.autograd.Variable\\n            Input tensor of shape Bx3xHxW. Values are expected to be in\\n            range (0, 1)\\n\\n        Returns\\n        -------\\n        List of torch.autograd.Variable, corresponding to the selected output\\n        block, sorted ascending by index\\n        \"\"\"', '\\n', 'outp', '=', '[', ']', '\\n', 'x', '=', 'inp', '\\n', '\\n', 'if', 'self', '.', 'resize_input', ':', '\\n', '            ', 'x', '=', 'F', '.', 'interpolate', '(', 'x', ',', '\\n', 'size', '=', '(', '299', ',', '299', ')', ',', '\\n', 'mode', '=', \"'bilinear'\", ',', '\\n', 'align_corners', '=', 'False', ')', '\\n', '\\n', '', 'if', 'self', '.', 'normalize_input', ':', '\\n', '            ', 'x', '=', '2', '*', 'x', '-', '1', '# Scale from range (0, 1) to range (-1, 1)', '\\n', '\\n', '', 'for', 'idx', ',', 'block', 'in', 'enumerate', '(', 'self', '.', 'blocks', ')', ':', '\\n', '            ', 'x', '=', 'block', '(', 'x', ')', '\\n', 'if', 'idx', 'in', 'self', '.', 'output_blocks', ':', '\\n', '                ', 'outp', '.', 'append', '(', 'x', ')', '\\n', '\\n', '', 'if', 'idx', '==', 'self', '.', 'last_needed_block', ':', '\\n', '                ', 'break', '\\n', '\\n', '', '', 'return', 'outp', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionA.__init__': [[195, 197], ['super().__init__'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['def', '__init__', '(', 'self', ',', 'in_channels', ',', 'pool_features', ')', ':', '\\n', '        ', 'super', '(', 'FIDInceptionA', ',', 'self', ')', '.', '__init__', '(', 'in_channels', ',', 'pool_features', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionA.forward': [[198, 216], ['inception.FIDInceptionA.branch1x1', 'inception.FIDInceptionA.branch5x5_1', 'inception.FIDInceptionA.branch5x5_2', 'inception.FIDInceptionA.branch3x3dbl_1', 'inception.FIDInceptionA.branch3x3dbl_2', 'inception.FIDInceptionA.branch3x3dbl_3', 'torch.avg_pool2d', 'torch.avg_pool2d', 'torch.avg_pool2d', 'inception.FIDInceptionA.branch_pool', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'x', ')', ':', '\\n', '        ', 'branch1x1', '=', 'self', '.', 'branch1x1', '(', 'x', ')', '\\n', '\\n', 'branch5x5', '=', 'self', '.', 'branch5x5_1', '(', 'x', ')', '\\n', 'branch5x5', '=', 'self', '.', 'branch5x5_2', '(', 'branch5x5', ')', '\\n', '\\n', 'branch3x3dbl', '=', 'self', '.', 'branch3x3dbl_1', '(', 'x', ')', '\\n', 'branch3x3dbl', '=', 'self', '.', 'branch3x3dbl_2', '(', 'branch3x3dbl', ')', '\\n', 'branch3x3dbl', '=', 'self', '.', 'branch3x3dbl_3', '(', 'branch3x3dbl', ')', '\\n', '\\n', \"# Patch: Tensorflow's average pool does not use the padded zero's in\", '\\n', '# its average calculation', '\\n', 'branch_pool', '=', 'F', '.', 'avg_pool2d', '(', 'x', ',', 'kernel_size', '=', '3', ',', 'stride', '=', '1', ',', 'padding', '=', '1', ',', '\\n', 'count_include_pad', '=', 'False', ')', '\\n', 'branch_pool', '=', 'self', '.', 'branch_pool', '(', 'branch_pool', ')', '\\n', '\\n', 'outputs', '=', '[', 'branch1x1', ',', 'branch5x5', ',', 'branch3x3dbl', ',', 'branch_pool', ']', '\\n', 'return', 'torch', '.', 'cat', '(', 'outputs', ',', '1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionC.__init__': [[220, 222], ['super().__init__'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['def', '__init__', '(', 'self', ',', 'in_channels', ',', 'channels_7x7', ')', ':', '\\n', '        ', 'super', '(', 'FIDInceptionC', ',', 'self', ')', '.', '__init__', '(', 'in_channels', ',', 'channels_7x7', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionC.forward': [[223, 244], ['inception.FIDInceptionC.branch1x1', 'inception.FIDInceptionC.branch7x7_1', 'inception.FIDInceptionC.branch7x7_2', 'inception.FIDInceptionC.branch7x7_3', 'inception.FIDInceptionC.branch7x7dbl_1', 'inception.FIDInceptionC.branch7x7dbl_2', 'inception.FIDInceptionC.branch7x7dbl_3', 'inception.FIDInceptionC.branch7x7dbl_4', 'inception.FIDInceptionC.branch7x7dbl_5', 'torch.avg_pool2d', 'torch.avg_pool2d', 'torch.avg_pool2d', 'inception.FIDInceptionC.branch_pool', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'x', ')', ':', '\\n', '        ', 'branch1x1', '=', 'self', '.', 'branch1x1', '(', 'x', ')', '\\n', '\\n', 'branch7x7', '=', 'self', '.', 'branch7x7_1', '(', 'x', ')', '\\n', 'branch7x7', '=', 'self', '.', 'branch7x7_2', '(', 'branch7x7', ')', '\\n', 'branch7x7', '=', 'self', '.', 'branch7x7_3', '(', 'branch7x7', ')', '\\n', '\\n', 'branch7x7dbl', '=', 'self', '.', 'branch7x7dbl_1', '(', 'x', ')', '\\n', 'branch7x7dbl', '=', 'self', '.', 'branch7x7dbl_2', '(', 'branch7x7dbl', ')', '\\n', 'branch7x7dbl', '=', 'self', '.', 'branch7x7dbl_3', '(', 'branch7x7dbl', ')', '\\n', 'branch7x7dbl', '=', 'self', '.', 'branch7x7dbl_4', '(', 'branch7x7dbl', ')', '\\n', 'branch7x7dbl', '=', 'self', '.', 'branch7x7dbl_5', '(', 'branch7x7dbl', ')', '\\n', '\\n', \"# Patch: Tensorflow's average pool does not use the padded zero's in\", '\\n', '# its average calculation', '\\n', 'branch_pool', '=', 'F', '.', 'avg_pool2d', '(', 'x', ',', 'kernel_size', '=', '3', ',', 'stride', '=', '1', ',', 'padding', '=', '1', ',', '\\n', 'count_include_pad', '=', 'False', ')', '\\n', 'branch_pool', '=', 'self', '.', 'branch_pool', '(', 'branch_pool', ')', '\\n', '\\n', 'outputs', '=', '[', 'branch1x1', ',', 'branch7x7', ',', 'branch7x7dbl', ',', 'branch_pool', ']', '\\n', 'return', 'torch', '.', 'cat', '(', 'outputs', ',', '1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionE_1.__init__': [[248, 250], ['super().__init__'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['def', '__init__', '(', 'self', ',', 'in_channels', ')', ':', '\\n', '        ', 'super', '(', 'FIDInceptionE_1', ',', 'self', ')', '.', '__init__', '(', 'in_channels', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionE_1.forward': [[251, 277], ['inception.FIDInceptionE_1.branch1x1', 'inception.FIDInceptionE_1.branch3x3_1', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'inception.FIDInceptionE_1.branch3x3dbl_1', 'inception.FIDInceptionE_1.branch3x3dbl_2', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.avg_pool2d', 'torch.avg_pool2d', 'torch.avg_pool2d', 'inception.FIDInceptionE_1.branch_pool', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'inception.FIDInceptionE_1.branch3x3_2a', 'inception.FIDInceptionE_1.branch3x3_2b', 'inception.FIDInceptionE_1.branch3x3dbl_3a', 'inception.FIDInceptionE_1.branch3x3dbl_3b'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'x', ')', ':', '\\n', '        ', 'branch1x1', '=', 'self', '.', 'branch1x1', '(', 'x', ')', '\\n', '\\n', 'branch3x3', '=', 'self', '.', 'branch3x3_1', '(', 'x', ')', '\\n', 'branch3x3', '=', '[', '\\n', 'self', '.', 'branch3x3_2a', '(', 'branch3x3', ')', ',', '\\n', 'self', '.', 'branch3x3_2b', '(', 'branch3x3', ')', ',', '\\n', ']', '\\n', 'branch3x3', '=', 'torch', '.', 'cat', '(', 'branch3x3', ',', '1', ')', '\\n', '\\n', 'branch3x3dbl', '=', 'self', '.', 'branch3x3dbl_1', '(', 'x', ')', '\\n', 'branch3x3dbl', '=', 'self', '.', 'branch3x3dbl_2', '(', 'branch3x3dbl', ')', '\\n', 'branch3x3dbl', '=', '[', '\\n', 'self', '.', 'branch3x3dbl_3a', '(', 'branch3x3dbl', ')', ',', '\\n', 'self', '.', 'branch3x3dbl_3b', '(', 'branch3x3dbl', ')', ',', '\\n', ']', '\\n', 'branch3x3dbl', '=', 'torch', '.', 'cat', '(', 'branch3x3dbl', ',', '1', ')', '\\n', '\\n', \"# Patch: Tensorflow's average pool does not use the padded zero's in\", '\\n', '# its average calculation', '\\n', 'branch_pool', '=', 'F', '.', 'avg_pool2d', '(', 'x', ',', 'kernel_size', '=', '3', ',', 'stride', '=', '1', ',', 'padding', '=', '1', ',', '\\n', 'count_include_pad', '=', 'False', ')', '\\n', 'branch_pool', '=', 'self', '.', 'branch_pool', '(', 'branch_pool', ')', '\\n', '\\n', 'outputs', '=', '[', 'branch1x1', ',', 'branch3x3', ',', 'branch3x3dbl', ',', 'branch_pool', ']', '\\n', 'return', 'torch', '.', 'cat', '(', 'outputs', ',', '1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionE_2.__init__': [[281, 283], ['super().__init__'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['def', '__init__', '(', 'self', ',', 'in_channels', ')', ':', '\\n', '        ', 'super', '(', 'FIDInceptionE_2', ',', 'self', ')', '.', '__init__', '(', 'in_channels', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionE_2.forward': [[284, 311], ['inception.FIDInceptionE_2.branch1x1', 'inception.FIDInceptionE_2.branch3x3_1', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'inception.FIDInceptionE_2.branch3x3dbl_1', 'inception.FIDInceptionE_2.branch3x3dbl_2', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.max_pool2d', 'torch.max_pool2d', 'torch.max_pool2d', 'inception.FIDInceptionE_2.branch_pool', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'inception.FIDInceptionE_2.branch3x3_2a', 'inception.FIDInceptionE_2.branch3x3_2b', 'inception.FIDInceptionE_2.branch3x3dbl_3a', 'inception.FIDInceptionE_2.branch3x3dbl_3b'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'x', ')', ':', '\\n', '        ', 'branch1x1', '=', 'self', '.', 'branch1x1', '(', 'x', ')', '\\n', '\\n', 'branch3x3', '=', 'self', '.', 'branch3x3_1', '(', 'x', ')', '\\n', 'branch3x3', '=', '[', '\\n', 'self', '.', 'branch3x3_2a', '(', 'branch3x3', ')', ',', '\\n', 'self', '.', 'branch3x3_2b', '(', 'branch3x3', ')', ',', '\\n', ']', '\\n', 'branch3x3', '=', 'torch', '.', 'cat', '(', 'branch3x3', ',', '1', ')', '\\n', '\\n', 'branch3x3dbl', '=', 'self', '.', 'branch3x3dbl_1', '(', 'x', ')', '\\n', 'branch3x3dbl', '=', 'self', '.', 'branch3x3dbl_2', '(', 'branch3x3dbl', ')', '\\n', 'branch3x3dbl', '=', '[', '\\n', 'self', '.', 'branch3x3dbl_3a', '(', 'branch3x3dbl', ')', ',', '\\n', 'self', '.', 'branch3x3dbl_3b', '(', 'branch3x3dbl', ')', ',', '\\n', ']', '\\n', 'branch3x3dbl', '=', 'torch', '.', 'cat', '(', 'branch3x3dbl', ',', '1', ')', '\\n', '\\n', '# Patch: The FID Inception model uses max pooling instead of average', '\\n', '# pooling. This is likely an error in this specific Inception', '\\n', '# implementation, as other Inception models use average pooling here', '\\n', '# (which matches the description in the paper).', '\\n', 'branch_pool', '=', 'F', '.', 'max_pool2d', '(', 'x', ',', 'kernel_size', '=', '3', ',', 'stride', '=', '1', ',', 'padding', '=', '1', ')', '\\n', 'branch_pool', '=', 'self', '.', 'branch_pool', '(', 'branch_pool', ')', '\\n', '\\n', 'outputs', '=', '[', 'branch1x1', ',', 'branch3x3', ',', 'branch3x3dbl', ',', 'branch_pool', ']', '\\n', 'return', 'torch', '.', 'cat', '(', 'outputs', ',', '1', ')', '\\n', '', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.fid_inception_v3': [[166, 191], ['torchvision.models.inception_v3', 'inception.FIDInceptionA', 'inception.FIDInceptionA', 'inception.FIDInceptionA', 'inception.FIDInceptionC', 'inception.FIDInceptionC', 'inception.FIDInceptionC', 'inception.FIDInceptionC', 'inception.FIDInceptionE_1', 'inception.FIDInceptionE_2', 'load_state_dict_from_url', 'models.inception_v3.load_state_dict'], 'function', ['None'], ['', '', 'def', 'fid_inception_v3', '(', ')', ':', '\\n', '    ', '\"\"\"Build pretrained Inception model for FID computation\\n\\n    The Inception model for FID computation uses a different set of weights\\n    and has a slightly different structure than torchvision\\'s Inception.\\n\\n    This method first constructs torchvision\\'s Inception and then patches the\\n    necessary parts that are different in the FID Inception model.\\n    \"\"\"', '\\n', 'inception', '=', 'models', '.', 'inception_v3', '(', 'num_classes', '=', '1008', ',', '\\n', 'aux_logits', '=', 'False', ',', '\\n', 'pretrained', '=', 'False', ')', '\\n', 'inception', '.', 'Mixed_5b', '=', 'FIDInceptionA', '(', '192', ',', 'pool_features', '=', '32', ')', '\\n', 'inception', '.', 'Mixed_5c', '=', 'FIDInceptionA', '(', '256', ',', 'pool_features', '=', '64', ')', '\\n', 'inception', '.', 'Mixed_5d', '=', 'FIDInceptionA', '(', '288', ',', 'pool_features', '=', '64', ')', '\\n', 'inception', '.', 'Mixed_6b', '=', 'FIDInceptionC', '(', '768', ',', 'channels_7x7', '=', '128', ')', '\\n', 'inception', '.', 'Mixed_6c', '=', 'FIDInceptionC', '(', '768', ',', 'channels_7x7', '=', '160', ')', '\\n', 'inception', '.', 'Mixed_6d', '=', 'FIDInceptionC', '(', '768', ',', 'channels_7x7', '=', '160', ')', '\\n', 'inception', '.', 'Mixed_6e', '=', 'FIDInceptionC', '(', '768', ',', 'channels_7x7', '=', '192', ')', '\\n', 'inception', '.', 'Mixed_7b', '=', 'FIDInceptionE_1', '(', '1280', ')', '\\n', 'inception', '.', 'Mixed_7c', '=', 'FIDInceptionE_2', '(', '2048', ')', '\\n', '\\n', 'state_dict', '=', 'load_state_dict_from_url', '(', 'FID_WEIGHTS_URL', ',', 'progress', '=', 'True', ')', '\\n', 'inception', '.', 'load_state_dict', '(', 'state_dict', ')', '\\n', 'return', 'inception', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.HaarTransform.__init__': [[28, 37], ['torch.nn.Module.__init__', 'swagan.get_haar_wavelet', 'swagan.HaarTransform.register_buffer', 'swagan.HaarTransform.register_buffer', 'swagan.HaarTransform.register_buffer', 'swagan.HaarTransform.register_buffer'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.get_haar_wavelet'], ['    ', 'def', '__init__', '(', 'self', ',', 'in_channels', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'll', ',', 'lh', ',', 'hl', ',', 'hh', '=', 'get_haar_wavelet', '(', 'in_channels', ')', '\\n', '\\n', 'self', '.', 'register_buffer', '(', \"'ll'\", ',', 'll', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'lh'\", ',', 'lh', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'hl'\", ',', 'hl', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'hh'\", ',', 'hh', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.HaarTransform.forward': [[38, 45], ['op.upfirdn2d', 'op.upfirdn2d', 'op.upfirdn2d', 'op.upfirdn2d', 'torch.cat'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'll', '=', 'upfirdn2d', '(', 'input', ',', 'self', '.', 'll', ',', 'down', '=', '2', ')', '\\n', 'lh', '=', 'upfirdn2d', '(', 'input', ',', 'self', '.', 'lh', ',', 'down', '=', '2', ')', '\\n', 'hl', '=', 'upfirdn2d', '(', 'input', ',', 'self', '.', 'hl', ',', 'down', '=', '2', ')', '\\n', 'hh', '=', 'upfirdn2d', '(', 'input', ',', 'self', '.', 'hh', ',', 'down', '=', '2', ')', '\\n', '\\n', 'return', 'torch', '.', 'cat', '(', '(', 'll', ',', 'lh', ',', 'hl', ',', 'hh', ')', ',', '1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.InverseHaarTransform.__init__': [[47, 56], ['torch.nn.Module.__init__', 'swagan.get_haar_wavelet', 'swagan.InverseHaarTransform.register_buffer', 'swagan.InverseHaarTransform.register_buffer', 'swagan.InverseHaarTransform.register_buffer', 'swagan.InverseHaarTransform.register_buffer'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.get_haar_wavelet'], ['    ', 'def', '__init__', '(', 'self', ',', 'in_channels', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'll', ',', 'lh', ',', 'hl', ',', 'hh', '=', 'get_haar_wavelet', '(', 'in_channels', ')', '\\n', '\\n', 'self', '.', 'register_buffer', '(', \"'ll'\", ',', 'll', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'lh'\", ',', '-', 'lh', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'hl'\", ',', '-', 'hl', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'hh'\", ',', 'hh', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.InverseHaarTransform.forward': [[57, 65], ['input.chunk', 'op.upfirdn2d', 'op.upfirdn2d', 'op.upfirdn2d', 'op.upfirdn2d'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'll', ',', 'lh', ',', 'hl', ',', 'hh', '=', 'input', '.', 'chunk', '(', '4', ',', '1', ')', '\\n', 'll', '=', 'upfirdn2d', '(', 'll', ',', 'self', '.', 'll', ',', 'up', '=', '2', ',', 'pad', '=', '(', '1', ',', '0', ',', '1', ',', '0', ')', ')', '\\n', 'lh', '=', 'upfirdn2d', '(', 'lh', ',', 'self', '.', 'lh', ',', 'up', '=', '2', ',', 'pad', '=', '(', '1', ',', '0', ',', '1', ',', '0', ')', ')', '\\n', 'hl', '=', 'upfirdn2d', '(', 'hl', ',', 'self', '.', 'hl', ',', 'up', '=', '2', ',', 'pad', '=', '(', '1', ',', '0', ',', '1', ',', '0', ')', ')', '\\n', 'hh', '=', 'upfirdn2d', '(', 'hh', ',', 'self', '.', 'hh', ',', 'up', '=', '2', ',', 'pad', '=', '(', '1', ',', '0', ',', '1', ',', '0', ')', ')', '\\n', '\\n', 'return', 'll', '+', 'lh', '+', 'hl', '+', 'hh', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.ToRGB.__init__': [[68, 78], ['torch.nn.Module.__init__', 'model.ModulatedConv2d', 'torch.nn.Parameter', 'swagan.InverseHaarTransform', 'model.Upsample', 'swagan.HaarTransform', 'torch.zeros'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'in_channel', ',', 'style_dim', ',', 'upsample', '=', 'True', ',', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'if', 'upsample', ':', '\\n', '            ', 'self', '.', 'iwt', '=', 'InverseHaarTransform', '(', '3', ')', '\\n', 'self', '.', 'upsample', '=', 'Upsample', '(', 'blur_kernel', ')', '\\n', 'self', '.', 'dwt', '=', 'HaarTransform', '(', '3', ')', '\\n', '\\n', '', 'self', '.', 'conv', '=', 'ModulatedConv2d', '(', 'in_channel', ',', '3', '*', '4', ',', '1', ',', 'style_dim', ',', 'demodulate', '=', 'False', ')', '\\n', 'self', '.', 'bias', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'zeros', '(', '1', ',', '3', '*', '4', ',', '1', ',', '1', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.ToRGB.forward': [[79, 91], ['swagan.ToRGB.conv', 'swagan.ToRGB.iwt', 'swagan.ToRGB.upsample', 'swagan.ToRGB.dwt'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.upsample'], ['', 'def', 'forward', '(', 'self', ',', 'input', ',', 'style', ',', 'skip', '=', 'None', ')', ':', '\\n', '        ', 'out', '=', 'self', '.', 'conv', '(', 'input', ',', 'style', ')', '\\n', 'out', '=', 'out', '+', 'self', '.', 'bias', '\\n', '\\n', 'if', 'skip', 'is', 'not', 'None', ':', '\\n', '            ', 'skip', '=', 'self', '.', 'iwt', '(', 'skip', ')', '\\n', 'skip', '=', 'self', '.', 'upsample', '(', 'skip', ')', '\\n', 'skip', '=', 'self', '.', 'dwt', '(', 'skip', ')', '\\n', '\\n', 'out', '=', 'out', '+', 'skip', '\\n', '\\n', '', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Generator.__init__': [[94, 180], ['torch.nn.Module.__init__', 'range', 'torch.nn.Sequential', 'model.ConstantInput', 'model.StyledConv', 'swagan.ToRGB', 'torch.nn.ModuleList', 'torch.nn.ModuleList', 'torch.nn.ModuleList', 'torch.nn.Module', 'range', 'range', 'swagan.InverseHaarTransform', 'model.PixelNorm', 'layers.append', 'int', 'swagan.Generator.noises.register_buffer', 'swagan.Generator.convs.append', 'swagan.Generator.convs.append', 'swagan.Generator.to_rgbs.append', 'model.EqualLinear', 'math.log', 'torch.randn', 'model.StyledConv', 'model.StyledConv', 'swagan.ToRGB'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', '\\n', 'self', ',', '\\n', 'size', ',', '\\n', 'style_dim', ',', '\\n', 'n_mlp', ',', '\\n', 'channel_multiplier', '=', '2', ',', '\\n', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ',', '\\n', 'lr_mlp', '=', '0.01', ',', '\\n', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'size', '=', 'size', '\\n', '\\n', 'self', '.', 'style_dim', '=', 'style_dim', '\\n', '\\n', 'layers', '=', '[', 'PixelNorm', '(', ')', ']', '\\n', '\\n', 'for', 'i', 'in', 'range', '(', 'n_mlp', ')', ':', '\\n', '            ', 'layers', '.', 'append', '(', '\\n', 'EqualLinear', '(', '\\n', 'style_dim', ',', 'style_dim', ',', 'lr_mul', '=', 'lr_mlp', ',', 'activation', '=', '\"fused_lrelu\"', '\\n', ')', '\\n', ')', '\\n', '\\n', '', 'self', '.', 'style', '=', 'nn', '.', 'Sequential', '(', '*', 'layers', ')', '\\n', '\\n', 'self', '.', 'channels', '=', '{', '\\n', '4', ':', '512', ',', '\\n', '8', ':', '512', ',', '\\n', '16', ':', '512', ',', '\\n', '32', ':', '512', ',', '\\n', '64', ':', '256', '*', 'channel_multiplier', ',', '\\n', '128', ':', '128', '*', 'channel_multiplier', ',', '\\n', '256', ':', '64', '*', 'channel_multiplier', ',', '\\n', '512', ':', '32', '*', 'channel_multiplier', ',', '\\n', '1024', ':', '16', '*', 'channel_multiplier', ',', '\\n', '}', '\\n', '\\n', 'self', '.', 'input', '=', 'ConstantInput', '(', 'self', '.', 'channels', '[', '4', ']', ')', '\\n', 'self', '.', 'conv1', '=', 'StyledConv', '(', '\\n', 'self', '.', 'channels', '[', '4', ']', ',', 'self', '.', 'channels', '[', '4', ']', ',', '3', ',', 'style_dim', ',', 'blur_kernel', '=', 'blur_kernel', '\\n', ')', '\\n', 'self', '.', 'to_rgb1', '=', 'ToRGB', '(', 'self', '.', 'channels', '[', '4', ']', ',', 'style_dim', ',', 'upsample', '=', 'False', ')', '\\n', '\\n', 'self', '.', 'log_size', '=', 'int', '(', 'math', '.', 'log', '(', 'size', ',', '2', ')', ')', '-', '1', '\\n', 'self', '.', 'num_layers', '=', '(', 'self', '.', 'log_size', '-', '2', ')', '*', '2', '+', '1', '\\n', '\\n', 'self', '.', 'convs', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', 'self', '.', 'upsamples', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', 'self', '.', 'to_rgbs', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', 'self', '.', 'noises', '=', 'nn', '.', 'Module', '(', ')', '\\n', '\\n', 'in_channel', '=', 'self', '.', 'channels', '[', '4', ']', '\\n', '\\n', 'for', 'layer_idx', 'in', 'range', '(', 'self', '.', 'num_layers', ')', ':', '\\n', '            ', 'res', '=', '(', 'layer_idx', '+', '5', ')', '//', '2', '\\n', 'shape', '=', '[', '1', ',', '1', ',', '2', '**', 'res', ',', '2', '**', 'res', ']', '\\n', 'self', '.', 'noises', '.', 'register_buffer', '(', 'f\"noise_{layer_idx}\"', ',', 'torch', '.', 'randn', '(', '*', 'shape', ')', ')', '\\n', '\\n', '', 'for', 'i', 'in', 'range', '(', '3', ',', 'self', '.', 'log_size', '+', '1', ')', ':', '\\n', '            ', 'out_channel', '=', 'self', '.', 'channels', '[', '2', '**', 'i', ']', '\\n', '\\n', 'self', '.', 'convs', '.', 'append', '(', '\\n', 'StyledConv', '(', '\\n', 'in_channel', ',', '\\n', 'out_channel', ',', '\\n', '3', ',', '\\n', 'style_dim', ',', '\\n', 'upsample', '=', 'True', ',', '\\n', 'blur_kernel', '=', 'blur_kernel', ',', '\\n', ')', '\\n', ')', '\\n', '\\n', 'self', '.', 'convs', '.', 'append', '(', '\\n', 'StyledConv', '(', '\\n', 'out_channel', ',', 'out_channel', ',', '3', ',', 'style_dim', ',', 'blur_kernel', '=', 'blur_kernel', '\\n', ')', '\\n', ')', '\\n', '\\n', 'self', '.', 'to_rgbs', '.', 'append', '(', 'ToRGB', '(', 'out_channel', ',', 'style_dim', ')', ')', '\\n', '\\n', 'in_channel', '=', 'out_channel', '\\n', '\\n', '', 'self', '.', 'iwt', '=', 'InverseHaarTransform', '(', '3', ')', '\\n', '\\n', 'self', '.', 'n_latent', '=', 'self', '.', 'log_size', '*', '2', '-', '2', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Generator.make_noise': [[181, 191], ['range', 'torch.randn', 'range', 'noises.append', 'torch.randn'], 'methods', ['None'], ['', 'def', 'make_noise', '(', 'self', ')', ':', '\\n', '        ', 'device', '=', 'self', '.', 'input', '.', 'input', '.', 'device', '\\n', '\\n', 'noises', '=', '[', 'torch', '.', 'randn', '(', '1', ',', '1', ',', '2', '**', '2', ',', '2', '**', '2', ',', 'device', '=', 'device', ')', ']', '\\n', '\\n', 'for', 'i', 'in', 'range', '(', '3', ',', 'self', '.', 'log_size', '+', '1', ')', ':', '\\n', '            ', 'for', '_', 'in', 'range', '(', '2', ')', ':', '\\n', '                ', 'noises', '.', 'append', '(', 'torch', '.', 'randn', '(', '1', ',', '1', ',', '2', '**', 'i', ',', '2', '**', 'i', ',', 'device', '=', 'device', ')', ')', '\\n', '\\n', '', '', 'return', 'noises', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Generator.mean_latent': [[192, 199], ['torch.randn', 'swagan.Generator.style().mean', 'swagan.Generator.style'], 'methods', ['None'], ['', 'def', 'mean_latent', '(', 'self', ',', 'n_latent', ')', ':', '\\n', '        ', 'latent_in', '=', 'torch', '.', 'randn', '(', '\\n', 'n_latent', ',', 'self', '.', 'style_dim', ',', 'device', '=', 'self', '.', 'input', '.', 'input', '.', 'device', '\\n', ')', '\\n', 'latent', '=', 'self', '.', 'style', '(', 'latent_in', ')', '.', 'mean', '(', '0', ',', 'keepdim', '=', 'True', ')', '\\n', '\\n', 'return', 'latent', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Generator.get_latent': [[200, 202], ['swagan.Generator.style'], 'methods', ['None'], ['', 'def', 'get_latent', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'return', 'self', '.', 'style', '(', 'input', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Generator.forward': [[203, 275], ['swagan.Generator.input', 'swagan.Generator.conv1', 'swagan.Generator.to_rgb1', 'zip', 'swagan.Generator.iwt', 'len', 'styles[].unsqueeze().repeat', 'styles[].unsqueeze().repeat', 'torch.cat', 'conv1', 'conv2', 'to_rgb', 'swagan.Generator.style', 'style_t.append', 'styles[].unsqueeze().repeat', 'random.randint', 'getattr', 'styles[].unsqueeze', 'styles[].unsqueeze', 'range', 'styles[].unsqueeze'], 'methods', ['None'], ['', 'def', 'forward', '(', '\\n', 'self', ',', '\\n', 'styles', ',', '\\n', 'return_latents', '=', 'False', ',', '\\n', 'inject_index', '=', 'None', ',', '\\n', 'truncation', '=', '1', ',', '\\n', 'truncation_latent', '=', 'None', ',', '\\n', 'input_is_latent', '=', 'False', ',', '\\n', 'noise', '=', 'None', ',', '\\n', 'randomize_noise', '=', 'True', ',', '\\n', ')', ':', '\\n', '        ', 'if', 'not', 'input_is_latent', ':', '\\n', '            ', 'styles', '=', '[', 'self', '.', 'style', '(', 's', ')', 'for', 's', 'in', 'styles', ']', '\\n', '\\n', '', 'if', 'noise', 'is', 'None', ':', '\\n', '            ', 'if', 'randomize_noise', ':', '\\n', '                ', 'noise', '=', '[', 'None', ']', '*', 'self', '.', 'num_layers', '\\n', '', 'else', ':', '\\n', '                ', 'noise', '=', '[', '\\n', 'getattr', '(', 'self', '.', 'noises', ',', 'f\"noise_{i}\"', ')', 'for', 'i', 'in', 'range', '(', 'self', '.', 'num_layers', ')', '\\n', ']', '\\n', '\\n', '', '', 'if', 'truncation', '<', '1', ':', '\\n', '            ', 'style_t', '=', '[', ']', '\\n', '\\n', 'for', 'style', 'in', 'styles', ':', '\\n', '                ', 'style_t', '.', 'append', '(', '\\n', 'truncation_latent', '+', 'truncation', '*', '(', 'style', '-', 'truncation_latent', ')', '\\n', ')', '\\n', '\\n', '', 'styles', '=', 'style_t', '\\n', '\\n', '', 'if', 'len', '(', 'styles', ')', '<', '2', ':', '\\n', '            ', 'inject_index', '=', 'self', '.', 'n_latent', '\\n', '\\n', 'if', 'styles', '[', '0', ']', '.', 'ndim', '<', '3', ':', '\\n', '                ', 'latent', '=', 'styles', '[', '0', ']', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'inject_index', ',', '1', ')', '\\n', '\\n', '', 'else', ':', '\\n', '                ', 'latent', '=', 'styles', '[', '0', ']', '\\n', '\\n', '', '', 'else', ':', '\\n', '            ', 'if', 'inject_index', 'is', 'None', ':', '\\n', '                ', 'inject_index', '=', 'random', '.', 'randint', '(', '1', ',', 'self', '.', 'n_latent', '-', '1', ')', '\\n', '\\n', '', 'latent', '=', 'styles', '[', '0', ']', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'inject_index', ',', '1', ')', '\\n', 'latent2', '=', 'styles', '[', '1', ']', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'self', '.', 'n_latent', '-', 'inject_index', ',', '1', ')', '\\n', '\\n', 'latent', '=', 'torch', '.', 'cat', '(', '[', 'latent', ',', 'latent2', ']', ',', '1', ')', '\\n', '\\n', '', 'out', '=', 'self', '.', 'input', '(', 'latent', ')', '\\n', 'out', '=', 'self', '.', 'conv1', '(', 'out', ',', 'latent', '[', ':', ',', '0', ']', ',', 'noise', '=', 'noise', '[', '0', ']', ')', '\\n', '\\n', 'skip', '=', 'self', '.', 'to_rgb1', '(', 'out', ',', 'latent', '[', ':', ',', '1', ']', ')', '\\n', '\\n', 'i', '=', '1', '\\n', 'for', 'conv1', ',', 'conv2', ',', 'noise1', ',', 'noise2', ',', 'to_rgb', 'in', 'zip', '(', '\\n', 'self', '.', 'convs', '[', ':', ':', '2', ']', ',', 'self', '.', 'convs', '[', '1', ':', ':', '2', ']', ',', 'noise', '[', '1', ':', ':', '2', ']', ',', 'noise', '[', '2', ':', ':', '2', ']', ',', 'self', '.', 'to_rgbs', '\\n', ')', ':', '\\n', '            ', 'out', '=', 'conv1', '(', 'out', ',', 'latent', '[', ':', ',', 'i', ']', ',', 'noise', '=', 'noise1', ')', '\\n', 'out', '=', 'conv2', '(', 'out', ',', 'latent', '[', ':', ',', 'i', '+', '1', ']', ',', 'noise', '=', 'noise2', ')', '\\n', 'skip', '=', 'to_rgb', '(', 'out', ',', 'latent', '[', ':', ',', 'i', '+', '2', ']', ',', 'skip', ')', '\\n', '\\n', 'i', '+=', '2', '\\n', '\\n', '', 'image', '=', 'self', '.', 'iwt', '(', 'skip', ')', '\\n', '\\n', 'if', 'return_latents', ':', '\\n', '            ', 'return', 'image', ',', 'latent', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'return', 'image', ',', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.ConvBlock.__init__': [[278, 283], ['torch.nn.Module.__init__', 'model.ConvLayer', 'model.ConvLayer'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'in_channel', ',', 'out_channel', ',', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'conv1', '=', 'ConvLayer', '(', 'in_channel', ',', 'in_channel', ',', '3', ')', '\\n', 'self', '.', 'conv2', '=', 'ConvLayer', '(', 'in_channel', ',', 'out_channel', ',', '3', ',', 'downsample', '=', 'True', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.ConvBlock.forward': [[284, 289], ['swagan.ConvBlock.conv1', 'swagan.ConvBlock.conv2'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'out', '=', 'self', '.', 'conv1', '(', 'input', ')', '\\n', 'out', '=', 'self', '.', 'conv2', '(', 'out', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.FromRGB.__init__': [[292, 303], ['torch.nn.Module.__init__', 'model.ConvLayer', 'swagan.InverseHaarTransform', 'model.Downsample', 'swagan.HaarTransform'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'out_channel', ',', 'downsample', '=', 'True', ',', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'downsample', '=', 'downsample', '\\n', '\\n', 'if', 'downsample', ':', '\\n', '            ', 'self', '.', 'iwt', '=', 'InverseHaarTransform', '(', '3', ')', '\\n', 'self', '.', 'downsample', '=', 'Downsample', '(', 'blur_kernel', ')', '\\n', 'self', '.', 'dwt', '=', 'HaarTransform', '(', '3', ')', '\\n', '\\n', '', 'self', '.', 'conv', '=', 'ConvLayer', '(', '3', '*', '4', ',', 'out_channel', ',', '1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.FromRGB.forward': [[304, 316], ['swagan.FromRGB.conv', 'swagan.FromRGB.iwt', 'swagan.FromRGB.downsample', 'swagan.FromRGB.dwt'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ',', 'skip', '=', 'None', ')', ':', '\\n', '        ', 'if', 'self', '.', 'downsample', ':', '\\n', '            ', 'input', '=', 'self', '.', 'iwt', '(', 'input', ')', '\\n', 'input', '=', 'self', '.', 'downsample', '(', 'input', ')', '\\n', 'input', '=', 'self', '.', 'dwt', '(', 'input', ')', '\\n', '\\n', '', 'out', '=', 'self', '.', 'conv', '(', 'input', ')', '\\n', '\\n', 'if', 'skip', 'is', 'not', 'None', ':', '\\n', '            ', 'out', '=', 'out', '+', 'skip', '\\n', '\\n', '', 'return', 'input', ',', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Discriminator.__init__': [[319, 360], ['torch.nn.Module.__init__', 'swagan.HaarTransform', 'torch.nn.ModuleList', 'torch.nn.ModuleList', 'range', 'swagan.Discriminator.from_rgbs.append', 'model.ConvLayer', 'torch.nn.Sequential', 'int', 'swagan.Discriminator.from_rgbs.append', 'swagan.Discriminator.convs.append', 'swagan.FromRGB', 'model.EqualLinear', 'model.EqualLinear', 'math.log', 'swagan.FromRGB', 'swagan.ConvBlock'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'size', ',', 'channel_multiplier', '=', '2', ',', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'channels', '=', '{', '\\n', '4', ':', '512', ',', '\\n', '8', ':', '512', ',', '\\n', '16', ':', '512', ',', '\\n', '32', ':', '512', ',', '\\n', '64', ':', '256', '*', 'channel_multiplier', ',', '\\n', '128', ':', '128', '*', 'channel_multiplier', ',', '\\n', '256', ':', '64', '*', 'channel_multiplier', ',', '\\n', '512', ':', '32', '*', 'channel_multiplier', ',', '\\n', '1024', ':', '16', '*', 'channel_multiplier', ',', '\\n', '}', '\\n', '\\n', 'self', '.', 'dwt', '=', 'HaarTransform', '(', '3', ')', '\\n', '\\n', 'self', '.', 'from_rgbs', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', 'self', '.', 'convs', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', '\\n', 'log_size', '=', 'int', '(', 'math', '.', 'log', '(', 'size', ',', '2', ')', ')', '-', '1', '\\n', '\\n', 'in_channel', '=', 'channels', '[', 'size', ']', '\\n', '\\n', 'for', 'i', 'in', 'range', '(', 'log_size', ',', '2', ',', '-', '1', ')', ':', '\\n', '            ', 'out_channel', '=', 'channels', '[', '2', '**', '(', 'i', '-', '1', ')', ']', '\\n', '\\n', 'self', '.', 'from_rgbs', '.', 'append', '(', 'FromRGB', '(', 'in_channel', ',', 'downsample', '=', 'i', '!=', 'log_size', ')', ')', '\\n', 'self', '.', 'convs', '.', 'append', '(', 'ConvBlock', '(', 'in_channel', ',', 'out_channel', ',', 'blur_kernel', ')', ')', '\\n', '\\n', 'in_channel', '=', 'out_channel', '\\n', '\\n', '', 'self', '.', 'from_rgbs', '.', 'append', '(', 'FromRGB', '(', 'channels', '[', '4', ']', ')', ')', '\\n', '\\n', 'self', '.', 'stddev_group', '=', '4', '\\n', 'self', '.', 'stddev_feat', '=', '1', '\\n', '\\n', 'self', '.', 'final_conv', '=', 'ConvLayer', '(', 'in_channel', '+', '1', ',', 'channels', '[', '4', ']', ',', '3', ')', '\\n', 'self', '.', 'final_linear', '=', 'nn', '.', 'Sequential', '(', '\\n', 'EqualLinear', '(', 'channels', '[', '4', ']', '*', '4', '*', '4', ',', 'channels', '[', '4', ']', ',', 'activation', '=', '\"fused_lrelu\"', ')', ',', '\\n', 'EqualLinear', '(', 'channels', '[', '4', ']', ',', '1', ')', ',', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Discriminator.forward': [[362, 388], ['swagan.Discriminator.dwt', 'zip', 'min', 'conv.view', 'torch.sqrt', 'stddev.repeat.repeat.mean().squeeze', 'stddev.repeat.repeat.repeat', 'torch.cat', 'swagan.Discriminator.final_conv', 'conv.view', 'swagan.Discriminator.final_linear', 'from_rgb', 'conv', 'stddev.repeat.repeat.var', 'stddev.repeat.repeat.mean'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'input', '=', 'self', '.', 'dwt', '(', 'input', ')', '\\n', 'out', '=', 'None', '\\n', '\\n', 'for', 'from_rgb', ',', 'conv', 'in', 'zip', '(', 'self', '.', 'from_rgbs', ',', 'self', '.', 'convs', ')', ':', '\\n', '            ', 'input', ',', 'out', '=', 'from_rgb', '(', 'input', ',', 'out', ')', '\\n', 'out', '=', 'conv', '(', 'out', ')', '\\n', '\\n', '', '_', ',', 'out', '=', 'self', '.', 'from_rgbs', '[', '-', '1', ']', '(', 'input', ',', 'out', ')', '\\n', '\\n', 'batch', ',', 'channel', ',', 'height', ',', 'width', '=', 'out', '.', 'shape', '\\n', 'group', '=', 'min', '(', 'batch', ',', 'self', '.', 'stddev_group', ')', '\\n', 'stddev', '=', 'out', '.', 'view', '(', '\\n', 'group', ',', '-', '1', ',', 'self', '.', 'stddev_feat', ',', 'channel', '//', 'self', '.', 'stddev_feat', ',', 'height', ',', 'width', '\\n', ')', '\\n', 'stddev', '=', 'torch', '.', 'sqrt', '(', 'stddev', '.', 'var', '(', '0', ',', 'unbiased', '=', 'False', ')', '+', '1e-8', ')', '\\n', 'stddev', '=', 'stddev', '.', 'mean', '(', '[', '2', ',', '3', ',', '4', ']', ',', 'keepdims', '=', 'True', ')', '.', 'squeeze', '(', '2', ')', '\\n', 'stddev', '=', 'stddev', '.', 'repeat', '(', 'group', ',', '1', ',', 'height', ',', 'width', ')', '\\n', 'out', '=', 'torch', '.', 'cat', '(', '[', 'out', ',', 'stddev', ']', ',', '1', ')', '\\n', '\\n', 'out', '=', 'self', '.', 'final_conv', '(', 'out', ')', '\\n', '\\n', 'out', '=', 'out', '.', 'view', '(', 'batch', ',', '-', '1', ')', '\\n', 'out', '=', 'self', '.', 'final_linear', '(', 'out', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.get_haar_wavelet': [[14, 25], ['torch.ones', 'torch.ones'], 'function', ['None'], ['def', 'get_haar_wavelet', '(', 'in_channels', ')', ':', '\\n', '    ', 'haar_wav_l', '=', '1', '/', '(', '2', '**', '0.5', ')', '*', 'torch', '.', 'ones', '(', '1', ',', '2', ')', '\\n', 'haar_wav_h', '=', '1', '/', '(', '2', '**', '0.5', ')', '*', 'torch', '.', 'ones', '(', '1', ',', '2', ')', '\\n', 'haar_wav_h', '[', '0', ',', '0', ']', '=', '-', '1', '*', 'haar_wav_h', '[', '0', ',', '0', ']', '\\n', '\\n', 'haar_wav_ll', '=', 'haar_wav_l', '.', 'T', '*', 'haar_wav_l', '\\n', 'haar_wav_lh', '=', 'haar_wav_h', '.', 'T', '*', 'haar_wav_l', '\\n', 'haar_wav_hl', '=', 'haar_wav_l', '.', 'T', '*', 'haar_wav_h', '\\n', 'haar_wav_hh', '=', 'haar_wav_h', '.', 'T', '*', 'haar_wav_h', '\\n', '\\n', 'return', 'haar_wav_ll', ',', 'haar_wav_lh', ',', 'haar_wav_hl', ',', 'haar_wav_hh', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.normalize': [[12, 14], ['torch.sqrt', 'x.pow().sum', 'x.pow'], 'function', ['None'], ['def', 'normalize', '(', 'x', ')', ':', '\\n', '    ', 'return', 'x', '/', 'torch', '.', 'sqrt', '(', 'x', '.', 'pow', '(', '2', ')', '.', 'sum', '(', '-', '1', ',', 'keepdim', '=', 'True', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.slerp': [[16, 25], ['ppl.normalize', 'ppl.normalize', 'ppl.normalize', 'ppl.normalize', 'torch.acos', 'torch.cos', 'torch.sin'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.normalize', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.normalize', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.normalize', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.normalize'], ['', 'def', 'slerp', '(', 'a', ',', 'b', ',', 't', ')', ':', '\\n', '    ', 'a', '=', 'normalize', '(', 'a', ')', '\\n', 'b', '=', 'normalize', '(', 'b', ')', '\\n', 'd', '=', '(', 'a', '*', 'b', ')', '.', 'sum', '(', '-', '1', ',', 'keepdim', '=', 'True', ')', '\\n', 'p', '=', 't', '*', 'torch', '.', 'acos', '(', 'd', ')', '\\n', 'c', '=', 'normalize', '(', 'b', '-', 'd', '*', 'a', ')', '\\n', 'd', '=', 'a', '*', 'torch', '.', 'cos', '(', 'p', ')', '+', 'c', '*', 'torch', '.', 'sin', '(', 'p', ')', '\\n', '\\n', 'return', 'normalize', '(', 'd', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.lerp': [[27, 29], ['None'], 'function', ['None'], ['', 'def', 'lerp', '(', 'a', ',', 'b', ',', 't', ')', ':', '\\n', '    ', 'return', 'a', '+', '(', 'b', '-', 'a', ')', '*', 't', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.data_sampler': [[34, 43], ['torch.utils.data.distributed.DistributedSampler', 'torch.utils.data.RandomSampler', 'torch.utils.data.SequentialSampler'], 'function', ['None'], ['def', 'data_sampler', '(', 'dataset', ',', 'shuffle', ',', 'distributed', ')', ':', '\\n', '    ', 'if', 'distributed', ':', '\\n', '        ', 'return', 'data', '.', 'distributed', '.', 'DistributedSampler', '(', 'dataset', ',', 'shuffle', '=', 'shuffle', ')', '\\n', '\\n', '', 'if', 'shuffle', ':', '\\n', '        ', 'return', 'data', '.', 'RandomSampler', '(', 'dataset', ')', '\\n', '\\n', '', 'else', ':', '\\n', '        ', 'return', 'data', '.', 'SequentialSampler', '(', 'dataset', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.requires_grad': [[45, 48], ['model.parameters'], 'function', ['None'], ['', '', 'def', 'requires_grad', '(', 'model', ',', 'flag', '=', 'True', ')', ':', '\\n', '    ', 'for', 'p', 'in', 'model', '.', 'parameters', '(', ')', ':', '\\n', '        ', 'p', '.', 'requires_grad', '=', 'flag', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.accumulate': [[50, 56], ['dict', 'dict', 'dict.keys', 'model1.named_parameters', 'model2.named_parameters', 'par1[].data.mul_().add_', 'par1[].data.mul_'], 'function', ['None'], ['', '', 'def', 'accumulate', '(', 'model1', ',', 'model2', ',', 'decay', '=', '0.999', ')', ':', '\\n', '    ', 'par1', '=', 'dict', '(', 'model1', '.', 'named_parameters', '(', ')', ')', '\\n', 'par2', '=', 'dict', '(', 'model2', '.', 'named_parameters', '(', ')', ')', '\\n', '\\n', 'for', 'k', 'in', 'par1', '.', 'keys', '(', ')', ':', '\\n', '        ', 'par1', '[', 'k', ']', '.', 'data', '.', 'mul_', '(', 'decay', ')', '.', 'add_', '(', 'par2', '[', 'k', ']', '.', 'data', ',', 'alpha', '=', '1', '-', 'decay', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.sample_data': [[58, 62], ['None'], 'function', ['None'], ['', '', 'def', 'sample_data', '(', 'loader', ')', ':', '\\n', '    ', 'while', 'True', ':', '\\n', '        ', 'for', 'batch', 'in', 'loader', ':', '\\n', '            ', 'yield', 'batch', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.d_logistic_loss': [[64, 69], ['torch.nn.functional.softplus', 'torch.nn.functional.softplus', 'F.softplus.mean', 'F.softplus.mean'], 'function', ['None'], ['', '', '', 'def', 'd_logistic_loss', '(', 'real_pred', ',', 'fake_pred', ')', ':', '\\n', '    ', 'real_loss', '=', 'F', '.', 'softplus', '(', '-', 'real_pred', ')', '\\n', 'fake_loss', '=', 'F', '.', 'softplus', '(', 'fake_pred', ')', '\\n', '\\n', 'return', 'real_loss', '.', 'mean', '(', ')', '+', 'fake_loss', '.', 'mean', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.d_r1_loss': [[71, 79], ['grad_real.pow().reshape().sum().mean', 'op.conv2d_gradfix.no_weight_gradients', 'torch.autograd.grad', 'grad_real.pow().reshape().sum', 'real_pred.sum', 'grad_real.pow().reshape', 'grad_real.pow'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.no_weight_gradients'], ['', 'def', 'd_r1_loss', '(', 'real_pred', ',', 'real_img', ')', ':', '\\n', '    ', 'with', 'conv2d_gradfix', '.', 'no_weight_gradients', '(', ')', ':', '\\n', '        ', 'grad_real', ',', '=', 'autograd', '.', 'grad', '(', '\\n', 'outputs', '=', 'real_pred', '.', 'sum', '(', ')', ',', 'inputs', '=', 'real_img', ',', 'create_graph', '=', 'True', '\\n', ')', '\\n', '', 'grad_penalty', '=', 'grad_real', '.', 'pow', '(', '2', ')', '.', 'reshape', '(', 'grad_real', '.', 'shape', '[', '0', ']', ',', '-', '1', ')', '.', 'sum', '(', '1', ')', '.', 'mean', '(', ')', '\\n', '\\n', 'return', 'grad_penalty', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.g_nonsaturating_loss': [[81, 85], ['torch.nn.functional.softplus().mean', 'torch.nn.functional.softplus'], 'function', ['None'], ['', 'def', 'g_nonsaturating_loss', '(', 'fake_pred', ')', ':', '\\n', '    ', 'loss', '=', 'F', '.', 'softplus', '(', '-', 'fake_pred', ')', '.', 'mean', '(', ')', '\\n', '\\n', 'return', 'loss', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.g_path_regularize': [[87, 101], ['torch.autograd.grad', 'torch.sqrt', 'torch.sqrt', 'torch.randn_like', 'torch.randn_like', 'math.sqrt', 'grad.pow().sum().mean', 'path_mean.detach', 'grad.pow().sum', 'torch.sqrt.mean', 'grad.pow'], 'function', ['None'], ['', 'def', 'g_path_regularize', '(', 'fake_img', ',', 'latents', ',', 'mean_path_length', ',', 'decay', '=', '0.01', ')', ':', '\\n', '    ', 'noise', '=', 'torch', '.', 'randn_like', '(', 'fake_img', ')', '/', 'math', '.', 'sqrt', '(', '\\n', 'fake_img', '.', 'shape', '[', '2', ']', '*', 'fake_img', '.', 'shape', '[', '3', ']', '\\n', ')', '\\n', 'grad', ',', '=', 'autograd', '.', 'grad', '(', '\\n', 'outputs', '=', '(', 'fake_img', '*', 'noise', ')', '.', 'sum', '(', ')', ',', 'inputs', '=', 'latents', ',', 'create_graph', '=', 'True', '\\n', ')', '\\n', 'path_lengths', '=', 'torch', '.', 'sqrt', '(', 'grad', '.', 'pow', '(', '2', ')', '.', 'sum', '(', '2', ')', '.', 'mean', '(', '1', ')', ')', '\\n', '\\n', 'path_mean', '=', 'mean_path_length', '+', 'decay', '*', '(', 'path_lengths', '.', 'mean', '(', ')', '-', 'mean_path_length', ')', '\\n', '\\n', 'path_penalty', '=', '(', 'path_lengths', '-', 'path_mean', ')', '.', 'pow', '(', '2', ')', '.', 'mean', '(', ')', '\\n', '\\n', 'return', 'path_penalty', ',', 'path_mean', '.', 'detach', '(', ')', ',', 'path_lengths', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.make_noise': [[103, 110], ['torch.randn().unbind', 'torch.randn().unbind', 'torch.randn', 'torch.randn', 'torch.randn', 'torch.randn'], 'function', ['None'], ['', 'def', 'make_noise', '(', 'batch', ',', 'latent_dim', ',', 'n_noise', ',', 'device', ')', ':', '\\n', '    ', 'if', 'n_noise', '==', '1', ':', '\\n', '        ', 'return', 'torch', '.', 'randn', '(', 'batch', ',', 'latent_dim', ',', 'device', '=', 'device', ')', '\\n', '\\n', '', 'noises', '=', 'torch', '.', 'randn', '(', 'n_noise', ',', 'batch', ',', 'latent_dim', ',', 'device', '=', 'device', ')', '.', 'unbind', '(', '0', ')', '\\n', '\\n', 'return', 'noises', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.mixing_noise': [[112, 118], ['train.make_noise', 'random.random', 'train.make_noise'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.make_noise', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.make_noise'], ['', 'def', 'mixing_noise', '(', 'batch', ',', 'latent_dim', ',', 'prob', ',', 'device', ')', ':', '\\n', '    ', 'if', 'prob', '>', '0', 'and', 'random', '.', 'random', '(', ')', '<', 'prob', ':', '\\n', '        ', 'return', 'make_noise', '(', 'batch', ',', 'latent_dim', ',', '2', ',', 'device', ')', '\\n', '\\n', '', 'else', ':', '\\n', '        ', 'return', '[', 'make_noise', '(', 'batch', ',', 'latent_dim', ',', '1', ',', 'device', ')', ']', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.set_grad_none': [[120, 124], ['model.named_parameters'], 'function', ['None'], ['', '', 'def', 'set_grad_none', '(', 'model', ',', 'targets', ')', ':', '\\n', '    ', 'for', 'n', ',', 'p', 'in', 'model', '.', 'named_parameters', '(', ')', ':', '\\n', '        ', 'if', 'n', 'in', 'targets', ':', '\\n', '            ', 'p', '.', 'grad', '=', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.train': [[126, 330], ['train.sample_data', 'range', 'torch.tensor', 'torch.tensor', 'torch.tensor', 'torch.tensor', 'torch.tensor', 'torch.tensor', 'torch.randn', 'torch.randn', 'distributed.get_rank', 'tqdm.tqdm', 'non_leaking.AdaptiveAugment', 'next', 'real_img.to.to', 'train.requires_grad', 'train.requires_grad', 'train.mixing_noise', 'generator', 'discriminator', 'discriminator', 'train.d_logistic_loss', 'discriminator.mean', 'discriminator.mean', 'discriminator.zero_grad', 'd_logistic_loss.backward', 'd_optim.step', 'train.requires_grad', 'train.requires_grad', 'train.mixing_noise', 'generator', 'discriminator', 'train.g_nonsaturating_loss', 'generator.zero_grad', 'g_nonsaturating_loss.backward', 'g_optim.step', 'torch.tensor.mean', 'train.accumulate', 'distributed.reduce_loss_dict', 'loss_reduced[].mean().item', 'loss_reduced[].mean().item', 'loss_reduced[].mean().item', 'loss_reduced[].mean().item', 'loss_reduced[].mean().item', 'loss_reduced[].mean().item', 'loss_reduced[].mean().item', 'print', 'non_leaking.augment', 'non_leaking.augment', 'non_leaking.AdaptiveAugment.tune', 'discriminator', 'train.d_r1_loss', 'discriminator.zero_grad', 'd_optim.step', 'non_leaking.augment', 'max', 'train.mixing_noise', 'generator', 'train.g_path_regularize', 'generator.zero_grad', 'weighted_path_loss.backward', 'g_optim.step', 'distributed.get_rank', 'tqdm.tqdm.set_description', 'non_leaking.augment', 'distributed.reduce_sum().item', 'distributed.get_world_size', 'loss_reduced[].mean', 'loss_reduced[].mean', 'loss_reduced[].mean', 'loss_reduced[].mean', 'loss_reduced[].mean', 'loss_reduced[].mean', 'loss_reduced[].mean', 'wandb.log', 'torch.save', 'torch.save', 'torch.no_grad', 'torch.no_grad', 'g_ema.eval', 'g_ema', 'torchvision.utils.save_image', 'distributed.reduce_sum', 'g_module.state_dict', 'd_module.state_dict', 'g_ema.state_dict', 'g_optim.state_dict', 'd_optim.state_dict', 'int', 'str().zfill', 'str().zfill', 'str', 'str'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.sample_data', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_rank', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.requires_grad', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.requires_grad', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.mixing_noise', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.d_logistic_loss', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.backward', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.requires_grad', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.requires_grad', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.mixing_noise', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.g_nonsaturating_loss', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.backward', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.accumulate', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.reduce_loss_dict', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.augment', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.augment', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.AdaptiveAugment.tune', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.d_r1_loss', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.augment', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.mixing_noise', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.g_path_regularize', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.backward', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_rank', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.augment', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.reduce_sum'], ['', '', '', 'def', 'train', '(', 'args', ',', 'loader', ',', 'generator', ',', 'discriminator', ',', 'g_optim', ',', 'd_optim', ',', 'g_ema', ',', 'device', ')', ':', '\\n', '    ', 'loader', '=', 'sample_data', '(', 'loader', ')', '\\n', '\\n', 'pbar', '=', 'range', '(', 'args', '.', 'iter', ')', '\\n', '\\n', 'if', 'get_rank', '(', ')', '==', '0', ':', '\\n', '        ', 'pbar', '=', 'tqdm', '(', 'pbar', ',', 'initial', '=', 'args', '.', 'start_iter', ',', 'dynamic_ncols', '=', 'True', ',', 'smoothing', '=', '0.01', ')', '\\n', '\\n', '', 'mean_path_length', '=', '0', '\\n', '\\n', 'd_loss_val', '=', '0', '\\n', 'r1_loss', '=', 'torch', '.', 'tensor', '(', '0.0', ',', 'device', '=', 'device', ')', '\\n', 'g_loss_val', '=', '0', '\\n', 'path_loss', '=', 'torch', '.', 'tensor', '(', '0.0', ',', 'device', '=', 'device', ')', '\\n', 'path_lengths', '=', 'torch', '.', 'tensor', '(', '0.0', ',', 'device', '=', 'device', ')', '\\n', 'mean_path_length_avg', '=', '0', '\\n', 'loss_dict', '=', '{', '}', '\\n', '\\n', 'if', 'args', '.', 'distributed', ':', '\\n', '        ', 'g_module', '=', 'generator', '.', 'module', '\\n', 'd_module', '=', 'discriminator', '.', 'module', '\\n', '\\n', '', 'else', ':', '\\n', '        ', 'g_module', '=', 'generator', '\\n', 'd_module', '=', 'discriminator', '\\n', '\\n', '', 'accum', '=', '0.5', '**', '(', '32', '/', '(', '10', '*', '1000', ')', ')', '\\n', 'ada_aug_p', '=', 'args', '.', 'augment_p', 'if', 'args', '.', 'augment_p', '>', '0', 'else', '0.0', '\\n', 'r_t_stat', '=', '0', '\\n', '\\n', 'if', 'args', '.', 'augment', 'and', 'args', '.', 'augment_p', '==', '0', ':', '\\n', '        ', 'ada_augment', '=', 'AdaptiveAugment', '(', 'args', '.', 'ada_target', ',', 'args', '.', 'ada_length', ',', '8', ',', 'device', ')', '\\n', '\\n', '', 'sample_z', '=', 'torch', '.', 'randn', '(', 'args', '.', 'n_sample', ',', 'args', '.', 'latent', ',', 'device', '=', 'device', ')', '\\n', '\\n', 'for', 'idx', 'in', 'pbar', ':', '\\n', '        ', 'i', '=', 'idx', '+', 'args', '.', 'start_iter', '\\n', '\\n', 'if', 'i', '>', 'args', '.', 'iter', ':', '\\n', '            ', 'print', '(', '\"Done!\"', ')', '\\n', '\\n', 'break', '\\n', '\\n', '', 'real_img', '=', 'next', '(', 'loader', ')', '\\n', 'real_img', '=', 'real_img', '.', 'to', '(', 'device', ')', '\\n', '\\n', 'requires_grad', '(', 'generator', ',', 'False', ')', '\\n', 'requires_grad', '(', 'discriminator', ',', 'True', ')', '\\n', '\\n', 'noise', '=', 'mixing_noise', '(', 'args', '.', 'batch', ',', 'args', '.', 'latent', ',', 'args', '.', 'mixing', ',', 'device', ')', '\\n', 'fake_img', ',', '_', '=', 'generator', '(', 'noise', ')', '\\n', '\\n', 'if', 'args', '.', 'augment', ':', '\\n', '            ', 'real_img_aug', ',', '_', '=', 'augment', '(', 'real_img', ',', 'ada_aug_p', ')', '\\n', 'fake_img', ',', '_', '=', 'augment', '(', 'fake_img', ',', 'ada_aug_p', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'real_img_aug', '=', 'real_img', '\\n', '\\n', '', 'fake_pred', '=', 'discriminator', '(', 'fake_img', ')', '\\n', 'real_pred', '=', 'discriminator', '(', 'real_img_aug', ')', '\\n', 'd_loss', '=', 'd_logistic_loss', '(', 'real_pred', ',', 'fake_pred', ')', '\\n', '\\n', 'loss_dict', '[', '\"d\"', ']', '=', 'd_loss', '\\n', 'loss_dict', '[', '\"real_score\"', ']', '=', 'real_pred', '.', 'mean', '(', ')', '\\n', 'loss_dict', '[', '\"fake_score\"', ']', '=', 'fake_pred', '.', 'mean', '(', ')', '\\n', '\\n', 'discriminator', '.', 'zero_grad', '(', ')', '\\n', 'd_loss', '.', 'backward', '(', ')', '\\n', 'd_optim', '.', 'step', '(', ')', '\\n', '\\n', 'if', 'args', '.', 'augment', 'and', 'args', '.', 'augment_p', '==', '0', ':', '\\n', '            ', 'ada_aug_p', '=', 'ada_augment', '.', 'tune', '(', 'real_pred', ')', '\\n', 'r_t_stat', '=', 'ada_augment', '.', 'r_t_stat', '\\n', '\\n', '', 'd_regularize', '=', 'i', '%', 'args', '.', 'd_reg_every', '==', '0', '\\n', '\\n', 'if', 'd_regularize', ':', '\\n', '            ', 'real_img', '.', 'requires_grad', '=', 'True', '\\n', '\\n', 'if', 'args', '.', 'augment', ':', '\\n', '                ', 'real_img_aug', ',', '_', '=', 'augment', '(', 'real_img', ',', 'ada_aug_p', ')', '\\n', '\\n', '', 'else', ':', '\\n', '                ', 'real_img_aug', '=', 'real_img', '\\n', '\\n', '', 'real_pred', '=', 'discriminator', '(', 'real_img_aug', ')', '\\n', 'r1_loss', '=', 'd_r1_loss', '(', 'real_pred', ',', 'real_img', ')', '\\n', '\\n', 'discriminator', '.', 'zero_grad', '(', ')', '\\n', '(', 'args', '.', 'r1', '/', '2', '*', 'r1_loss', '*', 'args', '.', 'd_reg_every', '+', '0', '*', 'real_pred', '[', '0', ']', ')', '.', 'backward', '(', ')', '\\n', '\\n', 'd_optim', '.', 'step', '(', ')', '\\n', '\\n', '', 'loss_dict', '[', '\"r1\"', ']', '=', 'r1_loss', '\\n', '\\n', 'requires_grad', '(', 'generator', ',', 'True', ')', '\\n', 'requires_grad', '(', 'discriminator', ',', 'False', ')', '\\n', '\\n', 'noise', '=', 'mixing_noise', '(', 'args', '.', 'batch', ',', 'args', '.', 'latent', ',', 'args', '.', 'mixing', ',', 'device', ')', '\\n', 'fake_img', ',', '_', '=', 'generator', '(', 'noise', ')', '\\n', '\\n', 'if', 'args', '.', 'augment', ':', '\\n', '            ', 'fake_img', ',', '_', '=', 'augment', '(', 'fake_img', ',', 'ada_aug_p', ')', '\\n', '\\n', '', 'fake_pred', '=', 'discriminator', '(', 'fake_img', ')', '\\n', 'g_loss', '=', 'g_nonsaturating_loss', '(', 'fake_pred', ')', '\\n', '\\n', 'loss_dict', '[', '\"g\"', ']', '=', 'g_loss', '\\n', '\\n', 'generator', '.', 'zero_grad', '(', ')', '\\n', 'g_loss', '.', 'backward', '(', ')', '\\n', 'g_optim', '.', 'step', '(', ')', '\\n', '\\n', '#g_regularize = i % args.g_reg_every == 0', '\\n', 'g_regularize', '=', 'False', '\\n', '\\n', 'if', 'g_regularize', ':', '\\n', '            ', 'path_batch_size', '=', 'max', '(', '1', ',', 'args', '.', 'batch', '//', 'args', '.', 'path_batch_shrink', ')', '\\n', 'noise', '=', 'mixing_noise', '(', 'path_batch_size', ',', 'args', '.', 'latent', ',', 'args', '.', 'mixing', ',', 'device', ')', '\\n', 'fake_img', ',', 'latents', '=', 'generator', '(', 'noise', ',', 'return_latents', '=', 'True', ')', '\\n', '\\n', 'path_loss', ',', 'mean_path_length', ',', 'path_lengths', '=', 'g_path_regularize', '(', '\\n', 'fake_img', ',', 'latents', ',', 'mean_path_length', '\\n', ')', '\\n', '\\n', 'generator', '.', 'zero_grad', '(', ')', '\\n', 'weighted_path_loss', '=', 'args', '.', 'path_regularize', '*', 'args', '.', 'g_reg_every', '*', 'path_loss', '\\n', '\\n', 'if', 'args', '.', 'path_batch_shrink', ':', '\\n', '                ', 'weighted_path_loss', '+=', '0', '*', 'fake_img', '[', '0', ',', '0', ',', '0', ',', '0', ']', '\\n', '\\n', '', 'weighted_path_loss', '.', 'backward', '(', ')', '\\n', '\\n', 'g_optim', '.', 'step', '(', ')', '\\n', '\\n', 'mean_path_length_avg', '=', '(', '\\n', 'reduce_sum', '(', 'mean_path_length', ')', '.', 'item', '(', ')', '/', 'get_world_size', '(', ')', '\\n', ')', '\\n', '\\n', '', 'loss_dict', '[', '\"path\"', ']', '=', 'path_loss', '\\n', 'loss_dict', '[', '\"path_length\"', ']', '=', 'path_lengths', '.', 'mean', '(', ')', '\\n', '\\n', 'accumulate', '(', 'g_ema', ',', 'g_module', ',', 'accum', ')', '\\n', '\\n', 'loss_reduced', '=', 'reduce_loss_dict', '(', 'loss_dict', ')', '\\n', '\\n', 'd_loss_val', '=', 'loss_reduced', '[', '\"d\"', ']', '.', 'mean', '(', ')', '.', 'item', '(', ')', '\\n', 'g_loss_val', '=', 'loss_reduced', '[', '\"g\"', ']', '.', 'mean', '(', ')', '.', 'item', '(', ')', '\\n', 'r1_val', '=', 'loss_reduced', '[', '\"r1\"', ']', '.', 'mean', '(', ')', '.', 'item', '(', ')', '\\n', 'path_loss_val', '=', 'loss_reduced', '[', '\"path\"', ']', '.', 'mean', '(', ')', '.', 'item', '(', ')', '\\n', 'real_score_val', '=', 'loss_reduced', '[', '\"real_score\"', ']', '.', 'mean', '(', ')', '.', 'item', '(', ')', '\\n', 'fake_score_val', '=', 'loss_reduced', '[', '\"fake_score\"', ']', '.', 'mean', '(', ')', '.', 'item', '(', ')', '\\n', 'path_length_val', '=', 'loss_reduced', '[', '\"path_length\"', ']', '.', 'mean', '(', ')', '.', 'item', '(', ')', '\\n', '\\n', 'if', 'get_rank', '(', ')', '==', '0', ':', '\\n', '            ', 'pbar', '.', 'set_description', '(', '\\n', '(', '\\n', 'f\"d: {d_loss_val:.4f}; g: {g_loss_val:.4f}; r1: {r1_val:.4f}; \"', '\\n', 'f\"path: {path_loss_val:.4f}; mean path: {mean_path_length_avg:.4f}; \"', '\\n', 'f\"augment: {ada_aug_p:.4f}\"', '\\n', ')', '\\n', ')', '\\n', '\\n', 'if', 'wandb', 'and', 'args', '.', 'wandb', ':', '\\n', '                ', 'wandb', '.', 'log', '(', '\\n', '{', '\\n', '\"Generator\"', ':', 'g_loss_val', ',', '\\n', '\"Discriminator\"', ':', 'd_loss_val', ',', '\\n', '\"Augment\"', ':', 'ada_aug_p', ',', '\\n', '\"Rt\"', ':', 'r_t_stat', ',', '\\n', '\"R1\"', ':', 'r1_val', ',', '\\n', '\"Path Length Regularization\"', ':', 'path_loss_val', ',', '\\n', '\"Mean Path Length\"', ':', 'mean_path_length', ',', '\\n', '\"Real Score\"', ':', 'real_score_val', ',', '\\n', '\"Fake Score\"', ':', 'fake_score_val', ',', '\\n', '\"Path Length\"', ':', 'path_length_val', ',', '\\n', '}', '\\n', ')', '\\n', '\\n', '', 'if', 'i', '%', '10000', '==', '0', ':', '\\n', '                ', 'with', 'torch', '.', 'no_grad', '(', ')', ':', '\\n', '                    ', 'g_ema', '.', 'eval', '(', ')', '\\n', 'sample', ',', '_', '=', 'g_ema', '(', '[', 'sample_z', ']', ')', '\\n', 'utils', '.', 'save_image', '(', '\\n', 'sample', ',', '\\n', 'f\"sample/{args.name}/{str(i).zfill(6)}.png\"', ',', '\\n', 'nrow', '=', 'int', '(', 'args', '.', 'n_sample', '**', '0.5', ')', ',', '\\n', 'normalize', '=', 'True', ',', '\\n', 'range', '=', '(', '-', '1', ',', '1', ')', ',', '\\n', ')', '\\n', '\\n', '', '', 'if', 'i', '%', '50000', '==', '0', ':', '\\n', '                ', 'torch', '.', 'save', '(', '\\n', '{', '\\n', '\"g\"', ':', 'g_module', '.', 'state_dict', '(', ')', ',', '\\n', '\"d\"', ':', 'd_module', '.', 'state_dict', '(', ')', ',', '\\n', '\"g_ema\"', ':', 'g_ema', '.', 'state_dict', '(', ')', ',', '\\n', '\"g_optim\"', ':', 'g_optim', '.', 'state_dict', '(', ')', ',', '\\n', '\"d_optim\"', ':', 'd_optim', '.', 'state_dict', '(', ')', ',', '\\n', '\"args\"', ':', 'args', ',', '\\n', '\"ada_aug_p\"', ':', 'ada_aug_p', ',', '\\n', '}', ',', '\\n', 'f\"checkpoint/{args.name}/{str(i).zfill(6)}.pt\"', ',', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.dataset.MultiResolutionDataset.__init__': [[9, 27], ['lmdb.open', 'IOError', 'dataset.MultiResolutionDataset.env.begin', 'int', 'txn.get().decode', 'txn.get'], 'methods', ['None'], ['    ', 'def', '__init__', '(', 'self', ',', 'path', ',', 'transform', ',', 'resolution', '=', '256', ')', ':', '\\n', '        ', 'self', '.', 'env', '=', 'lmdb', '.', 'open', '(', '\\n', 'path', ',', '\\n', 'max_readers', '=', '32', ',', '\\n', 'readonly', '=', 'True', ',', '\\n', 'lock', '=', 'False', ',', '\\n', 'readahead', '=', 'False', ',', '\\n', 'meminit', '=', 'False', ',', '\\n', ')', '\\n', '\\n', 'if', 'not', 'self', '.', 'env', ':', '\\n', '            ', 'raise', 'IOError', '(', \"'Cannot open lmdb dataset'\", ',', 'path', ')', '\\n', '\\n', '', 'with', 'self', '.', 'env', '.', 'begin', '(', 'write', '=', 'False', ')', 'as', 'txn', ':', '\\n', '            ', 'self', '.', 'length', '=', 'int', '(', 'txn', '.', 'get', '(', \"'length'\", '.', 'encode', '(', \"'utf-8'\", ')', ')', '.', 'decode', '(', \"'utf-8'\", ')', ')', '\\n', '\\n', '', 'self', '.', 'resolution', '=', 'resolution', '\\n', 'self', '.', 'transform', '=', 'transform', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.dataset.MultiResolutionDataset.__len__': [[28, 30], ['None'], 'methods', ['None'], ['', 'def', '__len__', '(', 'self', ')', ':', '\\n', '        ', 'return', 'self', '.', 'length', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.dataset.MultiResolutionDataset.__getitem__': [[31, 41], ['io.BytesIO', 'PIL.Image.open', 'dataset.MultiResolutionDataset.transform', 'dataset.MultiResolutionDataset.env.begin', 'txn.get', 'str().zfill', 'str'], 'methods', ['None'], ['', 'def', '__getitem__', '(', 'self', ',', 'index', ')', ':', '\\n', '        ', 'with', 'self', '.', 'env', '.', 'begin', '(', 'write', '=', 'False', ')', 'as', 'txn', ':', '\\n', '            ', 'key', '=', \"f'{self.resolution}-{str(index).zfill(5)}'\", '.', 'encode', '(', \"'utf-8'\", ')', '\\n', 'img_bytes', '=', 'txn', '.', 'get', '(', 'key', ')', '\\n', '\\n', '', 'buffer', '=', 'BytesIO', '(', 'img_bytes', ')', '\\n', 'img', '=', 'Image', '.', 'open', '(', 'buffer', ')', '\\n', 'img', '=', 'self', '.', 'transform', '(', 'img', ')', '\\n', '\\n', 'return', 'img', '\\n', '', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.calc_inception.Inception3Feature.forward': [[19, 49], ['calc_inception.Inception3Feature.Conv2d_1a_3x3', 'calc_inception.Inception3Feature.Conv2d_2a_3x3', 'calc_inception.Inception3Feature.Conv2d_2b_3x3', 'torch.nn.functional.max_pool2d', 'calc_inception.Inception3Feature.Conv2d_3b_1x1', 'calc_inception.Inception3Feature.Conv2d_4a_3x3', 'torch.nn.functional.max_pool2d', 'calc_inception.Inception3Feature.Mixed_5b', 'calc_inception.Inception3Feature.Mixed_5c', 'calc_inception.Inception3Feature.Mixed_5d', 'calc_inception.Inception3Feature.Mixed_6a', 'calc_inception.Inception3Feature.Mixed_6b', 'calc_inception.Inception3Feature.Mixed_6c', 'calc_inception.Inception3Feature.Mixed_6d', 'calc_inception.Inception3Feature.Mixed_6e', 'calc_inception.Inception3Feature.Mixed_7a', 'calc_inception.Inception3Feature.Mixed_7b', 'calc_inception.Inception3Feature.Mixed_7c', 'torch.nn.functional.avg_pool2d', 'torch.nn.functional.interpolate.view', 'torch.nn.functional.interpolate'], 'methods', ['None'], ['    ', 'def', 'forward', '(', 'self', ',', 'x', ')', ':', '\\n', '        ', 'if', 'x', '.', 'shape', '[', '2', ']', '!=', '299', 'or', 'x', '.', 'shape', '[', '3', ']', '!=', '299', ':', '\\n', '            ', 'x', '=', 'F', '.', 'interpolate', '(', 'x', ',', 'size', '=', '(', '299', ',', '299', ')', ',', 'mode', '=', '\"bilinear\"', ',', 'align_corners', '=', 'True', ')', '\\n', '\\n', '', 'x', '=', 'self', '.', 'Conv2d_1a_3x3', '(', 'x', ')', '# 299 x 299 x 3', '\\n', 'x', '=', 'self', '.', 'Conv2d_2a_3x3', '(', 'x', ')', '# 149 x 149 x 32', '\\n', 'x', '=', 'self', '.', 'Conv2d_2b_3x3', '(', 'x', ')', '# 147 x 147 x 32', '\\n', 'x', '=', 'F', '.', 'max_pool2d', '(', 'x', ',', 'kernel_size', '=', '3', ',', 'stride', '=', '2', ')', '# 147 x 147 x 64', '\\n', '\\n', 'x', '=', 'self', '.', 'Conv2d_3b_1x1', '(', 'x', ')', '# 73 x 73 x 64', '\\n', 'x', '=', 'self', '.', 'Conv2d_4a_3x3', '(', 'x', ')', '# 73 x 73 x 80', '\\n', 'x', '=', 'F', '.', 'max_pool2d', '(', 'x', ',', 'kernel_size', '=', '3', ',', 'stride', '=', '2', ')', '# 71 x 71 x 192', '\\n', '\\n', 'x', '=', 'self', '.', 'Mixed_5b', '(', 'x', ')', '# 35 x 35 x 192', '\\n', 'x', '=', 'self', '.', 'Mixed_5c', '(', 'x', ')', '# 35 x 35 x 256', '\\n', 'x', '=', 'self', '.', 'Mixed_5d', '(', 'x', ')', '# 35 x 35 x 288', '\\n', '\\n', 'x', '=', 'self', '.', 'Mixed_6a', '(', 'x', ')', '# 35 x 35 x 288', '\\n', 'x', '=', 'self', '.', 'Mixed_6b', '(', 'x', ')', '# 17 x 17 x 768', '\\n', 'x', '=', 'self', '.', 'Mixed_6c', '(', 'x', ')', '# 17 x 17 x 768', '\\n', 'x', '=', 'self', '.', 'Mixed_6d', '(', 'x', ')', '# 17 x 17 x 768', '\\n', 'x', '=', 'self', '.', 'Mixed_6e', '(', 'x', ')', '# 17 x 17 x 768', '\\n', '\\n', 'x', '=', 'self', '.', 'Mixed_7a', '(', 'x', ')', '# 17 x 17 x 768', '\\n', 'x', '=', 'self', '.', 'Mixed_7b', '(', 'x', ')', '# 8 x 8 x 1280', '\\n', 'x', '=', 'self', '.', 'Mixed_7c', '(', 'x', ')', '# 8 x 8 x 2048', '\\n', '\\n', 'x', '=', 'F', '.', 'avg_pool2d', '(', 'x', ',', 'kernel_size', '=', '8', ')', '# 8 x 8 x 2048', '\\n', '\\n', 'return', 'x', '.', 'view', '(', 'x', '.', 'shape', '[', '0', ']', ',', 'x', '.', 'shape', '[', '1', ']', ')', '# 1 x 1 x 2048', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.calc_inception.load_patched_inception_v3': [[51, 58], ['inception.InceptionV3'], 'function', ['None'], ['', '', 'def', 'load_patched_inception_v3', '(', ')', ':', '\\n', '# inception = inception_v3(pretrained=True)', '\\n', '# inception_feat = Inception3Feature()', '\\n', '# inception_feat.load_state_dict(inception.state_dict())', '\\n', '    ', 'inception_feat', '=', 'InceptionV3', '(', '[', '3', ']', ',', 'normalize_input', '=', 'False', ')', '\\n', '\\n', 'return', 'inception_feat', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.calc_inception.extract_features': [[60, 74], ['torch.no_grad', 'tqdm.tqdm', 'torch.cat', 'img.to.to', '[].view', 'feature_list.append', '[].view.to', 'inception'], 'function', ['None'], ['', '@', 'torch', '.', 'no_grad', '(', ')', '\\n', 'def', 'extract_features', '(', 'loader', ',', 'inception', ',', 'device', ')', ':', '\\n', '    ', 'pbar', '=', 'tqdm', '(', 'loader', ')', '\\n', '\\n', 'feature_list', '=', '[', ']', '\\n', '\\n', 'for', 'img', 'in', 'pbar', ':', '\\n', '        ', 'img', '=', 'img', '.', 'to', '(', 'device', ')', '\\n', 'feature', '=', 'inception', '(', 'img', ')', '[', '0', ']', '.', 'view', '(', 'img', '.', 'shape', '[', '0', ']', ',', '-', '1', ')', '\\n', 'feature_list', '.', 'append', '(', 'feature', '.', 'to', '(', '\"cpu\"', ')', ')', '\\n', '\\n', '', 'features', '=', 'torch', '.', 'cat', '(', 'feature_list', ',', '0', ')', '\\n', '\\n', 'return', 'features', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PixelNorm.__init__': [[15, 17], ['torch.nn.Module.__init__'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PixelNorm.forward': [[18, 20], ['torch.rsqrt', 'torch.mean'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'return', 'input', '*', 'torch', '.', 'rsqrt', '(', 'torch', '.', 'mean', '(', 'input', '**', '2', ',', 'dim', '=', '1', ',', 'keepdim', '=', 'True', ')', '+', '1e-8', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Upsample.__init__': [[34, 47], ['torch.nn.Module.__init__', 'model.Upsample.register_buffer', 'model.make_kernel'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.make_kernel'], ['    ', 'def', '__init__', '(', 'self', ',', 'kernel', ',', 'factor', '=', '2', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'factor', '=', 'factor', '\\n', 'kernel', '=', 'make_kernel', '(', 'kernel', ')', '*', '(', 'factor', '**', '2', ')', '\\n', 'self', '.', 'register_buffer', '(', '\"kernel\"', ',', 'kernel', ')', '\\n', '\\n', 'p', '=', 'kernel', '.', 'shape', '[', '0', ']', '-', 'factor', '\\n', '\\n', 'pad0', '=', '(', 'p', '+', '1', ')', '//', '2', '+', 'factor', '-', '1', '\\n', 'pad1', '=', 'p', '//', '2', '\\n', '\\n', 'self', '.', 'pad', '=', '(', 'pad0', ',', 'pad1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Upsample.forward': [[48, 52], ['op.upfirdn2d'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'out', '=', 'upfirdn2d', '(', 'input', ',', 'self', '.', 'kernel', ',', 'up', '=', 'self', '.', 'factor', ',', 'down', '=', '1', ',', 'pad', '=', 'self', '.', 'pad', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Downsample.__init__': [[55, 68], ['torch.nn.Module.__init__', 'model.make_kernel', 'model.Downsample.register_buffer'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.make_kernel'], ['    ', 'def', '__init__', '(', 'self', ',', 'kernel', ',', 'factor', '=', '2', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'factor', '=', 'factor', '\\n', 'kernel', '=', 'make_kernel', '(', 'kernel', ')', '\\n', 'self', '.', 'register_buffer', '(', '\"kernel\"', ',', 'kernel', ')', '\\n', '\\n', 'p', '=', 'kernel', '.', 'shape', '[', '0', ']', '-', 'factor', '\\n', '\\n', 'pad0', '=', '(', 'p', '+', '1', ')', '//', '2', '\\n', 'pad1', '=', 'p', '//', '2', '\\n', '\\n', 'self', '.', 'pad', '=', '(', 'pad0', ',', 'pad1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Downsample.forward': [[69, 73], ['op.upfirdn2d'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'out', '=', 'upfirdn2d', '(', 'input', ',', 'self', '.', 'kernel', ',', 'up', '=', '1', ',', 'down', '=', 'self', '.', 'factor', ',', 'pad', '=', 'self', '.', 'pad', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Blur.__init__': [[76, 87], ['torch.nn.Module.__init__', 'model.make_kernel', 'model.Blur.register_buffer'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.make_kernel'], ['    ', 'def', '__init__', '(', 'self', ',', 'kernel', ',', 'pad', ',', 'upsample_factor', '=', '1', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'kernel', '=', 'make_kernel', '(', 'kernel', ')', '\\n', '\\n', 'if', 'upsample_factor', '>', '1', ':', '\\n', '            ', 'kernel', '=', 'kernel', '*', '(', 'upsample_factor', '**', '2', ')', '\\n', '\\n', '', 'self', '.', 'register_buffer', '(', '\"kernel\"', ',', 'kernel', ')', '\\n', '\\n', 'self', '.', 'pad', '=', 'pad', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Blur.forward': [[88, 92], ['op.upfirdn2d'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'out', '=', 'upfirdn2d', '(', 'input', ',', 'self', '.', 'kernel', ',', 'pad', '=', 'self', '.', 'pad', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualConv2d.__init__': [[95, 113], ['torch.nn.Module.__init__', 'torch.nn.Parameter', 'torch.randn', 'math.sqrt', 'torch.nn.Parameter', 'torch.zeros'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', '\\n', 'self', ',', 'in_channel', ',', 'out_channel', ',', 'kernel_size', ',', 'stride', '=', '1', ',', 'padding', '=', '0', ',', 'bias', '=', 'True', '\\n', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'weight', '=', 'nn', '.', 'Parameter', '(', '\\n', 'torch', '.', 'randn', '(', 'out_channel', ',', 'in_channel', ',', 'kernel_size', ',', 'kernel_size', ')', '\\n', ')', '\\n', 'self', '.', 'scale', '=', '1', '/', 'math', '.', 'sqrt', '(', 'in_channel', '*', 'kernel_size', '**', '2', ')', '\\n', '\\n', 'self', '.', 'stride', '=', 'stride', '\\n', 'self', '.', 'padding', '=', 'padding', '\\n', '\\n', 'if', 'bias', ':', '\\n', '            ', 'self', '.', 'bias', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'zeros', '(', 'out_channel', ')', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'self', '.', 'bias', '=', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualConv2d.forward': [[114, 124], ['op.conv2d_gradfix.conv2d'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d'], ['', '', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'out', '=', 'conv2d_gradfix', '.', 'conv2d', '(', '\\n', 'input', ',', '\\n', 'self', '.', 'weight', '*', 'self', '.', 'scale', ',', '\\n', 'bias', '=', 'self', '.', 'bias', ',', '\\n', 'stride', '=', 'self', '.', 'stride', ',', '\\n', 'padding', '=', 'self', '.', 'padding', ',', '\\n', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualConv2d.__repr__': [[125, 128], ['None'], 'methods', ['None'], ['', 'def', '__repr__', '(', 'self', ')', ':', '\\n', '        ', 'return', '(', '\\n', 'f\"{self.__class__.__name__}({self.weight.shape[1]}, {self.weight.shape[0]},\"', '\\n', 'f\" {self.weight.shape[2]}, stride={self.stride}, padding={self.padding})\"', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualLinear.__init__': [[133, 150], ['torch.nn.Module.__init__', 'torch.nn.Parameter', 'torch.randn().div_', 'torch.nn.Parameter', 'torch.zeros().fill_', 'math.sqrt', 'torch.randn', 'torch.zeros'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', '\\n', 'self', ',', 'in_dim', ',', 'out_dim', ',', 'bias', '=', 'True', ',', 'bias_init', '=', '0', ',', 'lr_mul', '=', '1', ',', 'activation', '=', 'None', '\\n', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'weight', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'randn', '(', 'out_dim', ',', 'in_dim', ')', '.', 'div_', '(', 'lr_mul', ')', ')', '\\n', '\\n', 'if', 'bias', ':', '\\n', '            ', 'self', '.', 'bias', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'zeros', '(', 'out_dim', ')', '.', 'fill_', '(', 'bias_init', ')', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'self', '.', 'bias', '=', 'None', '\\n', '\\n', '', 'self', '.', 'activation', '=', 'activation', '\\n', '\\n', 'self', '.', 'scale', '=', '(', '1', '/', 'math', '.', 'sqrt', '(', 'in_dim', ')', ')', '*', 'lr_mul', '\\n', 'self', '.', 'lr_mul', '=', 'lr_mul', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualLinear.forward': [[151, 162], ['torch.nn.functional.linear', 'op.fused_leaky_relu', 'torch.nn.functional.linear'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.fused_leaky_relu'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'if', 'self', '.', 'activation', ':', '\\n', '            ', 'out', '=', 'F', '.', 'linear', '(', 'input', ',', 'self', '.', 'weight', '*', 'self', '.', 'scale', ')', '\\n', 'out', '=', 'fused_leaky_relu', '(', 'out', ',', 'self', '.', 'bias', '*', 'self', '.', 'lr_mul', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'out', '=', 'F', '.', 'linear', '(', '\\n', 'input', ',', 'self', '.', 'weight', '*', 'self', '.', 'scale', ',', 'bias', '=', 'self', '.', 'bias', '*', 'self', '.', 'lr_mul', '\\n', ')', '\\n', '\\n', '', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualLinear.__repr__': [[163, 166], ['None'], 'methods', ['None'], ['', 'def', '__repr__', '(', 'self', ')', ':', '\\n', '        ', 'return', '(', '\\n', 'f\"{self.__class__.__name__}({self.weight.shape[1]}, {self.weight.shape[0]})\"', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ModulatedConv2d.__init__': [[170, 219], ['torch.nn.Module.__init__', 'torch.nn.Parameter', 'model.EqualLinear', 'model.Blur', 'model.Blur', 'math.sqrt', 'torch.randn', 'len', 'len'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', '\\n', 'self', ',', '\\n', 'in_channel', ',', '\\n', 'out_channel', ',', '\\n', 'kernel_size', ',', '\\n', 'style_dim', ',', '\\n', 'demodulate', '=', 'True', ',', '\\n', 'upsample', '=', 'False', ',', '\\n', 'downsample', '=', 'False', ',', '\\n', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ',', '\\n', 'fused', '=', 'True', ',', '\\n', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'eps', '=', '1e-8', '\\n', 'self', '.', 'kernel_size', '=', 'kernel_size', '\\n', 'self', '.', 'in_channel', '=', 'in_channel', '\\n', 'self', '.', 'out_channel', '=', 'out_channel', '\\n', 'self', '.', 'upsample', '=', 'upsample', '\\n', 'self', '.', 'downsample', '=', 'downsample', '\\n', '\\n', 'if', 'upsample', ':', '\\n', '            ', 'factor', '=', '2', '\\n', 'p', '=', '(', 'len', '(', 'blur_kernel', ')', '-', 'factor', ')', '-', '(', 'kernel_size', '-', '1', ')', '\\n', 'pad0', '=', '(', 'p', '+', '1', ')', '//', '2', '+', 'factor', '-', '1', '\\n', 'pad1', '=', 'p', '//', '2', '+', '1', '\\n', '\\n', 'self', '.', 'blur', '=', 'Blur', '(', 'blur_kernel', ',', 'pad', '=', '(', 'pad0', ',', 'pad1', ')', ',', 'upsample_factor', '=', 'factor', ')', '\\n', '\\n', '', 'if', 'downsample', ':', '\\n', '            ', 'factor', '=', '2', '\\n', 'p', '=', '(', 'len', '(', 'blur_kernel', ')', '-', 'factor', ')', '+', '(', 'kernel_size', '-', '1', ')', '\\n', 'pad0', '=', '(', 'p', '+', '1', ')', '//', '2', '\\n', 'pad1', '=', 'p', '//', '2', '\\n', '\\n', 'self', '.', 'blur', '=', 'Blur', '(', 'blur_kernel', ',', 'pad', '=', '(', 'pad0', ',', 'pad1', ')', ')', '\\n', '\\n', '', 'fan_in', '=', 'in_channel', '*', 'kernel_size', '**', '2', '\\n', 'self', '.', 'scale', '=', '1', '/', 'math', '.', 'sqrt', '(', 'fan_in', ')', '\\n', 'self', '.', 'padding', '=', 'kernel_size', '//', '2', '\\n', '\\n', 'self', '.', 'weight', '=', 'nn', '.', 'Parameter', '(', '\\n', 'torch', '.', 'randn', '(', '1', ',', 'out_channel', ',', 'in_channel', ',', 'kernel_size', ',', 'kernel_size', ')', '\\n', ')', '\\n', '\\n', 'self', '.', 'modulation', '=', 'EqualLinear', '(', 'style_dim', ',', 'in_channel', ',', 'bias_init', '=', '1', ')', '\\n', '\\n', 'self', '.', 'demodulate', '=', 'demodulate', '\\n', 'self', '.', 'fused', '=', 'fused', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ModulatedConv2d.__repr__': [[220, 223], ['None'], 'methods', ['None'], ['', 'def', '__repr__', '(', 'self', ')', ':', '\\n', '        ', 'return', '(', '\\n', 'f\"{self.__class__.__name__}({self.in_channel}, {self.out_channel}, {self.kernel_size}, \"', '\\n', 'f\"upsample={self.upsample}, downsample={self.downsample})\"', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ModulatedConv2d.forward': [[226, 303], ['model.ModulatedConv2d.modulation().view', 'weight.transpose.transpose.view', 'model.ModulatedConv2d.modulation', 'torch.rsqrt', 'model.ModulatedConv2d.view', 'weight.transpose.transpose.view', 'weight.transpose.transpose.transpose().reshape', 'op.conv2d_gradfix.conv_transpose2d', 'op.conv2d_gradfix.conv2d.view', 'model.ModulatedConv2d.blur', 'model.ModulatedConv2d.weight.squeeze', 'model.ModulatedConv2d.reshape', 'weight.transpose.transpose.transpose', 'op.conv2d_gradfix.conv_transpose2d', 'model.ModulatedConv2d.blur', 'model.ModulatedConv2d.modulation', 'torch.rsqrt.view', 'model.ModulatedConv2d.blur', 'model.ModulatedConv2d.view', 'op.conv2d_gradfix.conv2d', 'op.conv2d_gradfix.conv2d.view', 'model.ModulatedConv2d.view', 'op.conv2d_gradfix.conv2d', 'op.conv2d_gradfix.conv2d.view', 'weight.transpose.transpose.unsqueeze', 'model.ModulatedConv2d.view', 'model.ModulatedConv2d.blur', 'op.conv2d_gradfix.conv2d', 'op.conv2d_gradfix.conv2d', 'dcoefs.view', 'weight.transpose.transpose.pow().sum', 'weight.transpose.transpose.transpose', 'w.square().sum', 'weight.transpose.transpose.pow', 'w.square'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv_transpose2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv_transpose2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d'], ['', 'def', 'forward', '(', 'self', ',', 'input', ',', 'style', ')', ':', '\\n', '        ', 'batch', ',', 'in_channel', ',', 'height', ',', 'width', '=', 'input', '.', 'shape', '\\n', '\\n', 'if', 'not', 'self', '.', 'fused', ':', '\\n', '            ', 'weight', '=', 'self', '.', 'scale', '*', 'self', '.', 'weight', '.', 'squeeze', '(', '0', ')', '\\n', 'style', '=', 'self', '.', 'modulation', '(', 'style', ')', '\\n', '\\n', 'if', 'self', '.', 'demodulate', ':', '\\n', '                ', 'w', '=', 'weight', '.', 'unsqueeze', '(', '0', ')', '*', 'style', '.', 'view', '(', 'batch', ',', '1', ',', 'in_channel', ',', '1', ',', '1', ')', '\\n', 'dcoefs', '=', '(', 'w', '.', 'square', '(', ')', '.', 'sum', '(', '(', '2', ',', '3', ',', '4', ')', ')', '+', '1e-8', ')', '.', 'rsqrt', '(', ')', '\\n', '\\n', '', 'input', '=', 'input', '*', 'style', '.', 'reshape', '(', 'batch', ',', 'in_channel', ',', '1', ',', '1', ')', '\\n', '\\n', 'if', 'self', '.', 'upsample', ':', '\\n', '                ', 'weight', '=', 'weight', '.', 'transpose', '(', '0', ',', '1', ')', '\\n', 'out', '=', 'conv2d_gradfix', '.', 'conv_transpose2d', '(', '\\n', 'input', ',', 'weight', ',', 'padding', '=', '0', ',', 'stride', '=', '2', '\\n', ')', '\\n', 'out', '=', 'self', '.', 'blur', '(', 'out', ')', '\\n', '\\n', '', 'elif', 'self', '.', 'downsample', ':', '\\n', '                ', 'input', '=', 'self', '.', 'blur', '(', 'input', ')', '\\n', 'out', '=', 'conv2d_gradfix', '.', 'conv2d', '(', 'input', ',', 'weight', ',', 'padding', '=', '0', ',', 'stride', '=', '2', ')', '\\n', '\\n', '', 'else', ':', '\\n', '                ', 'out', '=', 'conv2d_gradfix', '.', 'conv2d', '(', 'input', ',', 'weight', ',', 'padding', '=', 'self', '.', 'padding', ')', '\\n', '\\n', '', 'if', 'self', '.', 'demodulate', ':', '\\n', '                ', 'out', '=', 'out', '*', 'dcoefs', '.', 'view', '(', 'batch', ',', '-', '1', ',', '1', ',', '1', ')', '\\n', '\\n', '', 'return', 'out', '\\n', '\\n', '', 'style', '=', 'self', '.', 'modulation', '(', 'style', ')', '.', 'view', '(', 'batch', ',', '1', ',', 'in_channel', ',', '1', ',', '1', ')', '\\n', 'weight', '=', 'self', '.', 'scale', '*', 'self', '.', 'weight', '*', 'style', '\\n', '\\n', 'if', 'self', '.', 'demodulate', ':', '\\n', '            ', 'demod', '=', 'torch', '.', 'rsqrt', '(', 'weight', '.', 'pow', '(', '2', ')', '.', 'sum', '(', '[', '2', ',', '3', ',', '4', ']', ')', '+', '1e-8', ')', '\\n', 'weight', '=', 'weight', '*', 'demod', '.', 'view', '(', 'batch', ',', 'self', '.', 'out_channel', ',', '1', ',', '1', ',', '1', ')', '\\n', '\\n', '', 'weight', '=', 'weight', '.', 'view', '(', '\\n', 'batch', '*', 'self', '.', 'out_channel', ',', 'in_channel', ',', 'self', '.', 'kernel_size', ',', 'self', '.', 'kernel_size', '\\n', ')', '\\n', '\\n', 'if', 'self', '.', 'upsample', ':', '\\n', '            ', 'input', '=', 'input', '.', 'view', '(', '1', ',', 'batch', '*', 'in_channel', ',', 'height', ',', 'width', ')', '\\n', 'weight', '=', 'weight', '.', 'view', '(', '\\n', 'batch', ',', 'self', '.', 'out_channel', ',', 'in_channel', ',', 'self', '.', 'kernel_size', ',', 'self', '.', 'kernel_size', '\\n', ')', '\\n', 'weight', '=', 'weight', '.', 'transpose', '(', '1', ',', '2', ')', '.', 'reshape', '(', '\\n', 'batch', '*', 'in_channel', ',', 'self', '.', 'out_channel', ',', 'self', '.', 'kernel_size', ',', 'self', '.', 'kernel_size', '\\n', ')', '\\n', 'out', '=', 'conv2d_gradfix', '.', 'conv_transpose2d', '(', '\\n', 'input', ',', 'weight', ',', 'padding', '=', '0', ',', 'stride', '=', '2', ',', 'groups', '=', 'batch', '\\n', ')', '\\n', '_', ',', '_', ',', 'height', ',', 'width', '=', 'out', '.', 'shape', '\\n', 'out', '=', 'out', '.', 'view', '(', 'batch', ',', 'self', '.', 'out_channel', ',', 'height', ',', 'width', ')', '\\n', 'out', '=', 'self', '.', 'blur', '(', 'out', ')', '\\n', '\\n', '', 'elif', 'self', '.', 'downsample', ':', '\\n', '            ', 'input', '=', 'self', '.', 'blur', '(', 'input', ')', '\\n', '_', ',', '_', ',', 'height', ',', 'width', '=', 'input', '.', 'shape', '\\n', 'input', '=', 'input', '.', 'view', '(', '1', ',', 'batch', '*', 'in_channel', ',', 'height', ',', 'width', ')', '\\n', 'out', '=', 'conv2d_gradfix', '.', 'conv2d', '(', '\\n', 'input', ',', 'weight', ',', 'padding', '=', '0', ',', 'stride', '=', '2', ',', 'groups', '=', 'batch', '\\n', ')', '\\n', '_', ',', '_', ',', 'height', ',', 'width', '=', 'out', '.', 'shape', '\\n', 'out', '=', 'out', '.', 'view', '(', 'batch', ',', 'self', '.', 'out_channel', ',', 'height', ',', 'width', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'input', '=', 'input', '.', 'view', '(', '1', ',', 'batch', '*', 'in_channel', ',', 'height', ',', 'width', ')', '\\n', 'out', '=', 'conv2d_gradfix', '.', 'conv2d', '(', '\\n', 'input', ',', 'weight', ',', 'padding', '=', 'self', '.', 'padding', ',', 'groups', '=', 'batch', '\\n', ')', '\\n', '_', ',', '_', ',', 'height', ',', 'width', '=', 'out', '.', 'shape', '\\n', 'out', '=', 'out', '.', 'view', '(', 'batch', ',', 'self', '.', 'out_channel', ',', 'height', ',', 'width', ')', '\\n', '\\n', '', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.NoiseInjection.__init__': [[306, 310], ['torch.nn.Module.__init__', 'torch.nn.Parameter', 'torch.zeros'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'weight', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'zeros', '(', '1', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.NoiseInjection.forward': [[311, 317], ['image.new_empty().normal_', 'image.new_empty'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'image', ',', 'noise', '=', 'None', ')', ':', '\\n', '        ', 'if', 'noise', 'is', 'None', ':', '\\n', '            ', 'batch', ',', '_', ',', 'height', ',', 'width', '=', 'image', '.', 'shape', '\\n', 'noise', '=', 'image', '.', 'new_empty', '(', 'batch', ',', '1', ',', 'height', ',', 'width', ')', '.', 'normal_', '(', ')', '\\n', '\\n', '', 'return', 'image', '+', 'self', '.', 'weight', '*', 'noise', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ConstantInput.__init__': [[320, 324], ['torch.nn.Module.__init__', 'torch.nn.Parameter', 'torch.randn'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'channel', ',', 'size', '=', '4', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'input', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'randn', '(', '1', ',', 'channel', ',', 'size', ',', 'size', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ConstantInput.forward': [[325, 335], ['model.ConstantInput.input.repeat', 'torch.roll', 'torch.roll', 'torch.roll', 'torch.roll', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ',', 'shift_h', '=', '0', ',', 'shift_w', '=', '0', ',', 'transform', '=', 'None', ')', ':', '\\n', '        ', 'batch', '=', 'input', '.', 'shape', '[', '0', ']', '\\n', 'out', '=', 'self', '.', 'input', '.', 'repeat', '(', 'batch', ',', '1', ',', '1', ',', '1', ')', '\\n', '# shift. details in appendix', '\\n', 'out', '=', 'torch', '.', 'roll', '(', 'out', ',', 'int', '(', 'shift_h', ')', ',', '2', ')', '*', '(', '1', '-', 'shift_h', '+', 'int', '(', 'shift_h', ')', ')', '+', 'torch', '.', 'roll', '(', 'out', ',', 'int', '(', 'shift_h', ')', '+', '1', ',', '2', ')', '*', '(', '\\n', 'shift_h', '-', 'int', '(', 'shift_h', ')', ')', '\\n', 'out', '=', 'torch', '.', 'roll', '(', 'out', ',', 'int', '(', 'shift_w', ')', ',', '3', ')', '*', '(', '1', '-', 'shift_w', '+', 'int', '(', 'shift_w', ')', ')', '+', 'torch', '.', 'roll', '(', 'out', ',', 'int', '(', 'shift_w', ')', '+', '1', ',', '3', ')', '*', '(', '\\n', 'shift_w', '-', 'int', '(', 'shift_w', ')', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.StyledConv.__init__': [[338, 364], ['torch.nn.Module.__init__', 'model.ModulatedConv2d', 'model.NoiseInjection', 'op.FusedLeakyReLU'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', '\\n', 'self', ',', '\\n', 'in_channel', ',', '\\n', 'out_channel', ',', '\\n', 'kernel_size', ',', '\\n', 'style_dim', ',', '\\n', 'upsample', '=', 'False', ',', '\\n', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ',', '\\n', 'demodulate', '=', 'True', ',', '\\n', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'conv', '=', 'ModulatedConv2d', '(', '\\n', 'in_channel', ',', '\\n', 'out_channel', ',', '\\n', 'kernel_size', ',', '\\n', 'style_dim', ',', '\\n', 'upsample', '=', 'upsample', ',', '\\n', 'blur_kernel', '=', 'blur_kernel', ',', '\\n', 'demodulate', '=', 'demodulate', ',', '\\n', ')', '\\n', '\\n', 'self', '.', 'noise', '=', 'NoiseInjection', '(', ')', '\\n', '# self.bias = nn.Parameter(torch.zeros(1, out_channel, 1, 1))', '\\n', '# self.activate = ScaledLeakyReLU(0.2)', '\\n', 'self', '.', 'activate', '=', 'FusedLeakyReLU', '(', 'out_channel', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.StyledConv.forward': [[365, 372], ['model.StyledConv.conv', 'model.StyledConv.noise', 'model.StyledConv.activate'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ',', 'style', ',', 'noise', '=', 'None', ')', ':', '\\n', '        ', 'out', '=', 'self', '.', 'conv', '(', 'input', ',', 'style', ')', '\\n', 'out', '=', 'self', '.', 'noise', '(', 'out', ',', 'noise', '=', 'noise', ')', '\\n', '# out = out + self.bias', '\\n', 'out', '=', 'self', '.', 'activate', '(', 'out', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ToRGB.__init__': [[375, 383], ['torch.nn.Module.__init__', 'model.ModulatedConv2d', 'torch.nn.Parameter', 'model.Upsample', 'torch.zeros'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'in_channel', ',', 'style_dim', ',', 'upsample', '=', 'True', ',', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'if', 'upsample', ':', '\\n', '            ', 'self', '.', 'upsample', '=', 'Upsample', '(', 'blur_kernel', ')', '\\n', '\\n', '', 'self', '.', 'conv', '=', 'ModulatedConv2d', '(', 'in_channel', ',', '3', ',', '1', ',', 'style_dim', ',', 'demodulate', '=', 'False', ')', '\\n', 'self', '.', 'bias', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'zeros', '(', '1', ',', '3', ',', '1', ',', '1', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ToRGB.forward': [[384, 394], ['model.ToRGB.conv', 'model.ToRGB.upsample'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.upsample'], ['', 'def', 'forward', '(', 'self', ',', 'input', ',', 'style', ',', 'skip', '=', 'None', ')', ':', '\\n', '        ', 'out', '=', 'self', '.', 'conv', '(', 'input', ',', 'style', ')', '\\n', 'out', '=', 'out', '+', 'self', '.', 'bias', '\\n', '\\n', 'if', 'skip', 'is', 'not', 'None', ':', '\\n', '            ', 'skip', '=', 'self', '.', 'upsample', '(', 'skip', ')', '\\n', '\\n', 'out', '=', 'out', '+', 'skip', '\\n', '\\n', '', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.__init__': [[397, 510], ['torch.nn.Module.__init__', 'range', 'torch.nn.Sequential', 'model.StyledConv', 'model.ToRGB', 'int', 'torch.nn.ModuleList', 'torch.nn.ModuleList', 'torch.nn.ModuleList', 'torch.nn.Module', 'range', 'range', 'range', 'model.PixelNorm', 'layers.append', 'model.PE2dStart', 'model.ConstantInput', 'model.EqualLinear', 'model.Generator.affine_fourier.weight.detach().zero_', 'model.Generator.affine_fourier.bias.detach().copy_', 'math.log', 'torch.nn.ModuleList', 'model.Generator.noises.register_buffer', 'model.Generator.convs.append', 'model.Generator.convs.append', 'model.Generator.to_rgbs.append', 'model.EqualLinear', 'torch.tensor', 'torch.randn', 'model.StyledConv', 'model.Generator.pes.append', 'model.StyledConv', 'model.ToRGB', 'model.Generator.affine_fourier.weight.detach', 'model.Generator.affine_fourier.bias.detach', 'model.PE2d'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', '\\n', 'self', ',', '\\n', 'size', ',', '\\n', 'style_dim', ',', '\\n', 'n_mlp', ',', '\\n', 'channel_multiplier', '=', '2', ',', '\\n', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ',', '\\n', 'lr_mlp', '=', '0.01', ',', '\\n', 'position', '=', \"'none'\", ',', '\\n', 'kernel_size', '=', '3', ',', '\\n', 'affine', '=', 'False', ',', '\\n', 'scale', '=', '1.0', ',', '\\n', 'device', '=', '\"cuda\"', ',', '\\n', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'size', '=', 'size', '\\n', '\\n', 'self', '.', 'style_dim', '=', 'style_dim', '\\n', '\\n', 'self', '.', 'position', '=', 'position', '\\n', 'self', '.', 'affine', '=', 'affine', '\\n', 'self', '.', 'device', '=', 'device', '\\n', '\\n', 'layers', '=', '[', 'PixelNorm', '(', ')', ']', '\\n', '\\n', 'for', 'i', 'in', 'range', '(', 'n_mlp', ')', ':', '\\n', '            ', 'layers', '.', 'append', '(', '\\n', 'EqualLinear', '(', '\\n', 'style_dim', ',', 'style_dim', ',', 'lr_mul', '=', 'lr_mlp', ',', 'activation', '=', '\"fused_lrelu\"', '\\n', ')', '\\n', ')', '\\n', '\\n', '', 'self', '.', 'style', '=', 'nn', '.', 'Sequential', '(', '*', 'layers', ')', '\\n', '\\n', 'self', '.', 'channels', '=', '{', '\\n', '4', ':', '512', ',', '\\n', '8', ':', '512', ',', '\\n', '16', ':', '512', ',', '\\n', '32', ':', '512', ',', '\\n', '64', ':', '256', '*', 'channel_multiplier', ',', '\\n', '128', ':', '128', '*', 'channel_multiplier', ',', '\\n', '256', ':', '64', '*', 'channel_multiplier', ',', '\\n', '512', ':', '32', '*', 'channel_multiplier', ',', '\\n', '1024', ':', '16', '*', 'channel_multiplier', ',', '\\n', '}', '\\n', 'if', \"'pe'\", 'in', 'self', '.', 'position', ':', '\\n', '            ', 'self', '.', 'input', '=', 'PE2dStart', '(', '512', ',', '4', ',', '4', ',', 'scale', '=', 'scale', ',', 'device', '=', 'device', ')', '\\n', '', 'else', ':', '\\n', '            ', 'self', '.', 'input', '=', 'ConstantInput', '(', 'self', '.', 'channels', '[', '4', ']', ')', '\\n', '', 'self', '.', 'shift_h_dict', '=', '{', '4', ':', '0', '}', '\\n', 'self', '.', 'shift_w_dict', '=', '{', '4', ':', '0', '}', '\\n', '\\n', 'if', 'self', '.', 'affine', ':', '\\n', '            ', 'self', '.', 'affine_fourier', '=', 'EqualLinear', '(', 'style_dim', ',', '4', ')', '\\n', 'self', '.', 'affine_fourier', '.', 'weight', '.', 'detach', '(', ')', '.', 'zero_', '(', ')', '\\n', 'self', '.', 'affine_fourier', '.', 'bias', '.', 'detach', '(', ')', '.', 'copy_', '(', '\\n', 'torch', '.', 'tensor', '(', '[', '1', ',', '0', ',', '0', ',', '0', ']', ',', 'dtype', '=', 'torch', '.', 'float32', ')', '\\n', ')', '\\n', '\\n', '', 'self', '.', 'conv1', '=', 'StyledConv', '(', '\\n', 'self', '.', 'channels', '[', '4', ']', ',', 'self', '.', 'channels', '[', '4', ']', ',', 'kernel_size', ',', 'style_dim', ',', 'blur_kernel', '=', 'blur_kernel', '\\n', ')', '\\n', 'self', '.', 'to_rgb1', '=', 'ToRGB', '(', 'self', '.', 'channels', '[', '4', ']', ',', 'style_dim', ',', 'upsample', '=', 'False', ')', '\\n', '\\n', 'self', '.', 'log_size', '=', 'int', '(', 'math', '.', 'log', '(', 'size', ',', '2', ')', ')', '\\n', 'self', '.', 'num_layers', '=', '(', 'self', '.', 'log_size', '-', '2', ')', '*', '2', '+', '1', '\\n', '\\n', 'self', '.', 'convs', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', 'self', '.', 'upsamples', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', 'self', '.', 'to_rgbs', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', 'self', '.', 'noises', '=', 'nn', '.', 'Module', '(', ')', '\\n', 'if', \"'mspe'\", 'in', 'self', '.', 'position', ':', '\\n', '            ', 'self', '.', 'pes', '=', 'nn', '.', 'ModuleList', '(', ')', '\\n', '', 'for', 'i', 'in', 'range', '(', '3', ',', 'self', '.', 'log_size', '+', '1', ')', ':', '\\n', '            ', 'self', '.', 'shift_h_dict', '[', '2', '**', 'i', ']', '=', '0', '\\n', 'self', '.', 'shift_w_dict', '[', '2', '**', 'i', ']', '=', '0', '\\n', '\\n', '', 'in_channel', '=', 'self', '.', 'channels', '[', '4', ']', '\\n', '\\n', 'for', 'layer_idx', 'in', 'range', '(', 'self', '.', 'num_layers', ')', ':', '\\n', '            ', 'res', '=', '(', 'layer_idx', '+', '5', ')', '//', '2', '\\n', 'shape', '=', '[', '1', ',', '1', ',', '2', '**', 'res', ',', '2', '**', 'res', ']', '\\n', 'self', '.', 'noises', '.', 'register_buffer', '(', 'f\"noise_{layer_idx}\"', ',', 'torch', '.', 'randn', '(', '*', 'shape', ')', ')', '\\n', '\\n', '', 'for', 'i', 'in', 'range', '(', '3', ',', 'self', '.', 'log_size', '+', '1', ')', ':', '\\n', '            ', 'out_channel', '=', 'self', '.', 'channels', '[', '2', '**', 'i', ']', '\\n', '\\n', 'self', '.', 'convs', '.', 'append', '(', '\\n', 'StyledConv', '(', '\\n', 'in_channel', ',', '\\n', 'out_channel', ',', '\\n', 'kernel_size', ',', '\\n', 'style_dim', ',', '\\n', 'upsample', '=', 'True', ',', '\\n', 'blur_kernel', '=', 'blur_kernel', ',', '\\n', ')', '\\n', ')', '\\n', '###### positional encoding ######', '\\n', 'if', \"'mspe'\", 'in', 'self', '.', 'position', ':', '\\n', '                ', 'self', '.', 'pes', '.', 'append', '(', 'PE2d', '(', 'out_channel', ',', '2', '**', 'i', ',', '2', '**', 'i', ',', 'scale', ',', 'device', '=', 'device', ')', ')', '\\n', '\\n', '', 'self', '.', 'convs', '.', 'append', '(', '\\n', 'StyledConv', '(', '\\n', 'out_channel', ',', 'out_channel', ',', 'kernel_size', ',', 'style_dim', ',', 'blur_kernel', '=', 'blur_kernel', '\\n', ')', '\\n', ')', '\\n', '\\n', 'self', '.', 'to_rgbs', '.', 'append', '(', 'ToRGB', '(', 'out_channel', ',', 'style_dim', ')', ')', '\\n', '\\n', 'in_channel', '=', 'out_channel', '\\n', '\\n', '', 'self', '.', 'n_latent', '=', 'self', '.', 'log_size', '*', '2', '-', '2', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.make_noise': [[511, 521], ['range', 'torch.randn', 'range', 'noises.append', 'torch.randn'], 'methods', ['None'], ['', 'def', 'make_noise', '(', 'self', ')', ':', '\\n', '        ', 'device', '=', 'self', '.', 'device', '\\n', '\\n', 'noises', '=', '[', 'torch', '.', 'randn', '(', '1', ',', '1', ',', '2', '**', '2', ',', '2', '**', '2', ',', 'device', '=', 'device', ')', ']', '\\n', '\\n', 'for', 'i', 'in', 'range', '(', '3', ',', 'self', '.', 'log_size', '+', '1', ')', ':', '\\n', '            ', 'for', '_', 'in', 'range', '(', '2', ')', ':', '\\n', '                ', 'noises', '.', 'append', '(', 'torch', '.', 'randn', '(', '1', ',', '1', ',', '2', '**', 'i', ',', '2', '**', 'i', ',', 'device', '=', 'device', ')', ')', '\\n', '\\n', '', '', 'return', 'noises', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.mean_latent': [[522, 529], ['torch.randn', 'model.Generator.style().mean', 'model.Generator.style'], 'methods', ['None'], ['', 'def', 'mean_latent', '(', 'self', ',', 'n_latent', ')', ':', '\\n', '        ', 'latent_in', '=', 'torch', '.', 'randn', '(', '\\n', 'n_latent', ',', 'self', '.', 'style_dim', ',', 'device', '=', 'self', '.', 'device', '\\n', ')', '\\n', 'latent', '=', 'self', '.', 'style', '(', 'latent_in', ')', '.', 'mean', '(', '0', ',', 'keepdim', '=', 'True', ')', '\\n', '\\n', 'return', 'latent', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.get_latent': [[530, 532], ['model.Generator.style'], 'methods', ['None'], ['', 'def', 'get_latent', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'return', 'self', '.', 'style', '(', 'input', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.forward': [[533, 628], ['model.Generator.input', 'model.Generator.conv1', 'model.Generator.to_rgb1', 'zip', 'range', 'range', 'len', 'styles[].unsqueeze().repeat', 'styles[].unsqueeze().repeat', 'torch.cat', 'model.Generator.affine_fourier', 'conv1', 'conv2', 'to_rgb', 'model.Generator.style', 'style_t.append', 'styles[].unsqueeze().repeat', 'random.randint', 'getattr', 'styles[].unsqueeze', 'styles[].unsqueeze', 'range', 'styles[].unsqueeze'], 'methods', ['None'], ['', 'def', 'forward', '(', '\\n', 'self', ',', '\\n', 'styles', ',', '\\n', 'return_latents', '=', 'False', ',', '\\n', 'inject_index', '=', 'None', ',', '\\n', 'truncation', '=', '1', ',', '\\n', 'truncation_latent', '=', 'None', ',', '\\n', 'input_is_latent', '=', 'False', ',', '\\n', 'noise', '=', 'None', ',', '\\n', 'randomize_noise', '=', 'True', ',', '\\n', 'shift_h', '=', '0', ',', '\\n', 'shift_w', '=', '0', ',', '\\n', 'transform', '=', 'None', ',', '\\n', ')', ':', '\\n', '##### positional encoding #####', '\\n', '# continuous roll', '\\n', '        ', 'if', 'shift_h', ':', '\\n', '            ', 'for', 'i', 'in', 'range', '(', '2', ',', 'self', '.', 'log_size', '+', '1', ')', ':', '\\n', '                ', 'self', '.', 'shift_h_dict', '[', '2', '**', 'i', ']', '=', 'shift_h', '/', '(', 'self', '.', 'size', '//', '(', '2', '**', 'i', ')', ')', '\\n', '', '', 'if', 'shift_w', ':', '\\n', '            ', 'for', 'i', 'in', 'range', '(', '2', ',', 'self', '.', 'log_size', '+', '1', ')', ':', '\\n', '                ', 'self', '.', 'shift_w_dict', '[', '2', '**', 'i', ']', '=', 'shift_w', '/', '(', 'self', '.', 'size', '//', '(', '2', '**', 'i', ')', ')', '\\n', '\\n', '', '', 'if', 'not', 'input_is_latent', ':', '\\n', '            ', 'styles', '=', '[', 'self', '.', 'style', '(', 's', ')', 'for', 's', 'in', 'styles', ']', '\\n', '\\n', '', 'if', 'noise', 'is', 'None', ':', '\\n', '            ', 'if', 'randomize_noise', ':', '\\n', '                ', 'noise', '=', '[', 'None', ']', '*', 'self', '.', 'num_layers', '\\n', '', 'else', ':', '\\n', '                ', 'noise', '=', '[', '\\n', 'getattr', '(', 'self', '.', 'noises', ',', 'f\"noise_{i}\"', ')', 'for', 'i', 'in', 'range', '(', 'self', '.', 'num_layers', ')', '\\n', ']', '\\n', '\\n', '', '', 'if', 'truncation', '<', '1', ':', '\\n', '            ', 'style_t', '=', '[', ']', '\\n', '\\n', 'for', 'style', 'in', 'styles', ':', '\\n', '                ', 'style_t', '.', 'append', '(', '\\n', 'truncation_latent', '+', 'truncation', '*', '(', 'style', '-', 'truncation_latent', ')', '\\n', ')', '\\n', '\\n', '', 'styles', '=', 'style_t', '\\n', '\\n', '', 'if', 'len', '(', 'styles', ')', '<', '2', ':', '\\n', '            ', 'inject_index', '=', 'self', '.', 'n_latent', '\\n', '\\n', 'if', 'styles', '[', '0', ']', '.', 'ndim', '<', '3', ':', '\\n', '                ', 'latent', '=', 'styles', '[', '0', ']', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'inject_index', ',', '1', ')', '\\n', '\\n', '', 'else', ':', '\\n', '                ', 'latent', '=', 'styles', '[', '0', ']', '\\n', '\\n', '', '', 'else', ':', '\\n', '            ', 'if', 'inject_index', 'is', 'None', ':', '\\n', '                ', 'inject_index', '=', 'random', '.', 'randint', '(', '1', ',', 'self', '.', 'n_latent', '-', '1', ')', '\\n', '\\n', '', 'latent', '=', 'styles', '[', '0', ']', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'inject_index', ',', '1', ')', '\\n', 'latent2', '=', 'styles', '[', '1', ']', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'self', '.', 'n_latent', '-', 'inject_index', ',', '1', ')', '\\n', '\\n', 'latent', '=', 'torch', '.', 'cat', '(', '[', 'latent', ',', 'latent2', ']', ',', '1', ')', '\\n', '\\n', '', 'if', 'self', '.', 'affine', 'and', 'transform', 'is', 'None', ':', '\\n', '            ', 'transform', '=', 'self', '.', 'affine_fourier', '(', 'latent', ')', '\\n', '\\n', \"#if 'pe' in self.position:\", '\\n', '', 'out', '=', 'self', '.', 'input', '(', 'latent', ',', 'self', '.', 'shift_h_dict', '[', '4', ']', ',', 'self', '.', 'shift_w_dict', '[', '4', ']', ',', 'transform', '=', 'transform', ')', '\\n', '#else:', '\\n', '#    out = self.input(latent)', '\\n', 'out', '=', 'self', '.', 'conv1', '(', 'out', ',', 'latent', '[', ':', ',', '0', ']', ',', 'noise', '=', 'noise', '[', '0', ']', ')', '\\n', '\\n', 'skip', '=', 'self', '.', 'to_rgb1', '(', 'out', ',', 'latent', '[', ':', ',', '1', ']', ')', '\\n', '\\n', 'i', '=', '1', '\\n', 'for', 'conv1', ',', 'conv2', ',', 'noise1', ',', 'noise2', ',', 'to_rgb', 'in', 'zip', '(', '\\n', 'self', '.', 'convs', '[', ':', ':', '2', ']', ',', 'self', '.', 'convs', '[', '1', ':', ':', '2', ']', ',', 'noise', '[', '1', ':', ':', '2', ']', ',', 'noise', '[', '2', ':', ':', '2', ']', ',', 'self', '.', 'to_rgbs', '\\n', ')', ':', '\\n', '            ', 'out', '=', 'conv1', '(', 'out', ',', 'latent', '[', ':', ',', 'i', ']', ',', 'noise', '=', 'noise1', ')', '\\n', '\\n', 'if', \"'mspe'\", 'in', 'self', '.', 'position', ':', '\\n', '                ', 'res', '=', '8', '*', '(', '2', '**', '(', '(', 'i', '-', '1', ')', '//', '2', ')', ')', '\\n', 'out', '=', 'self', '.', 'pes', '[', '(', 'i', '-', '1', ')', '//', '2', ']', '(', 'out', ',', 'shift_h', '=', 'self', '.', 'shift_h_dict', '[', 'res', ']', ',', 'shift_w', '=', 'self', '.', 'shift_w_dict', '[', 'res', ']', ')', '\\n', '\\n', '', 'out', '=', 'conv2', '(', 'out', ',', 'latent', '[', ':', ',', 'i', '+', '1', ']', ',', 'noise', '=', 'noise2', ')', '\\n', 'skip', '=', 'to_rgb', '(', 'out', ',', 'latent', '[', ':', ',', 'i', '+', '2', ']', ',', 'skip', ')', '\\n', '\\n', 'i', '+=', '2', '\\n', '\\n', '', 'image', '=', 'skip', '\\n', '\\n', 'if', 'return_latents', ':', '\\n', '            ', 'return', 'image', ',', 'latent', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'return', 'image', ',', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ConvLayer.__init__': [[631, 673], ['layers.append', 'torch.nn.Sequential.__init__', 'layers.append', 'model.EqualConv2d', 'layers.append', 'model.Blur', 'op.FusedLeakyReLU', 'len'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', '\\n', 'self', ',', '\\n', 'in_channel', ',', '\\n', 'out_channel', ',', '\\n', 'kernel_size', ',', '\\n', 'downsample', '=', 'False', ',', '\\n', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ',', '\\n', 'bias', '=', 'True', ',', '\\n', 'activate', '=', 'True', ',', '\\n', ')', ':', '\\n', '        ', 'layers', '=', '[', ']', '\\n', '\\n', 'if', 'downsample', ':', '\\n', '            ', 'factor', '=', '2', '\\n', 'p', '=', '(', 'len', '(', 'blur_kernel', ')', '-', 'factor', ')', '+', '(', 'kernel_size', '-', '1', ')', '\\n', 'pad0', '=', '(', 'p', '+', '1', ')', '//', '2', '\\n', 'pad1', '=', 'p', '//', '2', '\\n', '\\n', 'layers', '.', 'append', '(', 'Blur', '(', 'blur_kernel', ',', 'pad', '=', '(', 'pad0', ',', 'pad1', ')', ')', ')', '\\n', '\\n', 'stride', '=', '2', '\\n', 'self', '.', 'padding', '=', '0', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'stride', '=', '1', '\\n', 'self', '.', 'padding', '=', 'kernel_size', '//', '2', '\\n', '\\n', '', 'layers', '.', 'append', '(', '\\n', 'EqualConv2d', '(', '\\n', 'in_channel', ',', '\\n', 'out_channel', ',', '\\n', 'kernel_size', ',', '\\n', 'padding', '=', 'self', '.', 'padding', ',', '\\n', 'stride', '=', 'stride', ',', '\\n', 'bias', '=', 'bias', 'and', 'not', 'activate', ',', '\\n', ')', '\\n', ')', '\\n', '\\n', 'if', 'activate', ':', '\\n', '            ', 'layers', '.', 'append', '(', 'FusedLeakyReLU', '(', 'out_channel', ',', 'bias', '=', 'bias', ')', ')', '\\n', '\\n', '', 'super', '(', ')', '.', '__init__', '(', '*', 'layers', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ResBlock.__init__': [[676, 684], ['torch.nn.Module.__init__', 'model.ConvLayer', 'model.ConvLayer', 'model.ConvLayer'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'in_channel', ',', 'out_channel', ',', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'conv1', '=', 'ConvLayer', '(', 'in_channel', ',', 'in_channel', ',', '3', ')', '\\n', 'self', '.', 'conv2', '=', 'ConvLayer', '(', 'in_channel', ',', 'out_channel', ',', '3', ',', 'downsample', '=', 'True', ')', '\\n', '\\n', 'self', '.', 'skip', '=', 'ConvLayer', '(', '\\n', 'in_channel', ',', 'out_channel', ',', '1', ',', 'downsample', '=', 'True', ',', 'activate', '=', 'False', ',', 'bias', '=', 'False', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ResBlock.forward': [[686, 694], ['model.ResBlock.conv1', 'model.ResBlock.conv2', 'model.ResBlock.skip', 'math.sqrt'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'out', '=', 'self', '.', 'conv1', '(', 'input', ')', '\\n', 'out', '=', 'self', '.', 'conv2', '(', 'out', ')', '\\n', '\\n', 'skip', '=', 'self', '.', 'skip', '(', 'input', ')', '\\n', 'out', '=', '(', 'out', '+', 'skip', ')', '/', 'math', '.', 'sqrt', '(', '2', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Discriminator.__init__': [[697, 734], ['torch.nn.Module.__init__', 'int', 'range', 'torch.nn.Sequential', 'model.ConvLayer', 'torch.nn.Sequential', 'model.ConvLayer', 'math.log', 'convs.append', 'model.EqualLinear', 'model.EqualLinear', 'model.ResBlock'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'size', ',', 'channel_multiplier', '=', '2', ',', 'blur_kernel', '=', '[', '1', ',', '3', ',', '3', ',', '1', ']', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'channels', '=', '{', '\\n', '4', ':', '512', ',', '\\n', '8', ':', '512', ',', '\\n', '16', ':', '512', ',', '\\n', '32', ':', '512', ',', '\\n', '64', ':', '256', '*', 'channel_multiplier', ',', '\\n', '128', ':', '128', '*', 'channel_multiplier', ',', '\\n', '256', ':', '64', '*', 'channel_multiplier', ',', '\\n', '512', ':', '32', '*', 'channel_multiplier', ',', '\\n', '1024', ':', '16', '*', 'channel_multiplier', ',', '\\n', '}', '\\n', '\\n', 'convs', '=', '[', 'ConvLayer', '(', '3', ',', 'channels', '[', 'size', ']', ',', '1', ')', ']', '\\n', '\\n', 'log_size', '=', 'int', '(', 'math', '.', 'log', '(', 'size', ',', '2', ')', ')', '\\n', '\\n', 'in_channel', '=', 'channels', '[', 'size', ']', '\\n', '\\n', 'for', 'i', 'in', 'range', '(', 'log_size', ',', '2', ',', '-', '1', ')', ':', '\\n', '            ', 'out_channel', '=', 'channels', '[', '2', '**', '(', 'i', '-', '1', ')', ']', '\\n', '\\n', 'convs', '.', 'append', '(', 'ResBlock', '(', 'in_channel', ',', 'out_channel', ',', 'blur_kernel', ')', ')', '\\n', '\\n', 'in_channel', '=', 'out_channel', '\\n', '\\n', '', 'self', '.', 'convs', '=', 'nn', '.', 'Sequential', '(', '*', 'convs', ')', '\\n', '\\n', 'self', '.', 'stddev_group', '=', '4', '\\n', 'self', '.', 'stddev_feat', '=', '1', '\\n', '\\n', 'self', '.', 'final_conv', '=', 'ConvLayer', '(', 'in_channel', '+', '1', ',', 'channels', '[', '4', ']', ',', '3', ')', '\\n', 'self', '.', 'final_linear', '=', 'nn', '.', 'Sequential', '(', '\\n', 'EqualLinear', '(', 'channels', '[', '4', ']', '*', '4', '*', '4', ',', 'channels', '[', '4', ']', ',', 'activation', '=', '\"fused_lrelu\"', ')', ',', '\\n', 'EqualLinear', '(', 'channels', '[', '4', ']', ',', '1', ')', ',', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Discriminator.forward': [[736, 755], ['model.Discriminator.convs', 'min', 'model.Discriminator.view', 'torch.sqrt', 'stddev.repeat.repeat.mean().squeeze', 'stddev.repeat.repeat.repeat', 'torch.cat', 'model.Discriminator.final_conv', 'model.Discriminator.view', 'model.Discriminator.final_linear', 'stddev.repeat.repeat.var', 'stddev.repeat.repeat.mean'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'out', '=', 'self', '.', 'convs', '(', 'input', ')', '\\n', '\\n', 'batch', ',', 'channel', ',', 'height', ',', 'width', '=', 'out', '.', 'shape', '\\n', 'group', '=', 'min', '(', 'batch', ',', 'self', '.', 'stddev_group', ')', '\\n', 'stddev', '=', 'out', '.', 'view', '(', '\\n', 'group', ',', '-', '1', ',', 'self', '.', 'stddev_feat', ',', 'channel', '//', 'self', '.', 'stddev_feat', ',', 'height', ',', 'width', '\\n', ')', '\\n', 'stddev', '=', 'torch', '.', 'sqrt', '(', 'stddev', '.', 'var', '(', '0', ',', 'unbiased', '=', 'False', ')', '+', '1e-8', ')', '\\n', 'stddev', '=', 'stddev', '.', 'mean', '(', '[', '2', ',', '3', ',', '4', ']', ',', 'keepdims', '=', 'True', ')', '.', 'squeeze', '(', '2', ')', '\\n', 'stddev', '=', 'stddev', '.', 'repeat', '(', 'group', ',', '1', ',', 'height', ',', 'width', ')', '\\n', 'out', '=', 'torch', '.', 'cat', '(', '[', 'out', ',', 'stddev', ']', ',', '1', ')', '\\n', '\\n', 'out', '=', 'self', '.', 'final_conv', '(', 'out', ')', '\\n', '\\n', 'out', '=', 'out', '.', 'view', '(', 'batch', ',', '-', '1', ')', '\\n', 'out', '=', 'self', '.', 'final_linear', '(', 'out', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PE2d.__init__': [[758, 774], ['torch.nn.Module.__init__', 'int', 'int', 'torch.zeros', 'int', 'torch.arange().unsqueeze', 'torch.arange().unsqueeze', 'torch.nn.Parameter', 'ValueError', 'torch.exp', 'torch.ones', 'torch.arange', 'torch.arange', 'torch.arange', 'math.log'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'channel', ',', 'height', ',', 'width', ',', 'scale', '=', '1.0', ',', 'device', '=', '\"cuda\"', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', 'if', 'channel', '%', '4', '!=', '0', ':', '\\n', '            ', 'raise', 'ValueError', '(', '\"Cannot use sin/cos positional encoding with \"', '\\n', '\"odd dimension (got dim={:d})\"', '.', 'format', '(', 'channel', ')', ')', '\\n', '', 'height', '=', 'int', '(', 'height', '*', 'scale', ')', '\\n', 'width', '=', 'int', '(', 'width', '*', 'scale', ')', '\\n', 'self', '.', 'pe', '=', 'torch', '.', 'zeros', '(', 'channel', ',', 'height', ',', 'width', ',', 'device', '=', 'device', ')', '\\n', '\\n', '# Each dimension use half of d_model', '\\n', 'self', '.', 'd_model', '=', 'int', '(', 'channel', '/', '2', ')', '\\n', 'self', '.', 'div_term', '=', 'torch', '.', 'exp', '(', 'torch', '.', 'arange', '(', '0.', ',', 'self', '.', 'd_model', ',', '2', ')', '*', '-', '(', 'math', '.', 'log', '(', '10000.0', ')', '/', 'self', '.', 'd_model', ')', ')', '/', 'scale', '\\n', 'self', '.', 'pos_h', '=', 'torch', '.', 'arange', '(', '0.', ',', 'height', ')', '.', 'unsqueeze', '(', '1', ')', '\\n', 'self', '.', 'pos_w', '=', 'torch', '.', 'arange', '(', '0.', ',', 'width', ')', '.', 'unsqueeze', '(', '1', ')', '\\n', '\\n', 'self', '.', 'gamma', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'ones', '(', '1', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PE2d.forward': [[775, 787], ['torch.sin().transpose().unsqueeze().repeat', 'torch.cos().transpose().unsqueeze().repeat', 'torch.sin().transpose().unsqueeze().repeat', 'torch.cos().transpose().unsqueeze().repeat', 'torch.roll', 'torch.roll', 'round', 'round', 'round', 'round', 'torch.sin().transpose().unsqueeze', 'torch.cos().transpose().unsqueeze', 'torch.sin().transpose().unsqueeze', 'torch.cos().transpose().unsqueeze', 'model.PE2d.pe.unsqueeze', 'torch.sin().transpose', 'torch.cos().transpose', 'torch.sin().transpose', 'torch.cos().transpose', 'torch.sin', 'torch.cos', 'torch.sin', 'torch.cos'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'x', ',', 'shift_h', '=', '0', ',', 'shift_w', '=', '0', ')', ':', '\\n', '# continuous roll', '\\n', '        ', 'pos_h', '=', 'torch', '.', 'roll', '(', 'self', '.', 'pos_h', ',', 'round', '(', 'shift_h', ')', ',', '0', ')', '+', '(', 'round', '(', 'shift_h', ')', '-', 'shift_h', ')', '\\n', 'pos_w', '=', 'torch', '.', 'roll', '(', 'self', '.', 'pos_w', ',', 'round', '(', 'shift_w', ')', ',', '0', ')', '+', '(', 'round', '(', 'shift_w', ')', '-', 'shift_w', ')', '\\n', '\\n', 'self', '.', 'pe', '[', '0', ':', 'self', '.', 'd_model', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'sin', '(', 'pos_w', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'pos_h', '.', 'shape', '[', '0', ']', ',', '1', ')', '\\n', 'self', '.', 'pe', '[', '1', ':', 'self', '.', 'd_model', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'cos', '(', 'pos_w', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'pos_h', '.', 'shape', '[', '0', ']', ',', '1', ')', '\\n', '\\n', 'self', '.', 'pe', '[', 'self', '.', 'd_model', ':', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'sin', '(', 'pos_h', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '2', ')', '.', 'repeat', '(', '1', ',', '1', ',', 'pos_w', '.', 'shape', '[', '0', ']', ')', '\\n', 'self', '.', 'pe', '[', 'self', '.', 'd_model', '+', '1', ':', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'cos', '(', 'pos_h', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '2', ')', '.', 'repeat', '(', '1', ',', '1', ',', 'pos_w', '.', 'shape', '[', '0', ']', ')', '\\n', '\\n', 'return', 'x', '+', 'self', '.', 'gamma', '*', 'self', '.', 'pe', '.', 'unsqueeze', '(', '0', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PE2dStart.__init__': [[789, 803], ['torch.nn.Module.__init__', 'int', 'int', 'torch.zeros', 'int', 'torch.arange().unsqueeze', 'torch.arange().unsqueeze', 'ValueError', 'torch.exp', 'torch.arange', 'torch.arange', 'torch.arange', 'math.log'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'channel', ',', 'height', ',', 'width', ',', 'scale', '=', '1.0', ',', 'device', '=', '\"cuda\"', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', 'if', 'channel', '%', '4', '!=', '0', ':', '\\n', '            ', 'raise', 'ValueError', '(', '\"Cannot use sin/cos positional encoding with \"', '\\n', '\"odd dimension (got dim={:d})\"', '.', 'format', '(', 'channel', ')', ')', '\\n', '', 'height', '=', 'int', '(', 'height', '*', 'scale', ')', '\\n', 'width', '=', 'int', '(', 'width', '*', 'scale', ')', '\\n', 'self', '.', 'pe', '=', 'torch', '.', 'zeros', '(', 'channel', ',', 'height', ',', 'width', ',', 'device', '=', 'device', ')', '\\n', '\\n', '# Each dimension use half of d_model', '\\n', 'self', '.', 'd_model', '=', 'int', '(', 'channel', '/', '2', ')', '\\n', 'self', '.', 'div_term', '=', 'torch', '.', 'exp', '(', 'torch', '.', 'arange', '(', '0.', ',', 'self', '.', 'd_model', ',', '2', ')', '*', '-', '(', 'math', '.', 'log', '(', '10000.0', ')', '/', 'self', '.', 'd_model', ')', ')', '/', 'scale', '\\n', 'self', '.', 'pos_h', '=', 'torch', '.', 'arange', '(', '0.', ',', 'height', ')', '.', 'unsqueeze', '(', '1', ')', '\\n', 'self', '.', 'pos_w', '=', 'torch', '.', 'arange', '(', '0.', ',', 'width', ')', '.', 'unsqueeze', '(', '1', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PE2dStart.forward': [[804, 828], ['torch.sin().transpose().unsqueeze().repeat', 'torch.cos().transpose().unsqueeze().repeat', 'torch.sin().transpose().unsqueeze().repeat', 'torch.cos().transpose().unsqueeze().repeat', 'model.PE2dStart.pe.unsqueeze().repeat', 'torch.norm', 'affine.view().unbind', 'torch.roll', 'torch.roll', 'torch.sin().transpose().unsqueeze', 'torch.cos().transpose().unsqueeze', 'torch.sin().transpose().unsqueeze', 'torch.cos().transpose().unsqueeze', 'model.PE2dStart.pe.unsqueeze', 'affine.view', 'round', 'round', 'round', 'round', 'torch.sin().transpose', 'torch.cos().transpose', 'torch.sin().transpose', 'torch.cos().transpose', 'torch.sin', 'torch.cos', 'torch.sin', 'torch.cos'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'x', ',', 'shift_h', '=', '0', ',', 'shift_w', '=', '0', ',', 'transform', '=', 'None', ')', ':', '\\n', '# TODO', '\\n', '        ', 'if', 'transform', 'is', 'not', 'None', ':', '# from alias-free gan, not implemented yet', '\\n', '            ', 'norm', '=', 'torch', '.', 'norm', '(', 'transform', '[', ':', ',', ':', '2', ']', ',', 'dim', '=', '-', '1', ',', 'keepdim', '=', 'True', ')', '\\n', 'affine', '=', 'transform', '/', '(', 'norm', '+', '1e-8', ')', '\\n', '\\n', 'r_c', ',', 'r_s', ',', 't_x', ',', 't_y', '=', 'affine', '.', 'view', '(', '\\n', 'affine', '.', 'shape', '[', '0', ']', ',', '1', ',', '1', ',', '1', ',', 'affine', '.', 'shape', '[', '-', '1', ']', '\\n', ')', '.', 'unbind', '(', '-', '1', ')', '\\n', '\\n', 'pos_h', '=', '-', 'r_s', '*', 'self', '.', 'pos_w', '+', 'r_c', '*', 'self', '.', 'pos_h', '-', 't_y', '\\n', 'pos_w', '=', 'r_c', '*', 'self', '.', 'pos_w', '+', 'r_s', '*', 'self', '.', 'pos_h', '-', 't_x', '\\n', '', 'else', ':', '# our method', '\\n', '# continuous roll', '\\n', '            ', 'pos_h', '=', 'torch', '.', 'roll', '(', 'self', '.', 'pos_h', ',', 'round', '(', 'shift_h', ')', ',', '0', ')', '+', '(', 'round', '(', 'shift_h', ')', '-', 'shift_h', ')', '\\n', 'pos_w', '=', 'torch', '.', 'roll', '(', 'self', '.', 'pos_w', ',', 'round', '(', 'shift_w', ')', ',', '0', ')', '+', '(', 'round', '(', 'shift_w', ')', '-', 'shift_w', ')', '\\n', '\\n', '', 'self', '.', 'pe', '[', '0', ':', 'self', '.', 'd_model', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'sin', '(', 'pos_w', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'pos_h', '.', 'shape', '[', '0', ']', ',', '1', ')', '\\n', 'self', '.', 'pe', '[', '1', ':', 'self', '.', 'd_model', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'cos', '(', 'pos_w', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '1', ')', '.', 'repeat', '(', '1', ',', 'pos_h', '.', 'shape', '[', '0', ']', ',', '1', ')', '\\n', '\\n', 'self', '.', 'pe', '[', 'self', '.', 'd_model', ':', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'sin', '(', 'pos_h', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '2', ')', '.', 'repeat', '(', '1', ',', '1', ',', 'pos_w', '.', 'shape', '[', '0', ']', ')', '\\n', 'self', '.', 'pe', '[', 'self', '.', 'd_model', '+', '1', ':', ':', '2', ',', ':', ',', ':', ']', '=', 'torch', '.', 'cos', '(', 'pos_h', '*', 'self', '.', 'div_term', ')', '.', 'transpose', '(', '0', ',', '1', ')', '.', 'unsqueeze', '(', '2', ')', '.', 'repeat', '(', '1', ',', '1', ',', 'pos_w', '.', 'shape', '[', '0', ']', ')', '\\n', '\\n', 'return', 'self', '.', 'pe', '.', 'unsqueeze', '(', '0', ')', '.', 'repeat', '(', 'x', '.', 'shape', '[', '0', ']', ',', '1', ',', '1', ',', '1', ')', '', '', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.make_kernel': [[22, 31], ['torch.tensor', 'torch.tensor.sum'], 'function', ['None'], ['', '', 'def', 'make_kernel', '(', 'k', ')', ':', '\\n', '    ', 'k', '=', 'torch', '.', 'tensor', '(', 'k', ',', 'dtype', '=', 'torch', '.', 'float32', ')', '\\n', '\\n', 'if', 'k', '.', 'ndim', '==', '1', ':', '\\n', '        ', 'k', '=', 'k', '[', 'None', ',', ':', ']', '*', 'k', '[', ':', ',', 'None', ']', '\\n', '\\n', '', 'k', '/=', 'k', '.', 'sum', '(', ')', '\\n', '\\n', 'return', 'k', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_and_convert': [[13, 21], ['torchvision.transforms.functional.resize', 'torchvision.transforms.functional.center_crop', 'io.BytesIO', 'trans_fn.center_crop.save', 'io.BytesIO.getvalue'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save'], ['def', 'resize_and_convert', '(', 'img', ',', 'size', ',', 'resample', ',', 'quality', '=', '100', ')', ':', '\\n', '    ', 'img', '=', 'trans_fn', '.', 'resize', '(', 'img', ',', 'size', ',', 'resample', ')', '\\n', 'img', '=', 'trans_fn', '.', 'center_crop', '(', 'img', ',', 'size', ')', '\\n', 'buffer', '=', 'BytesIO', '(', ')', '\\n', 'img', '.', 'save', '(', 'buffer', ',', 'format', '=', '\"jpeg\"', ',', 'quality', '=', 'quality', ')', '\\n', 'val', '=', 'buffer', '.', 'getvalue', '(', ')', '\\n', '\\n', 'return', 'val', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_multiple': [[23, 32], ['imgs.append', 'prepare_data.resize_and_convert'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_and_convert'], ['', 'def', 'resize_multiple', '(', '\\n', 'img', ',', 'sizes', '=', '(', '128', ',', '256', ',', '512', ',', '1024', ')', ',', 'resample', '=', 'Image', '.', 'LANCZOS', ',', 'quality', '=', '100', '\\n', ')', ':', '\\n', '    ', 'imgs', '=', '[', ']', '\\n', '\\n', 'for', 'size', 'in', 'sizes', ':', '\\n', '        ', 'imgs', '.', 'append', '(', 'resize_and_convert', '(', 'img', ',', 'size', ',', 'resample', ',', 'quality', ')', ')', '\\n', '\\n', '', 'return', 'imgs', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_worker': [[34, 41], ['PIL.Image.open', 'img.convert.convert', 'prepare_data.resize_multiple'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_multiple'], ['', 'def', 'resize_worker', '(', 'img_file', ',', 'sizes', ',', 'resample', ')', ':', '\\n', '    ', 'i', ',', 'file', '=', 'img_file', '\\n', 'img', '=', 'Image', '.', 'open', '(', 'file', ')', '\\n', 'img', '=', 'img', '.', 'convert', '(', '\"RGB\"', ')', '\\n', 'out', '=', 'resize_multiple', '(', 'img', ',', 'sizes', '=', 'sizes', ',', 'resample', '=', 'resample', ')', '\\n', '\\n', 'return', 'i', ',', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.prepare': [[43, 64], ['functools.partial', 'sorted', 'multiprocessing.Pool', 'tqdm.tqdm', 'enumerate', 'pool.imap_unordered', 'zip', 'env.begin', 'txn.put', 'str().encode', 'env.begin', 'txn.put', 'str', 'str().zfill', 'str'], 'function', ['None'], ['', 'def', 'prepare', '(', '\\n', 'env', ',', 'dataset', ',', 'n_worker', ',', 'sizes', '=', '(', '128', ',', '256', ',', '512', ',', '1024', ')', ',', 'resample', '=', 'Image', '.', 'LANCZOS', '\\n', ')', ':', '\\n', '    ', 'resize_fn', '=', 'partial', '(', 'resize_worker', ',', 'sizes', '=', 'sizes', ',', 'resample', '=', 'resample', ')', '\\n', '\\n', 'files', '=', 'sorted', '(', 'dataset', '.', 'imgs', ',', 'key', '=', 'lambda', 'x', ':', 'x', '[', '0', ']', ')', '\\n', 'files', '=', '[', '(', 'i', ',', 'file', ')', 'for', 'i', ',', '(', 'file', ',', 'label', ')', 'in', 'enumerate', '(', 'files', ')', ']', '\\n', 'total', '=', '0', '\\n', '\\n', 'with', 'multiprocessing', '.', 'Pool', '(', 'n_worker', ')', 'as', 'pool', ':', '\\n', '        ', 'for', 'i', ',', 'imgs', 'in', 'tqdm', '(', 'pool', '.', 'imap_unordered', '(', 'resize_fn', ',', 'files', ')', ')', ':', '\\n', '            ', 'for', 'size', ',', 'img', 'in', 'zip', '(', 'sizes', ',', 'imgs', ')', ':', '\\n', '                ', 'key', '=', 'f\"{size}-{str(i).zfill(5)}\"', '.', 'encode', '(', '\"utf-8\"', ')', '\\n', '\\n', 'with', 'env', '.', 'begin', '(', 'write', '=', 'True', ')', 'as', 'txn', ':', '\\n', '                    ', 'txn', '.', 'put', '(', 'key', ',', 'img', ')', '\\n', '\\n', '', '', 'total', '+=', '1', '\\n', '\\n', '', 'with', 'env', '.', 'begin', '(', 'write', '=', 'True', ')', 'as', 'txn', ':', '\\n', '            ', 'txn', '.', 'put', '(', '\"length\"', '.', 'encode', '(', '\"utf-8\"', ')', ',', 'str', '(', 'total', ')', '.', 'encode', '(', '\"utf-8\"', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.fid.extract_feature_from_samples': [[14, 32], ['torch.no_grad', 'tqdm.tqdm', 'torch.cat', 'torch.randn', 'g', '[].view', 'torch.cat.append', '[].view.to', 'inception'], 'function', ['None'], ['@', 'torch', '.', 'no_grad', '(', ')', '\\n', 'def', 'extract_feature_from_samples', '(', '\\n', 'generator', ',', 'inception', ',', 'truncation', ',', 'truncation_latent', ',', 'batch_size', ',', 'n_sample', ',', 'device', '\\n', ')', ':', '\\n', '    ', 'n_batch', '=', 'n_sample', '//', 'batch_size', '\\n', 'resid', '=', 'n_sample', '-', '(', 'n_batch', '*', 'batch_size', ')', '\\n', 'batch_sizes', '=', '[', 'batch_size', ']', '*', 'n_batch', '+', '[', 'resid', ']', '\\n', 'features', '=', '[', ']', '\\n', '\\n', 'for', 'batch', 'in', 'tqdm', '(', 'batch_sizes', ')', ':', '\\n', '        ', 'latent', '=', 'torch', '.', 'randn', '(', 'batch', ',', '512', ',', 'device', '=', 'device', ')', '\\n', 'img', ',', '_', '=', 'g', '(', '[', 'latent', ']', ',', 'truncation', '=', 'truncation', ',', 'truncation_latent', '=', 'truncation_latent', ')', '\\n', 'feat', '=', 'inception', '(', 'img', ')', '[', '0', ']', '.', 'view', '(', 'img', '.', 'shape', '[', '0', ']', ',', '-', '1', ')', '\\n', 'features', '.', 'append', '(', 'feat', '.', 'to', '(', '\"cpu\"', ')', ')', '\\n', '\\n', '', 'features', '=', 'torch', '.', 'cat', '(', 'features', ',', '0', ')', '\\n', '\\n', 'return', 'features', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.fid.calc_fid': [[34, 58], ['scipy.linalg.sqrtm', 'numpy.iscomplexobj', 'numpy.isfinite().all', 'print', 'scipy.linalg.sqrtm', 'numpy.eye', 'numpy.allclose', 'numpy.max', 'ValueError', 'numpy.trace', 'numpy.trace', 'numpy.trace', 'numpy.isfinite', 'numpy.abs', 'numpy.diagonal'], 'function', ['None'], ['', 'def', 'calc_fid', '(', 'sample_mean', ',', 'sample_cov', ',', 'real_mean', ',', 'real_cov', ',', 'eps', '=', '1e-6', ')', ':', '\\n', '    ', 'cov_sqrt', ',', '_', '=', 'linalg', '.', 'sqrtm', '(', 'sample_cov', '@', 'real_cov', ',', 'disp', '=', 'False', ')', '\\n', '\\n', 'if', 'not', 'np', '.', 'isfinite', '(', 'cov_sqrt', ')', '.', 'all', '(', ')', ':', '\\n', '        ', 'print', '(', '\"product of cov matrices is singular\"', ')', '\\n', 'offset', '=', 'np', '.', 'eye', '(', 'sample_cov', '.', 'shape', '[', '0', ']', ')', '*', 'eps', '\\n', 'cov_sqrt', '=', 'linalg', '.', 'sqrtm', '(', '(', 'sample_cov', '+', 'offset', ')', '@', '(', 'real_cov', '+', 'offset', ')', ')', '\\n', '\\n', '', 'if', 'np', '.', 'iscomplexobj', '(', 'cov_sqrt', ')', ':', '\\n', '        ', 'if', 'not', 'np', '.', 'allclose', '(', 'np', '.', 'diagonal', '(', 'cov_sqrt', ')', '.', 'imag', ',', '0', ',', 'atol', '=', '1e-3', ')', ':', '\\n', '            ', 'm', '=', 'np', '.', 'max', '(', 'np', '.', 'abs', '(', 'cov_sqrt', '.', 'imag', ')', ')', '\\n', '\\n', 'raise', 'ValueError', '(', 'f\"Imaginary component {m}\"', ')', '\\n', '\\n', '', 'cov_sqrt', '=', 'cov_sqrt', '.', 'real', '\\n', '\\n', '', 'mean_diff', '=', 'sample_mean', '-', 'real_mean', '\\n', 'mean_norm', '=', 'mean_diff', '@', 'mean_diff', '\\n', '\\n', 'trace', '=', 'np', '.', 'trace', '(', 'sample_cov', ')', '+', 'np', '.', 'trace', '(', 'real_cov', ')', '-', '2', '*', 'np', '.', 'trace', '(', 'cov_sqrt', ')', '\\n', '\\n', 'fid', '=', 'mean_norm', '+', 'trace', '\\n', '\\n', 'return', 'fid', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.PNetLin.__init__': [[28, 63], ['torch.Module.__init__', 'networks_basic.ScalingLayer', 'len', 'net_type', 'networks_basic.NetLinLayer', 'networks_basic.NetLinLayer', 'networks_basic.NetLinLayer', 'networks_basic.NetLinLayer', 'networks_basic.NetLinLayer', 'networks_basic.NetLinLayer', 'networks_basic.NetLinLayer'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'pnet_type', '=', \"'vgg'\", ',', 'pnet_rand', '=', 'False', ',', 'pnet_tune', '=', 'False', ',', 'use_dropout', '=', 'True', ',', 'spatial', '=', 'False', ',', 'version', '=', \"'0.1'\", ',', 'lpips', '=', 'True', ')', ':', '\\n', '        ', 'super', '(', 'PNetLin', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'self', '.', 'pnet_type', '=', 'pnet_type', '\\n', 'self', '.', 'pnet_tune', '=', 'pnet_tune', '\\n', 'self', '.', 'pnet_rand', '=', 'pnet_rand', '\\n', 'self', '.', 'spatial', '=', 'spatial', '\\n', 'self', '.', 'lpips', '=', 'lpips', '\\n', 'self', '.', 'version', '=', 'version', '\\n', 'self', '.', 'scaling_layer', '=', 'ScalingLayer', '(', ')', '\\n', '\\n', 'if', '(', 'self', '.', 'pnet_type', 'in', '[', \"'vgg'\", ',', \"'vgg16'\", ']', ')', ':', '\\n', '            ', 'net_type', '=', 'pn', '.', 'vgg16', '\\n', 'self', '.', 'chns', '=', '[', '64', ',', '128', ',', '256', ',', '512', ',', '512', ']', '\\n', '', 'elif', '(', 'self', '.', 'pnet_type', '==', \"'alex'\", ')', ':', '\\n', '            ', 'net_type', '=', 'pn', '.', 'alexnet', '\\n', 'self', '.', 'chns', '=', '[', '64', ',', '192', ',', '384', ',', '256', ',', '256', ']', '\\n', '', 'elif', '(', 'self', '.', 'pnet_type', '==', \"'squeeze'\", ')', ':', '\\n', '            ', 'net_type', '=', 'pn', '.', 'squeezenet', '\\n', 'self', '.', 'chns', '=', '[', '64', ',', '128', ',', '256', ',', '384', ',', '384', ',', '512', ',', '512', ']', '\\n', '', 'self', '.', 'L', '=', 'len', '(', 'self', '.', 'chns', ')', '\\n', '\\n', 'self', '.', 'net', '=', 'net_type', '(', 'pretrained', '=', 'not', 'self', '.', 'pnet_rand', ',', 'requires_grad', '=', 'self', '.', 'pnet_tune', ')', '\\n', '\\n', 'if', '(', 'lpips', ')', ':', '\\n', '            ', 'self', '.', 'lin0', '=', 'NetLinLayer', '(', 'self', '.', 'chns', '[', '0', ']', ',', 'use_dropout', '=', 'use_dropout', ')', '\\n', 'self', '.', 'lin1', '=', 'NetLinLayer', '(', 'self', '.', 'chns', '[', '1', ']', ',', 'use_dropout', '=', 'use_dropout', ')', '\\n', 'self', '.', 'lin2', '=', 'NetLinLayer', '(', 'self', '.', 'chns', '[', '2', ']', ',', 'use_dropout', '=', 'use_dropout', ')', '\\n', 'self', '.', 'lin3', '=', 'NetLinLayer', '(', 'self', '.', 'chns', '[', '3', ']', ',', 'use_dropout', '=', 'use_dropout', ')', '\\n', 'self', '.', 'lin4', '=', 'NetLinLayer', '(', 'self', '.', 'chns', '[', '4', ']', ',', 'use_dropout', '=', 'use_dropout', ')', '\\n', 'self', '.', 'lins', '=', '[', 'self', '.', 'lin0', ',', 'self', '.', 'lin1', ',', 'self', '.', 'lin2', ',', 'self', '.', 'lin3', ',', 'self', '.', 'lin4', ']', '\\n', 'if', '(', 'self', '.', 'pnet_type', '==', \"'squeeze'\", ')', ':', '# 7 layers for squeezenet', '\\n', '                ', 'self', '.', 'lin5', '=', 'NetLinLayer', '(', 'self', '.', 'chns', '[', '5', ']', ',', 'use_dropout', '=', 'use_dropout', ')', '\\n', 'self', '.', 'lin6', '=', 'NetLinLayer', '(', 'self', '.', 'chns', '[', '6', ']', ',', 'use_dropout', '=', 'use_dropout', ')', '\\n', 'self', '.', 'lins', '+=', '[', 'self', '.', 'lin5', ',', 'self', '.', 'lin6', ']', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.PNetLin.forward': [[64, 93], ['range', 'range', 'networks_basic.PNetLin.net.forward', 'networks_basic.PNetLin.net.forward', 'networks_basic.PNetLin.scaling_layer', 'networks_basic.PNetLin.scaling_layer', 'lpips.normalize_tensor', 'lpips.normalize_tensor', 'networks_basic.upsample', 'networks_basic.spatial_average', 'networks_basic.upsample', 'networks_basic.spatial_average', 'networks_basic.PNetLin.lins[].model', 'range', 'networks_basic.PNetLin.lins[].model', 'range', 'diffs[].sum', 'range', 'diffs[].sum', 'range'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.normalize_tensor', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.normalize_tensor', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.upsample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.spatial_average', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.upsample', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.spatial_average'], ['', '', '', 'def', 'forward', '(', 'self', ',', 'in0', ',', 'in1', ',', 'retPerLayer', '=', 'False', ')', ':', '\\n', '# v0.0 - original release had a bug, where input was not scaled', '\\n', '        ', 'in0_input', ',', 'in1_input', '=', '(', 'self', '.', 'scaling_layer', '(', 'in0', ')', ',', 'self', '.', 'scaling_layer', '(', 'in1', ')', ')', 'if', 'self', '.', 'version', '==', \"'0.1'\", 'else', '(', 'in0', ',', 'in1', ')', '\\n', 'outs0', ',', 'outs1', '=', 'self', '.', 'net', '.', 'forward', '(', 'in0_input', ')', ',', 'self', '.', 'net', '.', 'forward', '(', 'in1_input', ')', '\\n', 'feats0', ',', 'feats1', ',', 'diffs', '=', '{', '}', ',', '{', '}', ',', '{', '}', '\\n', '\\n', 'for', 'kk', 'in', 'range', '(', 'self', '.', 'L', ')', ':', '\\n', '            ', 'feats0', '[', 'kk', ']', ',', 'feats1', '[', 'kk', ']', '=', 'util', '.', 'normalize_tensor', '(', 'outs0', '[', 'kk', ']', ')', ',', 'util', '.', 'normalize_tensor', '(', 'outs1', '[', 'kk', ']', ')', '\\n', 'diffs', '[', 'kk', ']', '=', '(', 'feats0', '[', 'kk', ']', '-', 'feats1', '[', 'kk', ']', ')', '**', '2', '\\n', '\\n', '', 'if', '(', 'self', '.', 'lpips', ')', ':', '\\n', '            ', 'if', '(', 'self', '.', 'spatial', ')', ':', '\\n', '                ', 'res', '=', '[', 'upsample', '(', 'self', '.', 'lins', '[', 'kk', ']', '.', 'model', '(', 'diffs', '[', 'kk', ']', ')', ',', 'out_H', '=', 'in0', '.', 'shape', '[', '2', ']', ')', 'for', 'kk', 'in', 'range', '(', 'self', '.', 'L', ')', ']', '\\n', '', 'else', ':', '\\n', '                ', 'res', '=', '[', 'spatial_average', '(', 'self', '.', 'lins', '[', 'kk', ']', '.', 'model', '(', 'diffs', '[', 'kk', ']', ')', ',', 'keepdim', '=', 'True', ')', 'for', 'kk', 'in', 'range', '(', 'self', '.', 'L', ')', ']', '\\n', '', '', 'else', ':', '\\n', '            ', 'if', '(', 'self', '.', 'spatial', ')', ':', '\\n', '                ', 'res', '=', '[', 'upsample', '(', 'diffs', '[', 'kk', ']', '.', 'sum', '(', 'dim', '=', '1', ',', 'keepdim', '=', 'True', ')', ',', 'out_H', '=', 'in0', '.', 'shape', '[', '2', ']', ')', 'for', 'kk', 'in', 'range', '(', 'self', '.', 'L', ')', ']', '\\n', '', 'else', ':', '\\n', '                ', 'res', '=', '[', 'spatial_average', '(', 'diffs', '[', 'kk', ']', '.', 'sum', '(', 'dim', '=', '1', ',', 'keepdim', '=', 'True', ')', ',', 'keepdim', '=', 'True', ')', 'for', 'kk', 'in', 'range', '(', 'self', '.', 'L', ')', ']', '\\n', '\\n', '', '', 'val', '=', 'res', '[', '0', ']', '\\n', 'for', 'l', 'in', 'range', '(', '1', ',', 'self', '.', 'L', ')', ':', '\\n', '            ', 'val', '+=', 'res', '[', 'l', ']', '\\n', '\\n', '', 'if', '(', 'retPerLayer', ')', ':', '\\n', '            ', 'return', '(', 'val', ',', 'res', ')', '\\n', '', 'else', ':', '\\n', '            ', 'return', 'val', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.ScalingLayer.__init__': [[95, 99], ['torch.Module.__init__', 'networks_basic.ScalingLayer.register_buffer', 'networks_basic.ScalingLayer.register_buffer', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ')', ':', '\\n', '        ', 'super', '(', 'ScalingLayer', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'shift'\", ',', 'torch', '.', 'Tensor', '(', '[', '-', '.030', ',', '-', '.088', ',', '-', '.188', ']', ')', '[', 'None', ',', ':', ',', 'None', ',', 'None', ']', ')', '\\n', 'self', '.', 'register_buffer', '(', \"'scale'\", ',', 'torch', '.', 'Tensor', '(', '[', '.458', ',', '.448', ',', '.450', ']', ')', '[', 'None', ',', ':', ',', 'None', ',', 'None', ']', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.ScalingLayer.forward': [[100, 102], ['None'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'inp', ')', ':', '\\n', '        ', 'return', '(', 'inp', '-', 'self', '.', 'shift', ')', '/', 'self', '.', 'scale', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.NetLinLayer.__init__': [[106, 112], ['torch.Module.__init__', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential', 'torch.Conv2d', 'torch.Conv2d', 'torch.Conv2d', 'torch.Dropout', 'torch.Dropout', 'torch.Dropout'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['def', '__init__', '(', 'self', ',', 'chn_in', ',', 'chn_out', '=', '1', ',', 'use_dropout', '=', 'False', ')', ':', '\\n', '        ', 'super', '(', 'NetLinLayer', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'layers', '=', '[', 'nn', '.', 'Dropout', '(', ')', ',', ']', 'if', '(', 'use_dropout', ')', 'else', '[', ']', '\\n', 'layers', '+=', '[', 'nn', '.', 'Conv2d', '(', 'chn_in', ',', 'chn_out', ',', '1', ',', 'stride', '=', '1', ',', 'padding', '=', '0', ',', 'bias', '=', 'False', ')', ',', ']', '\\n', 'self', '.', 'model', '=', 'nn', '.', 'Sequential', '(', '*', 'layers', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.Dist2LogitLayer.__init__': [[116, 127], ['torch.Module.__init__', 'torch.Sequential', 'torch.Sequential', 'torch.Sequential', 'torch.Conv2d', 'torch.Conv2d', 'torch.Conv2d', 'torch.LeakyReLU', 'torch.LeakyReLU', 'torch.LeakyReLU', 'torch.Conv2d', 'torch.Conv2d', 'torch.Conv2d', 'torch.LeakyReLU', 'torch.LeakyReLU', 'torch.LeakyReLU', 'torch.Conv2d', 'torch.Conv2d', 'torch.Conv2d', 'torch.Sigmoid', 'torch.Sigmoid', 'torch.Sigmoid'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['def', '__init__', '(', 'self', ',', 'chn_mid', '=', '32', ',', 'use_sigmoid', '=', 'True', ')', ':', '\\n', '        ', 'super', '(', 'Dist2LogitLayer', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'layers', '=', '[', 'nn', '.', 'Conv2d', '(', '5', ',', 'chn_mid', ',', '1', ',', 'stride', '=', '1', ',', 'padding', '=', '0', ',', 'bias', '=', 'True', ')', ',', ']', '\\n', 'layers', '+=', '[', 'nn', '.', 'LeakyReLU', '(', '0.2', ',', 'True', ')', ',', ']', '\\n', 'layers', '+=', '[', 'nn', '.', 'Conv2d', '(', 'chn_mid', ',', 'chn_mid', ',', '1', ',', 'stride', '=', '1', ',', 'padding', '=', '0', ',', 'bias', '=', 'True', ')', ',', ']', '\\n', 'layers', '+=', '[', 'nn', '.', 'LeakyReLU', '(', '0.2', ',', 'True', ')', ',', ']', '\\n', 'layers', '+=', '[', 'nn', '.', 'Conv2d', '(', 'chn_mid', ',', '1', ',', '1', ',', 'stride', '=', '1', ',', 'padding', '=', '0', ',', 'bias', '=', 'True', ')', ',', ']', '\\n', 'if', '(', 'use_sigmoid', ')', ':', '\\n', '            ', 'layers', '+=', '[', 'nn', '.', 'Sigmoid', '(', ')', ',', ']', '\\n', '', 'self', '.', 'model', '=', 'nn', '.', 'Sequential', '(', '*', 'layers', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.Dist2LogitLayer.forward': [[128, 130], ['networks_basic.Dist2LogitLayer.model.forward', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat', 'torch.cat'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward'], ['', 'def', 'forward', '(', 'self', ',', 'd0', ',', 'd1', ',', 'eps', '=', '0.1', ')', ':', '\\n', '        ', 'return', 'self', '.', 'model', '.', 'forward', '(', 'torch', '.', 'cat', '(', '(', 'd0', ',', 'd1', ',', 'd0', '-', 'd1', ',', 'd0', '/', '(', 'd1', '+', 'eps', ')', ',', 'd1', '/', '(', 'd0', '+', 'eps', ')', ')', ',', 'dim', '=', '1', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.BCERankingLoss.__init__': [[132, 137], ['torch.Module.__init__', 'networks_basic.Dist2LogitLayer', 'torch.nn.BCELoss', 'torch.nn.BCELoss', 'torch.nn.BCELoss', 'torch.nn.BCELoss', 'torch.nn.BCELoss', 'torch.nn.BCELoss', 'torch.nn.BCELoss', 'torch.nn.BCELoss', 'torch.nn.BCELoss'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'chn_mid', '=', '32', ')', ':', '\\n', '        ', 'super', '(', 'BCERankingLoss', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'self', '.', 'net', '=', 'Dist2LogitLayer', '(', 'chn_mid', '=', 'chn_mid', ')', '\\n', '# self.parameters = list(self.net.parameters())', '\\n', 'self', '.', 'loss', '=', 'torch', '.', 'nn', '.', 'BCELoss', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.BCERankingLoss.forward': [[138, 142], ['networks_basic.BCERankingLoss.net.forward', 'networks_basic.BCERankingLoss.loss'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward'], ['', 'def', 'forward', '(', 'self', ',', 'd0', ',', 'd1', ',', 'judge', ')', ':', '\\n', '        ', 'per', '=', '(', 'judge', '+', '1.', ')', '/', '2.', '\\n', 'self', '.', 'logit', '=', 'self', '.', 'net', '.', 'forward', '(', 'd0', ',', 'd1', ')', '\\n', 'return', 'self', '.', 'loss', '(', 'self', '.', 'logit', ',', 'per', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.FakeNet.__init__': [[145, 149], ['torch.Module.__init__'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'use_gpu', '=', 'True', ',', 'colorspace', '=', \"'Lab'\", ')', ':', '\\n', '        ', 'super', '(', 'FakeNet', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'self', '.', 'use_gpu', '=', 'use_gpu', '\\n', 'self', '.', 'colorspace', '=', 'colorspace', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.L2.forward': [[152, 166], ['in0.size', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'in0.size', 'lpips.l2().astype', 'torch.autograd.Variable', 'torch.autograd.Variable', 'torch.autograd.Variable', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'ret_var.cuda.cuda.cuda', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'lpips.l2', 'lpips.tensor2np', 'lpips.tensor2np', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'lpips.tensor2tensorlab', 'lpips.tensor2tensorlab', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean().view', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean', 'torch.mean'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.l2', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2np', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2np', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2tensorlab', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2tensorlab'], ['    ', 'def', 'forward', '(', 'self', ',', 'in0', ',', 'in1', ',', 'retPerLayer', '=', 'None', ')', ':', '\\n', '        ', 'assert', '(', 'in0', '.', 'size', '(', ')', '[', '0', ']', '==', '1', ')', '# currently only supports batchSize 1', '\\n', '\\n', 'if', '(', 'self', '.', 'colorspace', '==', \"'RGB'\", ')', ':', '\\n', '            ', '(', 'N', ',', 'C', ',', 'X', ',', 'Y', ')', '=', 'in0', '.', 'size', '(', ')', '\\n', 'value', '=', 'torch', '.', 'mean', '(', 'torch', '.', 'mean', '(', 'torch', '.', 'mean', '(', '(', 'in0', '-', 'in1', ')', '**', '2', ',', 'dim', '=', '1', ')', '.', 'view', '(', 'N', ',', '1', ',', 'X', ',', 'Y', ')', ',', 'dim', '=', '2', ')', '.', 'view', '(', 'N', ',', '1', ',', '1', ',', 'Y', ')', ',', 'dim', '=', '3', ')', '.', 'view', '(', 'N', ')', '\\n', 'return', 'value', '\\n', '', 'elif', '(', 'self', '.', 'colorspace', '==', \"'Lab'\", ')', ':', '\\n', '            ', 'value', '=', 'util', '.', 'l2', '(', 'util', '.', 'tensor2np', '(', 'util', '.', 'tensor2tensorlab', '(', 'in0', '.', 'data', ',', 'to_norm', '=', 'False', ')', ')', ',', '\\n', 'util', '.', 'tensor2np', '(', 'util', '.', 'tensor2tensorlab', '(', 'in1', '.', 'data', ',', 'to_norm', '=', 'False', ')', ')', ',', 'range', '=', '100.', ')', '.', 'astype', '(', \"'float'\", ')', '\\n', 'ret_var', '=', 'Variable', '(', 'torch', '.', 'Tensor', '(', '(', 'value', ',', ')', ')', ')', '\\n', 'if', '(', 'self', '.', 'use_gpu', ')', ':', '\\n', '                ', 'ret_var', '=', 'ret_var', '.', 'cuda', '(', ')', '\\n', '', 'return', 'ret_var', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.DSSIM.forward': [[169, 181], ['torch.autograd.Variable', 'torch.autograd.Variable', 'torch.autograd.Variable', 'lpips.dssim().astype', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'ret_var.cuda.cuda.cuda', 'in0.size', 'lpips.dssim().astype', 'lpips.dssim', 'lpips.dssim', 'lpips.tensor2im', 'lpips.tensor2im', 'lpips.tensor2np', 'lpips.tensor2np', 'lpips.tensor2tensorlab', 'lpips.tensor2tensorlab'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.dssim', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.dssim', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2np', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2np', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2tensorlab', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2tensorlab'], ['    ', 'def', 'forward', '(', 'self', ',', 'in0', ',', 'in1', ',', 'retPerLayer', '=', 'None', ')', ':', '\\n', '        ', 'assert', '(', 'in0', '.', 'size', '(', ')', '[', '0', ']', '==', '1', ')', '# currently only supports batchSize 1', '\\n', '\\n', 'if', '(', 'self', '.', 'colorspace', '==', \"'RGB'\", ')', ':', '\\n', '            ', 'value', '=', 'util', '.', 'dssim', '(', '1.', '*', 'util', '.', 'tensor2im', '(', 'in0', '.', 'data', ')', ',', '1.', '*', 'util', '.', 'tensor2im', '(', 'in1', '.', 'data', ')', ',', 'range', '=', '255.', ')', '.', 'astype', '(', \"'float'\", ')', '\\n', '', 'elif', '(', 'self', '.', 'colorspace', '==', \"'Lab'\", ')', ':', '\\n', '            ', 'value', '=', 'util', '.', 'dssim', '(', 'util', '.', 'tensor2np', '(', 'util', '.', 'tensor2tensorlab', '(', 'in0', '.', 'data', ',', 'to_norm', '=', 'False', ')', ')', ',', '\\n', 'util', '.', 'tensor2np', '(', 'util', '.', 'tensor2tensorlab', '(', 'in1', '.', 'data', ',', 'to_norm', '=', 'False', ')', ')', ',', 'range', '=', '100.', ')', '.', 'astype', '(', \"'float'\", ')', '\\n', '', 'ret_var', '=', 'Variable', '(', 'torch', '.', 'Tensor', '(', '(', 'value', ',', ')', ')', ')', '\\n', 'if', '(', 'self', '.', 'use_gpu', ')', ':', '\\n', '            ', 'ret_var', '=', 'ret_var', '.', 'cuda', '(', ')', '\\n', '', 'return', 'ret_var', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.spatial_average': [[17, 19], ['in_tens.mean'], 'function', ['None'], ['def', 'spatial_average', '(', 'in_tens', ',', 'keepdim', '=', 'True', ')', ':', '\\n', '    ', 'return', 'in_tens', '.', 'mean', '(', '[', '2', ',', '3', ']', ',', 'keepdim', '=', 'keepdim', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.upsample': [[20, 25], ['torch.Upsample'], 'function', ['None'], ['', 'def', 'upsample', '(', 'in_tens', ',', 'out_H', '=', '64', ')', ':', '# assumes scale factor is same for H and W', '\\n', '    ', 'in_H', '=', 'in_tens', '.', 'shape', '[', '2', ']', '\\n', 'scale_factor', '=', '1.', '*', 'out_H', '/', 'in_H', '\\n', '\\n', 'return', 'nn', '.', 'Upsample', '(', 'scale_factor', '=', 'scale_factor', ',', 'mode', '=', \"'bilinear'\", ',', 'align_corners', '=', 'False', ')', '(', 'in_tens', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.print_network': [[182, 188], ['net.parameters', 'print', 'print', 'param.numel'], 'function', ['None'], ['', '', 'def', 'print_network', '(', 'net', ')', ':', '\\n', '    ', 'num_params', '=', '0', '\\n', 'for', 'param', 'in', 'net', '.', 'parameters', '(', ')', ':', '\\n', '        ', 'num_params', '+=', 'param', '.', 'numel', '(', ')', '\\n', '', 'print', '(', \"'Network'\", ',', 'net', ')', '\\n', 'print', '(', \"'Total number of parameters: %d'\", '%', 'num_params', ')', '\\n', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.name': [[25, 27], ['None'], 'methods', ['None'], ['    ', 'def', 'name', '(', 'self', ')', ':', '\\n', '        ', 'return', 'self', '.', 'model_name', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.initialize': [[28, 108], ['base_model.BaseModel.initialize', 'list', 'networks_basic.PNetLin', 'dist_model.DistModel.net.parameters', 'networks_basic.BCERankingLoss', 'list', 'torch.optim.Adam', 'dist_model.DistModel.net.eval', 'dist_model.DistModel.net.to', 'torch.nn.DataParallel', 'print', 'networks_basic.print_network', 'print', 'os.path.abspath', 'print', 'dist_model.DistModel.net.load_state_dict', 'networks_basic.PNetLin', 'dist_model.DistModel.rankLoss.net.parameters', 'dist_model.DistModel.rankLoss.to', 'os.path.join', 'torch.load', 'networks_basic.L2', 'inspect.getfile', 'networks_basic.DSSIM', 'ValueError'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.initialize', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.print_network'], ['', 'def', 'initialize', '(', 'self', ',', 'model', '=', \"'net-lin'\", ',', 'net', '=', \"'alex'\", ',', 'colorspace', '=', \"'Lab'\", ',', 'pnet_rand', '=', 'False', ',', 'pnet_tune', '=', 'False', ',', 'model_path', '=', 'None', ',', '\\n', 'use_gpu', '=', 'True', ',', 'printNet', '=', 'False', ',', 'spatial', '=', 'False', ',', '\\n', 'is_train', '=', 'False', ',', 'lr', '=', '.0001', ',', 'beta1', '=', '0.5', ',', 'version', '=', \"'0.1'\", ',', 'gpu_ids', '=', '[', '0', ']', ')', ':', '\\n', '        ', \"'''\\n        INPUTS\\n            model - ['net-lin'] for linearly calibrated network\\n                    ['net'] for off-the-shelf network\\n                    ['L2'] for L2 distance in Lab colorspace\\n                    ['SSIM'] for ssim in RGB colorspace\\n            net - ['squeeze','alex','vgg']\\n            model_path - if None, will look in weights/[NET_NAME].pth\\n            colorspace - ['Lab','RGB'] colorspace to use for L2 and SSIM\\n            use_gpu - bool - whether or not to use a GPU\\n            printNet - bool - whether or not to print network architecture out\\n            spatial - bool - whether to output an array containing varying distances across spatial dimensions\\n            spatial_shape - if given, output spatial shape. if None then spatial shape is determined automatically via spatial_factor (see below).\\n            spatial_factor - if given, specifies upsampling factor relative to the largest spatial extent of a convolutional layer. if None then resized to size of input images.\\n            spatial_order - spline order of filter for upsampling in spatial mode, by default 1 (bilinear).\\n            is_train - bool - [True] for training mode\\n            lr - float - initial learning rate\\n            beta1 - float - initial momentum term for adam\\n            version - 0.1 for latest, 0.0 was original (with a bug)\\n            gpu_ids - int array - [0] by default, gpus to use\\n        '''\", '\\n', 'BaseModel', '.', 'initialize', '(', 'self', ',', 'use_gpu', '=', 'use_gpu', ',', 'gpu_ids', '=', 'gpu_ids', ')', '\\n', '\\n', 'self', '.', 'model', '=', 'model', '\\n', 'self', '.', 'net', '=', 'net', '\\n', 'self', '.', 'is_train', '=', 'is_train', '\\n', 'self', '.', 'spatial', '=', 'spatial', '\\n', 'self', '.', 'gpu_ids', '=', 'gpu_ids', '\\n', 'self', '.', 'model_name', '=', \"'%s [%s]'\", '%', '(', 'model', ',', 'net', ')', '\\n', '\\n', 'if', '(', 'self', '.', 'model', '==', \"'net-lin'\", ')', ':', '# pretrained net + linear layer', '\\n', '            ', 'self', '.', 'net', '=', 'networks', '.', 'PNetLin', '(', 'pnet_rand', '=', 'pnet_rand', ',', 'pnet_tune', '=', 'pnet_tune', ',', 'pnet_type', '=', 'net', ',', '\\n', 'use_dropout', '=', 'True', ',', 'spatial', '=', 'spatial', ',', 'version', '=', 'version', ',', 'lpips', '=', 'True', ')', '\\n', 'kw', '=', '{', '}', '\\n', 'if', 'not', 'use_gpu', ':', '\\n', '                ', 'kw', '[', \"'map_location'\", ']', '=', \"'cpu'\", '\\n', '', 'if', '(', 'model_path', 'is', 'None', ')', ':', '\\n', '                ', 'import', 'inspect', '\\n', 'model_path', '=', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'join', '(', 'inspect', '.', 'getfile', '(', 'self', '.', 'initialize', ')', ',', \"'..'\", ',', \"'weights/v%s/%s.pth'\", '%', '(', 'version', ',', 'net', ')', ')', ')', '\\n', '\\n', '', 'if', '(', 'not', 'is_train', ')', ':', '\\n', '                ', 'print', '(', \"'Loading model from: %s'\", '%', 'model_path', ')', '\\n', 'self', '.', 'net', '.', 'load_state_dict', '(', 'torch', '.', 'load', '(', 'model_path', ',', '**', 'kw', ')', ',', 'strict', '=', 'False', ')', '\\n', '\\n', '', '', 'elif', '(', 'self', '.', 'model', '==', \"'net'\", ')', ':', '# pretrained network', '\\n', '            ', 'self', '.', 'net', '=', 'networks', '.', 'PNetLin', '(', 'pnet_rand', '=', 'pnet_rand', ',', 'pnet_type', '=', 'net', ',', 'lpips', '=', 'False', ')', '\\n', '', 'elif', '(', 'self', '.', 'model', 'in', '[', \"'L2'\", ',', \"'l2'\", ']', ')', ':', '\\n', '            ', 'self', '.', 'net', '=', 'networks', '.', 'L2', '(', 'use_gpu', '=', 'use_gpu', ',', 'colorspace', '=', 'colorspace', ')', '# not really a network, only for testing', '\\n', 'self', '.', 'model_name', '=', \"'L2'\", '\\n', '', 'elif', '(', 'self', '.', 'model', 'in', '[', \"'DSSIM'\", ',', \"'dssim'\", ',', \"'SSIM'\", ',', \"'ssim'\", ']', ')', ':', '\\n', '            ', 'self', '.', 'net', '=', 'networks', '.', 'DSSIM', '(', 'use_gpu', '=', 'use_gpu', ',', 'colorspace', '=', 'colorspace', ')', '\\n', 'self', '.', 'model_name', '=', \"'SSIM'\", '\\n', '', 'else', ':', '\\n', '            ', 'raise', 'ValueError', '(', '\"Model [%s] not recognized.\"', '%', 'self', '.', 'model', ')', '\\n', '\\n', '', 'self', '.', 'parameters', '=', 'list', '(', 'self', '.', 'net', '.', 'parameters', '(', ')', ')', '\\n', '\\n', 'if', 'self', '.', 'is_train', ':', '# training mode', '\\n', '# extra network on top to go from distances (d0,d1) => predicted human judgment (h*)', '\\n', '            ', 'self', '.', 'rankLoss', '=', 'networks', '.', 'BCERankingLoss', '(', ')', '\\n', 'self', '.', 'parameters', '+=', 'list', '(', 'self', '.', 'rankLoss', '.', 'net', '.', 'parameters', '(', ')', ')', '\\n', 'self', '.', 'lr', '=', 'lr', '\\n', 'self', '.', 'old_lr', '=', 'lr', '\\n', 'self', '.', 'optimizer_net', '=', 'torch', '.', 'optim', '.', 'Adam', '(', 'self', '.', 'parameters', ',', 'lr', '=', 'lr', ',', 'betas', '=', '(', 'beta1', ',', '0.999', ')', ')', '\\n', '', 'else', ':', '# test mode', '\\n', '            ', 'self', '.', 'net', '.', 'eval', '(', ')', '\\n', '\\n', '', 'if', '(', 'use_gpu', ')', ':', '\\n', '            ', 'self', '.', 'net', '.', 'to', '(', 'gpu_ids', '[', '0', ']', ')', '\\n', 'self', '.', 'net', '=', 'torch', '.', 'nn', '.', 'DataParallel', '(', 'self', '.', 'net', ',', 'device_ids', '=', 'gpu_ids', ')', '\\n', 'if', '(', 'self', '.', 'is_train', ')', ':', '\\n', '                ', 'self', '.', 'rankLoss', '=', 'self', '.', 'rankLoss', '.', 'to', '(', 'device', '=', 'gpu_ids', '[', '0', ']', ')', '# just put this on GPU0', '\\n', '\\n', '', '', 'if', '(', 'printNet', ')', ':', '\\n', '            ', 'print', '(', \"'---------- Networks initialized -------------'\", ')', '\\n', 'networks', '.', 'print_network', '(', 'self', '.', 'net', ')', '\\n', 'print', '(', \"'-----------------------------------------------'\", ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.forward': [[109, 118], ['dist_model.DistModel.net.forward'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward'], ['', '', 'def', 'forward', '(', 'self', ',', 'in0', ',', 'in1', ',', 'retPerLayer', '=', 'False', ')', ':', '\\n', '        ', \"''' Function computes the distance between image patches in0 and in1\\n        INPUTS\\n            in0, in1 - torch.Tensor object of shape Nx3xXxY - image patch scaled to [-1,1]\\n        OUTPUT\\n            computed distances between in0 and in1\\n        '''\", '\\n', '\\n', 'return', 'self', '.', 'net', '.', 'forward', '(', 'in0', ',', 'in1', ',', 'retPerLayer', '=', 'retPerLayer', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.optimize_parameters': [[120, 126], ['dist_model.DistModel.forward_train', 'dist_model.DistModel.optimizer_net.zero_grad', 'dist_model.DistModel.backward_train', 'dist_model.DistModel.optimizer_net.step', 'dist_model.DistModel.clamp_weights'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.forward_train', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.backward_train', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.clamp_weights'], ['', 'def', 'optimize_parameters', '(', 'self', ')', ':', '\\n', '        ', 'self', '.', 'forward_train', '(', ')', '\\n', 'self', '.', 'optimizer_net', '.', 'zero_grad', '(', ')', '\\n', 'self', '.', 'backward_train', '(', ')', '\\n', 'self', '.', 'optimizer_net', '.', 'step', '(', ')', '\\n', 'self', '.', 'clamp_weights', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.clamp_weights': [[127, 131], ['dist_model.DistModel.net.modules', 'hasattr', 'torch.clamp'], 'methods', ['None'], ['', 'def', 'clamp_weights', '(', 'self', ')', ':', '\\n', '        ', 'for', 'module', 'in', 'self', '.', 'net', '.', 'modules', '(', ')', ':', '\\n', '            ', 'if', '(', 'hasattr', '(', 'module', ',', \"'weight'\", ')', 'and', 'module', '.', 'kernel_size', '==', '(', '1', ',', '1', ')', ')', ':', '\\n', '                ', 'module', '.', 'weight', '.', 'data', '=', 'torch', '.', 'clamp', '(', 'module', '.', 'weight', '.', 'data', ',', 'min', '=', '0', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.set_input': [[132, 147], ['torch.autograd.Variable', 'torch.autograd.Variable', 'torch.autograd.Variable', 'dist_model.DistModel.input_ref.to', 'dist_model.DistModel.input_p0.to', 'dist_model.DistModel.input_p1.to', 'dist_model.DistModel.input_judge.to'], 'methods', ['None'], ['', '', '', 'def', 'set_input', '(', 'self', ',', 'data', ')', ':', '\\n', '        ', 'self', '.', 'input_ref', '=', 'data', '[', \"'ref'\", ']', '\\n', 'self', '.', 'input_p0', '=', 'data', '[', \"'p0'\", ']', '\\n', 'self', '.', 'input_p1', '=', 'data', '[', \"'p1'\", ']', '\\n', 'self', '.', 'input_judge', '=', 'data', '[', \"'judge'\", ']', '\\n', '\\n', 'if', '(', 'self', '.', 'use_gpu', ')', ':', '\\n', '            ', 'self', '.', 'input_ref', '=', 'self', '.', 'input_ref', '.', 'to', '(', 'device', '=', 'self', '.', 'gpu_ids', '[', '0', ']', ')', '\\n', 'self', '.', 'input_p0', '=', 'self', '.', 'input_p0', '.', 'to', '(', 'device', '=', 'self', '.', 'gpu_ids', '[', '0', ']', ')', '\\n', 'self', '.', 'input_p1', '=', 'self', '.', 'input_p1', '.', 'to', '(', 'device', '=', 'self', '.', 'gpu_ids', '[', '0', ']', ')', '\\n', 'self', '.', 'input_judge', '=', 'self', '.', 'input_judge', '.', 'to', '(', 'device', '=', 'self', '.', 'gpu_ids', '[', '0', ']', ')', '\\n', '\\n', '', 'self', '.', 'var_ref', '=', 'Variable', '(', 'self', '.', 'input_ref', ',', 'requires_grad', '=', 'True', ')', '\\n', 'self', '.', 'var_p0', '=', 'Variable', '(', 'self', '.', 'input_p0', ',', 'requires_grad', '=', 'True', ')', '\\n', 'self', '.', 'var_p1', '=', 'Variable', '(', 'self', '.', 'input_p1', ',', 'requires_grad', '=', 'True', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.forward_train': [[148, 161], ['dist_model.DistModel.forward', 'dist_model.DistModel.forward', 'dist_model.DistModel.compute_accuracy', 'torch.autograd.Variable().view', 'dist_model.DistModel.rankLoss.forward', 'dist_model.DistModel.d0.size', 'torch.autograd.Variable'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.compute_accuracy', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward'], ['', 'def', 'forward_train', '(', 'self', ')', ':', '# run forward pass', '\\n', '# print(self.net.module.scaling_layer.shift)', '\\n', '# print(torch.norm(self.net.module.net.slice1[0].weight).item(), torch.norm(self.net.module.lin0.model[1].weight).item())', '\\n', '\\n', '        ', 'self', '.', 'd0', '=', 'self', '.', 'forward', '(', 'self', '.', 'var_ref', ',', 'self', '.', 'var_p0', ')', '\\n', 'self', '.', 'd1', '=', 'self', '.', 'forward', '(', 'self', '.', 'var_ref', ',', 'self', '.', 'var_p1', ')', '\\n', 'self', '.', 'acc_r', '=', 'self', '.', 'compute_accuracy', '(', 'self', '.', 'd0', ',', 'self', '.', 'd1', ',', 'self', '.', 'input_judge', ')', '\\n', '\\n', 'self', '.', 'var_judge', '=', 'Variable', '(', '1.', '*', 'self', '.', 'input_judge', ')', '.', 'view', '(', 'self', '.', 'd0', '.', 'size', '(', ')', ')', '\\n', '\\n', 'self', '.', 'loss_total', '=', 'self', '.', 'rankLoss', '.', 'forward', '(', 'self', '.', 'd0', ',', 'self', '.', 'd1', ',', 'self', '.', 'var_judge', '*', '2.', '-', '1.', ')', '\\n', '\\n', 'return', 'self', '.', 'loss_total', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.backward_train': [[162, 164], ['torch.mean().backward', 'torch.mean'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.backward'], ['', 'def', 'backward_train', '(', 'self', ')', ':', '\\n', '        ', 'torch', '.', 'mean', '(', 'self', '.', 'loss_total', ')', '.', 'backward', '(', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.compute_accuracy': [[165, 170], ['judge.cpu().numpy().flatten', 'judge.cpu().numpy', 'judge.cpu'], 'methods', ['None'], ['', 'def', 'compute_accuracy', '(', 'self', ',', 'd0', ',', 'd1', ',', 'judge', ')', ':', '\\n', '        ', \"''' d0, d1 are Variables, judge is a Tensor '''\", '\\n', 'd1_lt_d0', '=', '(', 'd1', '<', 'd0', ')', '.', 'cpu', '(', ')', '.', 'data', '.', 'numpy', '(', ')', '.', 'flatten', '(', ')', '\\n', 'judge_per', '=', 'judge', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '.', 'flatten', '(', ')', '\\n', 'return', 'd1_lt_d0', '*', 'judge_per', '+', '(', '1', '-', 'd1_lt_d0', ')', '*', '(', '1', '-', 'judge_per', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.get_current_errors': [[171, 179], ['collections.OrderedDict', 'collections.OrderedDict.keys', 'numpy.mean', 'dist_model.DistModel.loss_total.data.cpu().numpy', 'dist_model.DistModel.loss_total.data.cpu'], 'methods', ['None'], ['', 'def', 'get_current_errors', '(', 'self', ')', ':', '\\n', '        ', 'retDict', '=', 'OrderedDict', '(', '[', '(', \"'loss_total'\", ',', 'self', '.', 'loss_total', '.', 'data', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', ')', ',', '\\n', '(', \"'acc_r'\", ',', 'self', '.', 'acc_r', ')', ']', ')', '\\n', '\\n', 'for', 'key', 'in', 'retDict', '.', 'keys', '(', ')', ':', '\\n', '            ', 'retDict', '[', 'key', ']', '=', 'np', '.', 'mean', '(', 'retDict', '[', 'key', ']', ')', '\\n', '\\n', '', 'return', 'retDict', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.get_current_visuals': [[180, 194], ['lpips.tensor2im', 'lpips.tensor2im', 'lpips.tensor2im', 'scipy.ndimage.zoom', 'scipy.ndimage.zoom', 'scipy.ndimage.zoom', 'collections.OrderedDict', 'dist_model.DistModel.var_ref.data.size'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im'], ['', 'def', 'get_current_visuals', '(', 'self', ')', ':', '\\n', '        ', 'zoom_factor', '=', '256', '/', 'self', '.', 'var_ref', '.', 'data', '.', 'size', '(', ')', '[', '2', ']', '\\n', '\\n', 'ref_img', '=', 'util', '.', 'tensor2im', '(', 'self', '.', 'var_ref', '.', 'data', ')', '\\n', 'p0_img', '=', 'util', '.', 'tensor2im', '(', 'self', '.', 'var_p0', '.', 'data', ')', '\\n', 'p1_img', '=', 'util', '.', 'tensor2im', '(', 'self', '.', 'var_p1', '.', 'data', ')', '\\n', '\\n', 'ref_img_vis', '=', 'zoom', '(', 'ref_img', ',', '[', 'zoom_factor', ',', 'zoom_factor', ',', '1', ']', ',', 'order', '=', '0', ')', '\\n', 'p0_img_vis', '=', 'zoom', '(', 'p0_img', ',', '[', 'zoom_factor', ',', 'zoom_factor', ',', '1', ']', ',', 'order', '=', '0', ')', '\\n', 'p1_img_vis', '=', 'zoom', '(', 'p1_img', ',', '[', 'zoom_factor', ',', 'zoom_factor', ',', '1', ']', ',', 'order', '=', '0', ')', '\\n', '\\n', 'return', 'OrderedDict', '(', '[', '(', \"'ref'\", ',', 'ref_img_vis', ')', ',', '\\n', '(', \"'p0'\", ',', 'p0_img_vis', ')', ',', '\\n', '(', \"'p1'\", ',', 'p1_img_vis', ')', ']', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.save': [[195, 201], ['dist_model.DistModel.save_network', 'dist_model.DistModel.save_network', 'dist_model.DistModel.save_network'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save_network', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save_network', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save_network'], ['', 'def', 'save', '(', 'self', ',', 'path', ',', 'label', ')', ':', '\\n', '        ', 'if', '(', 'self', '.', 'use_gpu', ')', ':', '\\n', '            ', 'self', '.', 'save_network', '(', 'self', '.', 'net', '.', 'module', ',', 'path', ',', \"''\", ',', 'label', ')', '\\n', '', 'else', ':', '\\n', '            ', 'self', '.', 'save_network', '(', 'self', '.', 'net', ',', 'path', ',', \"''\", ',', 'label', ')', '\\n', '', 'self', '.', 'save_network', '(', 'self', '.', 'rankLoss', '.', 'net', ',', 'path', ',', \"'rank'\", ',', 'label', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.update_learning_rate': [[202, 211], ['print'], 'methods', ['None'], ['', 'def', 'update_learning_rate', '(', 'self', ',', 'nepoch_decay', ')', ':', '\\n', '        ', 'lrd', '=', 'self', '.', 'lr', '/', 'nepoch_decay', '\\n', 'lr', '=', 'self', '.', 'old_lr', '-', 'lrd', '\\n', '\\n', 'for', 'param_group', 'in', 'self', '.', 'optimizer_net', '.', 'param_groups', ':', '\\n', '            ', 'param_group', '[', \"'lr'\", ']', '=', 'lr', '\\n', '\\n', '', 'print', '(', \"'update lr [%s] decay: %f -> %f'\", '%', '(', 'type', ',', 'self', '.', 'old_lr', ',', 'lr', ')', ')', '\\n', 'self', '.', 'old_lr', '=', 'lr', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.score_2afc_dataset': [[212, 246], ['tqdm.tqdm', 'numpy.array', 'numpy.array', 'numpy.array', 'data_loader.load_data', 'func().data.cpu().numpy().flatten().tolist', 'func().data.cpu().numpy().flatten().tolist', 'data[].cpu().numpy().flatten().tolist', 'numpy.mean', 'dict', 'func().data.cpu().numpy().flatten', 'func().data.cpu().numpy().flatten', 'data[].cpu().numpy().flatten', 'func().data.cpu().numpy', 'func().data.cpu().numpy', 'data[].cpu().numpy', 'func().data.cpu', 'func().data.cpu', 'data[].cpu', 'func', 'func'], 'function', ['None'], ['', '', 'def', 'score_2afc_dataset', '(', 'data_loader', ',', 'func', ',', 'name', '=', \"''\", ')', ':', '\\n', '    ', '\\'\\'\\' Function computes Two Alternative Forced Choice (2AFC) score using\\n        distance function \\'func\\' in dataset \\'data_loader\\'\\n    INPUTS\\n        data_loader - CustomDatasetDataLoader object - contains a TwoAFCDataset inside\\n        func - callable distance function - calling d=func(in0,in1) should take 2\\n            pytorch tensors with shape Nx3xXxY, and return numpy array of length N\\n    OUTPUTS\\n        [0] - 2AFC score in [0,1], fraction of time func agrees with human evaluators\\n        [1] - dictionary with following elements\\n            d0s,d1s - N arrays containing distances between reference patch to perturbed patches \\n            gts - N array in [0,1], preferred patch selected by human evaluators\\n                (closer to \"0\" for left patch p0, \"1\" for right patch p1,\\n                \"0.6\" means 60pct people preferred right patch, 40pct preferred left)\\n            scores - N array in [0,1], corresponding to what percentage function agreed with humans\\n    CONSTS\\n        N - number of test triplets in data_loader\\n    \\'\\'\\'', '\\n', '\\n', 'd0s', '=', '[', ']', '\\n', 'd1s', '=', '[', ']', '\\n', 'gts', '=', '[', ']', '\\n', '\\n', 'for', 'data', 'in', 'tqdm', '(', 'data_loader', '.', 'load_data', '(', ')', ',', 'desc', '=', 'name', ')', ':', '\\n', '        ', 'd0s', '+=', 'func', '(', 'data', '[', \"'ref'\", ']', ',', 'data', '[', \"'p0'\", ']', ')', '.', 'data', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '.', 'flatten', '(', ')', '.', 'tolist', '(', ')', '\\n', 'd1s', '+=', 'func', '(', 'data', '[', \"'ref'\", ']', ',', 'data', '[', \"'p1'\", ']', ')', '.', 'data', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '.', 'flatten', '(', ')', '.', 'tolist', '(', ')', '\\n', 'gts', '+=', 'data', '[', \"'judge'\", ']', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '.', 'flatten', '(', ')', '.', 'tolist', '(', ')', '\\n', '\\n', '', 'd0s', '=', 'np', '.', 'array', '(', 'd0s', ')', '\\n', 'd1s', '=', 'np', '.', 'array', '(', 'd1s', ')', '\\n', 'gts', '=', 'np', '.', 'array', '(', 'gts', ')', '\\n', 'scores', '=', '(', 'd0s', '<', 'd1s', ')', '*', '(', '1.', '-', 'gts', ')', '+', '(', 'd1s', '<', 'd0s', ')', '*', 'gts', '+', '(', 'd1s', '==', 'd0s', ')', '*', '.5', '\\n', '\\n', 'return', '(', 'np', '.', 'mean', '(', 'scores', ')', ',', 'dict', '(', 'd0s', '=', 'd0s', ',', 'd1s', '=', 'd1s', ',', 'gts', '=', 'gts', ',', 'scores', '=', 'scores', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.score_jnd_dataset': [[247, 285], ['tqdm.tqdm', 'numpy.array', 'numpy.array', 'numpy.argsort', 'numpy.cumsum', 'numpy.cumsum', 'lpips.voc_ap', 'data_loader.load_data', 'func().data.cpu().numpy().tolist', 'data[].cpu().numpy().flatten().tolist', 'numpy.sum', 'dict', 'func().data.cpu().numpy', 'data[].cpu().numpy().flatten', 'func().data.cpu', 'data[].cpu().numpy', 'data[].cpu', 'func'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.voc_ap'], ['', 'def', 'score_jnd_dataset', '(', 'data_loader', ',', 'func', ',', 'name', '=', \"''\", ')', ':', '\\n', '    ', \"''' Function computes JND score using distance function 'func' in dataset 'data_loader'\\n    INPUTS\\n        data_loader - CustomDatasetDataLoader object - contains a JNDDataset inside\\n        func - callable distance function - calling d=func(in0,in1) should take 2\\n            pytorch tensors with shape Nx3xXxY, and return pytorch array of length N\\n    OUTPUTS\\n        [0] - JND score in [0,1], mAP score (area under precision-recall curve)\\n        [1] - dictionary with following elements\\n            ds - N array containing distances between two patches shown to human evaluator\\n            sames - N array containing fraction of people who thought the two patches were identical\\n    CONSTS\\n        N - number of test triplets in data_loader\\n    '''\", '\\n', '\\n', 'ds', '=', '[', ']', '\\n', 'gts', '=', '[', ']', '\\n', '\\n', 'for', 'data', 'in', 'tqdm', '(', 'data_loader', '.', 'load_data', '(', ')', ',', 'desc', '=', 'name', ')', ':', '\\n', '        ', 'ds', '+=', 'func', '(', 'data', '[', \"'p0'\", ']', ',', 'data', '[', \"'p1'\", ']', ')', '.', 'data', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '.', 'tolist', '(', ')', '\\n', 'gts', '+=', 'data', '[', \"'same'\", ']', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '.', 'flatten', '(', ')', '.', 'tolist', '(', ')', '\\n', '\\n', '', 'sames', '=', 'np', '.', 'array', '(', 'gts', ')', '\\n', 'ds', '=', 'np', '.', 'array', '(', 'ds', ')', '\\n', '\\n', 'sorted_inds', '=', 'np', '.', 'argsort', '(', 'ds', ')', '\\n', 'ds_sorted', '=', 'ds', '[', 'sorted_inds', ']', '\\n', 'sames_sorted', '=', 'sames', '[', 'sorted_inds', ']', '\\n', '\\n', 'TPs', '=', 'np', '.', 'cumsum', '(', 'sames_sorted', ')', '\\n', 'FPs', '=', 'np', '.', 'cumsum', '(', '1', '-', 'sames_sorted', ')', '\\n', 'FNs', '=', 'np', '.', 'sum', '(', 'sames_sorted', ')', '-', 'TPs', '\\n', '\\n', 'precs', '=', 'TPs', '/', '(', 'TPs', '+', 'FPs', ')', '\\n', 'recs', '=', 'TPs', '/', '(', 'TPs', '+', 'FNs', ')', '\\n', 'score', '=', 'util', '.', 'voc_ap', '(', 'recs', ',', 'precs', ')', '\\n', '\\n', 'return', '(', 'score', ',', 'dict', '(', 'ds', '=', 'ds', ',', 'sames', '=', 'sames', ')', ')', '\\n', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.squeezenet.__init__': [[7, 35], ['super().__init__', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'torchvision.models.squeezenet1_1', 'pretrained_networks.squeezenet.slice1.add_module', 'pretrained_networks.squeezenet.slice2.add_module', 'pretrained_networks.squeezenet.slice3.add_module', 'pretrained_networks.squeezenet.slice4.add_module', 'pretrained_networks.squeezenet.slice5.add_module', 'pretrained_networks.squeezenet.slice6.add_module', 'pretrained_networks.squeezenet.slice7.add_module', 'pretrained_networks.squeezenet.parameters', 'str', 'str', 'str', 'str', 'str', 'str', 'str'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'requires_grad', '=', 'False', ',', 'pretrained', '=', 'True', ')', ':', '\\n', '        ', 'super', '(', 'squeezenet', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'pretrained_features', '=', 'tv', '.', 'squeezenet1_1', '(', 'pretrained', '=', 'pretrained', ')', '.', 'features', '\\n', 'self', '.', 'slice1', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice2', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice3', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice4', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice5', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice6', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice7', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'N_slices', '=', '7', '\\n', 'for', 'x', 'in', 'range', '(', '2', ')', ':', '\\n', '            ', 'self', '.', 'slice1', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '2', ',', '5', ')', ':', '\\n', '            ', 'self', '.', 'slice2', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '5', ',', '8', ')', ':', '\\n', '            ', 'self', '.', 'slice3', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '8', ',', '10', ')', ':', '\\n', '            ', 'self', '.', 'slice4', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '10', ',', '11', ')', ':', '\\n', '            ', 'self', '.', 'slice5', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '11', ',', '12', ')', ':', '\\n', '            ', 'self', '.', 'slice6', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '12', ',', '13', ')', ':', '\\n', '            ', 'self', '.', 'slice7', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'pretrained_features', '[', 'x', ']', ')', '\\n', '', 'if', 'not', 'requires_grad', ':', '\\n', '            ', 'for', 'param', 'in', 'self', '.', 'parameters', '(', ')', ':', '\\n', '                ', 'param', '.', 'requires_grad', '=', 'False', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.squeezenet.forward': [[36, 55], ['pretrained_networks.squeezenet.slice1', 'pretrained_networks.squeezenet.slice2', 'pretrained_networks.squeezenet.slice3', 'pretrained_networks.squeezenet.slice4', 'pretrained_networks.squeezenet.slice5', 'pretrained_networks.squeezenet.slice6', 'pretrained_networks.squeezenet.slice7', 'collections.namedtuple', 'collections.namedtuple.'], 'methods', ['None'], ['', '', '', 'def', 'forward', '(', 'self', ',', 'X', ')', ':', '\\n', '        ', 'h', '=', 'self', '.', 'slice1', '(', 'X', ')', '\\n', 'h_relu1', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice2', '(', 'h', ')', '\\n', 'h_relu2', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice3', '(', 'h', ')', '\\n', 'h_relu3', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice4', '(', 'h', ')', '\\n', 'h_relu4', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice5', '(', 'h', ')', '\\n', 'h_relu5', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice6', '(', 'h', ')', '\\n', 'h_relu6', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice7', '(', 'h', ')', '\\n', 'h_relu7', '=', 'h', '\\n', 'vgg_outputs', '=', 'namedtuple', '(', '\"SqueezeOutputs\"', ',', '[', \"'relu1'\", ',', \"'relu2'\", ',', \"'relu3'\", ',', \"'relu4'\", ',', \"'relu5'\", ',', \"'relu6'\", ',', \"'relu7'\", ']', ')', '\\n', 'out', '=', 'vgg_outputs', '(', 'h_relu1', ',', 'h_relu2', ',', 'h_relu3', ',', 'h_relu4', ',', 'h_relu5', ',', 'h_relu6', ',', 'h_relu7', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.alexnet.__init__': [[58, 80], ['super().__init__', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'range', 'range', 'range', 'range', 'range', 'torchvision.models.alexnet', 'pretrained_networks.alexnet.slice1.add_module', 'pretrained_networks.alexnet.slice2.add_module', 'pretrained_networks.alexnet.slice3.add_module', 'pretrained_networks.alexnet.slice4.add_module', 'pretrained_networks.alexnet.slice5.add_module', 'pretrained_networks.alexnet.parameters', 'str', 'str', 'str', 'str', 'str'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'requires_grad', '=', 'False', ',', 'pretrained', '=', 'True', ')', ':', '\\n', '        ', 'super', '(', 'alexnet', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'alexnet_pretrained_features', '=', 'tv', '.', 'alexnet', '(', 'pretrained', '=', 'pretrained', ')', '.', 'features', '\\n', 'self', '.', 'slice1', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice2', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice3', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice4', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice5', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'N_slices', '=', '5', '\\n', 'for', 'x', 'in', 'range', '(', '2', ')', ':', '\\n', '            ', 'self', '.', 'slice1', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'alexnet_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '2', ',', '5', ')', ':', '\\n', '            ', 'self', '.', 'slice2', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'alexnet_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '5', ',', '8', ')', ':', '\\n', '            ', 'self', '.', 'slice3', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'alexnet_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '8', ',', '10', ')', ':', '\\n', '            ', 'self', '.', 'slice4', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'alexnet_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '10', ',', '12', ')', ':', '\\n', '            ', 'self', '.', 'slice5', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'alexnet_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'if', 'not', 'requires_grad', ':', '\\n', '            ', 'for', 'param', 'in', 'self', '.', 'parameters', '(', ')', ':', '\\n', '                ', 'param', '.', 'requires_grad', '=', 'False', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.alexnet.forward': [[81, 96], ['pretrained_networks.alexnet.slice1', 'pretrained_networks.alexnet.slice2', 'pretrained_networks.alexnet.slice3', 'pretrained_networks.alexnet.slice4', 'pretrained_networks.alexnet.slice5', 'collections.namedtuple', 'collections.namedtuple.'], 'methods', ['None'], ['', '', '', 'def', 'forward', '(', 'self', ',', 'X', ')', ':', '\\n', '        ', 'h', '=', 'self', '.', 'slice1', '(', 'X', ')', '\\n', 'h_relu1', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice2', '(', 'h', ')', '\\n', 'h_relu2', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice3', '(', 'h', ')', '\\n', 'h_relu3', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice4', '(', 'h', ')', '\\n', 'h_relu4', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice5', '(', 'h', ')', '\\n', 'h_relu5', '=', 'h', '\\n', 'alexnet_outputs', '=', 'namedtuple', '(', '\"AlexnetOutputs\"', ',', '[', \"'relu1'\", ',', \"'relu2'\", ',', \"'relu3'\", ',', \"'relu4'\", ',', \"'relu5'\", ']', ')', '\\n', 'out', '=', 'alexnet_outputs', '(', 'h_relu1', ',', 'h_relu2', ',', 'h_relu3', ',', 'h_relu4', ',', 'h_relu5', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.vgg16.__init__': [[98, 120], ['super().__init__', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'torch.nn.Sequential', 'range', 'range', 'range', 'range', 'range', 'torchvision.models.vgg16', 'pretrained_networks.vgg16.slice1.add_module', 'pretrained_networks.vgg16.slice2.add_module', 'pretrained_networks.vgg16.slice3.add_module', 'pretrained_networks.vgg16.slice4.add_module', 'pretrained_networks.vgg16.slice5.add_module', 'pretrained_networks.vgg16.parameters', 'str', 'str', 'str', 'str', 'str'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'requires_grad', '=', 'False', ',', 'pretrained', '=', 'True', ')', ':', '\\n', '        ', 'super', '(', 'vgg16', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'vgg_pretrained_features', '=', 'tv', '.', 'vgg16', '(', 'pretrained', '=', 'pretrained', ')', '.', 'features', '\\n', 'self', '.', 'slice1', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice2', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice3', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice4', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'slice5', '=', 'torch', '.', 'nn', '.', 'Sequential', '(', ')', '\\n', 'self', '.', 'N_slices', '=', '5', '\\n', 'for', 'x', 'in', 'range', '(', '4', ')', ':', '\\n', '            ', 'self', '.', 'slice1', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'vgg_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '4', ',', '9', ')', ':', '\\n', '            ', 'self', '.', 'slice2', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'vgg_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '9', ',', '16', ')', ':', '\\n', '            ', 'self', '.', 'slice3', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'vgg_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '16', ',', '23', ')', ':', '\\n', '            ', 'self', '.', 'slice4', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'vgg_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'for', 'x', 'in', 'range', '(', '23', ',', '30', ')', ':', '\\n', '            ', 'self', '.', 'slice5', '.', 'add_module', '(', 'str', '(', 'x', ')', ',', 'vgg_pretrained_features', '[', 'x', ']', ')', '\\n', '', 'if', 'not', 'requires_grad', ':', '\\n', '            ', 'for', 'param', 'in', 'self', '.', 'parameters', '(', ')', ':', '\\n', '                ', 'param', '.', 'requires_grad', '=', 'False', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.vgg16.forward': [[121, 136], ['pretrained_networks.vgg16.slice1', 'pretrained_networks.vgg16.slice2', 'pretrained_networks.vgg16.slice3', 'pretrained_networks.vgg16.slice4', 'pretrained_networks.vgg16.slice5', 'collections.namedtuple', 'collections.namedtuple.'], 'methods', ['None'], ['', '', '', 'def', 'forward', '(', 'self', ',', 'X', ')', ':', '\\n', '        ', 'h', '=', 'self', '.', 'slice1', '(', 'X', ')', '\\n', 'h_relu1_2', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice2', '(', 'h', ')', '\\n', 'h_relu2_2', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice3', '(', 'h', ')', '\\n', 'h_relu3_3', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice4', '(', 'h', ')', '\\n', 'h_relu4_3', '=', 'h', '\\n', 'h', '=', 'self', '.', 'slice5', '(', 'h', ')', '\\n', 'h_relu5_3', '=', 'h', '\\n', 'vgg_outputs', '=', 'namedtuple', '(', '\"VggOutputs\"', ',', '[', \"'relu1_2'\", ',', \"'relu2_2'\", ',', \"'relu3_3'\", ',', \"'relu4_3'\", ',', \"'relu5_3'\", ']', ')', '\\n', 'out', '=', 'vgg_outputs', '(', 'h_relu1_2', ',', 'h_relu2_2', ',', 'h_relu3_3', ',', 'h_relu4_3', ',', 'h_relu5_3', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.resnet.__init__': [[140, 162], ['super().__init__', 'torchvision.models.resnet18', 'torchvision.models.resnet34', 'torchvision.models.resnet50', 'torchvision.models.resnet101', 'torchvision.models.resnet152'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'requires_grad', '=', 'False', ',', 'pretrained', '=', 'True', ',', 'num', '=', '18', ')', ':', '\\n', '        ', 'super', '(', 'resnet', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'if', '(', 'num', '==', '18', ')', ':', '\\n', '            ', 'self', '.', 'net', '=', 'tv', '.', 'resnet18', '(', 'pretrained', '=', 'pretrained', ')', '\\n', '', 'elif', '(', 'num', '==', '34', ')', ':', '\\n', '            ', 'self', '.', 'net', '=', 'tv', '.', 'resnet34', '(', 'pretrained', '=', 'pretrained', ')', '\\n', '', 'elif', '(', 'num', '==', '50', ')', ':', '\\n', '            ', 'self', '.', 'net', '=', 'tv', '.', 'resnet50', '(', 'pretrained', '=', 'pretrained', ')', '\\n', '', 'elif', '(', 'num', '==', '101', ')', ':', '\\n', '            ', 'self', '.', 'net', '=', 'tv', '.', 'resnet101', '(', 'pretrained', '=', 'pretrained', ')', '\\n', '', 'elif', '(', 'num', '==', '152', ')', ':', '\\n', '            ', 'self', '.', 'net', '=', 'tv', '.', 'resnet152', '(', 'pretrained', '=', 'pretrained', ')', '\\n', '', 'self', '.', 'N_slices', '=', '5', '\\n', '\\n', 'self', '.', 'conv1', '=', 'self', '.', 'net', '.', 'conv1', '\\n', 'self', '.', 'bn1', '=', 'self', '.', 'net', '.', 'bn1', '\\n', 'self', '.', 'relu', '=', 'self', '.', 'net', '.', 'relu', '\\n', 'self', '.', 'maxpool', '=', 'self', '.', 'net', '.', 'maxpool', '\\n', 'self', '.', 'layer1', '=', 'self', '.', 'net', '.', 'layer1', '\\n', 'self', '.', 'layer2', '=', 'self', '.', 'net', '.', 'layer2', '\\n', 'self', '.', 'layer3', '=', 'self', '.', 'net', '.', 'layer3', '\\n', 'self', '.', 'layer4', '=', 'self', '.', 'net', '.', 'layer4', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.resnet.forward': [[163, 182], ['pretrained_networks.resnet.conv1', 'pretrained_networks.resnet.bn1', 'pretrained_networks.resnet.relu', 'pretrained_networks.resnet.maxpool', 'pretrained_networks.resnet.layer1', 'pretrained_networks.resnet.layer2', 'pretrained_networks.resnet.layer3', 'pretrained_networks.resnet.layer4', 'collections.namedtuple', 'collections.namedtuple.'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ',', 'X', ')', ':', '\\n', '        ', 'h', '=', 'self', '.', 'conv1', '(', 'X', ')', '\\n', 'h', '=', 'self', '.', 'bn1', '(', 'h', ')', '\\n', 'h', '=', 'self', '.', 'relu', '(', 'h', ')', '\\n', 'h_relu1', '=', 'h', '\\n', 'h', '=', 'self', '.', 'maxpool', '(', 'h', ')', '\\n', 'h', '=', 'self', '.', 'layer1', '(', 'h', ')', '\\n', 'h_conv2', '=', 'h', '\\n', 'h', '=', 'self', '.', 'layer2', '(', 'h', ')', '\\n', 'h_conv3', '=', 'h', '\\n', 'h', '=', 'self', '.', 'layer3', '(', 'h', ')', '\\n', 'h_conv4', '=', 'h', '\\n', 'h', '=', 'self', '.', 'layer4', '(', 'h', ')', '\\n', 'h_conv5', '=', 'h', '\\n', '\\n', 'outputs', '=', 'namedtuple', '(', '\"Outputs\"', ',', '[', \"'relu1'\", ',', \"'conv2'\", ',', \"'conv3'\", ',', \"'conv4'\", ',', \"'conv5'\", ']', ')', '\\n', 'out', '=', 'outputs', '(', 'h_relu1', ',', 'h_conv2', ',', 'h_conv3', ',', 'h_conv4', ',', 'h_conv5', ')', '\\n', '\\n', 'return', 'out', '\\n', '', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.PerceptualLoss.__init__': [[15, 26], ['super().__init__', 'print', 'lpips.dist_model.DistModel', '__init__.PerceptualLoss.model.initialize', 'print', 'print', '__init__.PerceptualLoss.model.name'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.initialize', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.name'], ['    ', 'def', '__init__', '(', 'self', ',', 'model', '=', \"'net-lin'\", ',', 'net', '=', \"'alex'\", ',', 'colorspace', '=', \"'rgb'\", ',', 'spatial', '=', 'False', ',', 'use_gpu', '=', 'True', ',', 'gpu_ids', '=', '[', '0', ']', ')', ':', '# VGG using our perceptually-learned weights (LPIPS metric)', '\\n', '# def __init__(self, model=\\'net\\', net=\\'vgg\\', use_gpu=True): # \"default\" way of using VGG as a perceptual loss', '\\n', '        ', 'super', '(', 'PerceptualLoss', ',', 'self', ')', '.', '__init__', '(', ')', '\\n', 'print', '(', \"'Setting up Perceptual loss...'\", ')', '\\n', 'self', '.', 'use_gpu', '=', 'use_gpu', '\\n', 'self', '.', 'spatial', '=', 'spatial', '\\n', 'self', '.', 'gpu_ids', '=', 'gpu_ids', '\\n', 'self', '.', 'model', '=', 'dist_model', '.', 'DistModel', '(', ')', '\\n', 'self', '.', 'model', '.', 'initialize', '(', 'model', '=', 'model', ',', 'net', '=', 'net', ',', 'use_gpu', '=', 'use_gpu', ',', 'colorspace', '=', 'colorspace', ',', 'spatial', '=', 'self', '.', 'spatial', ',', 'gpu_ids', '=', 'gpu_ids', ')', '\\n', 'print', '(', \"'...[%s] initialized'\", '%', 'self', '.', 'model', '.', 'name', '(', ')', ')', '\\n', 'print', '(', \"'...Done'\", ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.PerceptualLoss.forward': [[27, 42], ['__init__.PerceptualLoss.model.forward'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward'], ['', 'def', 'forward', '(', 'self', ',', 'pred', ',', 'target', ',', 'normalize', '=', 'False', ')', ':', '\\n', '        ', '\"\"\"\\n        Pred and target are Variables.\\n        If normalize is True, assumes the images are between [0,1] and then scales them between [-1,+1]\\n        If normalize is False, assumes the images are already between [-1,+1]\\n\\n        Inputs pred and target are Nx3xHxW\\n        Output pytorch Variable N long\\n        \"\"\"', '\\n', '\\n', 'if', 'normalize', ':', '\\n', '            ', 'target', '=', '2', '*', 'target', '-', '1', '\\n', 'pred', '=', '2', '*', 'pred', '-', '1', '\\n', '\\n', '', 'return', 'self', '.', 'model', '.', 'forward', '(', 'target', ',', 'pred', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.normalize_tensor': [[43, 46], ['torch.sqrt', 'torch.sum'], 'function', ['None'], ['', '', 'def', 'normalize_tensor', '(', 'in_feat', ',', 'eps', '=', '1e-10', ')', ':', '\\n', '    ', 'norm_factor', '=', 'torch', '.', 'sqrt', '(', 'torch', '.', 'sum', '(', 'in_feat', '**', '2', ',', 'dim', '=', '1', ',', 'keepdim', '=', 'True', ')', ')', '\\n', 'return', 'in_feat', '/', '(', 'norm_factor', '+', 'eps', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.l2': [[47, 49], ['numpy.mean'], 'function', ['None'], ['', 'def', 'l2', '(', 'p0', ',', 'p1', ',', 'range', '=', '255.', ')', ':', '\\n', '    ', 'return', '.5', '*', 'np', '.', 'mean', '(', '(', 'p0', '/', 'range', '-', 'p1', '/', 'range', ')', '**', '2', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.psnr': [[50, 52], ['numpy.log10', 'numpy.mean'], 'function', ['None'], ['', 'def', 'psnr', '(', 'p0', ',', 'p1', ',', 'peak', '=', '255.', ')', ':', '\\n', '    ', 'return', '10', '*', 'np', '.', 'log10', '(', 'peak', '**', '2', '/', 'np', '.', 'mean', '(', '(', '1.', '*', 'p0', '-', '1.', '*', 'p1', ')', '**', '2', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.dssim': [[53, 55], ['skimage.metrics.structural_similarity'], 'function', ['None'], ['', 'def', 'dssim', '(', 'p0', ',', 'p1', ',', 'range', '=', '255.', ')', ':', '\\n', '    ', 'return', '(', '1', '-', 'compare_ssim', '(', 'p0', ',', 'p1', ',', 'data_range', '=', 'range', ',', 'multichannel', '=', 'True', ')', ')', '/', '2.', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.rgb2lab': [[103, 106], ['color.rgb2lab'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.rgb2lab'], ['', '', 'def', 'rgb2lab', '(', 'input', ')', ':', '\\n', '    ', 'from', 'skimage', 'import', 'color', '\\n', 'return', 'color', '.', 'rgb2lab', '(', 'input', '/', '255.', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2np': [[63, 66], ['tensor_obj[].cpu().float().numpy().transpose', 'tensor_obj[].cpu().float().numpy', 'tensor_obj[].cpu().float', 'tensor_obj[].cpu'], 'function', ['None'], ['', 'def', 'tensor2np', '(', 'tensor_obj', ')', ':', '\\n', '# change dimension of a tensor object into a numpy array', '\\n', '    ', 'return', 'tensor_obj', '[', '0', ']', '.', 'cpu', '(', ')', '.', 'float', '(', ')', '.', 'numpy', '(', ')', '.', 'transpose', '(', '(', '1', ',', '2', ',', '0', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.np2tensor': [[67, 70], ['torch.Tensor', 'np_obj[].transpose'], 'function', ['None'], ['', 'def', 'np2tensor', '(', 'np_obj', ')', ':', '\\n', '# change dimenion of np array into tensor array', '\\n', '    ', 'return', 'torch', '.', 'Tensor', '(', 'np_obj', '[', ':', ',', ':', ',', ':', ',', 'np', '.', 'newaxis', ']', '.', 'transpose', '(', '(', '3', ',', '2', ',', '0', ',', '1', ')', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2tensorlab': [[71, 84], ['__init__.tensor2im', 'color.rgb2lab', '__init__.np2tensor'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.rgb2lab', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.np2tensor'], ['', 'def', 'tensor2tensorlab', '(', 'image_tensor', ',', 'to_norm', '=', 'True', ',', 'mc_only', '=', 'False', ')', ':', '\\n', '# image tensor to lab tensor', '\\n', '    ', 'from', 'skimage', 'import', 'color', '\\n', '\\n', 'img', '=', 'tensor2im', '(', 'image_tensor', ')', '\\n', 'img_lab', '=', 'color', '.', 'rgb2lab', '(', 'img', ')', '\\n', 'if', '(', 'mc_only', ')', ':', '\\n', '        ', 'img_lab', '[', ':', ',', ':', ',', '0', ']', '=', 'img_lab', '[', ':', ',', ':', ',', '0', ']', '-', '50', '\\n', '', 'if', '(', 'to_norm', 'and', 'not', 'mc_only', ')', ':', '\\n', '        ', 'img_lab', '[', ':', ',', ':', ',', '0', ']', '=', 'img_lab', '[', ':', ',', ':', ',', '0', ']', '-', '50', '\\n', 'img_lab', '=', 'img_lab', '/', '100.', '\\n', '\\n', '', 'return', 'np2tensor', '(', 'img_lab', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensorlab2tensor': [[85, 102], ['warnings.filterwarnings', '__init__.tensor2np', 'numpy.clip', 'color.rgb2lab', '__init__.np2tensor', '__init__.im2tensor', 'color.lab2rgb', 'rgb_back.astype', 'numpy.isclose', '__init__.im2tensor', 'lab.astype', 'numpy.prod'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2np', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.rgb2lab', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.np2tensor', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.im2tensor', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.im2tensor'], ['', 'def', 'tensorlab2tensor', '(', 'lab_tensor', ',', 'return_inbnd', '=', 'False', ')', ':', '\\n', '    ', 'from', 'skimage', 'import', 'color', '\\n', 'import', 'warnings', '\\n', 'warnings', '.', 'filterwarnings', '(', '\"ignore\"', ')', '\\n', '\\n', 'lab', '=', 'tensor2np', '(', 'lab_tensor', ')', '*', '100.', '\\n', 'lab', '[', ':', ',', ':', ',', '0', ']', '=', 'lab', '[', ':', ',', ':', ',', '0', ']', '+', '50', '\\n', '\\n', 'rgb_back', '=', '255.', '*', 'np', '.', 'clip', '(', 'color', '.', 'lab2rgb', '(', 'lab', '.', 'astype', '(', \"'float'\", ')', ')', ',', '0', ',', '1', ')', '\\n', 'if', '(', 'return_inbnd', ')', ':', '\\n', '# convert back to lab, see if we match', '\\n', '        ', 'lab_back', '=', 'color', '.', 'rgb2lab', '(', 'rgb_back', '.', 'astype', '(', \"'uint8'\", ')', ')', '\\n', 'mask', '=', '1.', '*', 'np', '.', 'isclose', '(', 'lab_back', ',', 'lab', ',', 'atol', '=', '2.', ')', '\\n', 'mask', '=', 'np2tensor', '(', 'np', '.', 'prod', '(', 'mask', ',', 'axis', '=', '2', ')', '[', ':', ',', ':', ',', 'np', '.', 'newaxis', ']', ')', '\\n', 'return', '(', 'im2tensor', '(', 'rgb_back', ')', ',', 'mask', ')', '\\n', '', 'else', ':', '\\n', '        ', 'return', 'im2tensor', '(', 'rgb_back', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im': [[152, 157], ['image_tensor[].cpu().float().numpy', 'image_tensor[].cpu().float().numpy.astype', 'image_tensor[].cpu().float', 'numpy.transpose', 'image_tensor[].cpu'], 'function', ['None'], ['', 'def', 'tensor2im', '(', 'image_tensor', ',', 'imtype', '=', 'np', '.', 'uint8', ',', 'cent', '=', '1.', ',', 'factor', '=', '255.', '/', '2.', ')', ':', '\\n', '# def tensor2im(image_tensor, imtype=np.uint8, cent=1., factor=1.):', '\\n', '    ', 'image_numpy', '=', 'image_tensor', '[', '0', ']', '.', 'cpu', '(', ')', '.', 'float', '(', ')', '.', 'numpy', '(', ')', '\\n', 'image_numpy', '=', '(', 'np', '.', 'transpose', '(', 'image_numpy', ',', '(', '1', ',', '2', ',', '0', ')', ')', '+', 'cent', ')', '*', 'factor', '\\n', 'return', 'image_numpy', '.', 'astype', '(', 'imtype', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.im2tensor': [[158, 162], ['torch.Tensor', '[].transpose'], 'function', ['None'], ['', 'def', 'im2tensor', '(', 'image', ',', 'imtype', '=', 'np', '.', 'uint8', ',', 'cent', '=', '1.', ',', 'factor', '=', '255.', '/', '2.', ')', ':', '\\n', '# def im2tensor(image, imtype=np.uint8, cent=1., factor=1.):', '\\n', '    ', 'return', 'torch', '.', 'Tensor', '(', '(', 'image', '/', 'factor', '-', 'cent', ')', '\\n', '[', ':', ',', ':', ',', ':', ',', 'np', '.', 'newaxis', ']', '.', 'transpose', '(', '(', '3', ',', '2', ',', '0', ',', '1', ')', ')', ')', '\\n', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2vec': [[116, 118], ['vector_tensor.data.cpu().numpy', 'vector_tensor.data.cpu'], 'function', ['None'], ['', 'def', 'tensor2vec', '(', 'vector_tensor', ')', ':', '\\n', '    ', 'return', 'vector_tensor', '.', 'data', '.', 'cpu', '(', ')', '.', 'numpy', '(', ')', '[', ':', ',', ':', ',', '0', ',', '0', ']', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.voc_ap': [[119, 151], ['numpy.arange', 'numpy.concatenate', 'numpy.concatenate', 'range', 'numpy.sum', 'numpy.maximum', 'numpy.where', 'numpy.sum', 'numpy.max'], 'function', ['None'], ['', 'def', 'voc_ap', '(', 'rec', ',', 'prec', ',', 'use_07_metric', '=', 'False', ')', ':', '\\n', '    ', '\"\"\" ap = voc_ap(rec, prec, [use_07_metric])\\n    Compute VOC AP given precision and recall.\\n    If use_07_metric is true, uses the\\n    VOC 07 11 point method (default:False).\\n    \"\"\"', '\\n', 'if', 'use_07_metric', ':', '\\n', '# 11 point metric', '\\n', '        ', 'ap', '=', '0.', '\\n', 'for', 't', 'in', 'np', '.', 'arange', '(', '0.', ',', '1.1', ',', '0.1', ')', ':', '\\n', '            ', 'if', 'np', '.', 'sum', '(', 'rec', '>=', 't', ')', '==', '0', ':', '\\n', '                ', 'p', '=', '0', '\\n', '', 'else', ':', '\\n', '                ', 'p', '=', 'np', '.', 'max', '(', 'prec', '[', 'rec', '>=', 't', ']', ')', '\\n', '', 'ap', '=', 'ap', '+', 'p', '/', '11.', '\\n', '', '', 'else', ':', '\\n', '# correct AP calculation', '\\n', '# first append sentinel values at the end', '\\n', '        ', 'mrec', '=', 'np', '.', 'concatenate', '(', '(', '[', '0.', ']', ',', 'rec', ',', '[', '1.', ']', ')', ')', '\\n', 'mpre', '=', 'np', '.', 'concatenate', '(', '(', '[', '0.', ']', ',', 'prec', ',', '[', '0.', ']', ')', ')', '\\n', '\\n', '# compute the precision envelope', '\\n', 'for', 'i', 'in', 'range', '(', 'mpre', '.', 'size', '-', '1', ',', '0', ',', '-', '1', ')', ':', '\\n', '            ', 'mpre', '[', 'i', '-', '1', ']', '=', 'np', '.', 'maximum', '(', 'mpre', '[', 'i', '-', '1', ']', ',', 'mpre', '[', 'i', ']', ')', '\\n', '\\n', '# to calculate area under PR curve, look for points', '\\n', '# where X axis (recall) changes value', '\\n', '', 'i', '=', 'np', '.', 'where', '(', 'mrec', '[', '1', ':', ']', '!=', 'mrec', '[', ':', '-', '1', ']', ')', '[', '0', ']', '\\n', '\\n', '# and sum (\\\\Delta recall) * prec', '\\n', 'ap', '=', 'np', '.', 'sum', '(', '(', 'mrec', '[', 'i', '+', '1', ']', '-', 'mrec', '[', 'i', ']', ')', '*', 'mpre', '[', 'i', '+', '1', ']', ')', '\\n', '', 'return', 'ap', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.__init__': [[9, 11], ['None'], 'methods', ['None'], ['    ', 'def', '__init__', '(', 'self', ')', ':', '\\n', '        ', 'pass', ';', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.name': [[12, 14], ['None'], 'methods', ['None'], ['', 'def', 'name', '(', 'self', ')', ':', '\\n', '        ', 'return', \"'BaseModel'\", '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.initialize': [[15, 18], ['None'], 'methods', ['None'], ['', 'def', 'initialize', '(', 'self', ',', 'use_gpu', '=', 'True', ',', 'gpu_ids', '=', '[', '0', ']', ')', ':', '\\n', '        ', 'self', '.', 'use_gpu', '=', 'use_gpu', '\\n', 'self', '.', 'gpu_ids', '=', 'gpu_ids', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.forward': [[19, 21], ['None'], 'methods', ['None'], ['', 'def', 'forward', '(', 'self', ')', ':', '\\n', '        ', 'pass', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.get_image_paths': [[53, 55], ['None'], 'methods', ['None'], ['', 'def', 'get_image_paths', '(', 'self', ')', ':', '\\n', '        ', 'return', 'self', '.', 'image_paths', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.optimize_parameters': [[25, 27], ['None'], 'methods', ['None'], ['', 'def', 'optimize_parameters', '(', 'self', ')', ':', '\\n', '        ', 'pass', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.get_current_visuals': [[28, 30], ['None'], 'methods', ['None'], ['', 'def', 'get_current_visuals', '(', 'self', ')', ':', '\\n', '        ', 'return', 'self', '.', 'input', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.get_current_errors': [[31, 33], ['None'], 'methods', ['None'], ['', 'def', 'get_current_errors', '(', 'self', ')', ':', '\\n', '        ', 'return', '{', '}', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save': [[34, 36], ['None'], 'methods', ['None'], ['', 'def', 'save', '(', 'self', ',', 'label', ')', ':', '\\n', '        ', 'pass', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save_network': [[38, 42], ['os.path.join', 'torch.save', 'network.state_dict'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save'], ['', 'def', 'save_network', '(', 'self', ',', 'network', ',', 'path', ',', 'network_label', ',', 'epoch_label', ')', ':', '\\n', '        ', 'save_filename', '=', \"'%s_net_%s.pth'\", '%', '(', 'epoch_label', ',', 'network_label', ')', '\\n', 'save_path', '=', 'os', '.', 'path', '.', 'join', '(', 'path', ',', 'save_filename', ')', '\\n', 'torch', '.', 'save', '(', 'network', '.', 'state_dict', '(', ')', ',', 'save_path', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.load_network': [[44, 49], ['os.path.join', 'print', 'network.load_state_dict', 'torch.load'], 'methods', ['None'], ['', 'def', 'load_network', '(', 'self', ',', 'network', ',', 'network_label', ',', 'epoch_label', ')', ':', '\\n', '        ', 'save_filename', '=', \"'%s_net_%s.pth'\", '%', '(', 'epoch_label', ',', 'network_label', ')', '\\n', 'save_path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'save_dir', ',', 'save_filename', ')', '\\n', 'print', '(', \"'Loading network from %s'\", '%', 'save_path', ')', '\\n', 'network', '.', 'load_state_dict', '(', 'torch', '.', 'load', '(', 'save_path', ')', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.update_learning_rate': [[50, 52], ['None'], 'methods', ['None'], ['', 'def', 'update_learning_rate', '(', ')', ':', '\\n', '        ', 'pass', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save_done': [[56, 59], ['numpy.save', 'numpy.savetxt', 'os.path.join', 'os.path.join'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save'], ['', 'def', 'save_done', '(', 'self', ',', 'flag', '=', 'False', ')', ':', '\\n', '        ', 'np', '.', 'save', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'save_dir', ',', \"'done_flag'\", ')', ',', 'flag', ')', '\\n', 'np', '.', 'savetxt', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'save_dir', ',', \"'done_flag'\", ')', ',', '[', 'flag', ',', ']', ',', 'fmt', '=', \"'%i'\", ')', '\\n', '', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLUFunctionBackward.forward': [[21, 45], ['ctx.save_for_backward', 'grad_output.new_empty', 'fused.fused_bias_act', 'grad_output.contiguous', 'list', 'fused.fused_bias_act.sum().detach', 'range', 'fused.fused_bias_act.sum'], 'methods', ['None'], ['    ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', 'ctx', ',', 'grad_output', ',', 'out', ',', 'bias', ',', 'negative_slope', ',', 'scale', ')', ':', '\\n', '        ', 'ctx', '.', 'save_for_backward', '(', 'out', ')', '\\n', 'ctx', '.', 'negative_slope', '=', 'negative_slope', '\\n', 'ctx', '.', 'scale', '=', 'scale', '\\n', '\\n', 'empty', '=', 'grad_output', '.', 'new_empty', '(', '0', ')', '\\n', '\\n', 'grad_input', '=', 'fused', '.', 'fused_bias_act', '(', '\\n', 'grad_output', '.', 'contiguous', '(', ')', ',', 'empty', ',', 'out', ',', '3', ',', '1', ',', 'negative_slope', ',', 'scale', '\\n', ')', '\\n', '\\n', 'dim', '=', '[', '0', ']', '\\n', '\\n', 'if', 'grad_input', '.', 'ndim', '>', '2', ':', '\\n', '            ', 'dim', '+=', 'list', '(', 'range', '(', '2', ',', 'grad_input', '.', 'ndim', ')', ')', '\\n', '\\n', '', 'if', 'bias', ':', '\\n', '            ', 'grad_bias', '=', 'grad_input', '.', 'sum', '(', 'dim', ')', '.', 'detach', '(', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'grad_bias', '=', 'empty', '\\n', '\\n', '', 'return', 'grad_input', ',', 'grad_bias', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLUFunctionBackward.backward': [[46, 54], ['fused.fused_bias_act'], 'methods', ['None'], ['', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'gradgrad_input', ',', 'gradgrad_bias', ')', ':', '\\n', '        ', 'out', ',', '=', 'ctx', '.', 'saved_tensors', '\\n', 'gradgrad_out', '=', 'fused', '.', 'fused_bias_act', '(', '\\n', 'gradgrad_input', ',', 'gradgrad_bias', ',', 'out', ',', '3', ',', '1', ',', 'ctx', '.', 'negative_slope', ',', 'ctx', '.', 'scale', '\\n', ')', '\\n', '\\n', 'return', 'gradgrad_out', ',', 'None', ',', 'None', ',', 'None', ',', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLUFunction.forward': [[57, 72], ['input.new_empty', 'fused.fused_bias_act', 'ctx.save_for_backward'], 'methods', ['None'], ['    ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', 'ctx', ',', 'input', ',', 'bias', ',', 'negative_slope', ',', 'scale', ')', ':', '\\n', '        ', 'empty', '=', 'input', '.', 'new_empty', '(', '0', ')', '\\n', '\\n', 'ctx', '.', 'bias', '=', 'bias', 'is', 'not', 'None', '\\n', '\\n', 'if', 'bias', 'is', 'None', ':', '\\n', '            ', 'bias', '=', 'empty', '\\n', '\\n', '', 'out', '=', 'fused', '.', 'fused_bias_act', '(', 'input', ',', 'bias', ',', 'empty', ',', '3', ',', '0', ',', 'negative_slope', ',', 'scale', ')', '\\n', 'ctx', '.', 'save_for_backward', '(', 'out', ')', '\\n', 'ctx', '.', 'negative_slope', '=', 'negative_slope', '\\n', 'ctx', '.', 'scale', '=', 'scale', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLUFunction.backward': [[73, 85], ['FusedLeakyReLUFunctionBackward.apply'], 'methods', ['None'], ['', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'grad_output', ')', ':', '\\n', '        ', 'out', ',', '=', 'ctx', '.', 'saved_tensors', '\\n', '\\n', 'grad_input', ',', 'grad_bias', '=', 'FusedLeakyReLUFunctionBackward', '.', 'apply', '(', '\\n', 'grad_output', ',', 'out', ',', 'ctx', '.', 'bias', ',', 'ctx', '.', 'negative_slope', ',', 'ctx', '.', 'scale', '\\n', ')', '\\n', '\\n', 'if', 'not', 'ctx', '.', 'bias', ':', '\\n', '            ', 'grad_bias', '=', 'None', '\\n', '\\n', '', 'return', 'grad_input', ',', 'grad_bias', ',', 'None', ',', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__': [[88, 99], ['torch.nn.Module.__init__', 'torch.nn.Parameter', 'torch.zeros'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__'], ['    ', 'def', '__init__', '(', 'self', ',', 'channel', ',', 'bias', '=', 'True', ',', 'negative_slope', '=', '0.2', ',', 'scale', '=', '2', '**', '0.5', ')', ':', '\\n', '        ', 'super', '(', ')', '.', '__init__', '(', ')', '\\n', '\\n', 'if', 'bias', ':', '\\n', '            ', 'self', '.', 'bias', '=', 'nn', '.', 'Parameter', '(', 'torch', '.', 'zeros', '(', 'channel', ')', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'self', '.', 'bias', '=', 'None', '\\n', '\\n', '', 'self', '.', 'negative_slope', '=', 'negative_slope', '\\n', 'self', '.', 'scale', '=', 'scale', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.forward': [[100, 102], ['fused_act.fused_leaky_relu'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.fused_leaky_relu'], ['', 'def', 'forward', '(', 'self', ',', 'input', ')', ':', '\\n', '        ', 'return', 'fused_leaky_relu', '(', 'input', ',', 'self', '.', 'bias', ',', 'self', '.', 'negative_slope', ',', 'self', '.', 'scale', ')', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.fused_leaky_relu': [[104, 120], ['FusedLeakyReLUFunction.apply', 'torch.nn.functional.leaky_relu', 'torch.nn.functional.leaky_relu', 'bias.view'], 'function', ['None'], ['', '', 'def', 'fused_leaky_relu', '(', 'input', ',', 'bias', '=', 'None', ',', 'negative_slope', '=', '0.2', ',', 'scale', '=', '2', '**', '0.5', ')', ':', '\\n', '    ', 'if', 'input', '.', 'device', '.', 'type', '==', '\"cpu\"', ':', '\\n', '        ', 'if', 'bias', 'is', 'not', 'None', ':', '\\n', '            ', 'rest_dim', '=', '[', '1', ']', '*', '(', 'input', '.', 'ndim', '-', 'bias', '.', 'ndim', '-', '1', ')', '\\n', 'return', '(', '\\n', 'F', '.', 'leaky_relu', '(', '\\n', 'input', '+', 'bias', '.', 'view', '(', '1', ',', 'bias', '.', 'shape', '[', '0', ']', ',', '*', 'rest_dim', ')', ',', 'negative_slope', '=', '0.2', '\\n', ')', '\\n', '*', 'scale', '\\n', ')', '\\n', '\\n', '', 'else', ':', '\\n', '            ', 'return', 'F', '.', 'leaky_relu', '(', 'input', ',', 'negative_slope', '=', '0.2', ')', '*', 'scale', '\\n', '\\n', '', '', 'else', ':', '\\n', '        ', 'return', 'FusedLeakyReLUFunction', '.', 'apply', '(', 'input', ',', 'bias', ',', 'negative_slope', ',', 'scale', ')', '\\n', '', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.no_weight_gradients': [[12, 20], ['None'], 'function', ['None'], ['@', 'contextlib', '.', 'contextmanager', '\\n', 'def', 'no_weight_gradients', '(', ')', ':', '\\n', '    ', 'global', 'weight_gradients_disabled', '\\n', '\\n', 'old', '=', 'weight_gradients_disabled', '\\n', 'weight_gradients_disabled', '=', 'True', '\\n', 'yield', '\\n', 'weight_gradients_disabled', '=', 'old', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d': [[22, 42], ['conv2d_gradfix.could_use_op', 'torch.nn.functional.conv2d', 'conv2d_gradfix().apply', 'conv2d_gradfix.conv2d_gradfix'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.could_use_op', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d_gradfix'], ['', 'def', 'conv2d', '(', 'input', ',', 'weight', ',', 'bias', '=', 'None', ',', 'stride', '=', '1', ',', 'padding', '=', '0', ',', 'dilation', '=', '1', ',', 'groups', '=', '1', ')', ':', '\\n', '    ', 'if', 'could_use_op', '(', 'input', ')', ':', '\\n', '        ', 'return', 'conv2d_gradfix', '(', '\\n', 'transpose', '=', 'False', ',', '\\n', 'weight_shape', '=', 'weight', '.', 'shape', ',', '\\n', 'stride', '=', 'stride', ',', '\\n', 'padding', '=', 'padding', ',', '\\n', 'output_padding', '=', '0', ',', '\\n', 'dilation', '=', 'dilation', ',', '\\n', 'groups', '=', 'groups', ',', '\\n', ')', '.', 'apply', '(', 'input', ',', 'weight', ',', 'bias', ')', '\\n', '\\n', '', 'return', 'F', '.', 'conv2d', '(', '\\n', 'input', '=', 'input', ',', '\\n', 'weight', '=', 'weight', ',', '\\n', 'bias', '=', 'bias', ',', '\\n', 'stride', '=', 'stride', ',', '\\n', 'padding', '=', 'padding', ',', '\\n', 'dilation', '=', 'dilation', ',', '\\n', 'groups', '=', 'groups', ',', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv_transpose2d': [[45, 75], ['conv2d_gradfix.could_use_op', 'torch.nn.functional.conv_transpose2d', 'conv2d_gradfix().apply', 'conv2d_gradfix.conv2d_gradfix'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.could_use_op', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv_transpose2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d_gradfix'], ['', 'def', 'conv_transpose2d', '(', '\\n', 'input', ',', '\\n', 'weight', ',', '\\n', 'bias', '=', 'None', ',', '\\n', 'stride', '=', '1', ',', '\\n', 'padding', '=', '0', ',', '\\n', 'output_padding', '=', '0', ',', '\\n', 'groups', '=', '1', ',', '\\n', 'dilation', '=', '1', ',', '\\n', ')', ':', '\\n', '    ', 'if', 'could_use_op', '(', 'input', ')', ':', '\\n', '        ', 'return', 'conv2d_gradfix', '(', '\\n', 'transpose', '=', 'True', ',', '\\n', 'weight_shape', '=', 'weight', '.', 'shape', ',', '\\n', 'stride', '=', 'stride', ',', '\\n', 'padding', '=', 'padding', ',', '\\n', 'output_padding', '=', 'output_padding', ',', '\\n', 'groups', '=', 'groups', ',', '\\n', 'dilation', '=', 'dilation', ',', '\\n', ')', '.', 'apply', '(', 'input', ',', 'weight', ',', 'bias', ')', '\\n', '\\n', '', 'return', 'F', '.', 'conv_transpose2d', '(', '\\n', 'input', '=', 'input', ',', '\\n', 'weight', '=', 'weight', ',', '\\n', 'bias', '=', 'bias', ',', '\\n', 'stride', '=', 'stride', ',', '\\n', 'padding', '=', 'padding', ',', '\\n', 'output_padding', '=', 'output_padding', ',', '\\n', 'dilation', '=', 'dilation', ',', '\\n', 'groups', '=', 'groups', ',', '\\n', ')', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.could_use_op': [[78, 93], ['any', 'warnings.warn', 'torch.__version__.startswith'], 'function', ['None'], ['', 'def', 'could_use_op', '(', 'input', ')', ':', '\\n', '    ', 'if', '(', 'not', 'enabled', ')', 'or', '(', 'not', 'torch', '.', 'backends', '.', 'cudnn', '.', 'enabled', ')', ':', '\\n', '        ', 'return', 'False', '\\n', '\\n', '', 'if', 'input', '.', 'device', '.', 'type', '!=', '\"cuda\"', ':', '\\n', '        ', 'return', 'False', '\\n', '\\n', '', 'if', 'any', '(', 'torch', '.', '__version__', '.', 'startswith', '(', 'x', ')', 'for', 'x', 'in', '[', '\"1.7.\"', ',', '\"1.8.\"', ']', ')', ':', '\\n', '        ', 'return', 'True', '\\n', '\\n', '', 'warnings', '.', 'warn', '(', '\\n', 'f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"', '\\n', ')', '\\n', '\\n', 'return', 'False', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.ensure_tuple': [[95, 99], ['isinstance', 'tuple'], 'function', ['None'], ['', 'def', 'ensure_tuple', '(', 'xs', ',', 'ndim', ')', ':', '\\n', '    ', 'xs', '=', 'tuple', '(', 'xs', ')', 'if', 'isinstance', '(', 'xs', ',', '(', 'tuple', ',', 'list', ')', ')', 'else', '(', 'xs', ',', ')', '*', 'ndim', '\\n', '\\n', 'return', 'xs', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d_gradfix': [[104, 228], ['tuple', 'conv2d_gradfix.ensure_tuple', 'conv2d_gradfix.ensure_tuple', 'conv2d_gradfix.ensure_tuple', 'conv2d_gradfix.ensure_tuple', 'dict', 'ctx.save_for_backward', 'torch._C._jit_get_operation', 'torch._C._jit_get_operation.', 'ctx.save_for_backward', 'range', 'torch.nn.functional.conv2d', 'torch.nn.functional.conv_transpose2d', 'conv2d_gradfix.conv2d_gradfix.calc_output_padding'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.ensure_tuple', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.ensure_tuple', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.ensure_tuple', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.ensure_tuple', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d', 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv_transpose2d'], ['def', 'conv2d_gradfix', '(', '\\n', 'transpose', ',', 'weight_shape', ',', 'stride', ',', 'padding', ',', 'output_padding', ',', 'dilation', ',', 'groups', '\\n', ')', ':', '\\n', '    ', 'ndim', '=', '2', '\\n', 'weight_shape', '=', 'tuple', '(', 'weight_shape', ')', '\\n', 'stride', '=', 'ensure_tuple', '(', 'stride', ',', 'ndim', ')', '\\n', 'padding', '=', 'ensure_tuple', '(', 'padding', ',', 'ndim', ')', '\\n', 'output_padding', '=', 'ensure_tuple', '(', 'output_padding', ',', 'ndim', ')', '\\n', 'dilation', '=', 'ensure_tuple', '(', 'dilation', ',', 'ndim', ')', '\\n', '\\n', 'key', '=', '(', 'transpose', ',', 'weight_shape', ',', 'stride', ',', 'padding', ',', 'output_padding', ',', 'dilation', ',', 'groups', ')', '\\n', 'if', 'key', 'in', 'conv2d_gradfix_cache', ':', '\\n', '        ', 'return', 'conv2d_gradfix_cache', '[', 'key', ']', '\\n', '\\n', '', 'common_kwargs', '=', 'dict', '(', '\\n', 'stride', '=', 'stride', ',', 'padding', '=', 'padding', ',', 'dilation', '=', 'dilation', ',', 'groups', '=', 'groups', '\\n', ')', '\\n', '\\n', 'def', 'calc_output_padding', '(', 'input_shape', ',', 'output_shape', ')', ':', '\\n', '        ', 'if', 'transpose', ':', '\\n', '            ', 'return', '[', '0', ',', '0', ']', '\\n', '\\n', '', 'return', '[', '\\n', 'input_shape', '[', 'i', '+', '2', ']', '\\n', '-', '(', 'output_shape', '[', 'i', '+', '2', ']', '-', '1', ')', '*', 'stride', '[', 'i', ']', '\\n', '-', '(', '1', '-', '2', '*', 'padding', '[', 'i', ']', ')', '\\n', '-', 'dilation', '[', 'i', ']', '*', '(', 'weight_shape', '[', 'i', '+', '2', ']', '-', '1', ')', '\\n', 'for', 'i', 'in', 'range', '(', 'ndim', ')', '\\n', ']', '\\n', '\\n', '', 'class', 'Conv2d', '(', 'autograd', '.', 'Function', ')', ':', '\\n', '        ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', 'ctx', ',', 'input', ',', 'weight', ',', 'bias', ')', ':', '\\n', '            ', 'if', 'not', 'transpose', ':', '\\n', '                ', 'out', '=', 'F', '.', 'conv2d', '(', 'input', '=', 'input', ',', 'weight', '=', 'weight', ',', 'bias', '=', 'bias', ',', '**', 'common_kwargs', ')', '\\n', '\\n', '', 'else', ':', '\\n', '                ', 'out', '=', 'F', '.', 'conv_transpose2d', '(', '\\n', 'input', '=', 'input', ',', '\\n', 'weight', '=', 'weight', ',', '\\n', 'bias', '=', 'bias', ',', '\\n', 'output_padding', '=', 'output_padding', ',', '\\n', '**', 'common_kwargs', ',', '\\n', ')', '\\n', '\\n', '', 'ctx', '.', 'save_for_backward', '(', 'input', ',', 'weight', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n', '', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'grad_output', ')', ':', '\\n', '            ', 'input', ',', 'weight', '=', 'ctx', '.', 'saved_tensors', '\\n', 'grad_input', ',', 'grad_weight', ',', 'grad_bias', '=', 'None', ',', 'None', ',', 'None', '\\n', '\\n', 'if', 'ctx', '.', 'needs_input_grad', '[', '0', ']', ':', '\\n', '                ', 'p', '=', 'calc_output_padding', '(', '\\n', 'input_shape', '=', 'input', '.', 'shape', ',', 'output_shape', '=', 'grad_output', '.', 'shape', '\\n', ')', '\\n', 'grad_input', '=', 'conv2d_gradfix', '(', '\\n', 'transpose', '=', '(', 'not', 'transpose', ')', ',', '\\n', 'weight_shape', '=', 'weight_shape', ',', '\\n', 'output_padding', '=', 'p', ',', '\\n', '**', 'common_kwargs', ',', '\\n', ')', '.', 'apply', '(', 'grad_output', ',', 'weight', ',', 'None', ')', '\\n', '\\n', '', 'if', 'ctx', '.', 'needs_input_grad', '[', '1', ']', 'and', 'not', 'weight_gradients_disabled', ':', '\\n', '                ', 'grad_weight', '=', 'Conv2dGradWeight', '.', 'apply', '(', 'grad_output', ',', 'input', ')', '\\n', '\\n', '', 'if', 'ctx', '.', 'needs_input_grad', '[', '2', ']', ':', '\\n', '                ', 'grad_bias', '=', 'grad_output', '.', 'sum', '(', '(', '0', ',', '2', ',', '3', ')', ')', '\\n', '\\n', '', 'return', 'grad_input', ',', 'grad_weight', ',', 'grad_bias', '\\n', '\\n', '', '', 'class', 'Conv2dGradWeight', '(', 'autograd', '.', 'Function', ')', ':', '\\n', '        ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', 'ctx', ',', 'grad_output', ',', 'input', ')', ':', '\\n', '            ', 'op', '=', 'torch', '.', '_C', '.', '_jit_get_operation', '(', '\\n', '\"aten::cudnn_convolution_backward_weight\"', '\\n', 'if', 'not', 'transpose', '\\n', 'else', '\"aten::cudnn_convolution_transpose_backward_weight\"', '\\n', ')', '\\n', 'flags', '=', '[', '\\n', 'torch', '.', 'backends', '.', 'cudnn', '.', 'benchmark', ',', '\\n', 'torch', '.', 'backends', '.', 'cudnn', '.', 'deterministic', ',', '\\n', 'torch', '.', 'backends', '.', 'cudnn', '.', 'allow_tf32', ',', '\\n', ']', '\\n', 'grad_weight', '=', 'op', '(', '\\n', 'weight_shape', ',', '\\n', 'grad_output', ',', '\\n', 'input', ',', '\\n', 'padding', ',', '\\n', 'stride', ',', '\\n', 'dilation', ',', '\\n', 'groups', ',', '\\n', '*', 'flags', ',', '\\n', ')', '\\n', 'ctx', '.', 'save_for_backward', '(', 'grad_output', ',', 'input', ')', '\\n', '\\n', 'return', 'grad_weight', '\\n', '\\n', '', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'grad_grad_weight', ')', ':', '\\n', '            ', 'grad_output', ',', 'input', '=', 'ctx', '.', 'saved_tensors', '\\n', 'grad_grad_output', ',', 'grad_grad_input', '=', 'None', ',', 'None', '\\n', '\\n', 'if', 'ctx', '.', 'needs_input_grad', '[', '0', ']', ':', '\\n', '                ', 'grad_grad_output', '=', 'Conv2d', '.', 'apply', '(', 'input', ',', 'grad_grad_weight', ',', 'None', ')', '\\n', '\\n', '', 'if', 'ctx', '.', 'needs_input_grad', '[', '1', ']', ':', '\\n', '                ', 'p', '=', 'calc_output_padding', '(', '\\n', 'input_shape', '=', 'input', '.', 'shape', ',', 'output_shape', '=', 'grad_output', '.', 'shape', '\\n', ')', '\\n', 'grad_grad_input', '=', 'conv2d_gradfix', '(', '\\n', 'transpose', '=', '(', 'not', 'transpose', ')', ',', '\\n', 'weight_shape', '=', 'weight_shape', ',', '\\n', 'output_padding', '=', 'p', ',', '\\n', '**', 'common_kwargs', ',', '\\n', ')', '.', 'apply', '(', 'grad_output', ',', 'grad_grad_weight', ',', 'None', ')', '\\n', '\\n', '', 'return', 'grad_grad_output', ',', 'grad_grad_input', '\\n', '\\n', '', '', 'conv2d_gradfix_cache', '[', 'key', ']', '=', 'Conv2d', '\\n', '\\n', 'return', 'Conv2d', '\\n', '', '']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2dBackward.forward': [[21, 62], ['grad_output.reshape.reshape.reshape', 'upfirdn2d_op.upfirdn2d', 'grad_input.view.view.view', 'ctx.save_for_backward'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['    ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', '\\n', 'ctx', ',', 'grad_output', ',', 'kernel', ',', 'grad_kernel', ',', 'up', ',', 'down', ',', 'pad', ',', 'g_pad', ',', 'in_size', ',', 'out_size', '\\n', ')', ':', '\\n', '\\n', '        ', 'up_x', ',', 'up_y', '=', 'up', '\\n', 'down_x', ',', 'down_y', '=', 'down', '\\n', 'g_pad_x0', ',', 'g_pad_x1', ',', 'g_pad_y0', ',', 'g_pad_y1', '=', 'g_pad', '\\n', '\\n', 'grad_output', '=', 'grad_output', '.', 'reshape', '(', '-', '1', ',', 'out_size', '[', '0', ']', ',', 'out_size', '[', '1', ']', ',', '1', ')', '\\n', '\\n', 'grad_input', '=', 'upfirdn2d_op', '.', 'upfirdn2d', '(', '\\n', 'grad_output', ',', '\\n', 'grad_kernel', ',', '\\n', 'down_x', ',', '\\n', 'down_y', ',', '\\n', 'up_x', ',', '\\n', 'up_y', ',', '\\n', 'g_pad_x0', ',', '\\n', 'g_pad_x1', ',', '\\n', 'g_pad_y0', ',', '\\n', 'g_pad_y1', ',', '\\n', ')', '\\n', 'grad_input', '=', 'grad_input', '.', 'view', '(', 'in_size', '[', '0', ']', ',', 'in_size', '[', '1', ']', ',', 'in_size', '[', '2', ']', ',', 'in_size', '[', '3', ']', ')', '\\n', '\\n', 'ctx', '.', 'save_for_backward', '(', 'kernel', ')', '\\n', '\\n', 'pad_x0', ',', 'pad_x1', ',', 'pad_y0', ',', 'pad_y1', '=', 'pad', '\\n', '\\n', 'ctx', '.', 'up_x', '=', 'up_x', '\\n', 'ctx', '.', 'up_y', '=', 'up_y', '\\n', 'ctx', '.', 'down_x', '=', 'down_x', '\\n', 'ctx', '.', 'down_y', '=', 'down_y', '\\n', 'ctx', '.', 'pad_x0', '=', 'pad_x0', '\\n', 'ctx', '.', 'pad_x1', '=', 'pad_x1', '\\n', 'ctx', '.', 'pad_y0', '=', 'pad_y0', '\\n', 'ctx', '.', 'pad_y1', '=', 'pad_y1', '\\n', 'ctx', '.', 'in_size', '=', 'in_size', '\\n', 'ctx', '.', 'out_size', '=', 'out_size', '\\n', '\\n', 'return', 'grad_input', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2dBackward.backward': [[63, 87], ['gradgrad_input.reshape.reshape.reshape', 'upfirdn2d_op.upfirdn2d', 'gradgrad_out.view.view.view'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'gradgrad_input', ')', ':', '\\n', '        ', 'kernel', ',', '=', 'ctx', '.', 'saved_tensors', '\\n', '\\n', 'gradgrad_input', '=', 'gradgrad_input', '.', 'reshape', '(', '-', '1', ',', 'ctx', '.', 'in_size', '[', '2', ']', ',', 'ctx', '.', 'in_size', '[', '3', ']', ',', '1', ')', '\\n', '\\n', 'gradgrad_out', '=', 'upfirdn2d_op', '.', 'upfirdn2d', '(', '\\n', 'gradgrad_input', ',', '\\n', 'kernel', ',', '\\n', 'ctx', '.', 'up_x', ',', '\\n', 'ctx', '.', 'up_y', ',', '\\n', 'ctx', '.', 'down_x', ',', '\\n', 'ctx', '.', 'down_y', ',', '\\n', 'ctx', '.', 'pad_x0', ',', '\\n', 'ctx', '.', 'pad_x1', ',', '\\n', 'ctx', '.', 'pad_y0', ',', '\\n', 'ctx', '.', 'pad_y1', ',', '\\n', ')', '\\n', '# gradgrad_out = gradgrad_out.view(ctx.in_size[0], ctx.out_size[0], ctx.out_size[1], ctx.in_size[3])', '\\n', 'gradgrad_out', '=', 'gradgrad_out', '.', 'view', '(', '\\n', 'ctx', '.', 'in_size', '[', '0', ']', ',', 'ctx', '.', 'in_size', '[', '1', ']', ',', 'ctx', '.', 'out_size', '[', '0', ']', ',', 'ctx', '.', 'out_size', '[', '1', ']', '\\n', ')', '\\n', '\\n', 'return', 'gradgrad_out', ',', 'None', ',', 'None', ',', 'None', ',', 'None', ',', 'None', ',', 'None', ',', 'None', ',', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward': [[90, 126], ['input.reshape.reshape.reshape', 'ctx.save_for_backward', 'upfirdn2d_op.upfirdn2d', 'out.view.view.view', 'torch.flip'], 'methods', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d'], ['    ', '@', 'staticmethod', '\\n', 'def', 'forward', '(', 'ctx', ',', 'input', ',', 'kernel', ',', 'up', ',', 'down', ',', 'pad', ')', ':', '\\n', '        ', 'up_x', ',', 'up_y', '=', 'up', '\\n', 'down_x', ',', 'down_y', '=', 'down', '\\n', 'pad_x0', ',', 'pad_x1', ',', 'pad_y0', ',', 'pad_y1', '=', 'pad', '\\n', '\\n', 'kernel_h', ',', 'kernel_w', '=', 'kernel', '.', 'shape', '\\n', 'batch', ',', 'channel', ',', 'in_h', ',', 'in_w', '=', 'input', '.', 'shape', '\\n', 'ctx', '.', 'in_size', '=', 'input', '.', 'shape', '\\n', '\\n', 'input', '=', 'input', '.', 'reshape', '(', '-', '1', ',', 'in_h', ',', 'in_w', ',', '1', ')', '\\n', '\\n', 'ctx', '.', 'save_for_backward', '(', 'kernel', ',', 'torch', '.', 'flip', '(', 'kernel', ',', '[', '0', ',', '1', ']', ')', ')', '\\n', '\\n', 'out_h', '=', '(', 'in_h', '*', 'up_y', '+', 'pad_y0', '+', 'pad_y1', '-', 'kernel_h', '+', 'down_y', ')', '//', 'down_y', '\\n', 'out_w', '=', '(', 'in_w', '*', 'up_x', '+', 'pad_x0', '+', 'pad_x1', '-', 'kernel_w', '+', 'down_x', ')', '//', 'down_x', '\\n', 'ctx', '.', 'out_size', '=', '(', 'out_h', ',', 'out_w', ')', '\\n', '\\n', 'ctx', '.', 'up', '=', '(', 'up_x', ',', 'up_y', ')', '\\n', 'ctx', '.', 'down', '=', '(', 'down_x', ',', 'down_y', ')', '\\n', 'ctx', '.', 'pad', '=', '(', 'pad_x0', ',', 'pad_x1', ',', 'pad_y0', ',', 'pad_y1', ')', '\\n', '\\n', 'g_pad_x0', '=', 'kernel_w', '-', 'pad_x0', '-', '1', '\\n', 'g_pad_y0', '=', 'kernel_h', '-', 'pad_y0', '-', '1', '\\n', 'g_pad_x1', '=', 'in_w', '*', 'up_x', '-', 'out_w', '*', 'down_x', '+', 'pad_x0', '-', 'up_x', '+', '1', '\\n', 'g_pad_y1', '=', 'in_h', '*', 'up_y', '-', 'out_h', '*', 'down_y', '+', 'pad_y0', '-', 'up_y', '+', '1', '\\n', '\\n', 'ctx', '.', 'g_pad', '=', '(', 'g_pad_x0', ',', 'g_pad_x1', ',', 'g_pad_y0', ',', 'g_pad_y1', ')', '\\n', '\\n', 'out', '=', 'upfirdn2d_op', '.', 'upfirdn2d', '(', '\\n', 'input', ',', 'kernel', ',', 'up_x', ',', 'up_y', ',', 'down_x', ',', 'down_y', ',', 'pad_x0', ',', 'pad_x1', ',', 'pad_y0', ',', 'pad_y1', '\\n', ')', '\\n', '# out = out.view(major, out_h, out_w, minor)', '\\n', 'out', '=', 'out', '.', 'view', '(', '-', '1', ',', 'channel', ',', 'out_h', ',', 'out_w', ')', '\\n', '\\n', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.backward': [[127, 147], ['UpFirDn2dBackward.apply'], 'methods', ['None'], ['', '@', 'staticmethod', '\\n', 'def', 'backward', '(', 'ctx', ',', 'grad_output', ')', ':', '\\n', '        ', 'kernel', ',', 'grad_kernel', '=', 'ctx', '.', 'saved_tensors', '\\n', '\\n', 'grad_input', '=', 'None', '\\n', '\\n', 'if', 'ctx', '.', 'needs_input_grad', '[', '0', ']', ':', '\\n', '            ', 'grad_input', '=', 'UpFirDn2dBackward', '.', 'apply', '(', '\\n', 'grad_output', ',', '\\n', 'kernel', ',', '\\n', 'grad_kernel', ',', '\\n', 'ctx', '.', 'up', ',', '\\n', 'ctx', '.', 'down', ',', '\\n', 'ctx', '.', 'pad', ',', '\\n', 'ctx', '.', 'g_pad', ',', '\\n', 'ctx', '.', 'in_size', ',', '\\n', 'ctx', '.', 'out_size', ',', '\\n', ')', '\\n', '\\n', '', 'return', 'grad_input', ',', 'None', ',', 'None', ',', 'None', ',', 'None', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d': [[149, 166], ['isinstance', 'isinstance', 'len', 'upfirdn2d.upfirdn2d_native', 'UpFirDn2d.apply'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d_native'], ['', '', 'def', 'upfirdn2d', '(', 'input', ',', 'kernel', ',', 'up', '=', '1', ',', 'down', '=', '1', ',', 'pad', '=', '(', '0', ',', '0', ')', ')', ':', '\\n', '    ', 'if', 'not', 'isinstance', '(', 'up', ',', 'abc', '.', 'Iterable', ')', ':', '\\n', '        ', 'up', '=', '(', 'up', ',', 'up', ')', '\\n', '\\n', '', 'if', 'not', 'isinstance', '(', 'down', ',', 'abc', '.', 'Iterable', ')', ':', '\\n', '        ', 'down', '=', '(', 'down', ',', 'down', ')', '\\n', '\\n', '', 'if', 'len', '(', 'pad', ')', '==', '2', ':', '\\n', '        ', 'pad', '=', '(', 'pad', '[', '0', ']', ',', 'pad', '[', '1', ']', ',', 'pad', '[', '0', ']', ',', 'pad', '[', '1', ']', ')', '\\n', '\\n', '', 'if', 'input', '.', 'device', '.', 'type', '==', '\"cpu\"', ':', '\\n', '        ', 'out', '=', 'upfirdn2d_native', '(', 'input', ',', 'kernel', ',', '*', 'up', ',', '*', 'down', ',', '*', 'pad', ')', '\\n', '\\n', '', 'else', ':', '\\n', '        ', 'out', '=', 'UpFirDn2d', '.', 'apply', '(', 'input', ',', 'kernel', ',', 'up', ',', 'down', ',', 'pad', ')', '\\n', '\\n', '', 'return', 'out', '\\n', '\\n']], 'home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d_native': [[168, 210], ['input.reshape.reshape', 'input.reshape.view', 'torch.nn.functional.pad', 'out.permute.view', 'torch.nn.functional.pad', 'out.permute.permute', 'out.permute.reshape', 'torch.flip().view', 'torch.nn.functional.conv2d', 'out.permute.reshape', 'out.permute.permute', 'out.permute.view', 'max', 'max', 'max', 'max', 'torch.flip', 'max', 'max', 'max', 'max'], 'function', ['home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d'], ['', 'def', 'upfirdn2d_native', '(', '\\n', 'input', ',', 'kernel', ',', 'up_x', ',', 'up_y', ',', 'down_x', ',', 'down_y', ',', 'pad_x0', ',', 'pad_x1', ',', 'pad_y0', ',', 'pad_y1', '\\n', ')', ':', '\\n', '    ', '_', ',', 'channel', ',', 'in_h', ',', 'in_w', '=', 'input', '.', 'shape', '\\n', 'input', '=', 'input', '.', 'reshape', '(', '-', '1', ',', 'in_h', ',', 'in_w', ',', '1', ')', '\\n', '\\n', '_', ',', 'in_h', ',', 'in_w', ',', 'minor', '=', 'input', '.', 'shape', '\\n', 'kernel_h', ',', 'kernel_w', '=', 'kernel', '.', 'shape', '\\n', '\\n', 'out', '=', 'input', '.', 'view', '(', '-', '1', ',', 'in_h', ',', '1', ',', 'in_w', ',', '1', ',', 'minor', ')', '\\n', 'out', '=', 'F', '.', 'pad', '(', 'out', ',', '[', '0', ',', '0', ',', '0', ',', 'up_x', '-', '1', ',', '0', ',', '0', ',', '0', ',', 'up_y', '-', '1', ']', ')', '\\n', 'out', '=', 'out', '.', 'view', '(', '-', '1', ',', 'in_h', '*', 'up_y', ',', 'in_w', '*', 'up_x', ',', 'minor', ')', '\\n', '\\n', 'out', '=', 'F', '.', 'pad', '(', '\\n', 'out', ',', '[', '0', ',', '0', ',', 'max', '(', 'pad_x0', ',', '0', ')', ',', 'max', '(', 'pad_x1', ',', '0', ')', ',', 'max', '(', 'pad_y0', ',', '0', ')', ',', 'max', '(', 'pad_y1', ',', '0', ')', ']', '\\n', ')', '\\n', 'out', '=', 'out', '[', '\\n', ':', ',', '\\n', 'max', '(', '-', 'pad_y0', ',', '0', ')', ':', 'out', '.', 'shape', '[', '1', ']', '-', 'max', '(', '-', 'pad_y1', ',', '0', ')', ',', '\\n', 'max', '(', '-', 'pad_x0', ',', '0', ')', ':', 'out', '.', 'shape', '[', '2', ']', '-', 'max', '(', '-', 'pad_x1', ',', '0', ')', ',', '\\n', ':', ',', '\\n', ']', '\\n', '\\n', 'out', '=', 'out', '.', 'permute', '(', '0', ',', '3', ',', '1', ',', '2', ')', '\\n', 'out', '=', 'out', '.', 'reshape', '(', '\\n', '[', '-', '1', ',', '1', ',', 'in_h', '*', 'up_y', '+', 'pad_y0', '+', 'pad_y1', ',', 'in_w', '*', 'up_x', '+', 'pad_x0', '+', 'pad_x1', ']', '\\n', ')', '\\n', 'w', '=', 'torch', '.', 'flip', '(', 'kernel', ',', '[', '0', ',', '1', ']', ')', '.', 'view', '(', '1', ',', '1', ',', 'kernel_h', ',', 'kernel_w', ')', '\\n', 'out', '=', 'F', '.', 'conv2d', '(', 'out', ',', 'w', ')', '\\n', 'out', '=', 'out', '.', 'reshape', '(', '\\n', '-', '1', ',', '\\n', 'minor', ',', '\\n', 'in_h', '*', 'up_y', '+', 'pad_y0', '+', 'pad_y1', '-', 'kernel_h', '+', '1', ',', '\\n', 'in_w', '*', 'up_x', '+', 'pad_x0', '+', 'pad_x1', '-', 'kernel_w', '+', '1', ',', '\\n', ')', '\\n', 'out', '=', 'out', '.', 'permute', '(', '0', ',', '2', ',', '3', ',', '1', ')', '\\n', 'out', '=', 'out', '[', ':', ',', ':', ':', 'down_y', ',', ':', ':', 'down_x', ',', ':', ']', '\\n', '\\n', 'out_h', '=', '(', 'in_h', '*', 'up_y', '+', 'pad_y0', '+', 'pad_y1', '-', 'kernel_h', '+', 'down_y', ')', '//', 'down_y', '\\n', 'out_w', '=', '(', 'in_w', '*', 'up_x', '+', 'pad_x0', '+', 'pad_x1', '-', 'kernel_w', '+', 'down_x', ')', '//', 'down_x', '\\n', '\\n', 'return', 'out', '.', 'view', '(', '-', '1', ',', 'channel', ',', 'out_h', ',', 'out_w', ')', '\\n', '', '']]}\n"
     ]
    }
   ],
   "source": [
    "print(graph_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.AdaptiveAugment.tune', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_mat_apply', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.sample_affine', 9), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.sample_color', 11), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.try_sample_affine_and_pad', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_apply_affine', 6), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.random_apply_color', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.augment', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_rank', 4), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.synchronize', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.get_world_size', 7), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.gather_grad', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.all_gather', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.reduce_loss_dict', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.InceptionV3.__init__', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionA.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionC.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionE_1.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.FIDInceptionE_2.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.HaarTransform.__init__', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.HaarTransform.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.InverseHaarTransform.__init__', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.InverseHaarTransform.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.ToRGB.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.ToRGB.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Generator.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.ConvBlock.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.FromRGB.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.Discriminator.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.slerp', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.d_r1_loss', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.mixing_noise', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.train', 16), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PixelNorm.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Upsample.__init__', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Upsample.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Downsample.__init__', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Downsample.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Blur.__init__', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Blur.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualConv2d.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualConv2d.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualLinear.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.EqualLinear.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ModulatedConv2d.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ModulatedConv2d.forward', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.NoiseInjection.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ConstantInput.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.StyledConv.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ToRGB.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ToRGB.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ConvLayer.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.ResBlock.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Discriminator.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PE2d.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.PE2dStart.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_and_convert', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_multiple', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.prepare_data.resize_worker', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.PNetLin.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.PNetLin.forward', 4), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.ScalingLayer.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.NetLinLayer.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.Dist2LogitLayer.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.Dist2LogitLayer.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.BCERankingLoss.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.BCERankingLoss.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.FakeNet.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.L2.forward', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.DSSIM.forward', 4), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.initialize', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.optimize_parameters', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.forward_train', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.backward_train', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.get_current_visuals', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.save', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.score_jnd_dataset', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.squeezenet.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.alexnet.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.vgg16.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.pretrained_networks.resnet.__init__', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.PerceptualLoss.__init__', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.PerceptualLoss.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.rgb2lab', 4), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2tensorlab', 5), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensorlab2tensor', 4), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save_network', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save_done', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.__init__', 42), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.FusedLeakyReLU.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d', 7), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv_transpose2d', 5), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.conv2d_gradfix', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2dBackward.forward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2dBackward.backward', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.forward', 7), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d', 10), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.upfirdn2d_native', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.distributed.reduce_sum', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.bernoulli_sample', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.category_sample', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.uniform_sample', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.lognormal_sample', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.normal_sample', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate3d_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale3d_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.luma_flip_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.rotate3d_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.saturation_mat', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.get_padding', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.affine_grid', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.translate_mat_single', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.scale_mat_single', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.non_leaking.apply_color', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.inception.fid_inception_v3', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.swagan.get_haar_wavelet', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.upsample', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.ppl.normalize', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.no_weight_gradients', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.Generator.make_noise', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.sample_data', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.requires_grad', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.d_logistic_loss', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.upfirdn2d.UpFirDn2d.backward', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.g_nonsaturating_loss', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.accumulate', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.train.g_path_regularize', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.save', 4), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.None.model.make_kernel', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.fused_act.fused_leaky_relu', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.normalize_tensor', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.spatial_average', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.l2', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2np', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.dssim', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.tensor2im', 3), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.initialize', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.networks_basic.print_network', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.clamp_weights', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.dist_model.DistModel.compute_accuracy', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.voc_ap', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.base_model.BaseModel.name', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.np2tensor', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.lpips.__init__.im2tensor', 1), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.could_use_op', 2), ('home.repos.pwc.inspect_result.jychoi118_toward_spatial_unbiased.op.conv2d_gradfix.ensure_tuple', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "for gkey, gval in graph_data.items():\n",
    "    if gval[3][0] != 'None':\n",
    "        G.add_node(gkey)\n",
    "\n",
    "for gkey, gval in graph_data.items():\n",
    "    if gval[3][0] != 'None':\n",
    "        for node in gval[3]:\n",
    "            G.add_edge(gkey, node)\n",
    "# print(labeldict)\n",
    "d = nx.degree(G)\n",
    "print(d)\n",
    "nx.draw_networkx(G, with_labels=False, node_size = 20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Sim Score\n",
    "Dataset: score.csv\n",
    "Columns: Graph_1, Graph_2, miniLM(Score), sbert(Score), tsdae(Score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                graph_1                            graph_2  miniLM   sbert  \\\n",
      "0  sustcsonglin_TN-PCFG               aioz-ai_BMVC20_CBSwR  0.4038  0.6282   \n",
      "1  sustcsonglin_TN-PCFG                 vinvino02_GLPDepth  0.4147  0.6573   \n",
      "2  sustcsonglin_TN-PCFG      pixelite1201_agora_evaluation  0.2553  0.5664   \n",
      "3  sustcsonglin_TN-PCFG  minzwon_tag-based-music-retrieval  0.4121  0.5965   \n",
      "4  sustcsonglin_TN-PCFG               princeton-nlp_semsup  0.5024  0.6293   \n",
      "\n",
      "    tsdae  \n",
      "0  0.5294  \n",
      "1  0.5728  \n",
      "2  0.5218  \n",
      "3  0.5402  \n",
      "4  0.5432  \n",
      "2041210\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('D:\\\\Projects\\\\UPM\\\\RepoUnder\\\\data\\\\score.csv')\n",
    "print(data.head(5))\n",
    "print(len(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "plot_data = data.sample(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2ae7fea4b20>]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "x = np.linspace(0, 10, 1000)\n",
    "ax.plot(x, plot_data['miniLM'])\n",
    "ax.plot(x, plot_data['sbert'])\n",
    "ax.plot(x, plot_data['tsdae'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([  2.,   3.,   1.,   3.,   6.,  13.,  29.,  27.,  40.,  78., 108.,\n        123., 132., 121., 121.,  82.,  62.,  35.,  10.,   4.]),\n array([0.0611  , 0.094035, 0.12697 , 0.159905, 0.19284 , 0.225775,\n        0.25871 , 0.291645, 0.32458 , 0.357515, 0.39045 , 0.423385,\n        0.45632 , 0.489255, 0.52219 , 0.555125, 0.58806 , 0.620995,\n        0.65393 , 0.686865, 0.7198  ]),\n <BarContainer object of 20 artists>)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(plot_data['miniLM'],bins = 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([  1.,   4.,   1.,   5.,   7.,  16.,  20.,  46.,  59.,  74.,  88.,\n        116., 105., 117., 126.,  99.,  64.,  35.,  12.,   5.]),\n array([0.3513 , 0.37615, 0.401  , 0.42585, 0.4507 , 0.47555, 0.5004 ,\n        0.52525, 0.5501 , 0.57495, 0.5998 , 0.62465, 0.6495 , 0.67435,\n        0.6992 , 0.72405, 0.7489 , 0.77375, 0.7986 , 0.82345, 0.8483 ]),\n <BarContainer object of 20 artists>)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(plot_data['sbert'],bins = 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([  2.,   0.,   2.,   5.,  12.,  16.,  30.,  53.,  70.,  86., 136.,\n        143., 122., 111.,  85.,  56.,  31.,  21.,  11.,   8.]),\n array([0.3969 , 0.41173, 0.42656, 0.44139, 0.45622, 0.47105, 0.48588,\n        0.50071, 0.51554, 0.53037, 0.5452 , 0.56003, 0.57486, 0.58969,\n        0.60452, 0.61935, 0.63418, 0.64901, 0.66384, 0.67867, 0.6935 ]),\n <BarContainer object of 20 artists>)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(plot_data['tsdae'],bins = 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Distribution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import scipy.stats as sta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def kl(p, q):\n",
    "    return sta.entropy(p, q, base=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029637841324845034\n",
      "0.026874094554518103\n",
      "0.009127581010191338\n",
      "0.009339798143358934\n",
      "0.02687152704312897\n",
      "0.030053395269814015\n"
     ]
    }
   ],
   "source": [
    "print(kl(plot_data['sbert'],plot_data['miniLM']))\n",
    "print(kl(plot_data['miniLM'],plot_data['sbert']))\n",
    "print(kl(plot_data['sbert'],plot_data['tsdae']))\n",
    "print(kl(plot_data['tsdae'],plot_data['sbert']))\n",
    "print(kl(plot_data['miniLM'],plot_data['tsdae']))\n",
    "print(kl(plot_data['tsdae'],plot_data['miniLM']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def js(p,q):\n",
    "    M=(p+q)/2\n",
    "    return 0.5*sta.entropy(p, M)+0.5*sta.entropy(q, M)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004952768463449931\n",
      "0.004952768463449931\n",
      "0.0016051303224158657\n",
      "0.0016051303224158657\n",
      "0.004899526758288944\n",
      "0.004899526758288944\n"
     ]
    }
   ],
   "source": [
    "print(js(plot_data['sbert'],plot_data['miniLM']))\n",
    "print(js(plot_data['miniLM'],plot_data['sbert']))\n",
    "print(js(plot_data['sbert'],plot_data['tsdae']))\n",
    "print(js(plot_data['tsdae'],plot_data['sbert']))\n",
    "print(js(plot_data['miniLM'],plot_data['tsdae']))\n",
    "print(js(plot_data['tsdae'],plot_data['miniLM']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}